{"func_name": "get_all_contributors", "func_src_before": "    @staticmethod\n    def get_all_contributors(project_id: int):\n        \"\"\" Get all contributors to a project \"\"\"\n        query = '''SELECT mapped_by as contributors from tasks where project_id = {0} and  mapped_by is not null\n                   UNION\n                   SELECT validated_by from tasks where tasks.project_id = {0} and validated_by is not null'''.format(project_id)\n\n        contributors = db.engine.execute(query)\n        return contributors", "func_src_after": "    @staticmethod\n    def get_all_contributors(project_id: int):\n        \"\"\" Get all contributors to a project \"\"\"\n        query = '''SELECT mapped_by as contributors from tasks where project_id = :project_id and mapped_by is not null\n                   UNION\n                   SELECT validated_by from tasks where tasks.project_id = :project_id and validated_by is not null'''\n\n        contributors = db.engine.execute(text(query), project_id=project_id)\n        return contributors", "line_changes": {"deleted": [{"line_no": 4, "char_start": 115, "char_end": 228, "line": "        query = '''SELECT mapped_by as contributors from tasks where project_id = {0} and  mapped_by is not null\n"}, {"line_no": 6, "char_start": 253, "char_end": 383, "line": "                   SELECT validated_by from tasks where tasks.project_id = {0} and validated_by is not null'''.format(project_id)\n"}, {"line_no": 8, "char_start": 384, "char_end": 432, "line": "        contributors = db.engine.execute(query)\n"}], "added": [{"line_no": 4, "char_start": 115, "char_end": 235, "line": "        query = '''SELECT mapped_by as contributors from tasks where project_id = :project_id and mapped_by is not null\n"}, {"line_no": 6, "char_start": 260, "char_end": 379, "line": "                   SELECT validated_by from tasks where tasks.project_id = :project_id and validated_by is not null'''\n"}, {"line_no": 8, "char_start": 380, "char_end": 457, "line": "        contributors = db.engine.execute(text(query), project_id=project_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 197, "char_end": 200, "chars": "{0}"}, {"char_start": 205, "char_end": 206, "chars": " "}, {"char_start": 328, "char_end": 331, "chars": "{0}"}, {"char_start": 363, "char_end": 382, "chars": ".format(project_id)"}, {"char_start": 425, "char_end": 430, "chars": "query"}], "added": [{"char_start": 197, "char_end": 208, "chars": ":project_id"}, {"char_start": 335, "char_end": 346, "chars": ":project_id"}, {"char_start": 421, "char_end": 455, "chars": "text(query), project_id=project_id"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/message.py", "vul_type": "cwe-089"}
{"func_name": "get_project_user_stats", "func_src_before": "    def get_project_user_stats(self, user_id: int) -> ProjectUserStatsDTO:\n        \"\"\"Compute project specific stats for a given user\"\"\"\n        stats_dto = ProjectUserStatsDTO()\n        stats_dto.time_spent_mapping = 0\n        stats_dto.time_spent_validating = 0\n        stats_dto.total_time_spent = 0\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_MAPPING'\n                and user_id = {0} and project_id = {1};\"\"\".format(user_id, self.id)\n        total_mapping_time = db.engine.execute(query)\n        for time in total_mapping_time:\n            total_mapping_time = time[0]\n            if total_mapping_time:\n                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_mapping\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                        WHERE action='LOCKED_FOR_VALIDATION'\n                        and user_id = {0} and project_id = {1};\"\"\".format(user_id, self.id)\n        total_validation_time = db.engine.execute(query)\n        for time in total_validation_time:\n            total_validation_time = time[0]\n            if total_validation_time:\n                stats_dto.time_spent_validating = total_validation_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_validating\n\n        return stats_dto", "func_src_after": "    def get_project_user_stats(self, user_id: int) -> ProjectUserStatsDTO:\n        \"\"\"Compute project specific stats for a given user\"\"\"\n        stats_dto = ProjectUserStatsDTO()\n        stats_dto.time_spent_mapping = 0\n        stats_dto.time_spent_validating = 0\n        stats_dto.total_time_spent = 0\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                   WHERE action='LOCKED_FOR_MAPPING'\n                   and user_id = :user_id and project_id = :project_id;\"\"\"\n        total_mapping_time = db.engine.execute(text(query), user_id=user_id, project_id=self.id)\n        for time in total_mapping_time:\n            total_mapping_time = time[0]\n            if total_mapping_time:\n                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_mapping\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                   WHERE action='LOCKED_FOR_VALIDATION'\n                   and user_id = :user_id and project_id = :project_id;\"\"\"\n        total_validation_time = db.engine.execute(text(query), user_id=user_id, project_id=self.id)\n        for time in total_validation_time:\n            total_validation_time = time[0]\n            if total_validation_time:\n                stats_dto.time_spent_validating = total_validation_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_validating\n\n        return stats_dto", "line_changes": {"deleted": [{"line_no": 9, "char_start": 399, "char_end": 449, "line": "                WHERE action='LOCKED_FOR_MAPPING'\n"}, {"line_no": 10, "char_start": 449, "char_end": 533, "line": "                and user_id = {0} and project_id = {1};\"\"\".format(user_id, self.id)\n"}, {"line_no": 11, "char_start": 533, "char_end": 587, "line": "        total_mapping_time = db.engine.execute(query)\n"}, {"line_no": 19, "char_start": 956, "char_end": 1017, "line": "                        WHERE action='LOCKED_FOR_VALIDATION'\n"}, {"line_no": 20, "char_start": 1017, "char_end": 1109, "line": "                        and user_id = {0} and project_id = {1};\"\"\".format(user_id, self.id)\n"}, {"line_no": 21, "char_start": 1109, "char_end": 1166, "line": "        total_validation_time = db.engine.execute(query)\n"}], "added": [{"line_no": 9, "char_start": 399, "char_end": 452, "line": "                   WHERE action='LOCKED_FOR_MAPPING'\n"}, {"line_no": 10, "char_start": 452, "char_end": 527, "line": "                   and user_id = :user_id and project_id = :project_id;\"\"\"\n"}, {"line_no": 11, "char_start": 527, "char_end": 624, "line": "        total_mapping_time = db.engine.execute(text(query), user_id=user_id, project_id=self.id)\n"}, {"line_no": 19, "char_start": 993, "char_end": 1049, "line": "                   WHERE action='LOCKED_FOR_VALIDATION'\n"}, {"line_no": 20, "char_start": 1049, "char_end": 1124, "line": "                   and user_id = :user_id and project_id = :project_id;\"\"\"\n"}, {"line_no": 21, "char_start": 1124, "char_end": 1224, "line": "        total_validation_time = db.engine.execute(text(query), user_id=user_id, project_id=self.id)\n"}]}, "char_changes": {"deleted": [{"char_start": 479, "char_end": 482, "chars": "{0}"}, {"char_start": 500, "char_end": 532, "chars": "{1};\"\"\".format(user_id, self.id)"}, {"char_start": 580, "char_end": 585, "chars": "query"}, {"char_start": 975, "char_end": 980, "chars": "     "}, {"char_start": 1036, "char_end": 1041, "chars": "     "}, {"char_start": 1055, "char_end": 1058, "chars": "{0}"}, {"char_start": 1076, "char_end": 1108, "chars": "{1};\"\"\".format(user_id, self.id)"}, {"char_start": 1159, "char_end": 1164, "chars": "query"}], "added": [{"char_start": 415, "char_end": 418, "chars": "   "}, {"char_start": 468, "char_end": 471, "chars": "   "}, {"char_start": 485, "char_end": 493, "chars": ":user_id"}, {"char_start": 511, "char_end": 526, "chars": ":project_id;\"\"\""}, {"char_start": 574, "char_end": 622, "chars": "text(query), user_id=user_id, project_id=self.id"}, {"char_start": 1082, "char_end": 1090, "chars": ":user_id"}, {"char_start": 1108, "char_end": 1123, "chars": ":project_id;\"\"\""}, {"char_start": 1174, "char_end": 1222, "chars": "text(query), user_id=user_id, project_id=self.id"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/project.py", "vul_type": "cwe-089"}
{"func_name": "get_project_stats", "func_src_before": "    def get_project_stats(self) -> ProjectStatsDTO:\n        \"\"\" Create Project Summary model for postgis project object\"\"\"\n        project_stats = ProjectStatsDTO()\n        project_stats.project_id = self.id\n        polygon = to_shape(self.geometry)\n        polygon_aea = transform(\n                            partial(\n                            pyproj.transform,\n                            pyproj.Proj(init='EPSG:4326'),\n                            pyproj.Proj(\n                                proj='aea',\n                                lat1=polygon.bounds[1],\n                                lat2=polygon.bounds[3])),\n                            polygon)\n        area = polygon_aea.area/1000000\n        project_stats.area = area\n        project_stats.total_mappers = db.session.query(User).filter(User.projects_mapped.any(self.id)).count()\n        project_stats.total_tasks = self.total_tasks\n        project_stats.total_comments = db.session.query(ProjectChat).filter(ProjectChat.project_id == self.id).count()\n        project_stats.percent_mapped = Project.calculate_tasks_percent('mapped', self.total_tasks,\n                                                                       self.tasks_mapped, self.tasks_validated,\n                                                                       self.tasks_bad_imagery)\n        project_stats.percent_validated = Project.calculate_tasks_percent('validated', self.total_tasks,\n                                                                          self.tasks_mapped, self.tasks_validated,\n                                                                          self.tasks_bad_imagery)\n        project_stats.percent_bad_imagery = Project.calculate_tasks_percent('bad_imagery', self.total_tasks,\n                                                                            self.tasks_mapped, self.tasks_validated,\n                                                                            self.tasks_bad_imagery)\n        centroid_geojson = db.session.scalar(self.centroid.ST_AsGeoJSON())\n        project_stats.aoi_centroid = geojson.loads(centroid_geojson)\n        unique_mappers = TaskHistory.query.filter(\n                TaskHistory.action == 'LOCKED_FOR_MAPPING',\n                TaskHistory.project_id == self.id\n            ).distinct(TaskHistory.user_id).count()\n        unique_validators = TaskHistory.query.filter(\n                TaskHistory.action == 'LOCKED_FOR_VALIDATION',\n                TaskHistory.project_id == self.id\n            ).distinct(TaskHistory.user_id).count()\n        project_stats.total_time_spent = 0\n        project_stats.total_mapping_time = 0\n        project_stats.total_validation_time = 0\n        project_stats.average_mapping_time = 0\n        project_stats.average_validation_time = 0\n\n        sql = '''SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                 WHERE action='LOCKED_FOR_MAPPING'and project_id = {0};'''.format(self.id)\n        total_mapping_time = db.engine.execute(sql)\n        for row in total_mapping_time:\n            total_mapping_time = row[0]\n            if total_mapping_time:\n                total_mapping_seconds = total_mapping_time.total_seconds()\n                project_stats.total_mapping_time = total_mapping_seconds\n                project_stats.total_time_spent += project_stats.total_mapping_time\n                if unique_mappers:\n                    average_mapping_time = total_mapping_seconds/unique_mappers\n                    project_stats.average_mapping_time = average_mapping_time\n\n        sql = '''SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_VALIDATION' and project_id = {0};'''.format(self.id)\n        total_validation_time = db.engine.execute(sql)\n        for row in total_validation_time:\n            total_validation_time = row[0]\n            if total_validation_time:\n                total_validation_seconds = total_validation_time.total_seconds()\n                project_stats.total_validation_time = total_validation_seconds\n                project_stats.total_time_spent += project_stats.total_validation_time\n                if unique_validators:\n                    average_validation_time = total_validation_seconds/unique_validators\n                    project_stats.average_validation_time = average_validation_time\n\n        return project_stats", "func_src_after": "    def get_project_stats(self) -> ProjectStatsDTO:\n        \"\"\" Create Project Summary model for postgis project object\"\"\"\n        project_stats = ProjectStatsDTO()\n        project_stats.project_id = self.id\n        polygon = to_shape(self.geometry)\n        polygon_aea = transform(\n                            partial(\n                            pyproj.transform,\n                            pyproj.Proj(init='EPSG:4326'),\n                            pyproj.Proj(\n                                proj='aea',\n                                lat1=polygon.bounds[1],\n                                lat2=polygon.bounds[3])),\n                            polygon)\n        area = polygon_aea.area/1000000\n        project_stats.area = area\n        project_stats.total_mappers = db.session.query(User).filter(User.projects_mapped.any(self.id)).count()\n        project_stats.total_tasks = self.total_tasks\n        project_stats.total_comments = db.session.query(ProjectChat).filter(ProjectChat.project_id == self.id).count()\n        project_stats.percent_mapped = Project.calculate_tasks_percent('mapped', self.total_tasks,\n                                                                       self.tasks_mapped, self.tasks_validated,\n                                                                       self.tasks_bad_imagery)\n        project_stats.percent_validated = Project.calculate_tasks_percent('validated', self.total_tasks,\n                                                                          self.tasks_mapped, self.tasks_validated,\n                                                                          self.tasks_bad_imagery)\n        project_stats.percent_bad_imagery = Project.calculate_tasks_percent('bad_imagery', self.total_tasks,\n                                                                            self.tasks_mapped, self.tasks_validated,\n                                                                            self.tasks_bad_imagery)\n        centroid_geojson = db.session.scalar(self.centroid.ST_AsGeoJSON())\n        project_stats.aoi_centroid = geojson.loads(centroid_geojson)\n        unique_mappers = TaskHistory.query.filter(\n                TaskHistory.action == 'LOCKED_FOR_MAPPING',\n                TaskHistory.project_id == self.id\n            ).distinct(TaskHistory.user_id).count()\n        unique_validators = TaskHistory.query.filter(\n                TaskHistory.action == 'LOCKED_FOR_VALIDATION',\n                TaskHistory.project_id == self.id\n            ).distinct(TaskHistory.user_id).count()\n        project_stats.total_time_spent = 0\n        project_stats.total_mapping_time = 0\n        project_stats.total_validation_time = 0\n        project_stats.average_mapping_time = 0\n        project_stats.average_validation_time = 0\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                   WHERE action='LOCKED_FOR_MAPPING' and project_id = :project_id;\"\"\"\n        total_mapping_time = db.engine.execute(text(query), project_id=self.id)\n        for row in total_mapping_time:\n            total_mapping_time = row[0]\n            if total_mapping_time:\n                total_mapping_seconds = total_mapping_time.total_seconds()\n                project_stats.total_mapping_time = total_mapping_seconds\n                project_stats.total_time_spent += project_stats.total_mapping_time\n                if unique_mappers:\n                    average_mapping_time = total_mapping_seconds/unique_mappers\n                    project_stats.average_mapping_time = average_mapping_time\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                   WHERE action='LOCKED_FOR_VALIDATION' and project_id = :project_id;\"\"\"\n        total_validation_time = db.engine.execute(text(query), project_id=self.id)\n        for row in total_validation_time:\n            total_validation_time = row[0]\n            if total_validation_time:\n                total_validation_seconds = total_validation_time.total_seconds()\n                project_stats.total_validation_time = total_validation_seconds\n                project_stats.total_time_spent += project_stats.total_validation_time\n                if unique_validators:\n                    average_validation_time = total_validation_seconds/unique_validators\n                    project_stats.average_validation_time = average_validation_time\n\n        return project_stats", "line_changes": {"deleted": [{"line_no": 45, "char_start": 2778, "char_end": 2871, "line": "        sql = '''SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n"}, {"line_no": 46, "char_start": 2871, "char_end": 2962, "line": "                 WHERE action='LOCKED_FOR_MAPPING'and project_id = {0};'''.format(self.id)\n"}, {"line_no": 47, "char_start": 2962, "char_end": 3014, "line": "        total_mapping_time = db.engine.execute(sql)\n"}, {"line_no": 58, "char_start": 3553, "char_end": 3646, "line": "        sql = '''SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n"}, {"line_no": 59, "char_start": 3646, "char_end": 3740, "line": "                WHERE action='LOCKED_FOR_VALIDATION' and project_id = {0};'''.format(self.id)\n"}, {"line_no": 60, "char_start": 3740, "char_end": 3795, "line": "        total_validation_time = db.engine.execute(sql)\n"}], "added": [{"line_no": 45, "char_start": 2778, "char_end": 2873, "line": "        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n"}, {"line_no": 46, "char_start": 2873, "char_end": 2959, "line": "                   WHERE action='LOCKED_FOR_MAPPING' and project_id = :project_id;\"\"\"\n"}, {"line_no": 47, "char_start": 2959, "char_end": 3039, "line": "        total_mapping_time = db.engine.execute(text(query), project_id=self.id)\n"}, {"line_no": 58, "char_start": 3578, "char_end": 3673, "line": "        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n"}, {"line_no": 59, "char_start": 3673, "char_end": 3762, "line": "                   WHERE action='LOCKED_FOR_VALIDATION' and project_id = :project_id;\"\"\"\n"}, {"line_no": 60, "char_start": 3762, "char_end": 3845, "line": "        total_validation_time = db.engine.execute(text(query), project_id=self.id)\n"}]}, "char_changes": {"deleted": [{"char_start": 2786, "char_end": 2795, "chars": "sql = '''"}, {"char_start": 2938, "char_end": 2961, "chars": "{0};'''.format(self.id)"}, {"char_start": 3009, "char_end": 3012, "chars": "sql"}, {"char_start": 3561, "char_end": 3570, "chars": "sql = '''"}, {"char_start": 3716, "char_end": 3739, "chars": "{0};'''.format(self.id)"}, {"char_start": 3790, "char_end": 3793, "chars": "sql"}], "added": [{"char_start": 2786, "char_end": 2797, "chars": "query = \"\"\""}, {"char_start": 2890, "char_end": 2892, "chars": "  "}, {"char_start": 2925, "char_end": 2926, "chars": " "}, {"char_start": 2943, "char_end": 2958, "chars": ":project_id;\"\"\""}, {"char_start": 3006, "char_end": 3037, "chars": "text(query), project_id=self.id"}, {"char_start": 3586, "char_end": 3597, "chars": "query = \"\"\""}, {"char_start": 3689, "char_end": 3692, "chars": "   "}, {"char_start": 3746, "char_end": 3761, "chars": ":project_id;\"\"\""}, {"char_start": 3812, "char_end": 3843, "chars": "text(query), project_id=self.id"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/project.py", "vul_type": "cwe-089"}
{"func_name": "auto_unlock_tasks", "func_src_before": "    @staticmethod\n    def auto_unlock_tasks(project_id: int):\n        \"\"\"Unlock all tasks locked for longer than the auto-unlock delta\"\"\"\n        expiry_delta = Task.auto_unlock_delta()\n        lock_duration = (datetime.datetime.min + expiry_delta).time().isoformat()\n        expiry_date = datetime.datetime.utcnow() - expiry_delta\n        old_locks_query = '''SELECT t.id\n            FROM tasks t, task_history th\n            WHERE t.id = th.task_id\n            AND t.project_id = th.project_id\n            AND t.task_status IN (1,3)\n            AND th.action IN ( 'LOCKED_FOR_VALIDATION','LOCKED_FOR_MAPPING' )\n            AND th.action_text IS NULL\n            AND t.project_id = {0}\n            AND th.action_date <= '{1}'\n            '''.format(project_id, str(expiry_date))\n\n        old_tasks = db.engine.execute(old_locks_query)\n\n        if old_tasks.rowcount == 0:\n            # no tasks older than the delta found, return without further processing\n            return\n\n        for old_task in old_tasks:\n            task = Task.get(old_task[0], project_id)\n            task.auto_unlock_expired_tasks(expiry_date, lock_duration)", "func_src_after": "    @staticmethod\n    def auto_unlock_tasks(project_id: int):\n        \"\"\"Unlock all tasks locked for longer than the auto-unlock delta\"\"\"\n        expiry_delta = Task.auto_unlock_delta()\n        lock_duration = (datetime.datetime.min + expiry_delta).time().isoformat()\n        expiry_date = datetime.datetime.utcnow() - expiry_delta\n        old_locks_query = '''SELECT t.id\n            FROM tasks t, task_history th\n            WHERE t.id = th.task_id\n            AND t.project_id = th.project_id\n            AND t.task_status IN (1,3)\n            AND th.action IN ( 'LOCKED_FOR_VALIDATION','LOCKED_FOR_MAPPING' )\n            AND th.action_text IS NULL\n            AND t.project_id = :project_id\n            AND th.action_date <= :expiry_date\n            '''\n\n        old_tasks = db.engine.execute(text(old_locks_query), project_id=project_id, expiry_date=str(expiry_date))\n\n        if old_tasks.rowcount == 0:\n            # no tasks older than the delta found, return without further processing\n            return\n\n        for old_task in old_tasks:\n            task = Task.get(old_task[0], project_id)\n            task.auto_unlock_expired_tasks(expiry_date, lock_duration)", "line_changes": {"deleted": [{"line_no": 14, "char_start": 652, "char_end": 687, "line": "            AND t.project_id = {0}\n"}, {"line_no": 15, "char_start": 687, "char_end": 727, "line": "            AND th.action_date <= '{1}'\n"}, {"line_no": 16, "char_start": 727, "char_end": 780, "line": "            '''.format(project_id, str(expiry_date))\n"}, {"line_no": 18, "char_start": 781, "char_end": 836, "line": "        old_tasks = db.engine.execute(old_locks_query)\n"}], "added": [{"line_no": 14, "char_start": 652, "char_end": 695, "line": "            AND t.project_id = :project_id\n"}, {"line_no": 15, "char_start": 695, "char_end": 742, "line": "            AND th.action_date <= :expiry_date\n"}, {"line_no": 16, "char_start": 742, "char_end": 758, "line": "            '''\n"}, {"line_no": 18, "char_start": 759, "char_end": 873, "line": "        old_tasks = db.engine.execute(text(old_locks_query), project_id=project_id, expiry_date=str(expiry_date))\n"}]}, "char_changes": {"deleted": [{"char_start": 683, "char_end": 686, "chars": "{0}"}, {"char_start": 721, "char_end": 726, "chars": "'{1}'"}, {"char_start": 742, "char_end": 779, "chars": ".format(project_id, str(expiry_date))"}], "added": [{"char_start": 683, "char_end": 694, "chars": ":project_id"}, {"char_start": 729, "char_end": 741, "chars": ":expiry_date"}, {"char_start": 797, "char_end": 802, "chars": "text("}, {"char_start": 818, "char_end": 872, "chars": ", project_id=project_id, expiry_date=str(expiry_date))"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/task.py", "vul_type": "cwe-089"}
{"func_name": "get_mapped_tasks_by_user", "func_src_before": "    @staticmethod\n    def get_mapped_tasks_by_user(project_id: int):\n        \"\"\" Gets all mapped tasks for supplied project grouped by user\"\"\"\n\n        # Raw SQL is easier to understand that SQL alchemy here :)\n        sql = \"\"\"select u.username, u.mapping_level, count(distinct(t.id)), json_agg(distinct(t.id)),\n                            max(th.action_date) last_seen, u.date_registered, u.last_validation_date\n                      from tasks t,\n                           task_history th,\n                           users u\n                     where t.project_id = th.project_id\n                       and t.id = th.task_id\n                       and t.mapped_by = u.id\n                       and t.project_id = {0}\n                       and t.task_status = 2\n                       and th.action_text = 'MAPPED'\n                     group by u.username, u.mapping_level, u.date_registered, u.last_validation_date\"\"\".format(project_id)\n\n        results = db.engine.execute(sql)\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_tasks_dto = MappedTasks()\n        for row in results:\n            user_mapped = MappedTasksByUser()\n            user_mapped.username = row[0]\n            user_mapped.mapping_level = MappingLevel(row[1]).name\n            user_mapped.mapped_task_count = row[2]\n            user_mapped.tasks_mapped = row[3]\n            user_mapped.last_seen = row[4]\n            user_mapped.date_registered = row[5]\n            user_mapped.last_validation_date = row[6]\n\n            mapped_tasks_dto.mapped_tasks.append(user_mapped)\n\n        return mapped_tasks_dto", "func_src_after": "    @staticmethod\n    def get_mapped_tasks_by_user(project_id: int):\n        \"\"\" Gets all mapped tasks for supplied project grouped by user\"\"\"\n\n        # Raw SQL is easier to understand that SQL alchemy here :)\n        sql = \"\"\"select u.username, u.mapping_level, count(distinct(t.id)), json_agg(distinct(t.id)),\n                            max(th.action_date) last_seen, u.date_registered, u.last_validation_date\n                      from tasks t,\n                           task_history th,\n                           users u\n                     where t.project_id = th.project_id\n                       and t.id = th.task_id\n                       and t.mapped_by = u.id\n                       and t.project_id = :project_id\n                       and t.task_status = 2\n                       and th.action_text = 'MAPPED'\n                     group by u.username, u.mapping_level, u.date_registered, u.last_validation_date\"\"\"\n\n        results = db.engine.execute(text(sql), project_id=project_id)\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_tasks_dto = MappedTasks()\n        for row in results:\n            user_mapped = MappedTasksByUser()\n            user_mapped.username = row[0]\n            user_mapped.mapping_level = MappingLevel(row[1]).name\n            user_mapped.mapped_task_count = row[2]\n            user_mapped.tasks_mapped = row[3]\n            user_mapped.last_seen = row[4]\n            user_mapped.date_registered = row[5]\n            user_mapped.last_validation_date = row[6]\n\n            mapped_tasks_dto.mapped_tasks.append(user_mapped)\n\n        return mapped_tasks_dto", "line_changes": {"deleted": [{"line_no": 14, "char_start": 676, "char_end": 722, "line": "                       and t.project_id = {0}\n"}, {"line_no": 17, "char_start": 820, "char_end": 943, "line": "                     group by u.username, u.mapping_level, u.date_registered, u.last_validation_date\"\"\".format(project_id)\n"}, {"line_no": 19, "char_start": 944, "char_end": 985, "line": "        results = db.engine.execute(sql)\n"}], "added": [{"line_no": 14, "char_start": 676, "char_end": 730, "line": "                       and t.project_id = :project_id\n"}, {"line_no": 17, "char_start": 828, "char_end": 932, "line": "                     group by u.username, u.mapping_level, u.date_registered, u.last_validation_date\"\"\"\n"}, {"line_no": 19, "char_start": 933, "char_end": 1003, "line": "        results = db.engine.execute(text(sql), project_id=project_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 718, "char_end": 721, "chars": "{0}"}, {"char_start": 923, "char_end": 942, "chars": ".format(project_id)"}, {"char_start": 980, "char_end": 983, "chars": "sql"}], "added": [{"char_start": 718, "char_end": 729, "chars": ":project_id"}, {"char_start": 969, "char_end": 1001, "chars": "text(sql), project_id=project_id"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/task.py", "vul_type": "cwe-089"}
{"func_name": "get_max_task_id_for_project", "func_src_before": "    @staticmethod\n    def get_max_task_id_for_project(project_id: int):\n        \"\"\"Gets the nights task id currently in use on a project\"\"\"\n        sql = \"\"\"select max(id) from tasks where project_id = {0} GROUP BY project_id\"\"\".format(project_id)\n        result = db.engine.execute(sql)\n        if result.rowcount == 0:\n            raise NotFound()\n        for row in result:\n            return row[0]", "func_src_after": "    @staticmethod\n    def get_max_task_id_for_project(project_id: int):\n        \"\"\"Gets the nights task id currently in use on a project\"\"\"\n        sql = \"\"\"select max(id) from tasks where project_id = :project_id GROUP BY project_id\"\"\"\n        result = db.engine.execute(text(sql), project_id=project_id)\n        if result.rowcount == 0:\n            raise NotFound()\n        for row in result:\n            return row[0]", "line_changes": {"deleted": [{"line_no": 4, "char_start": 140, "char_end": 248, "line": "        sql = \"\"\"select max(id) from tasks where project_id = {0} GROUP BY project_id\"\"\".format(project_id)\n"}, {"line_no": 5, "char_start": 248, "char_end": 288, "line": "        result = db.engine.execute(sql)\n"}], "added": [{"line_no": 4, "char_start": 140, "char_end": 237, "line": "        sql = \"\"\"select max(id) from tasks where project_id = :project_id GROUP BY project_id\"\"\"\n"}, {"line_no": 5, "char_start": 237, "char_end": 306, "line": "        result = db.engine.execute(text(sql), project_id=project_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 202, "char_end": 205, "chars": "{0}"}, {"char_start": 228, "char_end": 247, "chars": ".format(project_id)"}, {"char_start": 283, "char_end": 286, "chars": "sql"}], "added": [{"char_start": 202, "char_end": 213, "chars": ":project_id"}, {"char_start": 272, "char_end": 304, "chars": "text(sql), project_id=project_id"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/task.py", "vul_type": "cwe-089"}
{"func_name": "upsert_mapped_projects", "func_src_before": "    @staticmethod\n    def upsert_mapped_projects(user_id: int, project_id: int):\n        \"\"\" Adds projects to mapped_projects if it doesn't exist \"\"\"\n        sql = \"select * from users where id = {0} and projects_mapped @> '{{{1}}}'\".format(user_id, project_id)\n        result = db.engine.execute(sql)\n\n        if result.rowcount > 0:\n            return  # User has previously mapped this project so return\n\n        sql = '''update users\n                    set projects_mapped = array_append(projects_mapped, {0})\n                  where id = {1}'''.format(project_id, user_id)\n\n        db.engine.execute(sql)", "func_src_after": "    @staticmethod\n    def upsert_mapped_projects(user_id: int, project_id: int):\n        \"\"\" Adds projects to mapped_projects if it doesn't exist \"\"\"\n        sql = \"select * from users where id = :user_id and projects_mapped @> '{{:project_id}}'\"\n        result = db.engine.execute(text(sql), user_id=user_id, project_id=project_id)\n\n        if result.rowcount > 0:\n            return  # User has previously mapped this project so return\n\n        sql = '''update users\n                    set projects_mapped = array_append(projects_mapped, :project_id)\n                  where id = :user_id'''\n\n        db.engine.execute(text(sql), project_id=project_id, user_id=user_id)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 150, "char_end": 262, "line": "        sql = \"select * from users where id = {0} and projects_mapped @> '{{{1}}}'\".format(user_id, project_id)\n"}, {"line_no": 5, "char_start": 262, "char_end": 302, "line": "        result = db.engine.execute(sql)\n"}, {"line_no": 11, "char_start": 438, "char_end": 515, "line": "                    set projects_mapped = array_append(projects_mapped, {0})\n"}, {"line_no": 12, "char_start": 515, "char_end": 579, "line": "                  where id = {1}'''.format(project_id, user_id)\n"}, {"line_no": 14, "char_start": 580, "char_end": 610, "line": "        db.engine.execute(sql)\n"}], "added": [{"line_no": 4, "char_start": 150, "char_end": 247, "line": "        sql = \"select * from users where id = :user_id and projects_mapped @> '{{:project_id}}'\"\n"}, {"line_no": 5, "char_start": 247, "char_end": 333, "line": "        result = db.engine.execute(text(sql), user_id=user_id, project_id=project_id)\n"}, {"line_no": 11, "char_start": 469, "char_end": 554, "line": "                    set projects_mapped = array_append(projects_mapped, :project_id)\n"}, {"line_no": 12, "char_start": 554, "char_end": 595, "line": "                  where id = :user_id'''\n"}, {"line_no": 14, "char_start": 596, "char_end": 672, "line": "        db.engine.execute(text(sql), project_id=project_id, user_id=user_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 196, "char_end": 199, "chars": "{0}"}, {"char_start": 226, "char_end": 250, "chars": "{1}}}'\".format(user_id, "}, {"char_start": 260, "char_end": 261, "chars": ")"}, {"char_start": 297, "char_end": 300, "chars": "sql"}, {"char_start": 510, "char_end": 513, "chars": "{0}"}, {"char_start": 544, "char_end": 570, "chars": "{1}'''.format(project_id, "}, {"char_start": 577, "char_end": 578, "chars": ")"}, {"char_start": 606, "char_end": 609, "chars": "sql"}], "added": [{"char_start": 196, "char_end": 204, "chars": ":user_id"}, {"char_start": 231, "char_end": 232, "chars": ":"}, {"char_start": 242, "char_end": 246, "chars": "}}'\""}, {"char_start": 282, "char_end": 331, "chars": "text(sql), user_id=user_id, project_id=project_id"}, {"char_start": 541, "char_end": 552, "chars": ":project_id"}, {"char_start": 583, "char_end": 584, "chars": ":"}, {"char_start": 591, "char_end": 594, "chars": "'''"}, {"char_start": 622, "char_end": 671, "chars": "text(sql), project_id=project_id, user_id=user_id"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/user.py", "vul_type": "cwe-089"}
{"func_name": "get_mapped_projects", "func_src_before": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                                   AND t.validated_by = {0}\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                            AND t.mapped_by = {0}\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''.format(user_id)\n\n        results = db.engine.execute(sql)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "func_src_after": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                                   AND t.validated_by = :user_id\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                            AND t.mapped_by = :user_id\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''\n\n        results = db.engine.execute(text(sql), user_id=user_id)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "line_changes": {"deleted": [{"line_no": 21, "char_start": 1137, "char_end": 1251, "line": "                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n"}, {"line_no": 22, "char_start": 1251, "char_end": 1311, "line": "                                   AND t.validated_by = {0}\n"}, {"line_no": 28, "char_start": 1570, "char_end": 1677, "line": "                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n"}, {"line_no": 29, "char_start": 1677, "char_end": 1727, "line": "                            AND t.mapped_by = {0}\n"}, {"line_no": 32, "char_start": 1850, "char_end": 1933, "line": "                   WHERE p.id = c.project_id ORDER BY p.id DESC'''.format(user_id)\n"}, {"line_no": 34, "char_start": 1934, "char_end": 1975, "line": "        results = db.engine.execute(sql)\n"}], "added": [{"line_no": 21, "char_start": 1137, "char_end": 1256, "line": "                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n"}, {"line_no": 22, "char_start": 1256, "char_end": 1321, "line": "                                   AND t.validated_by = :user_id\n"}, {"line_no": 28, "char_start": 1580, "char_end": 1692, "line": "                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n"}, {"line_no": 29, "char_start": 1692, "char_end": 1747, "line": "                            AND t.mapped_by = :user_id\n"}, {"line_no": 32, "char_start": 1870, "char_end": 1937, "line": "                   WHERE p.id = c.project_id ORDER BY p.id DESC'''\n"}, {"line_no": 34, "char_start": 1938, "char_end": 2002, "line": "        results = db.engine.execute(text(sql), user_id=user_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 1246, "char_end": 1249, "chars": "{0}"}, {"char_start": 1307, "char_end": 1310, "chars": "{0}"}, {"char_start": 1672, "char_end": 1675, "chars": "{0}"}, {"char_start": 1723, "char_end": 1726, "chars": "{0}"}, {"char_start": 1916, "char_end": 1932, "chars": ".format(user_id)"}, {"char_start": 1970, "char_end": 1973, "chars": "sql"}], "added": [{"char_start": 1246, "char_end": 1254, "chars": ":user_id"}, {"char_start": 1312, "char_end": 1320, "chars": ":user_id"}, {"char_start": 1682, "char_end": 1690, "chars": ":user_id"}, {"char_start": 1738, "char_end": 1746, "chars": ":user_id"}, {"char_start": 1974, "char_end": 2000, "chars": "text(sql), user_id=user_id"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/user.py", "vul_type": "cwe-089"}
{"func_name": "as_dto", "func_src_before": "    def as_dto(self, logged_in_username: str) -> UserDTO:\n        \"\"\" Create DTO object from user in scope \"\"\"\n        user_dto = UserDTO()\n        user_dto.id = self.id\n        user_dto.username = self.username\n        user_dto.role = UserRole(self.role).name\n        user_dto.mapping_level = MappingLevel(self.mapping_level).name\n        user_dto.is_expert = self.is_expert or False\n        user_dto.date_registered = str(self.date_registered)\n        try:\n            user_dto.projects_mapped = len(self.projects_mapped)\n        # Handle users that haven't touched a project yet.\n        except:\n            user_dto.projects_mapped = 0\n        user_dto.tasks_mapped = self.tasks_mapped\n        user_dto.tasks_validated = self.tasks_validated\n        user_dto.tasks_invalidated = self.tasks_invalidated\n        user_dto.twitter_id = self.twitter_id\n        user_dto.linkedin_id = self.linkedin_id\n        user_dto.facebook_id = self.facebook_id\n        user_dto.validation_message = self.validation_message\n        user_dto.total_time_spent = 0\n        user_dto.time_spent_mapping = 0\n        user_dto.time_spent_validating = 0\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_VALIDATION'\n                and user_id = {0};\"\"\".format(self.id)\n        total_validation_time = db.engine.execute(sql)\n        for row in total_validation_time:\n            total_validation_time = row[0]\n            if total_validation_time:\n                total_validation_seconds = total_validation_time.total_seconds()\n                user_dto.time_spent_validating = total_validation_seconds\n                user_dto.total_time_spent += user_dto.time_spent_validating\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_MAPPING'\n                and user_id = {0};\"\"\".format(self.id)\n        total_mapping_time = db.engine.execute(sql)\n        for row in total_mapping_time:\n            total_mapping_time = row[0]\n            if total_mapping_time:\n                total_mapping_seconds = total_mapping_time.total_seconds()\n                user_dto.time_spent_mapping = total_mapping_seconds\n                user_dto.total_time_spent += user_dto.time_spent_mapping\n\n        if self.username == logged_in_username:\n            # Only return email address when logged in user is looking at their own profile\n            user_dto.email_address = self.email_address\n            user_dto.is_email_verified = self.is_email_verified\n        return user_dto", "func_src_after": "    def as_dto(self, logged_in_username: str) -> UserDTO:\n        \"\"\" Create DTO object from user in scope \"\"\"\n        user_dto = UserDTO()\n        user_dto.id = self.id\n        user_dto.username = self.username\n        user_dto.role = UserRole(self.role).name\n        user_dto.mapping_level = MappingLevel(self.mapping_level).name\n        user_dto.is_expert = self.is_expert or False\n        user_dto.date_registered = str(self.date_registered)\n        try:\n            user_dto.projects_mapped = len(self.projects_mapped)\n        # Handle users that haven't touched a project yet.\n        except:\n            user_dto.projects_mapped = 0\n        user_dto.tasks_mapped = self.tasks_mapped\n        user_dto.tasks_validated = self.tasks_validated\n        user_dto.tasks_invalidated = self.tasks_invalidated\n        user_dto.twitter_id = self.twitter_id\n        user_dto.linkedin_id = self.linkedin_id\n        user_dto.facebook_id = self.facebook_id\n        user_dto.validation_message = self.validation_message\n        user_dto.total_time_spent = 0\n        user_dto.time_spent_mapping = 0\n        user_dto.time_spent_validating = 0\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_VALIDATION'\n                and user_id = :user_id;\"\"\"\n        total_validation_time = db.engine.execute(text(sql), user_id=self.id)\n        for row in total_validation_time:\n            total_validation_time = row[0]\n            if total_validation_time:\n                total_validation_seconds = total_validation_time.total_seconds()\n                user_dto.time_spent_validating = total_validation_seconds\n                user_dto.total_time_spent += user_dto.time_spent_validating\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_MAPPING'\n                and user_id = :user_id;\"\"\"\n        total_mapping_time = db.engine.execute(text(sql), user_id=self.id)\n        for row in total_mapping_time:\n            total_mapping_time = row[0]\n            if total_mapping_time:\n                total_mapping_seconds = total_mapping_time.total_seconds()\n                user_dto.time_spent_mapping = total_mapping_seconds\n                user_dto.total_time_spent += user_dto.time_spent_mapping\n\n        if self.username == logged_in_username:\n            # Only return email address when logged in user is looking at their own profile\n            user_dto.email_address = self.email_address\n            user_dto.is_email_verified = self.is_email_verified\n        return user_dto", "line_changes": {"deleted": [{"line_no": 28, "char_start": 1278, "char_end": 1332, "line": "                and user_id = {0};\"\"\".format(self.id)\n"}, {"line_no": 29, "char_start": 1332, "char_end": 1387, "line": "        total_validation_time = db.engine.execute(sql)\n"}, {"line_no": 39, "char_start": 1885, "char_end": 1939, "line": "                and user_id = {0};\"\"\".format(self.id)\n"}, {"line_no": 40, "char_start": 1939, "char_end": 1991, "line": "        total_mapping_time = db.engine.execute(sql)\n"}], "added": [{"line_no": 28, "char_start": 1278, "char_end": 1321, "line": "                and user_id = :user_id;\"\"\"\n"}, {"line_no": 29, "char_start": 1321, "char_end": 1399, "line": "        total_validation_time = db.engine.execute(text(sql), user_id=self.id)\n"}, {"line_no": 39, "char_start": 1897, "char_end": 1940, "line": "                and user_id = :user_id;\"\"\"\n"}, {"line_no": 40, "char_start": 1940, "char_end": 2015, "line": "        total_mapping_time = db.engine.execute(text(sql), user_id=self.id)\n"}]}, "char_changes": {"deleted": [{"char_start": 1308, "char_end": 1331, "chars": "{0};\"\"\".format(self.id)"}, {"char_start": 1382, "char_end": 1385, "chars": "sql"}, {"char_start": 1915, "char_end": 1938, "chars": "{0};\"\"\".format(self.id)"}, {"char_start": 1986, "char_end": 1989, "chars": "sql"}], "added": [{"char_start": 1308, "char_end": 1320, "chars": ":user_id;\"\"\""}, {"char_start": 1371, "char_end": 1397, "chars": "text(sql), user_id=self.id"}, {"char_start": 1927, "char_end": 1939, "chars": ":user_id;\"\"\""}, {"char_start": 1987, "char_end": 2013, "chars": "text(sql), user_id=self.id"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/user.py", "vul_type": "cwe-089"}
{"func_name": "get_user_contributions", "func_src_before": "    @staticmethod\n    def get_user_contributions(project_id: int) -> ProjectContributionsDTO:\n        \"\"\" Get all user contributions on a project\"\"\"\n        contrib_query = '''select m.mapped_by, m.username, m.mapped, v.validated_by, v.username, v.validated\n                             from (select t.mapped_by, u.username, count(t.mapped_by) mapped\n                                     from tasks t,\n                                          users u\n                                    where t.mapped_by = u.id\n                                      and t.project_id = {0}\n                                      and t.mapped_by is not null\n                                    group by t.mapped_by, u.username) m FULL OUTER JOIN\n                                  (select t.validated_by, u.username, count(t.validated_by) validated\n                                     from tasks t,\n                                          users u\n                                    where t.validated_by = u.id\n                                      and t.project_id = {0}\n                                      and t.validated_by is not null\n                                    group by t.validated_by, u.username) v\n                                       ON m.mapped_by = v.validated_by\n        '''.format(project_id)\n\n        results = db.engine.execute(contrib_query)\n        if results.rowcount == 0:\n            raise NotFound()\n\n        contrib_dto = ProjectContributionsDTO()\n        for row in results:\n            user_id = row[0] or row[3]\n            user_contrib = UserContribution()\n            user_contrib.username = row[1] if row[1] else row[4]\n            user_contrib.mapped = row[2] if row[2] else 0\n            user_contrib.validated = row[5] if row[5] else 0\n            contrib_dto.user_contributions.append(user_contrib)\n        return contrib_dto", "func_src_after": "    @staticmethod\n    def get_user_contributions(project_id: int) -> ProjectContributionsDTO:\n        \"\"\" Get all user contributions on a project\"\"\"\n        contrib_query = '''select m.mapped_by, m.username, m.mapped, v.validated_by, v.username, v.validated\n                             from (select t.mapped_by, u.username, count(t.mapped_by) mapped\n                                     from tasks t,\n                                          users u\n                                    where t.mapped_by = u.id\n                                      and t.project_id = :project_id\n                                      and t.mapped_by is not null\n                                    group by t.mapped_by, u.username) m FULL OUTER JOIN\n                                  (select t.validated_by, u.username, count(t.validated_by) validated\n                                     from tasks t,\n                                          users u\n                                    where t.validated_by = u.id\n                                      and t.project_id = :project_id\n                                      and t.validated_by is not null\n                                    group by t.validated_by, u.username) v\n                                       ON m.mapped_by = v.validated_by\n        '''\n\n        results = db.engine.execute(text(contrib_query), project_id=project_id)\n        if results.rowcount == 0:\n            raise NotFound()\n\n        contrib_dto = ProjectContributionsDTO()\n        for row in results:\n            user_id = row[0] or row[3]\n            user_contrib = UserContribution()\n            user_contrib.username = row[1] if row[1] else row[4]\n            user_contrib.mapped = row[2] if row[2] else 0\n            user_contrib.validated = row[5] if row[5] else 0\n            contrib_dto.user_contributions.append(user_contrib)\n        return contrib_dto", "line_changes": {"deleted": [{"line_no": 9, "char_start": 513, "char_end": 574, "line": "                                      and t.project_id = {0}\n"}, {"line_no": 16, "char_start": 995, "char_end": 1056, "line": "                                      and t.project_id = {0}\n"}, {"line_no": 20, "char_start": 1271, "char_end": 1302, "line": "        '''.format(project_id)\n"}, {"line_no": 22, "char_start": 1303, "char_end": 1354, "line": "        results = db.engine.execute(contrib_query)\n"}], "added": [{"line_no": 9, "char_start": 513, "char_end": 582, "line": "                                      and t.project_id = :project_id\n"}, {"line_no": 16, "char_start": 1003, "char_end": 1072, "line": "                                      and t.project_id = :project_id\n"}, {"line_no": 20, "char_start": 1287, "char_end": 1299, "line": "        '''\n"}, {"line_no": 22, "char_start": 1300, "char_end": 1380, "line": "        results = db.engine.execute(text(contrib_query), project_id=project_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 570, "char_end": 573, "chars": "{0}"}, {"char_start": 1052, "char_end": 1055, "chars": "{0}"}, {"char_start": 1282, "char_end": 1301, "chars": ".format(project_id)"}], "added": [{"char_start": 570, "char_end": 581, "chars": ":project_id"}, {"char_start": 1060, "char_end": 1071, "chars": ":project_id"}, {"char_start": 1336, "char_end": 1341, "chars": "text("}, {"char_start": 1355, "char_end": 1379, "chars": ", project_id=project_id)"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/services/stats_service.py", "vul_type": "cwe-089"}
{"func_name": "get_detailed_stats", "func_src_before": "    @staticmethod\n    def get_detailed_stats(username: str):\n        user = UserService.get_user_by_username(username)\n        stats_dto = UserStatsDTO()\n\n        actions = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text != ''\n        ).all()\n\n        tasks_mapped = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text == 'MAPPED'\n        ).count()\n        tasks_validated = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text == 'VALIDATED'\n        ).count()\n        projects_mapped = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action == 'STATE_CHANGE'\n        ).distinct(TaskHistory.project_id).count()\n\n        stats_dto.tasks_mapped = tasks_mapped\n        stats_dto.tasks_validated = tasks_validated\n        stats_dto.projects_mapped = projects_mapped\n        stats_dto.total_time_spent = 0\n        stats_dto.time_spent_mapping = 0\n        stats_dto.time_spent_validating = 0\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_VALIDATION'\n                and user_id = {0};\"\"\".format(user.id)\n        total_validation_time = db.engine.execute(sql)\n        for time in total_validation_time:\n            total_validation_time = time[0]\n            if total_validation_time:\n                stats_dto.time_spent_validating = total_validation_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_validating\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_MAPPING'\n                and user_id = {0};\"\"\".format(user.id)\n        total_mapping_time = db.engine.execute(sql)\n        for time in total_mapping_time:\n            total_mapping_time = time[0]\n            if total_mapping_time:\n                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_mapping\n\n        return stats_dto", "func_src_after": "    @staticmethod\n    def get_detailed_stats(username: str):\n        user = UserService.get_user_by_username(username)\n        stats_dto = UserStatsDTO()\n\n        actions = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text != ''\n        ).all()\n\n        tasks_mapped = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text == 'MAPPED'\n        ).count()\n        tasks_validated = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text == 'VALIDATED'\n        ).count()\n        projects_mapped = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action == 'STATE_CHANGE'\n        ).distinct(TaskHistory.project_id).count()\n\n        stats_dto.tasks_mapped = tasks_mapped\n        stats_dto.tasks_validated = tasks_validated\n        stats_dto.projects_mapped = projects_mapped\n        stats_dto.total_time_spent = 0\n        stats_dto.time_spent_mapping = 0\n        stats_dto.time_spent_validating = 0\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_VALIDATION'\n                and user_id = :user_id;\"\"\"\n        total_validation_time = db.engine.execute(text(sql), user_id=user.id)\n        for time in total_validation_time:\n            total_validation_time = time[0]\n            if total_validation_time:\n                stats_dto.time_spent_validating = total_validation_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_validating\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_MAPPING'\n                and user_id = :user_id;\"\"\"\n        total_mapping_time = db.engine.execute(text(sql), user_id=user.id)\n        for time in total_mapping_time:\n            total_mapping_time = time[0]\n            if total_mapping_time:\n                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_mapping\n\n        return stats_dto", "line_changes": {"deleted": [{"line_no": 33, "char_start": 1244, "char_end": 1298, "line": "                and user_id = {0};\"\"\".format(user.id)\n"}, {"line_no": 34, "char_start": 1298, "char_end": 1353, "line": "        total_validation_time = db.engine.execute(sql)\n"}, {"line_no": 43, "char_start": 1788, "char_end": 1842, "line": "                and user_id = {0};\"\"\".format(user.id)\n"}, {"line_no": 44, "char_start": 1842, "char_end": 1894, "line": "        total_mapping_time = db.engine.execute(sql)\n"}], "added": [{"line_no": 33, "char_start": 1244, "char_end": 1287, "line": "                and user_id = :user_id;\"\"\"\n"}, {"line_no": 34, "char_start": 1287, "char_end": 1365, "line": "        total_validation_time = db.engine.execute(text(sql), user_id=user.id)\n"}, {"line_no": 43, "char_start": 1800, "char_end": 1843, "line": "                and user_id = :user_id;\"\"\"\n"}, {"line_no": 44, "char_start": 1843, "char_end": 1918, "line": "        total_mapping_time = db.engine.execute(text(sql), user_id=user.id)\n"}]}, "char_changes": {"deleted": [{"char_start": 1274, "char_end": 1289, "chars": "{0};\"\"\".format("}, {"char_start": 1293, "char_end": 1294, "chars": "."}, {"char_start": 1296, "char_end": 1297, "chars": ")"}, {"char_start": 1348, "char_end": 1351, "chars": "sql"}, {"char_start": 1818, "char_end": 1833, "chars": "{0};\"\"\".format("}, {"char_start": 1837, "char_end": 1838, "chars": "."}, {"char_start": 1840, "char_end": 1841, "chars": ")"}, {"char_start": 1889, "char_end": 1892, "chars": "sql"}], "added": [{"char_start": 1274, "char_end": 1275, "chars": ":"}, {"char_start": 1279, "char_end": 1280, "chars": "_"}, {"char_start": 1282, "char_end": 1286, "chars": ";\"\"\""}, {"char_start": 1337, "char_end": 1363, "chars": "text(sql), user_id=user.id"}, {"char_start": 1830, "char_end": 1831, "chars": ":"}, {"char_start": 1835, "char_end": 1836, "chars": "_"}, {"char_start": 1838, "char_end": 1842, "chars": ";\"\"\""}, {"char_start": 1890, "char_end": 1916, "chars": "text(sql), user_id=user.id"}]}, "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/services/users/user_service.py", "vul_type": "cwe-089"}
{"func_name": "search_by_name", "func_src_before": "    @classmethod\n    def search_by_name(self, text_query):\n        text_query_str = str(text_query) # SQLObject chokes on unicode.\n        # Todo: Change to use SQLObject statement objects.\n        sql_query = \"UPPER(tag.name) LIKE UPPER('%%%s%%')\" % text_query_str\n        return self.select(sql_query)", "func_src_after": "    @classmethod\n    def search_by_name(self, text_query):\n        text_query = str(text_query) # SQLObject chokes on unicode.\n        return self.select(self.q.name.contains(text_query.lower()))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 59, "char_end": 131, "line": "        text_query_str = str(text_query) # SQLObject chokes on unicode.\n"}, {"line_no": 5, "char_start": 190, "char_end": 266, "line": "        sql_query = \"UPPER(tag.name) LIKE UPPER('%%%s%%')\" % text_query_str\n"}, {"line_no": 6, "char_start": 266, "char_end": 303, "line": "        return self.select(sql_query)\n"}], "added": [{"line_no": 3, "char_start": 59, "char_end": 127, "line": "        text_query = str(text_query) # SQLObject chokes on unicode.\n"}, {"line_no": 4, "char_start": 127, "char_end": 195, "line": "        return self.select(self.q.name.contains(text_query.lower()))\n"}]}, "char_changes": {"deleted": [{"char_start": 77, "char_end": 81, "chars": "_str"}, {"char_start": 139, "char_end": 302, "chars": "# Todo: Change to use SQLObject statement objects.\n        sql_query = \"UPPER(tag.name) LIKE UPPER('%%%s%%')\" % text_query_str\n        return self.select(sql_query"}], "added": [{"char_start": 135, "char_end": 194, "chars": "return self.select(self.q.name.contains(text_query.lower())"}]}, "commit_link": "github.com/ambagape/opendatang/commit/f020853c54a1851f196d7fd8897c4620bccf9f6c", "file_name": "ckan/models/package.py", "vul_type": "cwe-089"}
{"func_name": "execute", "func_src_before": "    def execute(self, command, args=(), save=False):\n        ''' Wrapper for executing SQL commands '''\n        for tries in xrange(5, 0, -1):\n            try:\n                if args and isinstance(args, tuple):\n                    self.c.execute(command, args)\n                else:\n                    self.c.execute(command)\n                if save:\n                    self.save()\n                return True\n            except:\n                error = str(sys.exc_value)\n                if tries >= 0 and 'is locked' in error:\n                    logging.debug('Database locked, wait and retry')\n                    time.sleep(0.5)\n                    continue\n                elif 'readonly' in error:\n                    logging.error(T('Cannot write to History database, check access rights!'))\n                    # Report back success, because there's no recovery possible\n                    return True\n                elif 'not a database' in error or 'malformed' in error or 'duplicate column name' in error:\n                    logging.error(T('Damaged History database, created empty replacement'))\n                    logging.info(\"Traceback: \", exc_info=True)\n                    self.close()\n                    try:\n                        os.remove(HistoryDB.db_path)\n                    except:\n                        pass\n                    self.connect()\n                    # Return False in case of \"duplicate column\" error\n                    # because the column addition in connect() must be terminated\n                    return 'duplicate column name' not in error\n                else:\n                    logging.error(T('SQL Command Failed, see log'))\n                    logging.debug(\"SQL: %s\", command)\n                    logging.info(\"Traceback: \", exc_info=True)\n                    try:\n                        self.con.rollback()\n                    except:\n                        logging.debug(\"Rollback Failed:\", exc_info=True)\n            return False", "func_src_after": "    def execute(self, command, args=(), save=False):\n        ''' Wrapper for executing SQL commands '''\n        for tries in xrange(5, 0, -1):\n            try:\n                if args and isinstance(args, tuple):\n                    self.c.execute(command, args)\n                else:\n                    self.c.execute(command)\n                if save:\n                    self.save()\n                return True\n            except:\n                error = str(sys.exc_value)\n                if tries >= 0 and 'is locked' in error:\n                    logging.debug('Database locked, wait and retry')\n                    time.sleep(0.5)\n                    continue\n                elif 'readonly' in error:\n                    logging.error(T('Cannot write to History database, check access rights!'))\n                    # Report back success, because there's no recovery possible\n                    return True\n                elif 'not a database' in error or 'malformed' in error or 'duplicate column name' in error:\n                    logging.error(T('Damaged History database, created empty replacement'))\n                    logging.info(\"Traceback: \", exc_info=True)\n                    self.close()\n                    try:\n                        os.remove(HistoryDB.db_path)\n                    except:\n                        pass\n                    self.connect()\n                    # Return False in case of \"duplicate column\" error\n                    # because the column addition in connect() must be terminated\n                    return 'duplicate column name' not in error\n                else:\n                    logging.error(T('SQL Command Failed, see log'))\n                    logging.info(\"SQL: %s\", command)\n                    logging.info(\"Arguments: %s\", repr(args))\n                    logging.info(\"Traceback: \", exc_info=True)\n                    try:\n                        self.con.rollback()\n                    except:\n                        logging.debug(\"Rollback Failed:\", exc_info=True)\n            return False", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1689, "char_end": 1743, "line": "                    logging.debug(\"SQL: %s\", command)\n"}], "added": [{"line_no": 36, "char_start": 1689, "char_end": 1742, "line": "                    logging.info(\"SQL: %s\", command)\n"}, {"line_no": 37, "char_start": 1742, "char_end": 1804, "line": "                    logging.info(\"Arguments: %s\", repr(args))\n"}]}, "char_changes": {"deleted": [{"char_start": 1717, "char_end": 1722, "chars": "debug"}], "added": [{"char_start": 1717, "char_end": 1721, "chars": "info"}, {"char_start": 1742, "char_end": 1804, "chars": "                    logging.info(\"Arguments: %s\", repr(args))\n"}]}, "commit_link": "github.com/sabnzbd/sabnzbd/commit/ad9fef5f416ef31eb3fdf7c1774434092fd6a52c", "file_name": "sabnzbd/database.py", "vul_type": "cwe-089"}
{"func_name": "fetch_history", "func_src_before": "    def fetch_history(self, start=None, limit=None, search=None, failed_only=0, categories=None):\n        \"\"\" Return records for specified jobs \"\"\"\n        search = convert_search(search)\n\n        post = ''\n        if categories:\n            categories = ['*' if c == 'Default' else c for c in categories]\n            post = \" AND (CATEGORY = '\"\n            post += \"' OR CATEGORY = '\".join(categories)\n            post += \"' )\"\n        if failed_only:\n            post += ' AND STATUS = \"Failed\"'\n\n        cmd = 'SELECT COUNT(*) FROM history WHERE name LIKE ?'\n        res = self.execute(cmd + post, (search,))\n        total_items = -1\n        if res:\n            try:\n                total_items = self.c.fetchone().get('COUNT(*)')\n            except AttributeError:\n                pass\n\n        if not start:\n            start = 0\n        if not limit:\n            limit = total_items\n\n        t = (search, start, limit)\n        cmd = 'SELECT * FROM history WHERE name LIKE ?'\n        fetch_ok = self.execute(cmd + post + ' ORDER BY completed desc LIMIT ?, ?', t)\n\n        if fetch_ok:\n            items = self.c.fetchall()\n        else:\n            items = []\n\n        fetched_items = len(items)\n\n        # Unpack the single line stage log\n        # Stage Name is separated by ::: stage lines by ; and stages by \\r\\n\n        items = [unpack_history_info(item) for item in items]\n\n        return (items, fetched_items, total_items)", "func_src_after": "    def fetch_history(self, start=None, limit=None, search=None, failed_only=0, categories=None):\n        \"\"\" Return records for specified jobs \"\"\"\n        command_args = [convert_search(search)]\n\n        post = ''\n        if categories:\n            categories = ['*' if c == 'Default' else c for c in categories]\n            post = \" AND (CATEGORY = ?\"\n            post += \" OR CATEGORY = ? \" * (len(categories)-1)\n            post += \")\"\n            command_args.extend(categories)\n        if failed_only:\n            post += ' AND STATUS = \"Failed\"'\n\n        cmd = 'SELECT COUNT(*) FROM history WHERE name LIKE ?'\n        res = self.execute(cmd + post, tuple(command_args))\n        total_items = -1\n        if res:\n            try:\n                total_items = self.c.fetchone().get('COUNT(*)')\n            except AttributeError:\n                pass\n\n        if not start:\n            start = 0\n        if not limit:\n            limit = total_items\n\n        command_args.extend([start, limit])\n        cmd = 'SELECT * FROM history WHERE name LIKE ?'\n        fetch_ok = self.execute(cmd + post + ' ORDER BY completed desc LIMIT ?, ?', tuple(command_args))\n\n        if fetch_ok:\n            items = self.c.fetchall()\n        else:\n            items = []\n\n        fetched_items = len(items)\n\n        # Unpack the single line stage log\n        # Stage Name is separated by ::: stage lines by ; and stages by \\r\\n\n        items = [unpack_history_info(item) for item in items]\n\n        return (items, fetched_items, total_items)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 148, "char_end": 188, "line": "        search = convert_search(search)\n"}, {"line_no": 8, "char_start": 306, "char_end": 346, "line": "            post = \" AND (CATEGORY = '\"\n"}, {"line_no": 9, "char_start": 346, "char_end": 403, "line": "            post += \"' OR CATEGORY = '\".join(categories)\n"}, {"line_no": 10, "char_start": 403, "char_end": 429, "line": "            post += \"' )\"\n"}, {"line_no": 15, "char_start": 562, "char_end": 612, "line": "        res = self.execute(cmd + post, (search,))\n"}, {"line_no": 28, "char_start": 890, "char_end": 925, "line": "        t = (search, start, limit)\n"}, {"line_no": 30, "char_start": 981, "char_end": 1068, "line": "        fetch_ok = self.execute(cmd + post + ' ORDER BY completed desc LIMIT ?, ?', t)\n"}], "added": [{"line_no": 3, "char_start": 148, "char_end": 196, "line": "        command_args = [convert_search(search)]\n"}, {"line_no": 8, "char_start": 314, "char_end": 354, "line": "            post = \" AND (CATEGORY = ?\"\n"}, {"line_no": 9, "char_start": 354, "char_end": 416, "line": "            post += \" OR CATEGORY = ? \" * (len(categories)-1)\n"}, {"line_no": 10, "char_start": 416, "char_end": 440, "line": "            post += \")\"\n"}, {"line_no": 11, "char_start": 440, "char_end": 484, "line": "            command_args.extend(categories)\n"}, {"line_no": 16, "char_start": 617, "char_end": 677, "line": "        res = self.execute(cmd + post, tuple(command_args))\n"}, {"line_no": 29, "char_start": 955, "char_end": 999, "line": "        command_args.extend([start, limit])\n"}, {"line_no": 31, "char_start": 1055, "char_end": 1160, "line": "        fetch_ok = self.execute(cmd + post + ' ORDER BY completed desc LIMIT ?, ?', tuple(command_args))\n"}]}, "char_changes": {"deleted": [{"char_start": 156, "char_end": 162, "chars": "search"}, {"char_start": 343, "char_end": 344, "chars": "'"}, {"char_start": 367, "char_end": 368, "chars": "'"}, {"char_start": 383, "char_end": 389, "chars": "'\".joi"}, {"char_start": 424, "char_end": 426, "chars": "' "}, {"char_start": 601, "char_end": 609, "chars": "(search,"}, {"char_start": 898, "char_end": 911, "chars": "t = (search, "}, {"char_start": 981, "char_end": 981, "chars": ""}], "added": [{"char_start": 156, "char_end": 168, "chars": "command_args"}, {"char_start": 171, "char_end": 172, "chars": "["}, {"char_start": 194, "char_end": 195, "chars": "]"}, {"char_start": 351, "char_end": 352, "chars": "?"}, {"char_start": 390, "char_end": 399, "chars": "? \" * (le"}, {"char_start": 412, "char_end": 415, "chars": "-1)"}, {"char_start": 440, "char_end": 484, "chars": "            command_args.extend(categories)\n"}, {"char_start": 656, "char_end": 674, "chars": "tuple(command_args"}, {"char_start": 963, "char_end": 984, "chars": "command_args.extend(["}, {"char_start": 996, "char_end": 997, "chars": "]"}, {"char_start": 1140, "char_end": 1158, "chars": "uple(command_args)"}]}, "commit_link": "github.com/sabnzbd/sabnzbd/commit/ad9fef5f416ef31eb3fdf7c1774434092fd6a52c", "file_name": "sabnzbd/database.py", "vul_type": "cwe-089"}
{"func_name": "replace", "func_src_before": "    def replace(self, table, dataframe, batch_size=None):\n        import migrate.changeset\n        global _after_replace_callbacks\n        \n        with timer('REPLACE ' + table):\n            suffix = datetime.now().strftime('_%Y%m%d%H%M%S').encode('utf-8')\n            self.metadata\n            temp = 'tmp_'.encode('utf-8')\n            source = sqlalchemy.Table(table, self.metadata, autoload=True, autoload_with=self._engine)\n            destination_name = 'tmp_' + hashlib.sha256(temp + table.encode('utf-8') + suffix).hexdigest()[0:56]\n            destination = sqlalchemy.Table(destination_name, self.metadata, autoload=False)\n            for column in source.columns:\n                destination.append_column(column.copy())\n            destination.create()\n\n            original_names = {}\n            for index in source.indexes:\n                # make sure the name is < 63 chars with the suffix\n                name = hashlib.sha256(temp + index.name.encode('utf-8') + suffix).hexdigest()[0:60]\n                original_names[name] = index.name\n                columns = []\n                for column in index.columns:\n                    columns.append(next(x for x in destination.columns if x.name == column.name))\n                new = sqlalchemy.Index(name, *columns)\n                new.unique = index.unique\n                new.table = destination\n                new.create(bind=self._connection)\n            self.insert(destination.name, dataframe, batch_size=batch_size)\n            self.execute(\"BEGIN; SET LOCAL statement_timeout = '1min'; ANALYZE %s; COMMIT;\" % table)\n\n            with self as transaction:\n                backup = sqlalchemy.Table(table + '_b', self.metadata)\n                backup.drop(bind=self._connection, checkfirst=True)\n                source.rename(name=source.name + '_b', connection=self._connection)\n                destination.rename(name=table, connection=self._connection)\n                for index in source.indexes:\n                    index.rename(index.name[0:-2] + '_b', connection=self._connection)\n                for index in destination.indexes:\n                    index.rename(original_names[index.name], connection=self._connection)\n        \n        for func in _after_replace_callbacks:\n            func(destination, source)", "func_src_after": "    def replace(self, table, dataframe, batch_size=None):\n        import migrate.changeset\n        global _after_replace_callbacks\n        \n        with timer('REPLACE ' + table):\n            suffix = datetime.now().strftime('_%Y%m%d%H%M%S').encode('utf-8')\n            self.metadata\n            temp = 'tmp_'.encode('utf-8')\n            source = sqlalchemy.Table(table, self.metadata, autoload=True, autoload_with=self._engine)\n            destination_name = 'tmp_' + hashlib.sha256(temp + table.encode('utf-8') + suffix).hexdigest()[0:56]\n            destination = sqlalchemy.Table(destination_name, self.metadata, autoload=False)\n            for column in source.columns:\n                destination.append_column(column.copy())\n            destination.create()\n\n            original_names = {}\n            for index in source.indexes:\n                # make sure the name is < 63 chars with the suffix\n                name = hashlib.sha256(temp + index.name.encode('utf-8') + suffix).hexdigest()[0:60]\n                original_names[name] = index.name\n                columns = []\n                for column in index.columns:\n                    columns.append(next(x for x in destination.columns if x.name == column.name))\n                new = sqlalchemy.Index(name, *columns)\n                new.unique = index.unique\n                new.table = destination\n                new.create(bind=self._connection)\n            self.insert(destination.name, dataframe, batch_size=batch_size)\n            self.execute(\"BEGIN; SET LOCAL statement_timeout = '1min'; ANALYZE %s; COMMIT;\" % self.quote_identifier(table))\n\n            with self as transaction:\n                backup = sqlalchemy.Table(table + '_b', self.metadata)\n                backup.drop(bind=self._connection, checkfirst=True)\n                source.rename(name=source.name + '_b', connection=self._connection)\n                destination.rename(name=table, connection=self._connection)\n                for index in source.indexes:\n                    index.rename(index.name[0:-2] + '_b', connection=self._connection)\n                for index in destination.indexes:\n                    index.rename(original_names[index.name], connection=self._connection)\n        \n        for func in _after_replace_callbacks:\n            func(destination, source)", "line_changes": {"deleted": [{"line_no": 29, "char_start": 1491, "char_end": 1592, "line": "            self.execute(\"BEGIN; SET LOCAL statement_timeout = '1min'; ANALYZE %s; COMMIT;\" % table)\n"}], "added": [{"line_no": 29, "char_start": 1491, "char_end": 1615, "line": "            self.execute(\"BEGIN; SET LOCAL statement_timeout = '1min'; ANALYZE %s; COMMIT;\" % self.quote_identifier(table))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1585, "char_end": 1607, "chars": "self.quote_identifier("}, {"char_start": 1613, "char_end": 1614, "chars": ")"}]}, "commit_link": "github.com/instacart/lore/commit/a0a5fd945a8bf128d4b9fb6a3ebc6306f82fa4d0", "file_name": "lore/io/connection.py", "vul_type": "cwe-089"}
{"func_name": "get_content", "func_src_before": "    def get_content(self, uuid_):\n        try:\n            u_fl = self.st_uuid_idx[uuid_]\n        except Exception:\n            return b''\n        # Got file handle, now querying file data\n        content = self.st_db.execute(\"SELECT content FROM file_storage WHERE uuid = '%d';\" % uuid_)\n        return content", "func_src_after": "    def get_content(self, uuid_):\n        try:\n            u_fl = self.st_uuid_idx[uuid_]\n        except Exception:\n            return b''\n        # Got file handle, now querying file data\n        content = self.st_db.execute(\"SELECT content FROM file_storage WHERE uuid = '%s';\" % uuid_)\n        print(content)\n        return content", "line_changes": {"deleted": [{"line_no": 7, "char_start": 189, "char_end": 289, "line": "        content = self.st_db.execute(\"SELECT content FROM file_storage WHERE uuid = '%d';\" % uuid_)\n"}], "added": [{"line_no": 7, "char_start": 189, "char_end": 289, "line": "        content = self.st_db.execute(\"SELECT content FROM file_storage WHERE uuid = '%s';\" % uuid_)\n"}, {"line_no": 8, "char_start": 289, "char_end": 312, "line": "        print(content)\n"}]}, "char_changes": {"deleted": [{"char_start": 275, "char_end": 276, "chars": "d"}], "added": [{"char_start": 275, "char_end": 276, "chars": "s"}, {"char_start": 289, "char_end": 312, "chars": "        print(content)\n"}]}, "commit_link": "github.com/bzShare-dev/bzShare/commit/fa76c130ed80b9f5636cab41e88054536205c376", "file_name": "bzs/db.py", "vul_type": "cwe-089"}
{"func_name": "close_statement", "func_src_before": "    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n    #        if not list_statement:\n    #            return {}\n    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)\n    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}", "func_src_after": "    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}", "line_changes": {"deleted": [{"line_no": 17, "char_start": 802, "char_end": 856, "line": "        cr.execute(\"\"\" select id from account_journal\n"}, {"line_no": 18, "char_start": 856, "char_end": 923, "line": "                            where auto_cash='True' and type='cash'\n"}, {"line_no": 19, "char_start": 923, "char_end": 1024, "line": "                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n"}, {"line_no": 20, "char_start": 1024, "char_end": 1083, "line": "        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n"}], "added": [{"line_no": 17, "char_start": 802, "char_end": 924, "line": "        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n"}]}, "char_changes": {"deleted": [{"char_start": 810, "char_end": 1081, "chars": "cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall()"}, {"char_start": 1575, "char_end": 1892, "chars": "\n    #        if not list_statement:\n    #            return {}\n    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)\n    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']"}], "added": [{"char_start": 810, "char_end": 922, "chars": "journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)]"}, {"char_start": 1340, "char_end": 1340, "chars": ""}]}, "commit_link": "github.com/loxoalia/OCA-OCB/commit/b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "file_name": "addons/point_of_sale/wizard/pos_close_statement.py", "vul_type": "cwe-089"}
{"func_name": "get_product_available", "func_src_before": "    def get_product_available(self, cr, uid, ids, context=None):\n        \"\"\" Finds whether product is available or not in particular warehouse.\n        @return: Dictionary of values\n        \"\"\"\n        if context is None:\n            context = {}\n        states = context.get('states',[])\n        what = context.get('what',())\n        if not ids:\n            ids = self.search(cr, uid, [])\n        res = {}.fromkeys(ids, 0.0)\n        if not ids:\n            return res\n\n        if context.get('shop', False):\n            cr.execute('select warehouse_id from sale_shop where id=%s', (int(context['shop']),))\n            res2 = cr.fetchone()\n            if res2:\n                context['warehouse'] = res2[0]\n\n        if context.get('warehouse', False):\n            cr.execute('select lot_stock_id from stock_warehouse where id=%s', (int(context['warehouse']),))\n            res2 = cr.fetchone()\n            if res2:\n                context['location'] = res2[0]\n\n        if context.get('location', False):\n            if type(context['location']) == type(1):\n                location_ids = [context['location']]\n            elif type(context['location']) in (type(''), type(u'')):\n                location_ids = self.pool.get('stock.location').search(cr, uid, [('name','ilike',context['location'])], context=context)\n            else:\n                location_ids = context['location']\n        else:\n            location_ids = []\n            wids = self.pool.get('stock.warehouse').search(cr, uid, [], context=context)\n            for w in self.pool.get('stock.warehouse').browse(cr, uid, wids, context=context):\n                location_ids.append(w.lot_stock_id.id)\n\n        # build the list of ids of children of the location given by id\n        if context.get('compute_child',True):\n            child_location_ids = self.pool.get('stock.location').search(cr, uid, [('location_id', 'child_of', location_ids)])\n            location_ids = child_location_ids or location_ids\n        else:\n            location_ids = location_ids\n\n        uoms_o = {}\n        product2uom = {}\n        for product in self.browse(cr, uid, ids, context=context):\n            product2uom[product.id] = product.uom_id.id\n            uoms_o[product.uom_id.id] = product.uom_id\n\n        results = []\n        results2 = []\n\n        from_date=context.get('from_date',False)\n        to_date=context.get('to_date',False)\n        date_str=False\n        if from_date and to_date:\n            date_str=\"date_planned>='%s' and date_planned<='%s'\"%(from_date,to_date)\n        elif from_date:\n            date_str=\"date_planned>='%s'\"%(from_date)\n        elif to_date:\n            date_str=\"date_planned<='%s'\"%(to_date)\n\n        if 'in' in what:\n            # all moves from a location out of the set to a location in the set\n            cr.execute(\n                'select sum(product_qty), product_id, product_uom '\\\n                'from stock_move '\\\n                'where location_id NOT IN %s'\\\n                'and location_dest_id IN %s'\\\n                'and product_id IN %s'\\\n                'and state IN %s' + (date_str and 'and '+date_str+' ' or '') +''\\\n                'group by product_id,product_uom',(tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states),)\n            )\n            results = cr.fetchall()\n        if 'out' in what:\n            # all moves from a location in the set to a location out of the set\n            cr.execute(\n                'select sum(product_qty), product_id, product_uom '\\\n                'from stock_move '\\\n                'where location_id IN %s'\\\n                'and location_dest_id NOT IN %s '\\\n                'and product_id  IN %s'\\\n                'and state in %s' + (date_str and 'and '+date_str+' ' or '') + ''\\\n                'group by product_id,product_uom',(tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states),)\n            )\n            results2 = cr.fetchall()\n        uom_obj = self.pool.get('product.uom')\n        uoms = map(lambda x: x[2], results) + map(lambda x: x[2], results2)\n        if context.get('uom', False):\n            uoms += [context['uom']]\n\n        uoms = filter(lambda x: x not in uoms_o.keys(), uoms)\n        if uoms:\n            uoms = uom_obj.browse(cr, uid, list(set(uoms)), context=context)\n        for o in uoms:\n            uoms_o[o.id] = o\n        for amount, prod_id, prod_uom in results:\n            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,\n                    uoms_o[context.get('uom', False) or product2uom[prod_id]])\n            res[prod_id] += amount\n        for amount, prod_id, prod_uom in results2:\n            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,\n                    uoms_o[context.get('uom', False) or product2uom[prod_id]])\n            res[prod_id] -= amount\n        return res", "func_src_after": "    def get_product_available(self, cr, uid, ids, context=None):\n        \"\"\" Finds whether product is available or not in particular warehouse.\n        @return: Dictionary of values\n        \"\"\"\n        if context is None:\n            context = {}\n        states = context.get('states',[])\n        what = context.get('what',())\n        if not ids:\n            ids = self.search(cr, uid, [])\n        res = {}.fromkeys(ids, 0.0)\n        if not ids:\n            return res\n\n        if context.get('shop', False):\n            cr.execute('select warehouse_id from sale_shop where id=%s', (int(context['shop']),))\n            res2 = cr.fetchone()\n            if res2:\n                context['warehouse'] = res2[0]\n\n        if context.get('warehouse', False):\n            cr.execute('select lot_stock_id from stock_warehouse where id=%s', (int(context['warehouse']),))\n            res2 = cr.fetchone()\n            if res2:\n                context['location'] = res2[0]\n\n        if context.get('location', False):\n            if type(context['location']) == type(1):\n                location_ids = [context['location']]\n            elif type(context['location']) in (type(''), type(u'')):\n                location_ids = self.pool.get('stock.location').search(cr, uid, [('name','ilike',context['location'])], context=context)\n            else:\n                location_ids = context['location']\n        else:\n            location_ids = []\n            wids = self.pool.get('stock.warehouse').search(cr, uid, [], context=context)\n            for w in self.pool.get('stock.warehouse').browse(cr, uid, wids, context=context):\n                location_ids.append(w.lot_stock_id.id)\n\n        # build the list of ids of children of the location given by id\n        if context.get('compute_child',True):\n            child_location_ids = self.pool.get('stock.location').search(cr, uid, [('location_id', 'child_of', location_ids)])\n            location_ids = child_location_ids or location_ids\n        else:\n            location_ids = location_ids\n\n        uoms_o = {}\n        product2uom = {}\n        for product in self.browse(cr, uid, ids, context=context):\n            product2uom[product.id] = product.uom_id.id\n            uoms_o[product.uom_id.id] = product.uom_id\n\n        results = []\n        results2 = []\n\n        from_date = context.get('from_date',False)\n        to_date = context.get('to_date',False)\n        date_str = False\n        date_values = False\n        if from_date and to_date:\n            date_str = \"date_planned>=%s and date_planned<=%s\"\n            date_values = [from_date, to_date]\n        elif from_date:\n            date_str = \"date_planned>=%s\"\n            date_values = [from_date] \n        elif to_date:\n            date_str = \"date_planned<=%s\"\n            date_values = [to_date]\n\n        where = [tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states)]\n        if date_values:\n            where.append(tuple(date_values))\n        if 'in' in what:\n            # all moves from a location out of the set to a location in the set\n            cr.execute(\n                'select sum(product_qty), product_id, product_uom '\\\n                'from stock_move '\\\n                'where location_id NOT IN %s'\\\n                'and location_dest_id IN %s'\\\n                'and product_id IN %s'\\\n                'and state IN %s' + (date_str and 'and '+date_str+' ' or '') +''\\\n                'group by product_id,product_uom',tuple(where))\n            results = cr.fetchall()\n        if 'out' in what:\n            # all moves from a location in the set to a location out of the set\n            cr.execute(\n                'select sum(product_qty), product_id, product_uom '\\\n                'from stock_move '\\\n                'where location_id IN %s'\\\n                'and location_dest_id NOT IN %s '\\\n                'and product_id  IN %s'\\\n                'and state in %s' + (date_str and 'and '+date_str+' ' or '') + ''\\\n                'group by product_id,product_uom',tuple(where))\n            results2 = cr.fetchall()\n        uom_obj = self.pool.get('product.uom')\n        uoms = map(lambda x: x[2], results) + map(lambda x: x[2], results2)\n        if context.get('uom', False):\n            uoms += [context['uom']]\n\n        uoms = filter(lambda x: x not in uoms_o.keys(), uoms)\n        if uoms:\n            uoms = uom_obj.browse(cr, uid, list(set(uoms)), context=context)\n        for o in uoms:\n            uoms_o[o.id] = o\n        for amount, prod_id, prod_uom in results:\n            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,\n                    uoms_o[context.get('uom', False) or product2uom[prod_id]])\n            res[prod_id] += amount\n        for amount, prod_id, prod_uom in results2:\n            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,\n                    uoms_o[context.get('uom', False) or product2uom[prod_id]])\n            res[prod_id] -= amount\n        return res", "line_changes": {"deleted": [{"line_no": 56, "char_start": 2298, "char_end": 2347, "line": "        from_date=context.get('from_date',False)\n"}, {"line_no": 57, "char_start": 2347, "char_end": 2392, "line": "        to_date=context.get('to_date',False)\n"}, {"line_no": 58, "char_start": 2392, "char_end": 2415, "line": "        date_str=False\n"}, {"line_no": 60, "char_start": 2449, "char_end": 2534, "line": "            date_str=\"date_planned>='%s' and date_planned<='%s'\"%(from_date,to_date)\n"}, {"line_no": 62, "char_start": 2558, "char_end": 2612, "line": "            date_str=\"date_planned>='%s'\"%(from_date)\n"}, {"line_no": 64, "char_start": 2634, "char_end": 2686, "line": "            date_str=\"date_planned<='%s'\"%(to_date)\n"}, {"line_no": 75, "char_start": 3136, "char_end": 3254, "line": "                'group by product_id,product_uom',(tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states),)\n"}, {"line_no": 76, "char_start": 3254, "char_end": 3268, "line": "            )\n"}, {"line_no": 87, "char_start": 3757, "char_end": 3875, "line": "                'group by product_id,product_uom',(tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states),)\n"}, {"line_no": 88, "char_start": 3875, "char_end": 3889, "line": "            )\n"}], "added": [{"line_no": 56, "char_start": 2298, "char_end": 2349, "line": "        from_date = context.get('from_date',False)\n"}, {"line_no": 57, "char_start": 2349, "char_end": 2396, "line": "        to_date = context.get('to_date',False)\n"}, {"line_no": 58, "char_start": 2396, "char_end": 2421, "line": "        date_str = False\n"}, {"line_no": 59, "char_start": 2421, "char_end": 2449, "line": "        date_values = False\n"}, {"line_no": 61, "char_start": 2483, "char_end": 2546, "line": "            date_str = \"date_planned>=%s and date_planned<=%s\"\n"}, {"line_no": 62, "char_start": 2546, "char_end": 2593, "line": "            date_values = [from_date, to_date]\n"}, {"line_no": 64, "char_start": 2617, "char_end": 2659, "line": "            date_str = \"date_planned>=%s\"\n"}, {"line_no": 65, "char_start": 2659, "char_end": 2698, "line": "            date_values = [from_date] \n"}, {"line_no": 67, "char_start": 2720, "char_end": 2762, "line": "            date_str = \"date_planned<=%s\"\n"}, {"line_no": 68, "char_start": 2762, "char_end": 2798, "line": "            date_values = [to_date]\n"}, {"line_no": 70, "char_start": 2799, "char_end": 2882, "line": "        where = [tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states)]\n"}, {"line_no": 71, "char_start": 2882, "char_end": 2906, "line": "        if date_values:\n"}, {"line_no": 72, "char_start": 2906, "char_end": 2951, "line": "            where.append(tuple(date_values))\n"}, {"line_no": 82, "char_start": 3400, "char_end": 3464, "line": "                'group by product_id,product_uom',tuple(where))\n"}, {"line_no": 93, "char_start": 3953, "char_end": 4017, "line": "                'group by product_id,product_uom',tuple(where))\n"}]}, "char_changes": {"deleted": [{"char_start": 2315, "char_end": 2316, "chars": "="}, {"char_start": 2362, "char_end": 2363, "chars": "="}, {"char_start": 2408, "char_end": 2409, "chars": "="}, {"char_start": 2469, "char_end": 2470, "chars": "="}, {"char_start": 2485, "char_end": 2486, "chars": "'"}, {"char_start": 2488, "char_end": 2489, "chars": "'"}, {"char_start": 2508, "char_end": 2509, "chars": "'"}, {"char_start": 2511, "char_end": 2515, "chars": "'\"%("}, {"char_start": 2532, "char_end": 2533, "chars": ")"}, {"char_start": 2578, "char_end": 2579, "chars": "="}, {"char_start": 2594, "char_end": 2595, "chars": "'"}, {"char_start": 2597, "char_end": 2601, "chars": "'\"%("}, {"char_start": 2610, "char_end": 2611, "chars": ")"}, {"char_start": 2654, "char_end": 2655, "chars": "="}, {"char_start": 2670, "char_end": 2671, "chars": "'"}, {"char_start": 2673, "char_end": 2686, "chars": "'\"%(to_date)\n"}, {"char_start": 3186, "char_end": 3187, "chars": "("}, {"char_start": 3193, "char_end": 3266, "chars": "location_ids),tuple(location_ids),tuple(ids),tuple(states),)\n            "}, {"char_start": 3807, "char_end": 3808, "chars": "("}, {"char_start": 3814, "char_end": 3887, "chars": "location_ids),tuple(location_ids),tuple(ids),tuple(states),)\n            "}], "added": [{"char_start": 2315, "char_end": 2318, "chars": " = "}, {"char_start": 2364, "char_end": 2367, "chars": " = "}, {"char_start": 2412, "char_end": 2443, "chars": " = False\n        date_values = "}, {"char_start": 2503, "char_end": 2506, "chars": " = "}, {"char_start": 2544, "char_end": 2573, "chars": "\"\n            date_values = ["}, {"char_start": 2583, "char_end": 2584, "chars": " "}, {"char_start": 2591, "char_end": 2592, "chars": "]"}, {"char_start": 2637, "char_end": 2640, "chars": " = "}, {"char_start": 2657, "char_end": 2686, "chars": "\"\n            date_values = ["}, {"char_start": 2695, "char_end": 2697, "chars": "] "}, {"char_start": 2740, "char_end": 2743, "chars": " = "}, {"char_start": 2760, "char_end": 2950, "chars": "\"\n            date_values = [to_date]\n\n        where = [tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states)]\n        if date_values:\n            where.append(tuple(date_values))"}, {"char_start": 3456, "char_end": 3462, "chars": "where)"}, {"char_start": 4009, "char_end": 4015, "chars": "where)"}]}, "commit_link": "github.com/OSSESAC/odoopubarquiluz/commit/1521b235409982842b63b423c6ff7ac4ed4ca1db", "file_name": "addons/stock/product.py", "vul_type": "cwe-089"}
{"func_name": "_make_flat_wins_csv", "func_src_before": "    def _make_flat_wins_csv(self, **kwargs):\n        \"\"\"\n        Make CSV of all completed Wins till now for this financial year, with non-local data flattened\n        remove all rows where:\n        1. total expected export value = 0 and total non export value = 0 and total odi value = 0\n        2. date created = today (not necessary if this task runs before end of the day for next day download)\n        3. customer email sent is False / No\n        4. Customer response received is not from this financial year\n        Note that this view removes win, notification and customer response entries\n        that might have been made inactive in duecourse\n        \"\"\"\n        sql_str = \"SELECT id FROM wins_completed_wins_fy\"\n        if self.end_date:\n            sql_str = f\"{sql_str} where created <= '{self.end_date.strftime('%m-%d-%Y')}'\"\n\n        with connection.cursor() as cursor:\n            cursor.execute(sql_str)\n            ids = cursor.fetchall()\n\n        wins = Win.objects.filter(id__in=[id[0] for id in ids]).values()\n\n        for win in wins:\n            yield self._get_win_data(win)", "func_src_after": "    def _make_flat_wins_csv(self, **kwargs):\n        \"\"\"\n        Make CSV of all completed Wins till now for this financial year, with non-local data flattened\n        remove all rows where:\n        1. total expected export value = 0 and total non export value = 0 and total odi value = 0\n        2. date created = today (not necessary if this task runs before end of the day for next day download)\n        3. customer email sent is False / No\n        4. Customer response received is not from this financial year\n        Note that this view removes win, notification and customer response entries\n        that might have been made inactive in duecourse\n        \"\"\"\n        with connection.cursor() as cursor:\n            if self.end_date:\n                cursor.execute(\"SELECT id FROM wins_completed_wins_fy where created <= %s\", (self.end_date,))\n            else:\n                cursor.execute(\"SELECT id FROM wins_completed_wins_fy\")\n            ids = cursor.fetchall()\n\n        wins = Win.objects.filter(id__in=[id[0] for id in ids]).values()\n\n        for win in wins:\n            yield self._get_win_data(win)", "line_changes": {"deleted": [{"line_no": 12, "char_start": 666, "char_end": 724, "line": "        sql_str = \"SELECT id FROM wins_completed_wins_fy\"\n"}, {"line_no": 13, "char_start": 724, "char_end": 750, "line": "        if self.end_date:\n"}, {"line_no": 14, "char_start": 750, "char_end": 841, "line": "            sql_str = f\"{sql_str} where created <= '{self.end_date.strftime('%m-%d-%Y')}'\"\n"}, {"line_no": 15, "char_start": 841, "char_end": 842, "line": "\n"}, {"line_no": 17, "char_start": 886, "char_end": 922, "line": "            cursor.execute(sql_str)\n"}], "added": [{"line_no": 13, "char_start": 710, "char_end": 740, "line": "            if self.end_date:\n"}, {"line_no": 14, "char_start": 740, "char_end": 850, "line": "                cursor.execute(\"SELECT id FROM wins_completed_wins_fy where created <= %s\", (self.end_date,))\n"}, {"line_no": 15, "char_start": 850, "char_end": 868, "line": "            else:\n"}, {"line_no": 16, "char_start": 868, "char_end": 940, "line": "                cursor.execute(\"SELECT id FROM wins_completed_wins_fy\")\n"}]}, "char_changes": {"deleted": [{"char_start": 674, "char_end": 783, "chars": "sql_str = \"SELECT id FROM wins_completed_wins_fy\"\n        if self.end_date:\n            sql_str = f\"{sql_str}"}, {"char_start": 801, "char_end": 803, "chars": "'{"}, {"char_start": 816, "char_end": 920, "chars": ".strftime('%m-%d-%Y')}'\"\n\n        with connection.cursor() as cursor:\n            cursor.execute(sql_str"}], "added": [{"char_start": 674, "char_end": 809, "chars": "with connection.cursor() as cursor:\n            if self.end_date:\n                cursor.execute(\"SELECT id FROM wins_completed_wins_fy"}, {"char_start": 827, "char_end": 833, "chars": "%s\", ("}, {"char_start": 846, "char_end": 938, "chars": ",))\n            else:\n                cursor.execute(\"SELECT id FROM wins_completed_wins_fy\""}]}, "commit_link": "github.com/uktrade/export-wins-data/commit/307587cc00d2290a433bf74bd305aecffcbb05a2", "file_name": "wins/views/flat_csv.py", "vul_type": "cwe-089"}
{"func_name": "add_inverters", "func_src_before": "    def add_inverters(self):\n        interfaces = self.config.get_connection_interfaces()\n        for source in interfaces:\n            if source[\"type\"] == \"inverter\":\n\n                query = '''\n                    INSERT OR IGNORE INTO Inverters (\n                        Serial,\n                        EToday,\n                        ETotal\n                    ) VALUES (\n                        %s,\n                        %s,\n                        %s\n                    );\n                ''' % (source[\"serial_id\"], 0, source[\"prev_etotal\"])\n                self.c.execute(query)\n\n                query = '''\n                    UPDATE Inverters\n                    SET     \n                        Name='%s', \n                        Type='%s', \n                        SW_Version='%s', \n                        Status='%s',\n                        TimeStamp='%s'\n                    WHERE Serial='%s';\n                ''' % (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] )\n                self.c.execute(query)\n\n                self.db.commit()", "func_src_after": "    def add_inverters(self):\n        interfaces = self.config.get_connection_interfaces()\n        for source in interfaces:\n            if source[\"type\"] == \"inverter\":\n\n                query = '''\n                    INSERT OR IGNORE INTO Inverters (\n                        Serial,\n                        EToday,\n                        ETotal\n                    ) VALUES (\n                        ?,\n                        ?,\n                        ?\n                    );\n                '''\n                self.c.execute(query, (source[\"serial_id\"], 0, source[\"prev_etotal\"]))\n\n                query = '''\n                    UPDATE Inverters\n                    SET     \n                        Name=?, \n                        Type=?, \n                        SW_Version=?, \n                        Status=?,\n                        TimeStamp=?\n                    WHERE Serial=?;\n                '''\n                self.c.execute(query, (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] ))\n\n                self.db.commit()", "line_changes": {"deleted": [{"line_no": 12, "char_start": 378, "char_end": 406, "line": "                        %s,\n"}, {"line_no": 13, "char_start": 406, "char_end": 434, "line": "                        %s,\n"}, {"line_no": 14, "char_start": 434, "char_end": 461, "line": "                        %s\n"}, {"line_no": 16, "char_start": 484, "char_end": 554, "line": "                ''' % (source[\"serial_id\"], 0, source[\"prev_etotal\"])\n"}, {"line_no": 17, "char_start": 554, "char_end": 592, "line": "                self.c.execute(query)\n"}, {"line_no": 22, "char_start": 687, "char_end": 723, "line": "                        Name='%s', \n"}, {"line_no": 23, "char_start": 723, "char_end": 759, "line": "                        Type='%s', \n"}, {"line_no": 24, "char_start": 759, "char_end": 801, "line": "                        SW_Version='%s', \n"}, {"line_no": 25, "char_start": 801, "char_end": 838, "line": "                        Status='%s',\n"}, {"line_no": 26, "char_start": 838, "char_end": 877, "line": "                        TimeStamp='%s'\n"}, {"line_no": 27, "char_start": 877, "char_end": 916, "line": "                    WHERE Serial='%s';\n"}, {"line_no": 28, "char_start": 916, "char_end": 1057, "line": "                ''' % (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] )\n"}, {"line_no": 29, "char_start": 1057, "char_end": 1095, "line": "                self.c.execute(query)\n"}], "added": [{"line_no": 12, "char_start": 378, "char_end": 405, "line": "                        ?,\n"}, {"line_no": 13, "char_start": 405, "char_end": 432, "line": "                        ?,\n"}, {"line_no": 14, "char_start": 432, "char_end": 458, "line": "                        ?\n"}, {"line_no": 16, "char_start": 481, "char_end": 501, "line": "                '''\n"}, {"line_no": 17, "char_start": 501, "char_end": 588, "line": "                self.c.execute(query, (source[\"serial_id\"], 0, source[\"prev_etotal\"]))\n"}, {"line_no": 22, "char_start": 683, "char_end": 716, "line": "                        Name=?, \n"}, {"line_no": 23, "char_start": 716, "char_end": 749, "line": "                        Type=?, \n"}, {"line_no": 24, "char_start": 749, "char_end": 788, "line": "                        SW_Version=?, \n"}, {"line_no": 25, "char_start": 788, "char_end": 822, "line": "                        Status=?,\n"}, {"line_no": 26, "char_start": 822, "char_end": 858, "line": "                        TimeStamp=?\n"}, {"line_no": 27, "char_start": 858, "char_end": 894, "line": "                    WHERE Serial=?;\n"}, {"line_no": 28, "char_start": 894, "char_end": 914, "line": "                '''\n"}, {"line_no": 29, "char_start": 914, "char_end": 1072, "line": "                self.c.execute(query, (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] ))\n"}]}, "char_changes": {"deleted": [{"char_start": 402, "char_end": 404, "chars": "%s"}, {"char_start": 430, "char_end": 432, "chars": "%s"}, {"char_start": 458, "char_end": 460, "chars": "%s"}, {"char_start": 503, "char_end": 505, "chars": " %"}, {"char_start": 553, "char_end": 590, "chars": "\n                self.c.execute(query"}, {"char_start": 716, "char_end": 720, "chars": "'%s'"}, {"char_start": 752, "char_end": 756, "chars": "'%s'"}, {"char_start": 794, "char_end": 798, "chars": "'%s'"}, {"char_start": 832, "char_end": 836, "chars": "'%s'"}, {"char_start": 872, "char_end": 876, "chars": "'%s'"}, {"char_start": 910, "char_end": 914, "chars": "'%s'"}, {"char_start": 935, "char_end": 937, "chars": " %"}, {"char_start": 1056, "char_end": 1093, "chars": "\n                self.c.execute(query"}], "added": [{"char_start": 402, "char_end": 403, "chars": "?"}, {"char_start": 429, "char_end": 430, "chars": "?"}, {"char_start": 456, "char_end": 457, "chars": "?"}, {"char_start": 500, "char_end": 538, "chars": "\n                self.c.execute(query,"}, {"char_start": 712, "char_end": 713, "chars": "?"}, {"char_start": 745, "char_end": 746, "chars": "?"}, {"char_start": 784, "char_end": 785, "chars": "?"}, {"char_start": 819, "char_end": 820, "chars": "?"}, {"char_start": 856, "char_end": 857, "chars": "?"}, {"char_start": 891, "char_end": 892, "chars": "?"}, {"char_start": 913, "char_end": 951, "chars": "\n                self.c.execute(query,"}]}, "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "add_day_data_row", "func_src_before": "    def add_day_data_row(self, ts, data, prev_etotal):\n\n        if data['power'] > 0:\n\n            inv_serial = data['source']['serial_id']\n            query = '''\n               INSERT INTO DayData (\n                   TimeStamp,\n                   Serial,\n                   Power,\n                   TotalYield\n               ) VALUES (\n                   %s,\n                   %s,\n                   %s,\n                   %s\n               );\n            ''' % (ts, inv_serial, data['power'],  prev_etotal + data['energy'])\n            self.c.execute(query)", "func_src_after": "    def add_day_data_row(self, ts, data, prev_etotal):\n\n        if data['power'] > 0:\n\n            inv_serial = data['source']['serial_id']\n            query = '''\n               INSERT INTO DayData (\n                   TimeStamp,\n                   Serial,\n                   Power,\n                   TotalYield\n               ) VALUES (\n                   ?,\n                   ?,\n                   ?,\n                   ?\n               );\n            '''\n            self.c.execute(query, (ts, inv_serial, data['power'],  prev_etotal + data['energy']))", "line_changes": {"deleted": [{"line_no": 13, "char_start": 340, "char_end": 363, "line": "                   %s,\n"}, {"line_no": 14, "char_start": 363, "char_end": 386, "line": "                   %s,\n"}, {"line_no": 15, "char_start": 386, "char_end": 409, "line": "                   %s,\n"}, {"line_no": 16, "char_start": 409, "char_end": 431, "line": "                   %s\n"}, {"line_no": 18, "char_start": 449, "char_end": 530, "line": "            ''' % (ts, inv_serial, data['power'],  prev_etotal + data['energy'])\n"}, {"line_no": 19, "char_start": 530, "char_end": 563, "line": "            self.c.execute(query)\n"}], "added": [{"line_no": 13, "char_start": 340, "char_end": 362, "line": "                   ?,\n"}, {"line_no": 14, "char_start": 362, "char_end": 384, "line": "                   ?,\n"}, {"line_no": 15, "char_start": 384, "char_end": 406, "line": "                   ?,\n"}, {"line_no": 16, "char_start": 406, "char_end": 427, "line": "                   ?\n"}, {"line_no": 18, "char_start": 445, "char_end": 461, "line": "            '''\n"}, {"line_no": 19, "char_start": 461, "char_end": 558, "line": "            self.c.execute(query, (ts, inv_serial, data['power'],  prev_etotal + data['energy']))\n"}]}, "char_changes": {"deleted": [{"char_start": 359, "char_end": 361, "chars": "%s"}, {"char_start": 382, "char_end": 384, "chars": "%s"}, {"char_start": 405, "char_end": 407, "chars": "%s"}, {"char_start": 428, "char_end": 430, "chars": "%s"}, {"char_start": 464, "char_end": 466, "chars": " %"}, {"char_start": 529, "char_end": 562, "chars": "\n            self.c.execute(query"}], "added": [{"char_start": 359, "char_end": 360, "chars": "?"}, {"char_start": 381, "char_end": 382, "chars": "?"}, {"char_start": 403, "char_end": 404, "chars": "?"}, {"char_start": 425, "char_end": 426, "chars": "?"}, {"char_start": 460, "char_end": 494, "chars": "\n            self.c.execute(query,"}]}, "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "get_previous_yields", "func_src_before": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial = '%s'\n        ''' % (inverter_serial)\n        self.c.execute(query)\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "func_src_after": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial=?\n        '''\n        self.c.execute(query, (inverter_serial,))\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "line_changes": {"deleted": [{"line_no": 5, "char_start": 142, "char_end": 173, "line": "           WHERE Serial = '%s'\n"}, {"line_no": 6, "char_start": 173, "char_end": 205, "line": "        ''' % (inverter_serial)\n"}, {"line_no": 7, "char_start": 205, "char_end": 235, "line": "        self.c.execute(query)\n"}], "added": [{"line_no": 5, "char_start": 142, "char_end": 168, "line": "           WHERE Serial=?\n"}, {"line_no": 6, "char_start": 168, "char_end": 180, "line": "        '''\n"}, {"line_no": 7, "char_start": 180, "char_end": 230, "line": "        self.c.execute(query, (inverter_serial,))\n"}]}, "char_changes": {"deleted": [{"char_start": 165, "char_end": 172, "chars": " = '%s'"}, {"char_start": 184, "char_end": 204, "chars": " % (inverter_serial)"}], "added": [{"char_start": 165, "char_end": 167, "chars": "=?"}, {"char_start": 208, "char_end": 228, "chars": ", (inverter_serial,)"}]}, "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "update_inverter", "func_src_before": "    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp='%s', \n                Status='%s', \n                eToday='%s',\n                eTotal='%s'\n            WHERE Serial='%s';\n        ''' % (ts, status, etoday, etotal, inverter_serial)\n        self.c.execute(query)", "func_src_after": "    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp=?, \n                Status=?, \n                eToday=?,\n                eTotal=?\n            WHERE Serial=?;\n        '''\n        self.c.execute(query, (ts, status, etoday, etotal, inverter_serial))", "line_changes": {"deleted": [{"line_no": 5, "char_start": 146, "char_end": 179, "line": "                TimeStamp='%s', \n"}, {"line_no": 6, "char_start": 179, "char_end": 209, "line": "                Status='%s', \n"}, {"line_no": 7, "char_start": 209, "char_end": 238, "line": "                eToday='%s',\n"}, {"line_no": 8, "char_start": 238, "char_end": 266, "line": "                eTotal='%s'\n"}, {"line_no": 9, "char_start": 266, "char_end": 297, "line": "            WHERE Serial='%s';\n"}, {"line_no": 10, "char_start": 297, "char_end": 357, "line": "        ''' % (ts, status, etoday, etotal, inverter_serial)\n"}, {"line_no": 11, "char_start": 357, "char_end": 386, "line": "        self.c.execute(query)\n"}], "added": [{"line_no": 5, "char_start": 146, "char_end": 176, "line": "                TimeStamp=?, \n"}, {"line_no": 6, "char_start": 176, "char_end": 203, "line": "                Status=?, \n"}, {"line_no": 7, "char_start": 203, "char_end": 229, "line": "                eToday=?,\n"}, {"line_no": 8, "char_start": 229, "char_end": 254, "line": "                eTotal=?\n"}, {"line_no": 9, "char_start": 254, "char_end": 282, "line": "            WHERE Serial=?;\n"}, {"line_no": 10, "char_start": 282, "char_end": 294, "line": "        '''\n"}, {"line_no": 11, "char_start": 294, "char_end": 370, "line": "        self.c.execute(query, (ts, status, etoday, etotal, inverter_serial))\n"}]}, "char_changes": {"deleted": [{"char_start": 172, "char_end": 176, "chars": "'%s'"}, {"char_start": 202, "char_end": 206, "chars": "'%s'"}, {"char_start": 232, "char_end": 236, "chars": "'%s'"}, {"char_start": 261, "char_end": 265, "chars": "'%s'"}, {"char_start": 291, "char_end": 295, "chars": "'%s'"}, {"char_start": 308, "char_end": 310, "chars": " %"}, {"char_start": 356, "char_end": 385, "chars": "\n        self.c.execute(query"}], "added": [{"char_start": 172, "char_end": 173, "chars": "?"}, {"char_start": 199, "char_end": 200, "chars": "?"}, {"char_start": 226, "char_end": 227, "chars": "?"}, {"char_start": 252, "char_end": 253, "chars": "?"}, {"char_start": 279, "char_end": 280, "chars": "?"}, {"char_start": 293, "char_end": 323, "chars": "\n        self.c.execute(query,"}]}, "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "add_month_data_row", "func_src_before": "    def add_month_data_row(self, inverter_serial, ts, etoday, etotal):\n\n        y = datetime.fromtimestamp(ts) - timedelta(days=1)\n        y_ts = int(datetime(y.year, y.month, y.day, 23, tzinfo=pytz.utc).timestamp())\n\n        query = '''\n            INSERT INTO MonthData (\n                TimeStamp,\n                Serial,\n                DayYield,\n                TotalYield                                 \n            ) VALUES (\n                %s,\n                %s,\n                %s,\n                %s\n            );\n        ''' % (y_ts, inverter_serial, etoday, etotal)\n        self.c.execute(query)", "func_src_after": "    def add_month_data_row(self, inverter_serial, ts, etoday, etotal):\n\n        y = datetime.fromtimestamp(ts) - timedelta(days=1)\n        y_ts = int(datetime(y.year, y.month, y.day, 23, tzinfo=pytz.utc).timestamp())\n\n        query = '''\n            INSERT INTO MonthData (\n                TimeStamp,\n                Serial,\n                DayYield,\n                TotalYield                                 \n            ) VALUES (\n                ?,\n                ?,\n                ?,\n                ?\n            );\n        '''\n        self.c.execute(query, (y_ts, inverter_serial, etoday, etotal))", "line_changes": {"deleted": [{"line_no": 13, "char_start": 434, "char_end": 454, "line": "                %s,\n"}, {"line_no": 14, "char_start": 454, "char_end": 474, "line": "                %s,\n"}, {"line_no": 15, "char_start": 474, "char_end": 494, "line": "                %s,\n"}, {"line_no": 16, "char_start": 494, "char_end": 513, "line": "                %s\n"}, {"line_no": 18, "char_start": 528, "char_end": 582, "line": "        ''' % (y_ts, inverter_serial, etoday, etotal)\n"}, {"line_no": 19, "char_start": 582, "char_end": 611, "line": "        self.c.execute(query)\n"}], "added": [{"line_no": 13, "char_start": 434, "char_end": 453, "line": "                ?,\n"}, {"line_no": 14, "char_start": 453, "char_end": 472, "line": "                ?,\n"}, {"line_no": 15, "char_start": 472, "char_end": 491, "line": "                ?,\n"}, {"line_no": 16, "char_start": 491, "char_end": 509, "line": "                ?\n"}, {"line_no": 18, "char_start": 524, "char_end": 536, "line": "        '''\n"}, {"line_no": 19, "char_start": 536, "char_end": 606, "line": "        self.c.execute(query, (y_ts, inverter_serial, etoday, etotal))\n"}]}, "char_changes": {"deleted": [{"char_start": 450, "char_end": 452, "chars": "%s"}, {"char_start": 470, "char_end": 472, "chars": "%s"}, {"char_start": 490, "char_end": 492, "chars": "%s"}, {"char_start": 510, "char_end": 512, "chars": "%s"}, {"char_start": 539, "char_end": 541, "chars": " %"}, {"char_start": 581, "char_end": 610, "chars": "\n        self.c.execute(query"}], "added": [{"char_start": 450, "char_end": 451, "chars": "?"}, {"char_start": 469, "char_end": 470, "chars": "?"}, {"char_start": 488, "char_end": 489, "chars": "?"}, {"char_start": 507, "char_end": 508, "chars": "?"}, {"char_start": 535, "char_end": 565, "chars": "\n        self.c.execute(query,"}]}, "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "add_consumption_data_row", "func_src_before": "    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    %s,\n                    %s,\n                    %s\n                );\n            ''' % (ts, 0, 0)\n            self.c.execute(query)\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + %s,\n                PowerUsed = PowerUsed + %s\n                WHERE TimeStamp = %s;\n            ''' % (energy_used, power_used, ts)\n\n            self.c.execute(query)\n\n            self.db.commit()", "func_src_after": "    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    ?,\n                    ?,\n                    ?\n                );\n            '''\n            self.c.execute(query, (ts, 0, 0))\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + ?,\n                PowerUsed = PowerUsed + ?\n                WHERE TimeStamp=?;\n            '''\n\n            self.c.execute(query, (energy_used, power_used, ts))\n\n            self.db.commit()", "line_changes": {"deleted": [{"line_no": 11, "char_start": 326, "char_end": 350, "line": "                    %s,\n"}, {"line_no": 12, "char_start": 350, "char_end": 374, "line": "                    %s,\n"}, {"line_no": 13, "char_start": 374, "char_end": 397, "line": "                    %s\n"}, {"line_no": 15, "char_start": 416, "char_end": 445, "line": "            ''' % (ts, 0, 0)\n"}, {"line_no": 16, "char_start": 445, "char_end": 479, "line": "            self.c.execute(query)\n"}, {"line_no": 20, "char_start": 544, "char_end": 590, "line": "                EnergyUsed = EnergyUsed + %s,\n"}, {"line_no": 21, "char_start": 590, "char_end": 633, "line": "                PowerUsed = PowerUsed + %s\n"}, {"line_no": 22, "char_start": 633, "char_end": 671, "line": "                WHERE TimeStamp = %s;\n"}, {"line_no": 23, "char_start": 671, "char_end": 719, "line": "            ''' % (energy_used, power_used, ts)\n"}, {"line_no": 25, "char_start": 720, "char_end": 754, "line": "            self.c.execute(query)\n"}], "added": [{"line_no": 11, "char_start": 326, "char_end": 349, "line": "                    ?,\n"}, {"line_no": 12, "char_start": 349, "char_end": 372, "line": "                    ?,\n"}, {"line_no": 13, "char_start": 372, "char_end": 394, "line": "                    ?\n"}, {"line_no": 15, "char_start": 413, "char_end": 429, "line": "            '''\n"}, {"line_no": 16, "char_start": 429, "char_end": 475, "line": "            self.c.execute(query, (ts, 0, 0))\n"}, {"line_no": 20, "char_start": 540, "char_end": 585, "line": "                EnergyUsed = EnergyUsed + ?,\n"}, {"line_no": 21, "char_start": 585, "char_end": 627, "line": "                PowerUsed = PowerUsed + ?\n"}, {"line_no": 22, "char_start": 627, "char_end": 662, "line": "                WHERE TimeStamp=?;\n"}, {"line_no": 23, "char_start": 662, "char_end": 678, "line": "            '''\n"}, {"line_no": 25, "char_start": 679, "char_end": 744, "line": "            self.c.execute(query, (energy_used, power_used, ts))\n"}]}, "char_changes": {"deleted": [{"char_start": 346, "char_end": 348, "chars": "%s"}, {"char_start": 370, "char_end": 372, "chars": "%s"}, {"char_start": 394, "char_end": 396, "chars": "%s"}, {"char_start": 431, "char_end": 444, "chars": " % (ts, 0, 0)"}, {"char_start": 586, "char_end": 588, "chars": "%s"}, {"char_start": 630, "char_end": 632, "chars": "%s"}, {"char_start": 664, "char_end": 669, "chars": " = %s"}, {"char_start": 686, "char_end": 718, "chars": " % (energy_used, power_used, ts)"}], "added": [{"char_start": 346, "char_end": 347, "chars": "?"}, {"char_start": 369, "char_end": 370, "chars": "?"}, {"char_start": 392, "char_end": 393, "chars": "?"}, {"char_start": 461, "char_end": 473, "chars": ", (ts, 0, 0)"}, {"char_start": 582, "char_end": 583, "chars": "?"}, {"char_start": 625, "char_end": 626, "chars": "?"}, {"char_start": 658, "char_end": 660, "chars": "=?"}, {"char_start": 711, "char_end": 742, "chars": ", (energy_used, power_used, ts)"}]}, "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "on_save", "func_src_before": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            f\"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values ('{self.ip_address}', '{self.user_agent}', '{self.referrer}', '{self.full_path}', '{self.visit_time}');\")\n        connection.commit()\n        connection.close()\n        return 0", "func_src_after": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            \"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values (%s, %s, %s, %s, %s);\",\n            (str(self.ip_address), str(self.user_agent), str(self.referrer), str(self.full_path), self.visit_time))\n        connection.commit()\n        connection.close()\n        return 0", "line_changes": {"deleted": [{"line_no": 5, "char_start": 122, "char_end": 328, "line": "            f\"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values ('{self.ip_address}', '{self.user_agent}', '{self.referrer}', '{self.full_path}', '{self.visit_time}');\")\n"}], "added": [{"line_no": 5, "char_start": 122, "char_end": 245, "line": "            \"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values (%s, %s, %s, %s, %s);\",\n"}, {"line_no": 6, "char_start": 245, "char_end": 361, "line": "            (str(self.ip_address), str(self.user_agent), str(self.referrer), str(self.full_path), self.visit_time))\n"}]}, "char_changes": {"deleted": [{"char_start": 134, "char_end": 135, "chars": "f"}, {"char_start": 223, "char_end": 225, "chars": "'{"}, {"char_start": 240, "char_end": 246, "chars": "}', '{"}, {"char_start": 261, "char_end": 267, "chars": "}', '{"}, {"char_start": 280, "char_end": 286, "chars": "}', '{"}, {"char_start": 300, "char_end": 306, "chars": "}', '{"}, {"char_start": 321, "char_end": 326, "chars": "}');\""}], "added": [{"char_start": 222, "char_end": 262, "chars": "%s, %s, %s, %s, %s);\",\n            (str("}, {"char_start": 277, "char_end": 284, "chars": "), str("}, {"char_start": 299, "char_end": 306, "chars": "), str("}, {"char_start": 319, "char_end": 326, "chars": "), str("}, {"char_start": 340, "char_end": 343, "chars": "), "}, {"char_start": 358, "char_end": 359, "chars": ")"}]}, "commit_link": "github.com/onewyoming/onewyoming/commit/54fc7b076fda2de74eeb55e6b75b28e09ef231c2", "file_name": "experimental/python/buford/model/visitor.py", "vul_type": "cwe-089"}
{"func_name": "load_recipes", "func_src_before": "    def load_recipes(self):\n        recipes = []\n        try:\n            # Establishing a connection\n            connection = sqlite3.connect('brewdie.db')\n            cursor = connection.cursor()\n        \n            # Getting all the recipes\n            for row in cursor.execute('SELECT * FROM Recipes'):\n                # Converting a recipe database row into a python object\n                recipe = Recipe(row[0], row[1], row[2])\n\n                # Adding the malts\n                for malt_row in cursor.execute('SELECT * FROM Malts WHERE recipe_name=\\'%s\\'' % recipe.name):\n                    recipe.malts[malt_row[1]] = malt_row[2]\n\n                # Adding the rests\n                for rest_row in cursor.execute('SELECT * FROM Rests WHERE recipe_name=\\'%s\\' ORDER BY position ASC' % recipe.name):\n                    recipe.rests.append(Rest(rest_row[1], rest_row[2], rest_row[3]))\n\n                # Adding the hop dosages\n                for hop_dosage_row in cursor.execute('SELECT * FROM HopDosages WHERE recipe_name=\\'%s\\'' % recipe.name):\n                    recipe.hop_dosages.append(HopDosage(hop_dosage_row[1], hop_dosage_row[3], hop_dosage_row[2]))\n\n                # Adding the recipe to the list of recipes\n                recipes.append(recipe)\n\n        except sqlite3.Error as e:\n            print(\"Something went wrong\")\n            print(e)\n            if connection:\n                connection.rollback()\n            return\n\n        finally:\n            if connection:\n                connection.close()\n        return recipes", "func_src_after": "    def load_recipes(self):\n        recipes = []\n        try:\n            # Establishing a connection\n            connection = sqlite3.connect('brewdie.db')\n            cursor = connection.cursor()\n        \n            # Getting all the recipes\n            for row in cursor.execute('SELECT * FROM Recipes'):\n                # Converting a recipe database row into a python object\n                recipe = Recipe(row[0], row[1], row[2])\n                recipe_name = (recipe.name, )\n\n                # Adding the malts\n                for malt_row in cursor.execute('SELECT * FROM Malts WHERE recipe_name=?', recipe_name):\n                    recipe.malts[malt_row[1]] = malt_row[2]\n\n                # Adding the rests\n                for rest_row in cursor.execute('SELECT * FROM Rests WHERE recipe_name=? ORDER BY position ASC', recipe_name):\n                    recipe.rests.append(Rest(rest_row[1], rest_row[2], rest_row[3]))\n\n                # Adding the hop dosages\n                for hop_dosage_row in cursor.execute('SELECT * FROM HopDosages WHERE recipe_name=?', recipe_name):\n                    recipe.hop_dosages.append(HopDosage(hop_dosage_row[1], hop_dosage_row[3], hop_dosage_row[2]))\n\n                # Adding the recipe to the list of recipes\n                recipes.append(recipe)\n\n        except sqlite3.Error as e:\n            print(\"Something went wrong\")\n            print(e)\n            if connection:\n                connection.rollback()\n            return\n\n        finally:\n            if connection:\n                connection.close()\n        return recipes", "line_changes": {"deleted": [{"line_no": 14, "char_start": 473, "char_end": 583, "line": "                for malt_row in cursor.execute('SELECT * FROM Malts WHERE recipe_name=\\'%s\\'' % recipe.name):\n"}, {"line_no": 18, "char_start": 679, "char_end": 811, "line": "                for rest_row in cursor.execute('SELECT * FROM Rests WHERE recipe_name=\\'%s\\' ORDER BY position ASC' % recipe.name):\n"}, {"line_no": 22, "char_start": 938, "char_end": 1059, "line": "                for hop_dosage_row in cursor.execute('SELECT * FROM HopDosages WHERE recipe_name=\\'%s\\'' % recipe.name):\n"}], "added": [{"line_no": 12, "char_start": 437, "char_end": 483, "line": "                recipe_name = (recipe.name, )\n"}, {"line_no": 15, "char_start": 519, "char_end": 623, "line": "                for malt_row in cursor.execute('SELECT * FROM Malts WHERE recipe_name=?', recipe_name):\n"}, {"line_no": 19, "char_start": 719, "char_end": 845, "line": "                for rest_row in cursor.execute('SELECT * FROM Rests WHERE recipe_name=? ORDER BY position ASC', recipe_name):\n"}, {"line_no": 23, "char_start": 972, "char_end": 1087, "line": "                for hop_dosage_row in cursor.execute('SELECT * FROM HopDosages WHERE recipe_name=?', recipe_name):\n"}]}, "char_changes": {"deleted": [{"char_start": 559, "char_end": 568, "chars": "\\'%s\\'' %"}, {"char_start": 575, "char_end": 576, "chars": "."}, {"char_start": 765, "char_end": 771, "chars": "\\'%s\\'"}, {"char_start": 794, "char_end": 796, "chars": " %"}, {"char_start": 803, "char_end": 804, "chars": "."}, {"char_start": 1035, "char_end": 1044, "chars": "\\'%s\\'' %"}, {"char_start": 1051, "char_end": 1052, "chars": "."}], "added": [{"char_start": 436, "char_end": 482, "chars": "\n                recipe_name = (recipe.name, )"}, {"char_start": 605, "char_end": 608, "chars": "?',"}, {"char_start": 615, "char_end": 616, "chars": "_"}, {"char_start": 805, "char_end": 806, "chars": "?"}, {"char_start": 829, "char_end": 830, "chars": ","}, {"char_start": 837, "char_end": 838, "chars": "_"}, {"char_start": 1069, "char_end": 1072, "chars": "?',"}, {"char_start": 1079, "char_end": 1080, "chars": "_"}]}, "commit_link": "github.com/LukasJaeger307/brewdie/commit/c603201e401e414097358f32a23ca5521aa39dec", "file_name": "brewdiedb.py", "vul_type": "cwe-089"}
{"func_name": "create_account", "func_src_before": "async def create_account(name: str, password: str):\n    '''db\uc5d0 \uacc4\uc815\uc744 \uc0dd\uc131\ud55c\ub2e4.'''\n    global _pool\n    uid = -1\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\\\n                    \"INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)\"\\\n                    % (name, password))\n                uid = conn.insert_id()\n        except Exception as ex:\n            await conn.rollback()\n            _error_report(ex)\n            return False, -1  \n        await conn.commit()\n\n    return True, uid", "func_src_after": "async def create_account(name: str, password: str):\n    '''db\uc5d0 \uacc4\uc815\uc744 \uc0dd\uc131\ud55c\ub2e4.'''\n    global _pool\n    uid = -1\n    prevented_name = pymysql.escape_string(name)\n    query = \"INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)\" % (prevented_name, password)\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(query)\n                uid = conn.insert_id()\n        except Exception as ex:\n            await conn.rollback()\n            _error_report(ex)\n            return False, -1  \n        await conn.commit()\n\n    return True, uid", "line_changes": {"deleted": [{"line_no": 8, "char_start": 216, "char_end": 255, "line": "                await cursor.execute(\\\n"}, {"line_no": 9, "char_start": 255, "char_end": 357, "line": "                    \"INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)\"\\\n"}, {"line_no": 10, "char_start": 357, "char_end": 397, "line": "                    % (name, password))\n"}], "added": [{"line_no": 5, "char_start": 106, "char_end": 155, "line": "    prevented_name = pymysql.escape_string(name)\n"}, {"line_no": 6, "char_start": 155, "char_end": 277, "line": "    query = \"INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)\" % (prevented_name, password)\n"}, {"line_no": 10, "char_start": 387, "char_end": 431, "line": "                await cursor.execute(query)\n"}]}, "char_changes": {"deleted": [{"char_start": 253, "char_end": 395, "chars": "\\\n                    \"INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)\"\\\n                    % (name, password)"}], "added": [{"char_start": 106, "char_end": 277, "chars": "    prevented_name = pymysql.escape_string(name)\n    query = \"INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)\" % (prevented_name, password)\n"}, {"char_start": 424, "char_end": 429, "chars": "query"}]}, "commit_link": "github.com/kyojuceles/mud/commit/47f5aa6aa2e82de7ce2a440aea870958edf0ae77", "file_name": "db/db_processor_mysql.py", "vul_type": "cwe-089"}
{"func_name": "get_player_info", "func_src_before": "async def get_player_info(name: str) -> tuple:\n    '''db\uc5d0\uc11c \ud50c\ub808\uc774\uc5b4 \uc815\ubcf4\ub97c \uc5bb\uc5b4\uc628\ub2e4.'''\n    global _pool\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'\" % name)\n                data = cursor.fetchone()\n        except Exception as ex:\n            _error_report(ex)\n            return tuple()\n\n    if data is None:\n        return tuple()\n\n    return data", "func_src_after": "async def get_player_info(name: str) -> tuple:\n    '''db\uc5d0\uc11c \ud50c\ub808\uc774\uc5b4 \uc815\ubcf4\ub97c \uc5bb\uc5b4\uc628\ub2e4.'''\n    global _pool\n    prevented_name = pymysql.escape_string(name)\n    query = \"SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'\" % prevented_name\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(query)\n                data = cursor.fetchone()\n        except Exception as ex:\n            _error_report(ex)\n            return tuple()\n\n    if data is None:\n        return tuple()\n\n    return data", "line_changes": {"deleted": [{"line_no": 7, "char_start": 204, "char_end": 320, "line": "                await cursor.execute(\"SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'\" % name)\n"}], "added": [{"line_no": 4, "char_start": 94, "char_end": 143, "line": "    prevented_name = pymysql.escape_string(name)\n"}, {"line_no": 5, "char_start": 143, "char_end": 243, "line": "    query = \"SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'\" % prevented_name\n"}, {"line_no": 9, "char_start": 353, "char_end": 397, "line": "                await cursor.execute(query)\n"}]}, "char_changes": {"deleted": [{"char_start": 241, "char_end": 318, "chars": "\"SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'\" % name"}], "added": [{"char_start": 94, "char_end": 243, "chars": "    prevented_name = pymysql.escape_string(name)\n    query = \"SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'\" % prevented_name\n"}, {"char_start": 390, "char_end": 395, "chars": "query"}]}, "commit_link": "github.com/kyojuceles/mud/commit/47f5aa6aa2e82de7ce2a440aea870958edf0ae77", "file_name": "db/db_processor_mysql.py", "vul_type": "cwe-089"}
{"func_name": "get_game_info", "func_src_before": "def get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\" % game)\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)", "func_src_after": "def get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\", (game,))\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 94, "char_end": 183, "line": "    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\" % game)\n"}], "added": [{"line_no": 4, "char_start": 94, "char_end": 185, "line": "    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\", (game,))\n"}]}, "char_changes": {"deleted": [{"char_start": 174, "char_end": 177, "chars": " % "}], "added": [{"char_start": 174, "char_end": 177, "chars": ", ("}, {"char_start": 181, "char_end": 183, "chars": ",)"}]}, "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/common.py", "vul_type": "cwe-089"}
{"func_name": "build_board", "func_src_before": "def build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\" % game)\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)", "func_src_after": "def build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\", (game,))\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)", "line_changes": {"deleted": [{"line_no": 11, "char_start": 303, "char_end": 380, "line": "    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\" % game)\n"}], "added": [{"line_no": 11, "char_start": 303, "char_end": 382, "line": "    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\", (game,))\n"}]}, "char_changes": {"deleted": [{"char_start": 371, "char_end": 374, "chars": " % "}], "added": [{"char_start": 371, "char_end": 374, "chars": ", ("}, {"char_start": 378, "char_end": 380, "chars": ",)"}]}, "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/common.py", "vul_type": "cwe-089"}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\" % (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\", (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "line_changes": {"deleted": [{"line_no": 35, "char_start": 1148, "char_end": 1261, "line": "    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\" % (player1,player2,size))\n"}], "added": [{"line_no": 35, "char_start": 1148, "char_end": 1260, "line": "    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\", (player1,player2,size))\n"}]}, "char_changes": {"deleted": [{"char_start": 1234, "char_end": 1236, "chars": " %"}], "added": [{"char_start": 1234, "char_end": 1235, "chars": ","}]}, "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/create_game.py", "vul_type": "cwe-089"}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\" % (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\" % (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\" % (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "line_changes": {"deleted": [{"line_no": 50, "char_start": 1369, "char_end": 1479, "line": "        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\" % (other_player_name,game))\n"}, {"line_no": 63, "char_start": 1806, "char_end": 1927, "line": "        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\" % (game,x,y,letter))\n"}, {"line_no": 76, "char_start": 2237, "char_end": 2328, "line": "            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\" % (result,game))\n"}], "added": [{"line_no": 50, "char_start": 1369, "char_end": 1478, "line": "        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n"}, {"line_no": 63, "char_start": 1805, "char_end": 1925, "line": "        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n"}, {"line_no": 76, "char_start": 2235, "char_end": 2325, "line": "            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n"}]}, "char_changes": {"deleted": [{"char_start": 1450, "char_end": 1452, "chars": " %"}, {"char_start": 1905, "char_end": 1907, "chars": " %"}, {"char_start": 2310, "char_end": 2312, "chars": " %"}], "added": [{"char_start": 1450, "char_end": 1451, "chars": ","}, {"char_start": 1904, "char_end": 1905, "chars": ","}, {"char_start": 2308, "char_end": 2309, "chars": ","}]}, "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/move.py", "vul_type": "cwe-089"}
{"func_name": "get_game_info", "func_src_before": "def get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\", (game,))\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)", "func_src_after": "def get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %s;\", (game,))\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 94, "char_end": 185, "line": "    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\", (game,))\n"}], "added": [{"line_no": 4, "char_start": 94, "char_end": 185, "line": "    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %s;\", (game,))\n"}]}, "char_changes": {"deleted": [{"char_start": 171, "char_end": 172, "chars": "d"}], "added": [{"char_start": 171, "char_end": 172, "chars": "s"}]}, "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/ee20e755caaf20bfabd7cfedf2f4c4eb24b7cf15", "file_name": "cgi/common.py", "vul_type": "cwe-089"}
{"func_name": "build_board", "func_src_before": "def build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\", (game,))\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)", "func_src_after": "def build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %s;\", (game,))\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)", "line_changes": {"deleted": [{"line_no": 11, "char_start": 303, "char_end": 382, "line": "    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\", (game,))\n"}], "added": [{"line_no": 11, "char_start": 303, "char_end": 382, "line": "    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %s;\", (game,))\n"}]}, "char_changes": {"deleted": [{"char_start": 368, "char_end": 369, "chars": "d"}], "added": [{"char_start": 368, "char_end": 369, "chars": "s"}]}, "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/ee20e755caaf20bfabd7cfedf2f4c4eb24b7cf15", "file_name": "cgi/common.py", "vul_type": "cwe-089"}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\", (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(%s,%s,%s);\"\"\", (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "line_changes": {"deleted": [{"line_no": 35, "char_start": 1148, "char_end": 1260, "line": "    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\", (player1,player2,size))\n"}], "added": [{"line_no": 35, "char_start": 1148, "char_end": 1256, "line": "    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(%s,%s,%s);\"\"\", (player1,player2,size))\n"}]}, "char_changes": {"deleted": [{"char_start": 1217, "char_end": 1218, "chars": "\""}, {"char_start": 1220, "char_end": 1223, "chars": "\",\""}, {"char_start": 1225, "char_end": 1226, "chars": "\""}, {"char_start": 1228, "char_end": 1229, "chars": "d"}], "added": [{"char_start": 1219, "char_end": 1220, "chars": ","}, {"char_start": 1224, "char_end": 1225, "chars": "s"}]}, "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/ee20e755caaf20bfabd7cfedf2f4c4eb24b7cf15", "file_name": "cgi/create_game.py", "vul_type": "cwe-089"}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=%s WHERE id=%s;\"\"\", (other_player_name+\":resignation\",game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%s,%s,%s,%s,NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=%s WHERE id=%s;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "line_changes": {"deleted": [{"line_no": 50, "char_start": 1369, "char_end": 1478, "line": "        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n"}, {"line_no": 63, "char_start": 1805, "char_end": 1925, "line": "        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n"}, {"line_no": 76, "char_start": 2235, "char_end": 2325, "line": "            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n"}], "added": [{"line_no": 50, "char_start": 1369, "char_end": 1479, "line": "        cursor.execute(\"\"\"UPDATE games SET state=%s WHERE id=%s;\"\"\", (other_player_name+\":resignation\",game))\n"}, {"line_no": 63, "char_start": 1806, "char_end": 1924, "line": "        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%s,%s,%s,%s,NOW());\"\"\", (game,x,y,letter))\n"}, {"line_no": 76, "char_start": 2234, "char_end": 2322, "line": "            cursor.execute(\"\"\"UPDATE games SET state=%s WHERE id=%s;\"\"\", (result,game))\n"}]}, "char_changes": {"deleted": [{"char_start": 1418, "char_end": 1419, "chars": "\""}, {"char_start": 1421, "char_end": 1434, "chars": ":resignation\""}, {"char_start": 1445, "char_end": 1446, "chars": "d"}, {"char_start": 1881, "char_end": 1882, "chars": "d"}, {"char_start": 1884, "char_end": 1885, "chars": "d"}, {"char_start": 1887, "char_end": 1890, "chars": "d,\""}, {"char_start": 1892, "char_end": 1893, "chars": "\""}, {"char_start": 2288, "char_end": 2289, "chars": "\""}, {"char_start": 2291, "char_end": 2292, "chars": "\""}, {"char_start": 2303, "char_end": 2304, "chars": "d"}], "added": [{"char_start": 1431, "char_end": 1432, "chars": "s"}, {"char_start": 1456, "char_end": 1471, "chars": "+\":resignation\""}, {"char_start": 1882, "char_end": 1883, "chars": "s"}, {"char_start": 1885, "char_end": 1886, "chars": "s"}, {"char_start": 1888, "char_end": 1890, "chars": "s,"}, {"char_start": 2300, "char_end": 2301, "chars": "s"}]}, "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/ee20e755caaf20bfabd7cfedf2f4c4eb24b7cf15", "file_name": "cgi/move.py", "vul_type": "cwe-089"}
{"func_name": "create_video", "func_src_before": "def create_video(playlist_id, title, thumbnail, position):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES('{playlist_id}', '{title}', '{thumbnail}', '{position}');\".format(\n            playlist_id=playlist_id, title=title, thumbnail=thumbnail, position=position))\n    db.commit()\n    db.close()", "func_src_after": "def create_video(playlist_id, title, thumbnail, position):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES(%s, %s, %s, %s);\", (playlist_id, title, thumbnail, position,))\n    db.commit()\n    db.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 135, "char_end": 278, "line": "        \"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES('{playlist_id}', '{title}', '{thumbnail}', '{position}');\".format(\n"}, {"line_no": 6, "char_start": 278, "char_end": 369, "line": "            playlist_id=playlist_id, title=title, thumbnail=thumbnail, position=position))\n"}], "added": [{"line_no": 5, "char_start": 135, "char_end": 274, "line": "        \"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES(%s, %s, %s, %s);\", (playlist_id, title, thumbnail, position,))\n"}]}, "char_changes": {"deleted": [{"char_start": 211, "char_end": 302, "chars": "'{playlist_id}', '{title}', '{thumbnail}', '{position}');\".format(\n            playlist_id="}, {"char_start": 315, "char_end": 321, "chars": "title="}, {"char_start": 328, "char_end": 338, "chars": "thumbnail="}, {"char_start": 357, "char_end": 366, "chars": "=position"}], "added": [{"char_start": 211, "char_end": 231, "chars": "%s, %s, %s, %s);\", ("}, {"char_start": 270, "char_end": 271, "chars": ","}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "main_test.py", "vul_type": "cwe-089"}
{"func_name": "create_playlist", "func_src_before": "def create_playlist(name):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))\n    db.commit()\n    db.close()", "func_src_after": "def create_playlist(name):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))\n    db.commit()\n    db.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 103, "char_end": 197, "line": "        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))\n"}], "added": [{"line_no": 5, "char_start": 103, "char_end": 182, "line": "        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))\n"}]}, "char_changes": {"deleted": [{"char_start": 163, "char_end": 194, "chars": "'{name}', 0);\".format(name=name"}], "added": [{"char_start": 163, "char_end": 179, "chars": "%s, 0);\", (name,"}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "main_test.py", "vul_type": "cwe-089"}
{"func_name": "retrieve_playlist_by_id", "func_src_before": "def retrieve_playlist_by_id(id, db):\n    db.execute(\n        \"SELECT id, name, video_position from playlist WHERE id={id};\".format(id=id))\n    row = db.fetchone()\n    return row", "func_src_after": "def retrieve_playlist_by_id(id, db):\n    db.execute(\n        \"SELECT id, name, video_position from playlist WHERE id=%s;\", (id,))\n    row = db.fetchone()\n    return row", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 139, "line": "        \"SELECT id, name, video_position from playlist WHERE id={id};\".format(id=id))\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 130, "line": "        \"SELECT id, name, video_position from playlist WHERE id=%s;\", (id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 117, "char_end": 136, "chars": "{id};\".format(id=id"}], "added": [{"char_start": 117, "char_end": 127, "chars": "%s;\", (id,"}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089"}
{"func_name": "delete_playlist", "func_src_before": "def delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id={id};\".format(id=id))", "func_src_after": "def delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id=%s;\", (id,))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 29, "char_end": 96, "line": "    db.execute(\"DELETE FROM playlist where id={id};\".format(id=id))\n"}], "added": [{"line_no": 2, "char_start": 29, "char_end": 87, "line": "    db.execute(\"DELETE FROM playlist where id=%s;\", (id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 75, "char_end": 94, "chars": "{id};\".format(id=id"}], "added": [{"char_start": 75, "char_end": 85, "chars": "%s;\", (id,"}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089"}
{"func_name": "update_playlist", "func_src_before": "def update_playlist(id, name, db):\n    db.execute(\n        \"UPDATE playlist SET name='{name}' WHERE id={id};\".format(name=name, id=id))", "func_src_after": "def update_playlist(id, name, db):\n    db.execute(\"UPDATE playlist SET name=%s WHERE id=%s;\", (name, id,))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 35, "char_end": 51, "line": "    db.execute(\n"}, {"line_no": 3, "char_start": 51, "char_end": 135, "line": "        \"UPDATE playlist SET name='{name}' WHERE id={id};\".format(name=name, id=id))\n"}], "added": [{"line_no": 2, "char_start": 35, "char_end": 106, "line": "    db.execute(\"UPDATE playlist SET name=%s WHERE id=%s;\", (name, id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 50, "char_end": 59, "chars": "\n        "}, {"char_start": 85, "char_end": 93, "chars": "'{name}'"}, {"char_start": 103, "char_end": 122, "chars": "{id};\".format(name="}, {"char_start": 130, "char_end": 133, "chars": "=id"}], "added": [{"char_start": 76, "char_end": 78, "chars": "%s"}, {"char_start": 88, "char_end": 95, "chars": "%s;\", ("}, {"char_start": 103, "char_end": 104, "chars": ","}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089"}
{"func_name": "update_playlist_video_position", "func_src_before": "def update_playlist_video_position(id, position, db):\n    db.execute(\n        \"UPDATE playlist SET video_position='{position}' WHERE id={id};\".format(position=position, id=id))", "func_src_after": "def update_playlist_video_position(id, position, db):\n    db.execute(\"UPDATE playlist SET video_position=%s WHERE id=%s;\",\n               (position, id))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 54, "char_end": 70, "line": "    db.execute(\n"}, {"line_no": 3, "char_start": 70, "char_end": 176, "line": "        \"UPDATE playlist SET video_position='{position}' WHERE id={id};\".format(position=position, id=id))\n"}], "added": [{"line_no": 2, "char_start": 54, "char_end": 123, "line": "    db.execute(\"UPDATE playlist SET video_position=%s WHERE id=%s;\",\n"}, {"line_no": 3, "char_start": 123, "char_end": 153, "line": "               (position, id))\n"}]}, "char_changes": {"deleted": [{"char_start": 69, "char_end": 78, "chars": "\n        "}, {"char_start": 114, "char_end": 172, "chars": "'{position}' WHERE id={id};\".format(position=position, id="}], "added": [{"char_start": 105, "char_end": 149, "chars": "%s WHERE id=%s;\",\n               (position, "}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089"}
{"func_name": "create_playlist", "func_src_before": "def create_playlist(name, db):\n    db.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))", "func_src_after": "def create_playlist(name, db):\n    db.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 47, "char_end": 140, "line": "        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))\n"}], "added": [{"line_no": 3, "char_start": 47, "char_end": 125, "line": "        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 138, "chars": "'{name}', 0);\".format(name=name"}], "added": [{"char_start": 107, "char_end": 123, "chars": "%s, 0);\", (name,"}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089"}
{"func_name": "retrieve_videos_from_playlist", "func_src_before": "def retrieve_videos_from_playlist(playlist_id, db):\n    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id={playlist_id} ORDER BY position ASC;\".format(\n        playlist_id=playlist_id))\n    rows = db.fetchall()\n    return rows", "func_src_after": "def retrieve_videos_from_playlist(playlist_id, db):\n    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id=%s ORDER BY position ASC;\", (playlist_id,))\n    rows = db.fetchall()\n    return rows", "line_changes": {"deleted": [{"line_no": 2, "char_start": 52, "char_end": 181, "line": "    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id={playlist_id} ORDER BY position ASC;\".format(\n"}, {"line_no": 3, "char_start": 181, "char_end": 215, "line": "        playlist_id=playlist_id))\n"}], "added": [{"line_no": 2, "char_start": 52, "char_end": 179, "line": "    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id=%s ORDER BY position ASC;\", (playlist_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 135, "char_end": 148, "chars": "{playlist_id}"}, {"char_start": 172, "char_end": 201, "chars": ".format(\n        playlist_id="}], "added": [{"char_start": 135, "char_end": 137, "chars": "%s"}, {"char_start": 161, "char_end": 176, "chars": ", (playlist_id,"}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089"}
{"func_name": "retrieve_video", "func_src_before": "def retrieve_video(id, playlist_id, db):\n    db.execute(\"SELECT id, position from video WHERE id={id} and playlist_id={playlist_id};\".format(\n        id=id, playlist_id=playlist_id))\n    row = db.fetchone()\n    return row", "func_src_after": "def retrieve_video(id, playlist_id, db):\n    db.execute(\n        \"SELECT id, position from video WHERE id=%s and playlist_id=%s;\", (id, playlist_id))\n    row = db.fetchone()\n    return row", "line_changes": {"deleted": [{"line_no": 2, "char_start": 41, "char_end": 142, "line": "    db.execute(\"SELECT id, position from video WHERE id={id} and playlist_id={playlist_id};\".format(\n"}, {"line_no": 3, "char_start": 142, "char_end": 183, "line": "        id=id, playlist_id=playlist_id))\n"}], "added": [{"line_no": 2, "char_start": 41, "char_end": 57, "line": "    db.execute(\n"}, {"line_no": 3, "char_start": 57, "char_end": 150, "line": "        \"SELECT id, position from video WHERE id=%s and playlist_id=%s;\", (id, playlist_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 97, "char_end": 101, "chars": "{id}"}, {"char_start": 118, "char_end": 169, "chars": "{playlist_id};\".format(\n        id=id, playlist_id="}], "added": [{"char_start": 56, "char_end": 65, "chars": "\n        "}, {"char_start": 106, "char_end": 108, "chars": "%s"}, {"char_start": 125, "char_end": 136, "chars": "%s;\", (id, "}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089"}
{"func_name": "retrieve_last_video_position", "func_src_before": "def retrieve_last_video_position(playlist_id, db):\n    db.execute(\"SELECT max(position) as position from video WHERE playlist_id={playlist_id};\".format(\n        playlist_id=playlist_id))\n    row = db.fetchone()\n    return row['position']", "func_src_after": "def retrieve_last_video_position(playlist_id, db):\n    db.execute(\n        \"SELECT max(position) as position from video WHERE playlist_id=%s;\", (playlist_id,))\n    row = db.fetchone()\n    return row['position']", "line_changes": {"deleted": [{"line_no": 2, "char_start": 51, "char_end": 153, "line": "    db.execute(\"SELECT max(position) as position from video WHERE playlist_id={playlist_id};\".format(\n"}, {"line_no": 3, "char_start": 153, "char_end": 187, "line": "        playlist_id=playlist_id))\n"}], "added": [{"line_no": 2, "char_start": 51, "char_end": 67, "line": "    db.execute(\n"}, {"line_no": 3, "char_start": 67, "char_end": 160, "line": "        \"SELECT max(position) as position from video WHERE playlist_id=%s;\", (playlist_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 129, "char_end": 173, "chars": "{playlist_id};\".format(\n        playlist_id="}], "added": [{"char_start": 66, "char_end": 75, "chars": "\n        "}, {"char_start": 138, "char_end": 157, "chars": "%s;\", (playlist_id,"}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089"}
{"func_name": "delete_video", "func_src_before": "def delete_video(id, db):\n    db.execute(\"DELETE FROM video where id={id};\".format(id=id))", "func_src_after": "def delete_video(id, db):\n    db.execute(\"DELETE FROM video where id=%s;\", (id,))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 90, "line": "    db.execute(\"DELETE FROM video where id={id};\".format(id=id))\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 81, "line": "    db.execute(\"DELETE FROM video where id=%s;\", (id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 69, "char_end": 88, "chars": "{id};\".format(id=id"}], "added": [{"char_start": 69, "char_end": 79, "chars": "%s;\", (id,"}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089"}
{"func_name": "delete_playlists_videos", "func_src_before": "def delete_playlists_videos(playlist_id, db):\n    db.execute(\"DELETE FROM video where playlist_id={playlist_id};\".format(\n        playlist_id=playlist_id))", "func_src_after": "def delete_playlists_videos(playlist_id, db):\n    db.execute(\"DELETE FROM video where playlist_id=%s;\", (playlist_id,))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 46, "char_end": 122, "line": "    db.execute(\"DELETE FROM video where playlist_id={playlist_id};\".format(\n"}, {"line_no": 3, "char_start": 122, "char_end": 155, "line": "        playlist_id=playlist_id))\n"}], "added": [{"line_no": 2, "char_start": 46, "char_end": 119, "line": "    db.execute(\"DELETE FROM video where playlist_id=%s;\", (playlist_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 98, "char_end": 142, "chars": "{playlist_id};\".format(\n        playlist_id="}], "added": [{"char_start": 98, "char_end": 117, "chars": "%s;\", (playlist_id,"}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089"}
{"func_name": "create_video", "func_src_before": "def create_video(playlist_id, title, thumbnail, position, db):\n    db.execute(\n        \"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES({playlist_id}, '{title}', '{thumbnail}', {position});\".format(\n            playlist_id=playlist_id, title=title, thumbnail=thumbnail, position=position))", "func_src_after": "def create_video(playlist_id, title, thumbnail, position, db):\n    db.execute(\"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES(%s, %s, %s, %s);\",\n               (playlist_id, title, thumbnail, position))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 63, "char_end": 79, "line": "    db.execute(\n"}, {"line_no": 3, "char_start": 79, "char_end": 218, "line": "        \"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES({playlist_id}, '{title}', '{thumbnail}', {position});\".format(\n"}, {"line_no": 4, "char_start": 218, "char_end": 308, "line": "            playlist_id=playlist_id, title=title, thumbnail=thumbnail, position=position))\n"}], "added": [{"line_no": 2, "char_start": 63, "char_end": 165, "line": "    db.execute(\"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES(%s, %s, %s, %s);\",\n"}, {"line_no": 3, "char_start": 165, "char_end": 222, "line": "               (playlist_id, title, thumbnail, position))\n"}]}, "char_changes": {"deleted": [{"char_start": 78, "char_end": 87, "chars": "\n        "}, {"char_start": 155, "char_end": 242, "chars": "{playlist_id}, '{title}', '{thumbnail}', {position});\".format(\n            playlist_id="}, {"char_start": 255, "char_end": 261, "chars": "title="}, {"char_start": 277, "char_end": 298, "chars": "=thumbnail, position="}], "added": [{"char_start": 146, "char_end": 181, "chars": "%s, %s, %s, %s);\",\n               ("}, {"char_start": 210, "char_end": 212, "chars": ", "}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089"}
{"func_name": "update_video_positions", "func_src_before": "def update_video_positions(removed_position, db):\n    db.execute(\"UPDATE video SET position = position - 1 WHERE position > {removed_position}\".format(\n        removed_position=removed_position))", "func_src_after": "def update_video_positions(removed_position, db):\n    db.execute(\"UPDATE video SET position = position - 1 WHERE position > %s\", (removed_position,))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 50, "char_end": 152, "line": "    db.execute(\"UPDATE video SET position = position - 1 WHERE position > {removed_position}\".format(\n"}, {"line_no": 3, "char_start": 152, "char_end": 195, "line": "        removed_position=removed_position))\n"}], "added": [{"line_no": 2, "char_start": 50, "char_end": 149, "line": "    db.execute(\"UPDATE video SET position = position - 1 WHERE position > %s\", (removed_position,))\n"}]}, "char_changes": {"deleted": [{"char_start": 124, "char_end": 193, "chars": "{removed_position}\".format(\n        removed_position=removed_position"}], "added": [{"char_start": 124, "char_end": 147, "chars": "%s\", (removed_position,"}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089"}
{"func_name": "update_video_position", "func_src_before": "def update_video_position(id, position, next_position, db):\n    db.execute(\"UPDATE video SET position = Case position When {position} Then {next_position} Else position + 1 End WHERE position BETWEEN {next_position} AND {position};\".format(\n        position=position, next_position=next_position))", "func_src_after": "def update_video_position(id, position, next_position, db):\n    db.execute(\"UPDATE video SET position = Case position When %s Then %s Else position + 1 End WHERE position BETWEEN %s AND %s;\", (position, next_position, next_position, position))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 60, "char_end": 241, "line": "    db.execute(\"UPDATE video SET position = Case position When {position} Then {next_position} Else position + 1 End WHERE position BETWEEN {next_position} AND {position};\".format(\n"}, {"line_no": 3, "char_start": 241, "char_end": 297, "line": "        position=position, next_position=next_position))\n"}], "added": [{"line_no": 2, "char_start": 60, "char_end": 243, "line": "    db.execute(\"UPDATE video SET position = Case position When %s Then %s Else position + 1 End WHERE position BETWEEN %s AND %s;\", (position, next_position, next_position, position))"}]}, "char_changes": {"deleted": [{"char_start": 123, "char_end": 154, "chars": "{position} Then {next_position}"}, {"char_start": 200, "char_end": 249, "chars": "{next_position} AND {position};\".format(\n        "}, {"char_start": 257, "char_end": 258, "chars": "="}, {"char_start": 281, "char_end": 287, "chars": "=next_"}], "added": [{"char_start": 123, "char_end": 133, "chars": "%s Then %s"}, {"char_start": 179, "char_end": 193, "chars": "%s AND %s;\", ("}, {"char_start": 216, "char_end": 218, "chars": ", "}, {"char_start": 223, "char_end": 233, "chars": "position, "}]}, "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089"}
{"func_name": "addTags", "func_src_before": "def addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO {} VALUES {}\".format(listing_tags_table_name, str((listing_id, x)))\n        cur.execute(sql)", "func_src_after": "def addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO %s VALUES (%s %s)\"\n        cur.execute(sql, (listing_tags_table_name, listing_id, x))", "line_changes": {"deleted": [{"line_no": 7, "char_start": 183, "char_end": 278, "line": "        sql = \"INSERT INTO {} VALUES {}\".format(listing_tags_table_name, str((listing_id, x)))\n"}, {"line_no": 8, "char_start": 278, "char_end": 302, "line": "        cur.execute(sql)\n"}], "added": [{"line_no": 7, "char_start": 183, "char_end": 229, "line": "        sql = \"INSERT INTO %s VALUES (%s %s)\"\n"}, {"line_no": 8, "char_start": 229, "char_end": 295, "line": "        cur.execute(sql, (listing_tags_table_name, listing_id, x))\n"}]}, "char_changes": {"deleted": [{"char_start": 210, "char_end": 212, "chars": "{}"}, {"char_start": 220, "char_end": 230, "chars": "{}\".format"}, {"char_start": 256, "char_end": 261, "chars": "str(("}, {"char_start": 276, "char_end": 302, "chars": ")\n        cur.execute(sql)"}], "added": [{"char_start": 210, "char_end": 212, "chars": "%s"}, {"char_start": 220, "char_end": 254, "chars": "(%s %s)\"\n        cur.execute(sql, "}]}, "commit_link": "github.com/tasbir49/BreadWinner/commit/332a9f2c619be399ae94244bb8bd0977fc62bc16", "file_name": "backend-api/backend-api.py", "vul_type": "cwe-089"}
{"func_name": "insert", "func_src_before": "    def insert(self,targetWord,badwordlist):\n        if not targetWord.lower() in badwordlist:\n            self.connect()\n\n            sqlFormula = \"INSERT INTO badwords (word, badness) VALUE (%s,%s)\"\n            word = (targetWord.lower(),1)\n\n            self.cursor.execute(sqlFormula, word)\n            self.close()", "func_src_after": "    def insert(self,targetWord,badwordlist):\n        if not targetWord.lower() in badwordlist:\n            self.connect()\n\n            sqlFormula = \"INSERT INTO badwords (word, badness) VALUE (%s,%s)\"\n            word = (self.escapeString(targetWord.lower()),1)\n            \n            self.cursor.execute(sqlFormula,word)\n            self.close()", "line_changes": {"deleted": [{"line_no": 6, "char_start": 201, "char_end": 243, "line": "            word = (targetWord.lower(),1)\n"}, {"line_no": 7, "char_start": 243, "char_end": 244, "line": "\n"}, {"line_no": 8, "char_start": 244, "char_end": 294, "line": "            self.cursor.execute(sqlFormula, word)\n"}], "added": [{"line_no": 6, "char_start": 201, "char_end": 262, "line": "            word = (self.escapeString(targetWord.lower()),1)\n"}, {"line_no": 7, "char_start": 262, "char_end": 275, "line": "            \n"}, {"line_no": 8, "char_start": 275, "char_end": 324, "line": "            self.cursor.execute(sqlFormula,word)\n"}]}, "char_changes": {"deleted": [{"char_start": 287, "char_end": 288, "chars": " "}], "added": [{"char_start": 220, "char_end": 238, "chars": "(self.escapeString"}, {"char_start": 257, "char_end": 258, "chars": ")"}, {"char_start": 262, "char_end": 274, "chars": "            "}]}, "commit_link": "github.com/QiLinXue/discord-cyberbullying/commit/3c56a5ab85df68f79ded480ad026f974bce7d48c", "file_name": "server/functions/badWords.py", "vul_type": "cwe-089"}
{"func_name": "game_query_builder", "func_src_before": "def game_query_builder(key, value, query):\n    \"\"\"Modify textual sql query in order take into account an additional\n    WHERE condition.\n\n    Args:\n        key (str): condition name.\n        value (str): condition value.\n        query (str): SQL query.\n\n    Returns:\n        str: modified SQL query.\n    \"\"\"\n    d = {'id': \"id in ({value})\",\n         'name': \"name LIKE '{value}%'\",\n         'rating-min': 'bgg_rating>={value}',\n         'players-from': 'min_players<={value}',\n         'players-to': 'max_players>={value}',\n         'time-from': 'max_playtime>={value}',\n         'time-to': 'min_playtime<={value}',\n         'weight-min': 'weight>={value}',\n         'weight-max': 'weight<={value}',\n         }\n    if len(value) == 0 or value == 'any' or not d.get(key):\n        # do nothing\n        return query\n    elif key == 'id' and 'id in' in query:\n        pos = query.find(')', query.find('id in'))\n        return query[:pos] + ', ' + value + query[pos:]\n    else:\n        return query + d[key].format(value=value) + ' AND '", "func_src_after": "def game_query_builder(key, value, query, param_dict):\n    \"\"\"Modify textual sql query in order take into account an additional\n    WHERE condition.\n\n    Args:\n        key (str): condition name.\n        value (str): condition value.\n        query (str): textual SQL statement.\n        param_dict (dict): dict with params for textual SQL statement.\n\n    Returns:\n        str: modified SQL query.\n    \"\"\"\n    d = {'id': 'id in (:{val})',\n         'name': 'name LIKE :{val}',\n         'rating-min': 'bgg_rating>=:{val}',\n         'players-from': 'min_players<=:{val}',\n         'players-to': 'max_players>=:{val}',\n         'time-from': 'max_playtime>=:{val}',\n         'time-to': 'min_playtime<=:{val}',\n         'weight-min': 'weight>=:{val}',\n         'weight-max': 'weight<=:{val}',\n         }\n    if len(value) == 0 or value == 'any' or not d.get(key):\n        # Do nothing\n        return query, param_dict\n    # Add condition value to param_dict\n    param_key = 'val_{}'.format(len(param_dict) + 1)\n    if key == 'name':\n        value = '{}%'.format(value)\n    param_dict[param_key] = value\n    # Modify SQL statement\n    if key == 'id' and 'id in' in query:\n        pos = query.find(')', query.find('id in'))\n        query = query[:pos] + ', :' + param_key + query[pos:]\n    else:\n        query = query + d[key].format(val=param_key) + ' AND '\n    return query, param_dict", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 43, "line": "def game_query_builder(key, value, query):\n"}, {"line_no": 8, "char_start": 221, "char_end": 253, "line": "        query (str): SQL query.\n"}, {"line_no": 13, "char_start": 308, "char_end": 342, "line": "    d = {'id': \"id in ({value})\",\n"}, {"line_no": 14, "char_start": 342, "char_end": 383, "line": "         'name': \"name LIKE '{value}%'\",\n"}, {"line_no": 15, "char_start": 383, "char_end": 429, "line": "         'rating-min': 'bgg_rating>={value}',\n"}, {"line_no": 16, "char_start": 429, "char_end": 478, "line": "         'players-from': 'min_players<={value}',\n"}, {"line_no": 17, "char_start": 478, "char_end": 525, "line": "         'players-to': 'max_players>={value}',\n"}, {"line_no": 18, "char_start": 525, "char_end": 572, "line": "         'time-from': 'max_playtime>={value}',\n"}, {"line_no": 19, "char_start": 572, "char_end": 617, "line": "         'time-to': 'min_playtime<={value}',\n"}, {"line_no": 20, "char_start": 617, "char_end": 659, "line": "         'weight-min': 'weight>={value}',\n"}, {"line_no": 21, "char_start": 659, "char_end": 701, "line": "         'weight-max': 'weight<={value}',\n"}, {"line_no": 25, "char_start": 793, "char_end": 814, "line": "        return query\n"}, {"line_no": 26, "char_start": 814, "char_end": 857, "line": "    elif key == 'id' and 'id in' in query:\n"}, {"line_no": 28, "char_start": 908, "char_end": 964, "line": "        return query[:pos] + ', ' + value + query[pos:]\n"}, {"line_no": 30, "char_start": 974, "char_end": 1033, "line": "        return query + d[key].format(value=value) + ' AND '\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 55, "line": "def game_query_builder(key, value, query, param_dict):\n"}, {"line_no": 8, "char_start": 233, "char_end": 277, "line": "        query (str): textual SQL statement.\n"}, {"line_no": 9, "char_start": 277, "char_end": 348, "line": "        param_dict (dict): dict with params for textual SQL statement.\n"}, {"line_no": 14, "char_start": 403, "char_end": 436, "line": "    d = {'id': 'id in (:{val})',\n"}, {"line_no": 15, "char_start": 436, "char_end": 473, "line": "         'name': 'name LIKE :{val}',\n"}, {"line_no": 16, "char_start": 473, "char_end": 518, "line": "         'rating-min': 'bgg_rating>=:{val}',\n"}, {"line_no": 17, "char_start": 518, "char_end": 566, "line": "         'players-from': 'min_players<=:{val}',\n"}, {"line_no": 18, "char_start": 566, "char_end": 612, "line": "         'players-to': 'max_players>=:{val}',\n"}, {"line_no": 19, "char_start": 612, "char_end": 658, "line": "         'time-from': 'max_playtime>=:{val}',\n"}, {"line_no": 20, "char_start": 658, "char_end": 702, "line": "         'time-to': 'min_playtime<=:{val}',\n"}, {"line_no": 21, "char_start": 702, "char_end": 743, "line": "         'weight-min': 'weight>=:{val}',\n"}, {"line_no": 22, "char_start": 743, "char_end": 784, "line": "         'weight-max': 'weight<=:{val}',\n"}, {"line_no": 26, "char_start": 876, "char_end": 909, "line": "        return query, param_dict\n"}, {"line_no": 28, "char_start": 949, "char_end": 1002, "line": "    param_key = 'val_{}'.format(len(param_dict) + 1)\n"}, {"line_no": 29, "char_start": 1002, "char_end": 1024, "line": "    if key == 'name':\n"}, {"line_no": 30, "char_start": 1024, "char_end": 1060, "line": "        value = '{}%'.format(value)\n"}, {"line_no": 31, "char_start": 1060, "char_end": 1094, "line": "    param_dict[param_key] = value\n"}, {"line_no": 33, "char_start": 1121, "char_end": 1162, "line": "    if key == 'id' and 'id in' in query:\n"}, {"line_no": 35, "char_start": 1213, "char_end": 1275, "line": "        query = query[:pos] + ', :' + param_key + query[pos:]\n"}, {"line_no": 37, "char_start": 1285, "char_end": 1348, "line": "        query = query + d[key].format(val=param_key) + ' AND '\n"}, {"line_no": 38, "char_start": 1348, "char_end": 1376, "line": "    return query, param_dict\n"}]}, "char_changes": {"deleted": [{"char_start": 242, "char_end": 251, "chars": "SQL query"}, {"char_start": 323, "char_end": 324, "chars": "\""}, {"char_start": 335, "char_end": 337, "chars": "ue"}, {"char_start": 339, "char_end": 340, "chars": "\""}, {"char_start": 359, "char_end": 360, "chars": "\""}, {"char_start": 370, "char_end": 371, "chars": "'"}, {"char_start": 375, "char_end": 381, "chars": "ue}%'\""}, {"char_start": 423, "char_end": 425, "chars": "ue"}, {"char_start": 472, "char_end": 474, "chars": "ue"}, {"char_start": 519, "char_end": 521, "chars": "ue"}, {"char_start": 566, "char_end": 568, "chars": "ue"}, {"char_start": 611, "char_end": 613, "chars": "ue"}, {"char_start": 653, "char_end": 655, "chars": "ue"}, {"char_start": 695, "char_end": 697, "chars": "ue"}, {"char_start": 782, "char_end": 783, "chars": "d"}, {"char_start": 818, "char_end": 820, "chars": "el"}, {"char_start": 916, "char_end": 922, "chars": "return"}, {"char_start": 944, "char_end": 949, "chars": "value"}, {"char_start": 982, "char_end": 988, "chars": "return"}, {"char_start": 1014, "char_end": 1022, "chars": "ue=value"}], "added": [{"char_start": 40, "char_end": 52, "chars": ", param_dict"}, {"char_start": 254, "char_end": 346, "chars": "textual SQL statement.\n        param_dict (dict): dict with params for textual SQL statement"}, {"char_start": 418, "char_end": 419, "chars": "'"}, {"char_start": 426, "char_end": 427, "chars": ":"}, {"char_start": 433, "char_end": 434, "chars": "'"}, {"char_start": 453, "char_end": 454, "chars": "'"}, {"char_start": 464, "char_end": 465, "chars": ":"}, {"char_start": 469, "char_end": 471, "chars": "}'"}, {"char_start": 509, "char_end": 510, "chars": ":"}, {"char_start": 557, "char_end": 558, "chars": ":"}, {"char_start": 603, "char_end": 604, "chars": ":"}, {"char_start": 649, "char_end": 650, "chars": ":"}, {"char_start": 693, "char_end": 694, "chars": ":"}, {"char_start": 734, "char_end": 735, "chars": ":"}, {"char_start": 775, "char_end": 776, "chars": ":"}, {"char_start": 865, "char_end": 866, "chars": "D"}, {"char_start": 896, "char_end": 1120, "chars": ", param_dict\n    # Add condition value to param_dict\n    param_key = 'val_{}'.format(len(param_dict) + 1)\n    if key == 'name':\n        value = '{}%'.format(value)\n    param_dict[param_key] = value\n    # Modify SQL statement"}, {"char_start": 1221, "char_end": 1228, "chars": "query ="}, {"char_start": 1246, "char_end": 1247, "chars": ":"}, {"char_start": 1251, "char_end": 1260, "chars": "param_key"}, {"char_start": 1293, "char_end": 1300, "chars": "query ="}, {"char_start": 1326, "char_end": 1336, "chars": "=param_key"}, {"char_start": 1347, "char_end": 1376, "chars": "\n    return query, param_dict"}]}, "commit_link": "github.com/michalpytlos/FSND_p4/commit/49c1e478193930ddc9f4cfb873cfab8d8f5653bc", "file_name": "vagrant/4-project/boardgameclub/views.py", "vul_type": "cwe-089"}
{"func_name": "processing", "func_src_before": "@app.route('/processing')\n@is_logged_in\ndef processing():\n\n    # STEP 0: Time keeping\n    proc_start_time = time.time()\n\n    domain = session.get('domain', None)\n    if domain == None:\n        pass\n        # TODO think of bad cases\n\n    path = \"data/%s\" % (domain,)\n\n    # STEP 1: Call Helper function to create Json string\n\n    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..\n    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works\n    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work\n    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either\n    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3\n\n    # FIXME remove all session stores\n\n    # STEP 2: Call helper function to count number of pdf files\n    n_files = path_number_of_files(path)\n    session['n_files'] = n_files\n\n    # STEP 3: Extract tables from pdf's\n    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)\n\n    # STEP 4: Save stats\n    session['n_error'] = n_error\n    session['n_success'] = n_success\n    stats_json = json.dumps(stats, sort_keys=True, indent=4)\n    session['stats'] = stats_json\n\n    # STEP 5: Time Keeping\n    proc_over_time = time.time()\n    proc_total_time = proc_over_time - proc_start_time\n\n    # STEP 6: Save query in DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Execute query\n    cur.execute(\"INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)\",\n                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json, stats_json, session.get('crawl_total_time', None), proc_total_time))\n\n    # Commit to DB\n    mysql.connection.commit()\n\n    # Close connection\n    cur.close()\n\n    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)", "func_src_after": "@app.route('/processing')\n@is_logged_in\ndef processing():\n\n    # STEP 0: Time keeping\n    proc_start_time = time.time()\n\n    domain = session.get('domain', None)\n    if domain == None:\n        pass\n        # TODO think of bad cases\n\n    path = \"data/%s\" % (domain,)\n\n    # STEP 1: Call Helper function to create Json string\n\n    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..\n    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works\n    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work\n    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either\n    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3\n\n    # FIXME remove all session stores\n\n    # STEP 2: Call helper function to count number of pdf files\n    n_files = path_number_of_files(path)\n    session['n_files'] = n_files\n\n    # STEP 3: Extract tables from pdf's\n    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)\n\n    # STEP 4: Save stats\n    session['n_error'] = n_error\n    session['n_success'] = n_success\n    stats_json = json.dumps(stats, sort_keys=True, indent=4)\n    session['stats'] = stats_json\n\n    # STEP 5: Time Keeping\n    proc_over_time = time.time()\n    proc_total_time = proc_over_time - proc_start_time\n\n    # STEP 6: Save query in DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Execute query\n    cur.execute(\"\"\"INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, \n                stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json,\n                stats_json, session.get('crawl_total_time', None), proc_total_time))\n\n    # Commit to DB\n    mysql.connection.commit()\n\n    # Close connection\n    cur.close()\n\n    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)", "line_changes": {"deleted": [{"line_no": 47, "char_start": 1503, "char_end": 1723, "line": "    cur.execute(\"INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)\",\n"}, {"line_no": 48, "char_start": 1723, "char_end": 1888, "line": "                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json, stats_json, session.get('crawl_total_time', None), proc_total_time))\n"}], "added": [{"line_no": 47, "char_start": 1503, "char_end": 1627, "line": "    cur.execute(\"\"\"INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, \n"}, {"line_no": 48, "char_start": 1627, "char_end": 1744, "line": "                stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n"}, {"line_no": 49, "char_start": 1744, "char_end": 1840, "line": "                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json,\n"}, {"line_no": 50, "char_start": 1840, "char_end": 1925, "line": "                stats_json, session.get('crawl_total_time', None), proc_total_time))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1520, "char_end": 1522, "chars": "\"\""}, {"char_start": 1626, "char_end": 1643, "chars": "\n                "}, {"char_start": 1740, "char_end": 1742, "chars": "\"\""}, {"char_start": 1839, "char_end": 1855, "chars": "\n               "}]}, "commit_link": "github.com/yannvon/table-detection/commit/4bad3673debf0b9491b520f0e22e9186af78c375", "file_name": "bar.py", "vul_type": "cwe-089"}
{"func_name": "statistics", "func_src_before": "@app.route('/statistics')\n@is_logged_in\ndef statistics():\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get user by username\n    cur.execute(\"SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)\")\n\n    result = cur.fetchone()\n\n    # Close connection\n    cur.close()\n\n    if result:\n        cid_last_crawl = result[\"cid\"]\n        return redirect(url_for(\"cid_statistics\", cid=cid_last_crawl))\n    else:\n        flash(\"There are no statistics to display, please start a new query and wait for it to complete.\", \"danger\")\n        return redirect(url_for(\"index\"))", "func_src_after": "@app.route('/statistics')\n@is_logged_in\ndef statistics():\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get user by username\n    cur.execute(\"\"\"SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)\"\"\")\n\n    result = cur.fetchone()\n\n    # Close connection\n    cur.close()\n\n    if result:\n        cid_last_crawl = result[\"cid\"]\n        return redirect(url_for(\"cid_statistics\", cid=cid_last_crawl))\n    else:\n        flash(\"There are no statistics to display, please start a new query and wait for it to complete.\", \"danger\")\n        return redirect(url_for(\"index\"))", "line_changes": {"deleted": [{"line_no": 8, "char_start": 142, "char_end": 240, "line": "    cur.execute(\"SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)\")\n"}], "added": [{"line_no": 8, "char_start": 142, "char_end": 244, "line": "    cur.execute(\"\"\"SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)\"\"\")\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 159, "char_end": 161, "chars": "\"\""}, {"char_start": 240, "char_end": 242, "chars": "\"\""}]}, "commit_link": "github.com/yannvon/table-detection/commit/4bad3673debf0b9491b520f0e22e9186af78c375", "file_name": "bar.py", "vul_type": "cwe-089"}
{"func_name": "cid_statistics", "func_src_before": "@app.route('/statistics/<int:cid>')\n@is_logged_in\ndef cid_statistics(cid):\n\n    # STEP 1: retrieve all saved stats from DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    result = cur.execute('SELECT * FROM Crawls WHERE cid = %s' % cid)\n    crawl = cur.fetchall()[0]\n\n    # Close connection\n    cur.close();\n\n    print(session.get('stats', None))\n    print(crawl['stats'])\n\n    # STEP 2: do some processing to retrieve interesting info from stats\n    json_stats = json.loads(crawl['stats'])\n    json_hierarchy = json.loads(crawl['hierarchy'])\n\n    stats_items = json_stats.items()\n    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])\n    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])\n\n    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])\n    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])\n    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])\n\n    # Find some stats about creation dates\n    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]\n    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))\n\n    if len(creation_dates) > 0:\n        oldest_pdf = min(creation_dates)\n        most_recent_pdf = max(creation_dates)\n    else:\n        oldest_pdf = \"None\"\n        most_recent_pdf = \"None\"\n\n    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],\n                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],\n                           small_tables=small_tables, medium_tables=medium_tables,\n                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,\n                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),\n                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),\n                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)", "func_src_after": "@app.route('/statistics/<int:cid>')\n@is_logged_in\ndef cid_statistics(cid):\n\n    # STEP 1: retrieve all saved stats from DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    result = cur.execute(\"\"\"SELECT * FROM Crawls WHERE cid = %s\"\"\", (cid,))\n    crawl = cur.fetchall()[0]\n\n    # Close connection\n    cur.close();\n\n    print(session.get('stats', None))\n    print(crawl['stats'])\n\n    # STEP 2: do some processing to retrieve interesting info from stats\n    json_stats = json.loads(crawl['stats'])\n    json_hierarchy = json.loads(crawl['hierarchy'])\n\n    stats_items = json_stats.items()\n    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])\n    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])\n\n    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])\n    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])\n    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])\n\n    # Find some stats about creation dates\n    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]\n    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))\n\n    if len(creation_dates) > 0:\n        oldest_pdf = min(creation_dates)\n        most_recent_pdf = max(creation_dates)\n    else:\n        oldest_pdf = \"None\"\n        most_recent_pdf = \"None\"\n\n    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],\n                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],\n                           small_tables=small_tables, medium_tables=medium_tables,\n                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,\n                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),\n                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),\n                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)", "line_changes": {"deleted": [{"line_no": 9, "char_start": 180, "char_end": 250, "line": "    result = cur.execute('SELECT * FROM Crawls WHERE cid = %s' % cid)\n"}], "added": [{"line_no": 9, "char_start": 180, "char_end": 256, "line": "    result = cur.execute(\"\"\"SELECT * FROM Crawls WHERE cid = %s\"\"\", (cid,))\n"}]}, "char_changes": {"deleted": [{"char_start": 205, "char_end": 206, "chars": "'"}, {"char_start": 241, "char_end": 245, "chars": "' % "}], "added": [{"char_start": 205, "char_end": 208, "chars": "\"\"\""}, {"char_start": 243, "char_end": 249, "chars": "\"\"\", ("}, {"char_start": 252, "char_end": 254, "chars": ",)"}]}, "commit_link": "github.com/yannvon/table-detection/commit/4bad3673debf0b9491b520f0e22e9186af78c375", "file_name": "bar.py", "vul_type": "cwe-089"}
{"func_name": "login", "func_src_before": "@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        # Get Form Fields\n        username = request.form['username'] # FIXME SQL_injection danger?\n        password_candidate = request.form['password']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"SELECT * FROM Users WHERE username = %s\", [username])\n\n        if result > 0:\n            # Get stored hash\n            data = cur.fetchone() # FIXME fucking stupid username is not primary key\n            password = data['password']\n\n            # Compare passwords\n            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?\n\n                # Check was successful -> create session variables\n                session['logged_in'] = True\n                session['username'] = username\n\n                flash('You are now logged in', 'success')\n                return redirect(url_for('index'))\n            else:\n                error = 'Invalid login'\n                return render_template('login.html', error=error)\n\n        else:\n            error = 'Username not found'\n            return render_template('login.html', error=error)\n\n        # Close connection\n        cur.close() # FIXME shouldn't that happen before return?\n\n    return render_template('login.html')", "func_src_after": "@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        # Get Form Fields\n        username = request.form['username']\n        password_candidate = request.form['password']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"\"\"SELECT * FROM Users WHERE username = %s\"\"\", [username])\n\n        # Note: apparently this is safe from SQL injections see\n        # https://stackoverflow.com/questions/7929364/python-best-practice-and-securest-to-connect-to-mysql-and-execute-queries/7929438#7929438\n\n        if result > 0:\n            # Get stored hash\n            data = cur.fetchone() # FIXME why is username not primary key\n            password = data['password']\n\n            # Compare passwords\n            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?\n\n                # Check was successful -> create session variables\n                session['logged_in'] = True\n                session['username'] = username\n\n                flash('You are now logged in', 'success')\n                return redirect(url_for('index'))\n            else:\n                error = 'Invalid login'\n                return render_template('login.html', error=error)\n\n        else:\n            error = 'Username not found'\n            return render_template('login.html', error=error)\n\n        # Close connection\n        cur.close() # FIXME shouldn't that happen before return?\n\n    return render_template('login.html')", "line_changes": {"deleted": [{"line_no": 5, "char_start": 118, "char_end": 192, "line": "        username = request.form['username'] # FIXME SQL_injection danger?\n"}, {"line_no": 12, "char_start": 343, "char_end": 427, "line": "        result = cur.execute(\"SELECT * FROM Users WHERE username = %s\", [username])\n"}, {"line_no": 16, "char_start": 481, "char_end": 566, "line": "            data = cur.fetchone() # FIXME fucking stupid username is not primary key\n"}], "added": [{"line_no": 5, "char_start": 118, "char_end": 162, "line": "        username = request.form['username']\n"}, {"line_no": 12, "char_start": 313, "char_end": 401, "line": "        result = cur.execute(\"\"\"SELECT * FROM Users WHERE username = %s\"\"\", [username])\n"}, {"line_no": 13, "char_start": 401, "char_end": 402, "line": "\n"}, {"line_no": 19, "char_start": 664, "char_end": 738, "line": "            data = cur.fetchone() # FIXME why is username not primary key\n"}]}, "char_changes": {"deleted": [{"char_start": 161, "char_end": 191, "chars": " # FIXME SQL_injection danger?"}, {"char_start": 523, "char_end": 537, "chars": "fucking stupid"}, {"char_start": 547, "char_end": 550, "chars": "is "}], "added": [{"char_start": 343, "char_end": 345, "chars": "\"\""}, {"char_start": 385, "char_end": 387, "chars": "\"\""}, {"char_start": 402, "char_end": 611, "chars": "        # Note: apparently this is safe from SQL injections see\n        # https://stackoverflow.com/questions/7929364/python-best-practice-and-securest-to-connect-to-mysql-and-execute-queries/7929438#7929438\n\n"}, {"char_start": 706, "char_end": 712, "chars": "why is"}]}, "commit_link": "github.com/yannvon/table-detection/commit/4bad3673debf0b9491b520f0e22e9186af78c375", "file_name": "bar.py", "vul_type": "cwe-089"}
{"func_name": "delete_crawl", "func_src_before": "@app.route('/delete_crawl', methods=['POST'])\n@is_logged_in\ndef delete_crawl():\n\n        # Get Form Fields\n        cid = request.form['cid']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"DELETE FROM Crawls WHERE cid = %s\" % cid)\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        # FIXME check if successfull first, return message\n        flash('Crawl successfully removed', 'success')\n\n        return redirect(url_for('dashboard'))", "func_src_after": "@app.route('/delete_crawl', methods=['POST'])\n@is_logged_in\ndef delete_crawl():\n\n        # Get Form Fields\n        cid = request.form['cid']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"\"\"DELETE FROM Crawls WHERE cid = %s\"\"\" (cid,))\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        # FIXME check if successfull first, return message\n        flash('Crawl successfully removed', 'success')\n\n        return redirect(url_for('dashboard'))", "line_changes": {"deleted": [{"line_no": 12, "char_start": 238, "char_end": 310, "line": "        result = cur.execute(\"DELETE FROM Crawls WHERE cid = %s\" % cid)\n"}], "added": [{"line_no": 12, "char_start": 238, "char_end": 315, "line": "        result = cur.execute(\"\"\"DELETE FROM Crawls WHERE cid = %s\"\"\" (cid,))\n"}]}, "char_changes": {"deleted": [{"char_start": 302, "char_end": 305, "chars": " % "}], "added": [{"char_start": 268, "char_end": 270, "chars": "\"\""}, {"char_start": 304, "char_end": 308, "chars": "\"\" ("}, {"char_start": 311, "char_end": 313, "chars": ",)"}]}, "commit_link": "github.com/yannvon/table-detection/commit/4bad3673debf0b9491b520f0e22e9186af78c375", "file_name": "bar.py", "vul_type": "cwe-089"}
{"func_name": "dashboard", "func_src_before": "@app.route('/dashboard')\n@is_logged_in\ndef dashboard():\n\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get Crawls\n    result = cur.execute(\"SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls\")\n\n    crawls = cur.fetchall()\n\n    if result > 0:\n        return render_template('dashboard.html', crawls=crawls)\n    else:\n        msg = 'No Crawls Found'\n        return render_template('dashboard.html', msg=msg)\n\n    # Close connection FIXME is this code executed\n    cur.close()", "func_src_after": "@app.route('/dashboard')\n@is_logged_in\ndef dashboard():\n\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get Crawls\n    result = cur.execute(\"\"\"SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls\"\"\")\n\n    crawls = cur.fetchall()\n\n    if result > 0:\n        return render_template('dashboard.html', crawls=crawls)\n    else:\n        msg = 'No Crawls Found'\n        return render_template('dashboard.html', msg=msg)\n\n    # Close connection FIXME is this code executed\n    cur.close()", "line_changes": {"deleted": [{"line_no": 9, "char_start": 131, "char_end": 235, "line": "    result = cur.execute(\"SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls\")\n"}], "added": [{"line_no": 9, "char_start": 131, "char_end": 239, "line": "    result = cur.execute(\"\"\"SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls\"\"\")\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 157, "char_end": 159, "chars": "\"\""}, {"char_start": 235, "char_end": 237, "chars": "\"\""}]}, "commit_link": "github.com/yannvon/table-detection/commit/4bad3673debf0b9491b520f0e22e9186af78c375", "file_name": "bar.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection=self.connect()\n        try:\n            query=\"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection=self.connect()\n        try:\n            # seems the query could only execute one sql a time\n            query=\"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 78, "char_end": 159, "line": "            query=\"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n"}, {"line_no": 6, "char_start": 207, "char_end": 245, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 5, "char_start": 142, "char_end": 208, "line": "            query=\"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 7, "char_start": 256, "char_end": 300, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 138, "char_end": 158, "chars": "'{}');\".format(data)"}, {"char_start": 207, "char_end": 207, "chars": ""}], "added": [{"char_start": 78, "char_end": 142, "chars": "            # seems the query could only execute one sql a time\n"}, {"char_start": 202, "char_end": 207, "chars": "%s);\""}, {"char_start": 292, "char_end": 298, "chars": ", data"}]}, "commit_link": "github.com/dead911/flask/commit/5cb70a7a64d77955a702657a27a23cfc845007a6", "file_name": "crimemap/dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data) #i didn't understand this '.format(data)'\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "func_src_after": "\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES (%s);\"\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query, data)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 65, "char_end": 181, "line": "\t\t\tquery = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data) #i didn't understand this '.format(data)'\n"}, {"line_no": 6, "char_start": 220, "char_end": 246, "line": "\t\t\t\tcursor.execute(query)\n"}], "added": [{"line_no": 4, "char_start": 65, "char_end": 124, "line": "\t\t\tquery = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 6, "char_start": 163, "char_end": 195, "line": "\t\t\t\tcursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 118, "char_end": 180, "chars": "'{}');\".format(data) #i didn't understand this '.format(data)'"}], "added": [{"char_start": 118, "char_end": 123, "chars": "%s);\""}, {"char_start": 187, "char_end": 193, "chars": ", data"}]}, "commit_link": "github.com/memoryStack/crimeMap/commit/dbe43f01fe4b4c170486b723de2ec61736ba02c8", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "add_post", "func_src_before": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  cursor.execute(\"insert into posts values ('%s')\" % content)\n  conn.commit()\n  conn.close()", "func_src_after": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  one_post = content\n  cursor.execute(\"insert into posts values (%s)\", (one_post,))\n  conn.commit()\n  conn.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 155, "char_end": 217, "line": "  cursor.execute(\"insert into posts values ('%s')\" % content)\n"}], "added": [{"line_no": 5, "char_start": 155, "char_end": 176, "line": "  one_post = content\n"}, {"line_no": 6, "char_start": 176, "char_end": 239, "line": "  cursor.execute(\"insert into posts values (%s)\", (one_post,))\n"}]}, "char_changes": {"deleted": [{"char_start": 199, "char_end": 200, "chars": "'"}, {"char_start": 202, "char_end": 203, "chars": "'"}, {"char_start": 205, "char_end": 215, "chars": " % content"}], "added": [{"char_start": 155, "char_end": 176, "chars": "  one_post = content\n"}, {"char_start": 224, "char_end": 237, "chars": ", (one_post,)"}]}, "commit_link": "github.com/paulc1600/DB-API-Forum/commit/069700fb4beec79182fff3c556e9cccce3230d6f", "file_name": "forumdb.py", "vul_type": "cwe-089"}
{"func_name": "get_top_articles", "func_src_before": "def get_top_articles(cur, order, limit):\n    \"\"\"Fetches the top articles.\n\n    Fetches the number of top articles in the specified\n    order.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        order(str): The order to view the rows in.\n        limit(int): The number of rows to view.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT articles.title, COUNT(*) as views\n            FROM log, articles\n            WHERE log.path LIKE '%'||articles.slug AND\n            log.method = 'GET'\n            GROUP BY articles.title\n            ORDER BY views {}\n            LIMIT {}'''.format(order, limit)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"top_articles_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"\\\"{}\\\" - {} views \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_top_articles(cur, limit):\n    \"\"\"Fetches the top articles.\n\n    Fetches the number of top articles in the specified\n    order.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        limit(int): The number of rows to view.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (limit, )\n    query = '''SELECT articles.title, COUNT(*) as views\n            FROM log, articles\n            WHERE log.path = '/article/'||articles.slug AND\n            log.method = 'GET'\n            GROUP BY articles.title\n            ORDER BY views DESC\n            LIMIT %s'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"top_articles_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"\\\"{}\\\" - {} views \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 41, "line": "def get_top_articles(cur, order, limit):\n"}, {"line_no": 9, "char_start": 204, "char_end": 255, "line": "        order(str): The order to view the rows in.\n"}, {"line_no": 17, "char_start": 453, "char_end": 508, "line": "            WHERE log.path LIKE '%'||articles.slug AND\n"}, {"line_no": 20, "char_start": 575, "char_end": 605, "line": "            ORDER BY views {}\n"}, {"line_no": 21, "char_start": 605, "char_end": 650, "line": "            LIMIT {}'''.format(order, limit)\n"}, {"line_no": 22, "char_start": 650, "char_end": 682, "line": "    rows = get_data(cur, query)\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 34, "line": "def get_top_articles(cur, limit):\n"}, {"line_no": 14, "char_start": 308, "char_end": 329, "line": "    data = (limit, )\n"}, {"line_no": 17, "char_start": 416, "char_end": 476, "line": "            WHERE log.path = '/article/'||articles.slug AND\n"}, {"line_no": 20, "char_start": 543, "char_end": 575, "line": "            ORDER BY views DESC\n"}, {"line_no": 21, "char_start": 575, "char_end": 599, "line": "            LIMIT %s'''\n"}, {"line_no": 22, "char_start": 599, "char_end": 637, "line": "    rows = get_data(cur, query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 25, "char_end": 32, "chars": " order,"}, {"char_start": 204, "char_end": 255, "chars": "        order(str): The order to view the rows in.\n"}, {"char_start": 480, "char_end": 487, "chars": "LIKE '%"}, {"char_start": 602, "char_end": 604, "chars": "{}"}, {"char_start": 623, "char_end": 625, "chars": "{}"}, {"char_start": 628, "char_end": 649, "chars": ".format(order, limit)"}], "added": [{"char_start": 34, "char_end": 34, "chars": ""}, {"char_start": 308, "char_end": 329, "chars": "    data = (limit, )\n"}, {"char_start": 443, "char_end": 455, "chars": "= '/article/"}, {"char_start": 570, "char_end": 574, "chars": "DESC"}, {"char_start": 593, "char_end": 595, "chars": "%s"}, {"char_start": 629, "char_end": 635, "chars": ", data"}]}, "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089"}
{"func_name": "get_top_authors", "func_src_before": "def get_top_authors(cur, order):\n    \"\"\"Fetches the top authors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        order(str): The order to view the rows in.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT authors.name, COUNT(*) as views\n            FROM authors, articles, log\n            WHERE authors.id = articles.author AND\n            log.path LIKE '%'||articles.slug AND\n            log.method = 'GET'\n            GROUP BY authors.name\n            ORDER BY views {}'''.format(order)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"top_authors_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {} views \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_top_authors(cur):\n    \"\"\"Fetches the top authors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = ()\n    query = '''SELECT authors.name, COUNT(*) as views\n            FROM authors, articles, log\n            WHERE authors.id = articles.author AND\n            log.path = '/article/'||articles.slug AND\n            log.method = 'GET'\n            GROUP BY authors.name\n            ORDER BY COUNT(*) DESC'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"top_authors_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {} views \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 33, "line": "def get_top_authors(cur, order):\n"}, {"line_no": 6, "char_start": 127, "char_end": 178, "line": "        order(str): The order to view the rows in.\n"}, {"line_no": 14, "char_start": 386, "char_end": 435, "line": "            log.path LIKE '%'||articles.slug AND\n"}, {"line_no": 17, "char_start": 500, "char_end": 547, "line": "            ORDER BY views {}'''.format(order)\n"}, {"line_no": 18, "char_start": 547, "char_end": 579, "line": "    rows = get_data(cur, query)\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 26, "line": "def get_top_authors(cur):\n"}, {"line_no": 10, "char_start": 183, "char_end": 197, "line": "    data = ()\n"}, {"line_no": 14, "char_start": 342, "char_end": 396, "line": "            log.path = '/article/'||articles.slug AND\n"}, {"line_no": 17, "char_start": 461, "char_end": 499, "line": "            ORDER BY COUNT(*) DESC'''\n"}, {"line_no": 18, "char_start": 499, "char_end": 537, "line": "    rows = get_data(cur, query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 23, "char_end": 30, "chars": ", order"}, {"char_start": 126, "char_end": 177, "chars": "\n        order(str): The order to view the rows in."}, {"char_start": 407, "char_end": 414, "chars": "LIKE '%"}, {"char_start": 521, "char_end": 546, "chars": "views {}'''.format(order)"}], "added": [{"char_start": 26, "char_end": 26, "chars": ""}, {"char_start": 183, "char_end": 197, "chars": "    data = ()\n"}, {"char_start": 363, "char_end": 375, "chars": "= '/article/"}, {"char_start": 482, "char_end": 498, "chars": "COUNT(*) DESC'''"}, {"char_start": 529, "char_end": 535, "chars": ", data"}]}, "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089"}
{"func_name": "get_error_days", "func_src_before": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > {}\n            ORDER BY log_errors.date'''.format(error_percent)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (error_percent, )\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > %s\n            ORDER BY log_errors.date'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "line_changes": {"deleted": [{"line_no": 20, "char_start": 684, "char_end": 731, "line": "            / log_requests.total::numeric > {}\n"}, {"line_no": 21, "char_start": 731, "char_end": 793, "line": "            ORDER BY log_errors.date'''.format(error_percent)\n"}, {"line_no": 22, "char_start": 793, "char_end": 825, "line": "    rows = get_data(cur, query)\n"}], "added": [{"line_no": 14, "char_start": 384, "char_end": 413, "line": "    data = (error_percent, )\n"}, {"line_no": 21, "char_start": 713, "char_end": 760, "line": "            / log_requests.total::numeric > %s\n"}, {"line_no": 22, "char_start": 760, "char_end": 800, "line": "            ORDER BY log_errors.date'''\n"}, {"line_no": 23, "char_start": 800, "char_end": 838, "line": "    rows = get_data(cur, query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 728, "char_end": 730, "chars": "{}"}, {"char_start": 770, "char_end": 792, "chars": ".format(error_percent)"}], "added": [{"char_start": 384, "char_end": 413, "chars": "    data = (error_percent, )\n"}, {"char_start": 757, "char_end": 759, "chars": "%s"}, {"char_start": 830, "char_end": 836, "chars": ", data"}]}, "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089"}
{"func_name": "fetchObjectsOfClass", "func_src_before": "    def fetchObjectsOfClass(self, aClass,\n            clauses='', isDeep=True, refreshAttrs=True, serialNum=None):\n        \"\"\"Fetch a list of objects of a specific class.\n\n        The list may be empty if no objects are found.\n\n        aClass can be a Klass object (from the MiddleKit object model),\n        the name of the class (e.g., a string) or a Python class.\n\n        The clauses argument can be any SQL clauses such as 'where x<5 order by x'.\n        Obviously, these could be specific to your SQL database, thereby making\n        your code non-portable. Use your best judgement.\n\n        serialNum can be a specific serial number if you are looking for\n        a specific object. If serialNum is provided, it overrides the clauses.\n\n        You should label all arguments other than aClass:\n            objs = store.fetchObjectsOfClass('Foo', clauses='where x<5')\n        The reason for labeling is that this method is likely to undergo\n        improvements in the future which could include additional arguments.\n        No guarantees are made about the order of the arguments except that\n        aClass will always be the first.\n        Raises an exception if aClass parameter is invalid.\n        \"\"\"\n        klass = self._klassForClass(aClass)\n\n        # Fetch objects of subclasses first, because the code below\n        # will be  modifying clauses and serialNum\n        deepObjs = []\n        if isDeep:\n            for subklass in klass.subklasses():\n                deepObjs.extend(self.fetchObjectsOfClass(\n                    subklass, clauses, isDeep, refreshAttrs, serialNum))\n\n        # Now get objects of this exact class\n        objs = []\n        if not klass.isAbstract():\n            fetchSQLStart = klass.fetchSQLStart()\n            className = klass.name()\n            if serialNum is not None:\n                serialNum = int(serialNum)  # make sure it's a valid int\n                clauses = 'where %s=%d' % (klass.sqlSerialColumnName(), serialNum)\n            if self._markDeletes:\n                clauses = self.addDeletedToClauses(clauses)\n            conn, cur = self.executeSQL(fetchSQLStart + clauses + ';')\n            try:\n                for row in cur.fetchall():\n                    serialNum = row[0]\n                    key = ObjectKey().initFromClassNameAndSerialNum(className, serialNum)\n                    obj = self._objects.get(key)\n                    if obj is None:\n                        pyClass = klass.pyClass()\n                        obj = pyClass()\n                        assert isinstance(obj, MiddleObject), (\n                            'Not a MiddleObject. obj = %r, type = %r, MiddleObject = %r'\n                                % (obj, type(obj), MiddleObject))\n                        obj.readStoreData(self, row)\n                        obj.setKey(key)\n                        self._objects[key] = obj\n                    else:\n                        # Existing object\n                        if refreshAttrs:\n                            obj.readStoreData(self, row)\n                    objs.append(obj)\n            finally:\n                self.doneWithConnection(conn)\n        objs.extend(deepObjs)\n        return objs", "func_src_after": "    def fetchObjectsOfClass(self, aClass,\n            clauses='', isDeep=True, refreshAttrs=True, serialNum=None, clausesArgs=None):\n        \"\"\"Fetch a list of objects of a specific class.\n\n        The list may be empty if no objects are found.\n\n        aClass can be a Klass object (from the MiddleKit object model),\n        the name of the class (e.g., a string) or a Python class.\n\n        The clauses argument can be any SQL clauses such as 'where x<5 order by x'.\n        Obviously, these could be specific to your SQL database, thereby making\n        your code non-portable. Use your best judgement.\n\n        serialNum can be a specific serial number if you are looking for\n        a specific object. If serialNum is provided, it overrides the clauses.\n\n        You should label all arguments other than aClass:\n            objs = store.fetchObjectsOfClass('Foo', clauses='where x<5')\n        The reason for labeling is that this method is likely to undergo\n        improvements in the future which could include additional arguments.\n        No guarantees are made about the order of the arguments except that\n        aClass will always be the first.\n        Raises an exception if aClass parameter is invalid.\n        \"\"\"\n        klass = self._klassForClass(aClass)\n\n        # Fetch objects of subclasses first, because the code below\n        # will be  modifying clauses and serialNum\n        deepObjs = []\n        if isDeep:\n            for subklass in klass.subklasses():\n                deepObjs.extend(self.fetchObjectsOfClass(\n                    subklass, clauses, isDeep, refreshAttrs, serialNum, clausesArgs))\n\n        # Now get objects of this exact class\n        objs = []\n        if not klass.isAbstract():\n            fetchSQLStart = klass.fetchSQLStart()\n            className = klass.name()\n            if serialNum is not None:\n                serialNum = int(serialNum)  # make sure it's a valid int\n                clauses = 'where %s=%d' % (klass.sqlSerialColumnName(), serialNum)\n            if self._markDeletes:\n                clauses = self.addDeletedToClauses(clauses)\n            conn, cur = self.executeSQL(fetchSQLStart + clauses + ';', commit=False, clausesArgs=clausesArgs)\n            try:\n                for row in cur.fetchall():\n                    serialNum = row[0]\n                    key = ObjectKey().initFromClassNameAndSerialNum(className, serialNum)\n                    obj = self._objects.get(key)\n                    if obj is None:\n                        pyClass = klass.pyClass()\n                        obj = pyClass()\n                        assert isinstance(obj, MiddleObject), (\n                            'Not a MiddleObject. obj = %r, type = %r, MiddleObject = %r'\n                                % (obj, type(obj), MiddleObject))\n                        obj.readStoreData(self, row)\n                        obj.setKey(key)\n                        self._objects[key] = obj\n                    else:\n                        # Existing object\n                        if refreshAttrs:\n                            obj.readStoreData(self, row)\n                    objs.append(obj)\n            finally:\n                self.doneWithConnection(conn)\n        objs.extend(deepObjs)\n        return objs", "line_changes": {"deleted": [{"line_no": 2, "char_start": 42, "char_end": 115, "line": "            clauses='', isDeep=True, refreshAttrs=True, serialNum=None):\n"}, {"line_no": 33, "char_start": 1523, "char_end": 1596, "line": "                    subklass, clauses, isDeep, refreshAttrs, serialNum))\n"}, {"line_no": 45, "char_start": 2071, "char_end": 2142, "line": "            conn, cur = self.executeSQL(fetchSQLStart + clauses + ';')\n"}], "added": [{"line_no": 2, "char_start": 42, "char_end": 133, "line": "            clauses='', isDeep=True, refreshAttrs=True, serialNum=None, clausesArgs=None):\n"}, {"line_no": 33, "char_start": 1541, "char_end": 1627, "line": "                    subklass, clauses, isDeep, refreshAttrs, serialNum, clausesArgs))\n"}, {"line_no": 45, "char_start": 2102, "char_end": 2212, "line": "            conn, cur = self.executeSQL(fetchSQLStart + clauses + ';', commit=False, clausesArgs=clausesArgs)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 112, "char_end": 130, "chars": ", clausesArgs=None"}, {"char_start": 1611, "char_end": 1624, "chars": ", clausesArgs"}, {"char_start": 2171, "char_end": 2210, "chars": ", commit=False, clausesArgs=clausesArgs"}]}, "commit_link": "github.com/Cito/w4py/commit/23414a49db38c1a34097fe5682223b4e8c3518a9", "file_name": "MiddleKit/Run/SQLObjectStore.py", "vul_type": "cwe-089"}
{"func_name": "executeSQL", "func_src_before": "    def executeSQL(self, sql, connection=None, commit=False):\n        \"\"\"Execute the given SQL.\n\n        This will connect to the database for the first time if necessary.\n        This method will also log the SQL to self._sqlEcho, if it is not None.\n        Returns the connection and cursor used and relies on connectionAndCursor()\n        to obtain these. Note that you can pass in a connection to force a\n        particular one to be used and a flag to commit immediately.\n        \"\"\"\n        sql = str(sql)  # Excel-based models yield Unicode strings which some db modules don't like\n        sql = sql.strip()\n        if aggressiveGC:\n            import gc\n            assert gc.isenabled()\n            gc.collect()\n        self._sqlCount += 1\n        if self._sqlEcho:\n            timestamp = funcs.timestamp()['pretty']\n            self._sqlEcho.write('SQL %04i. %s %s\\n' % (self._sqlCount, timestamp, sql))\n            self._sqlEcho.flush()\n        conn, cur = self.connectionAndCursor(connection)\n        self._executeSQL(cur, sql)\n        if commit:\n            conn.commit()\n        return conn, cur", "func_src_after": "    def executeSQL(self, sql, connection=None, commit=False, clausesArgs=None):\n        \"\"\"Execute the given SQL.\n\n        This will connect to the database for the first time if necessary.\n        This method will also log the SQL to self._sqlEcho, if it is not None.\n        Returns the connection and cursor used and relies on connectionAndCursor()\n        to obtain these. Note that you can pass in a connection to force a\n        particular one to be used and a flag to commit immediately.\n        \"\"\"\n        sql = str(sql)  # Excel-based models yield Unicode strings which some db modules don't like\n        sql = sql.strip()\n        if aggressiveGC:\n            import gc\n            assert gc.isenabled()\n            gc.collect()\n        self._sqlCount += 1\n        if self._sqlEcho:\n            timestamp = funcs.timestamp()['pretty']\n            self._sqlEcho.write('SQL %04i. %s %s\\n' % (self._sqlCount, timestamp, sql))\n            self._sqlEcho.flush()\n        conn, cur = self.connectionAndCursor(connection)\n        self._executeSQL(cur, sql, clausesArgs)\n        if commit:\n            conn.commit()\n        return conn, cur", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 62, "line": "    def executeSQL(self, sql, connection=None, commit=False):\n"}, {"line_no": 22, "char_start": 1006, "char_end": 1041, "line": "        self._executeSQL(cur, sql)\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 80, "line": "    def executeSQL(self, sql, connection=None, commit=False, clausesArgs=None):\n"}, {"line_no": 22, "char_start": 1024, "char_end": 1072, "line": "        self._executeSQL(cur, sql, clausesArgs)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 59, "char_end": 77, "chars": ", clausesArgs=None"}, {"char_start": 1057, "char_end": 1070, "chars": ", clausesArgs"}]}, "commit_link": "github.com/Cito/w4py/commit/23414a49db38c1a34097fe5682223b4e8c3518a9", "file_name": "MiddleKit/Run/SQLObjectStore.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # protection from SQL Injections, previously use {}\n            # The following introduces a deliberate security flaw\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 146, "char_end": 229, "line": "            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n"}, {"line_no": 7, "char_start": 277, "char_end": 315, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 6, "char_start": 210, "char_end": 278, "line": "            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 8, "char_start": 326, "char_end": 370, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 208, "char_end": 228, "chars": "'{}');\".format(data)"}, {"char_start": 277, "char_end": 277, "chars": ""}], "added": [{"char_start": 80, "char_end": 144, "chars": "            # protection from SQL Injections, previously use {}\n"}, {"char_start": 272, "char_end": 277, "chars": "%s);\""}, {"char_start": 362, "char_end": 368, "chars": ", data"}]}, "commit_link": "github.com/repodevs/flask-crimemap/commit/c2bc9d0199ce90ae628efc10c51d252713caaeaf", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "fetch_page_name", "func_src_before": "  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id=\"{0}\"'.format(page_id)\n    self.cursor.execute(query)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')", "func_src_after": "  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id = ?;'\n    query_bindings = (page_id,)\n    self.cursor.execute(query, query_bindings)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')", "line_changes": {"deleted": [{"line_no": 16, "char_start": 378, "char_end": 446, "line": "    query = 'SELECT name FROM pages WHERE id=\"{0}\"'.format(page_id)\n"}, {"line_no": 17, "char_start": 446, "char_end": 477, "line": "    self.cursor.execute(query)\n"}], "added": [{"line_no": 16, "char_start": 378, "char_end": 429, "line": "    query = 'SELECT name FROM pages WHERE id = ?;'\n"}, {"line_no": 17, "char_start": 429, "char_end": 461, "line": "    query_bindings = (page_id,)\n"}, {"line_no": 18, "char_start": 461, "char_end": 508, "line": "    self.cursor.execute(query, query_bindings)\n"}]}, "char_changes": {"deleted": [{"char_start": 422, "char_end": 436, "chars": "=\"{0}\"'.format"}], "added": [{"char_start": 422, "char_end": 450, "chars": " = ?;'\n    query_bindings = "}, {"char_start": 458, "char_end": 459, "chars": ","}, {"char_start": 490, "char_end": 506, "chars": ", query_bindings"}]}, "commit_link": "github.com/jwngr/sdow/commit/4db98f3521592f17550d2b723336f33fec5e112a", "file_name": "sdow/database.py", "vul_type": "cwe-089"}
{"func_name": "fetch_redirected_page_id", "func_src_before": "  def fetch_redirected_page_id(self, from_page_id):\n    '''\n    If the provided page ID is a redirect, returns the ID of the page to which it redirects.\n    Otherwise, returns None.\n\n    Args:\n      from_page_id: The page ID whose redirected page ID to fetch.\n\n    Returns:\n      int: The ID of the page to which the provided page ID redirects.\n      OR\n      None: If the provided page ID is not a redirect.\n\n    Raises:\n      ValueError: If the provided page ID is invalid.\n    '''\n    helpers.validate_page_id(from_page_id)\n\n    query = 'SELECT to_id FROM redirects WHERE from_id=\"{0}\"'.format(from_page_id)\n    self.cursor.execute(query)\n\n    to_page_id = self.cursor.fetchone()\n\n    return to_page_id and to_page_id[0]", "func_src_after": "  def fetch_redirected_page_id(self, from_page_id):\n    '''\n    If the provided page ID is a redirect, returns the ID of the page to which it redirects.\n    Otherwise, returns None.\n\n    Args:\n      from_page_id: The page ID whose redirected page ID to fetch.\n\n    Returns:\n      int: The ID of the page to which the provided page ID redirects.\n      OR\n      None: If the provided page ID is not a redirect.\n\n    Raises:\n      ValueError: If the provided page ID is invalid.\n    '''\n    helpers.validate_page_id(from_page_id)\n\n    query = 'SELECT to_id FROM redirects WHERE from_id = ?'\n    query_bindings = (from_page_id,)\n    self.cursor.execute(query, query_bindings)\n\n    to_page_id = self.cursor.fetchone()\n\n    return to_page_id and to_page_id[0]", "line_changes": {"deleted": [{"line_no": 19, "char_start": 528, "char_end": 611, "line": "    query = 'SELECT to_id FROM redirects WHERE from_id=\"{0}\"'.format(from_page_id)\n"}, {"line_no": 20, "char_start": 611, "char_end": 642, "line": "    self.cursor.execute(query)\n"}], "added": [{"line_no": 19, "char_start": 528, "char_end": 588, "line": "    query = 'SELECT to_id FROM redirects WHERE from_id = ?'\n"}, {"line_no": 20, "char_start": 588, "char_end": 625, "line": "    query_bindings = (from_page_id,)\n"}, {"line_no": 21, "char_start": 625, "char_end": 672, "line": "    self.cursor.execute(query, query_bindings)\n"}]}, "char_changes": {"deleted": [{"char_start": 582, "char_end": 596, "chars": "=\"{0}\"'.format"}], "added": [{"char_start": 582, "char_end": 609, "chars": " = ?'\n    query_bindings = "}, {"char_start": 622, "char_end": 623, "chars": ","}, {"char_start": 654, "char_end": 670, "chars": ", query_bindings"}]}, "commit_link": "github.com/jwngr/sdow/commit/4db98f3521592f17550d2b723336f33fec5e112a", "file_name": "sdow/database.py", "vul_type": "cwe-089"}
{"func_name": "fetch_links_helper", "func_src_before": "  def fetch_links_helper(self, page_ids, to_id_or_from_id):\n    '''\n    Helper function which handles duplicate logic for fetch_forwards_links() and\n    fetch_backwards_links().\n\n    Args:\n      page_ids: The page IDs whose links to fetch.\n      to_id_or_from_id: String which indicates whether to fetch forwards (\"from_id\") or backwards\n                        (\"to_id\") links.\n\n    Returns:\n      [(int, int)]: A lists of integer tuples representing links from the list of provided page IDs\n                    to other pages.\n    '''\n\n    query = 'SELECT from_id, to_id FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)\n\n    #results = []\n    #for row in self.cursor.execute(query):\n    #  results.append(row)\n\n    # TODO: measure the performance impact of this versus just appending to an array (above) or\n    # just returning the cursor (not yet implemented)\n    self.cursor.execute(query)\n\n    return self.cursor.fetchall()", "func_src_after": "  def fetch_links_helper(self, page_ids, to_id_or_from_id):\n    '''\n    Helper function which handles duplicate logic for fetch_forwards_links() and\n    fetch_backwards_links().\n\n    Args:\n      page_ids: The page IDs whose links to fetch.\n      to_id_or_from_id: String which indicates whether to fetch forwards (\"from_id\") or backwards\n                        (\"to_id\") links.\n\n    Returns:\n      [(int, int)]: A lists of integer tuples representing links from the list of provided page IDs\n                    to other pages.\n    '''\n    #results = []\n    #for row in self.cursor.execute(query):\n    #  results.append(row)\n\n    # TODO: measure the performance impact of this versus just appending to an array (above) or\n    # just returning the cursor (not yet implemented)\n    # There is no need to escape the query parameters here since they are never user-defined\n    query = 'SELECT * FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)\n    self.cursor.execute(query)\n\n    return self.cursor.fetchall()", "line_changes": {"deleted": [{"line_no": 15, "char_start": 537, "char_end": 538, "line": "\n"}, {"line_no": 16, "char_start": 538, "char_end": 637, "line": "    query = 'SELECT from_id, to_id FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)\n"}, {"line_no": 17, "char_start": 637, "char_end": 638, "line": "\n"}], "added": [{"line_no": 22, "char_start": 870, "char_end": 956, "line": "    query = 'SELECT * FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)\n"}]}, "char_changes": {"deleted": [{"char_start": 537, "char_end": 638, "chars": "\n    query = 'SELECT from_id, to_id FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)\n\n"}], "added": [{"char_start": 777, "char_end": 956, "chars": "    # There is no need to escape the query parameters here since they are never user-defined\n    query = 'SELECT * FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)\n"}]}, "commit_link": "github.com/jwngr/sdow/commit/4db98f3521592f17550d2b723336f33fec5e112a", "file_name": "sdow/database.py", "vul_type": "cwe-089"}
{"func_name": "add_post", "func_src_before": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values('%s')\" % content)\n  db.commit()\n  db.close()", "func_src_after": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values(%s)\",(content,))\n  db.commit()\n  db.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 147, "char_end": 203, "line": "  c.execute(\"insert into posts values('%s')\" % content)\n"}], "added": [{"line_no": 5, "char_start": 147, "char_end": 202, "line": "  c.execute(\"insert into posts values(%s)\",(content,))\n"}]}, "char_changes": {"deleted": [{"char_start": 185, "char_end": 186, "chars": "'"}, {"char_start": 188, "char_end": 189, "chars": "'"}, {"char_start": 191, "char_end": 194, "chars": " % "}], "added": [{"char_start": 189, "char_end": 191, "chars": ",("}, {"char_start": 198, "char_end": 200, "chars": ",)"}]}, "commit_link": "github.com/tfalbo/SuzyMakeup/commit/1a5d6ccf02bec303d454f87a6bb39baed30c205f", "file_name": "vagrant/forum/forumdb.py", "vul_type": "cwe-089"}
{"func_name": "process_list", "func_src_before": "    def process_list(self, data):\n        \"\"\"\n        This method returns details for given set of CVEs.\n\n        :param data: data obtained from api, we're interested in data[\"cve_list\"]\n\n        :returns: list of dictionaries containing detailed information for given cve list}\n\n        \"\"\"\n\n        cves_to_process = data[\"cve_list\"]\n        cves_to_process = filter(None, cves_to_process)\n        answer = {}\n        if not cves_to_process:\n            return answer\n\n        # Select all cves in request\n        column_names = [\"cve.id\", \"redhat_url\", \"secondary_url\", \"cve.name\", \"severity.name\", \"published_date\",\n                        \"modified_date\", \"iava\", \"description\"]\n        cve_query = \"SELECT %s from cve\" % ', '.join(column for column in column_names)\n        cve_query = cve_query + \" LEFT JOIN severity ON severity_id = severity.id\"\n        cve_query = cve_query + \" WHERE cve.name IN %s\"\n        self.cursor.execute(cve_query, [tuple(cves_to_process)])\n        cves = self.cursor.fetchall()\n        cwe_map = self.get_cve_cwe_map([cve[column_names.index(\"cve.id\")] for cve in cves])  # generate cve ids\n        CVE.cve_cwe_map = cwe_map\n        cve_list = []\n        for cve_entry in cves:\n            cve = CVE(cve_entry, column_names)\n            cve_list.append(cve)\n\n        return self.construct_answer(cve_list)", "func_src_after": "    def process_list(self, data):\n        \"\"\"\n        This method returns details for given set of CVEs.\n\n        :param data: data obtained from api, we're interested in data[\"cve_list\"]\n\n        :returns: list of dictionaries containing detailed information for given cve list}\n\n        \"\"\"\n\n        cves_to_process = data[\"cve_list\"]\n        cves_to_process = filter(None, cves_to_process)\n        answer = {}\n        if not cves_to_process:\n            return answer\n\n        # Select all cves in request\n        cve_query = \"\"\"SELECT cve.id, cve.redhat_url, cve.secondary_url, cve.name, severity.name,\n                              cve.published_date, cve.modified_date, cve.iava, cve.description\n                         FROM cve\n                         LEFT JOIN severity ON cve.severity_id = severity.id\n                        WHERE cve.name IN %s\"\"\"\n        self.cursor.execute(cve_query, [tuple(cves_to_process)])\n        cves = self.cursor.fetchall()\n        cwe_map = self.get_cve_cwe_map([cve[column_names.index(\"cve.id\")] for cve in cves])  # generate cve ids\n        CVE.cve_cwe_map = cwe_map\n        cve_list = []\n        for cve_entry in cves:\n            cve = CVE(cve_entry, column_names)\n            cve_list.append(cve)\n\n        return self.construct_answer(cve_list)", "line_changes": {"deleted": [{"line_no": 18, "char_start": 509, "char_end": 621, "line": "        column_names = [\"cve.id\", \"redhat_url\", \"secondary_url\", \"cve.name\", \"severity.name\", \"published_date\",\n"}, {"line_no": 19, "char_start": 621, "char_end": 685, "line": "                        \"modified_date\", \"iava\", \"description\"]\n"}, {"line_no": 20, "char_start": 685, "char_end": 773, "line": "        cve_query = \"SELECT %s from cve\" % ', '.join(column for column in column_names)\n"}, {"line_no": 21, "char_start": 773, "char_end": 856, "line": "        cve_query = cve_query + \" LEFT JOIN severity ON severity_id = severity.id\"\n"}, {"line_no": 22, "char_start": 856, "char_end": 912, "line": "        cve_query = cve_query + \" WHERE cve.name IN %s\"\n"}], "added": [{"line_no": 18, "char_start": 509, "char_end": 607, "line": "        cve_query = \"\"\"SELECT cve.id, cve.redhat_url, cve.secondary_url, cve.name, severity.name,\n"}, {"line_no": 19, "char_start": 607, "char_end": 702, "line": "                              cve.published_date, cve.modified_date, cve.iava, cve.description\n"}, {"line_no": 20, "char_start": 702, "char_end": 736, "line": "                         FROM cve\n"}, {"line_no": 21, "char_start": 736, "char_end": 813, "line": "                         LEFT JOIN severity ON cve.severity_id = severity.id\n"}, {"line_no": 22, "char_start": 813, "char_end": 861, "line": "                        WHERE cve.name IN %s\"\"\"\n"}]}, "char_changes": {"deleted": [{"char_start": 518, "char_end": 534, "chars": "olumn_names = [\""}, {"char_start": 540, "char_end": 541, "chars": "\""}, {"char_start": 543, "char_end": 544, "chars": "\""}, {"char_start": 554, "char_end": 555, "chars": "\""}, {"char_start": 557, "char_end": 558, "chars": "\""}, {"char_start": 571, "char_end": 572, "chars": "\""}, {"char_start": 574, "char_end": 575, "chars": "\""}, {"char_start": 583, "char_end": 584, "chars": "\""}, {"char_start": 586, "char_end": 587, "chars": "\""}, {"char_start": 600, "char_end": 621, "chars": "\", \"published_date\",\n"}, {"char_start": 644, "char_end": 646, "chars": " \""}, {"char_start": 659, "char_end": 660, "chars": "\""}, {"char_start": 662, "char_end": 663, "chars": "\""}, {"char_start": 667, "char_end": 668, "chars": "\""}, {"char_start": 670, "char_end": 671, "chars": "\""}, {"char_start": 682, "char_end": 684, "chars": "\"]"}, {"char_start": 693, "char_end": 806, "chars": "cve_query = \"SELECT %s from cve\" % ', '.join(column for column in column_names)\n        cve_query = cve_query + \""}, {"char_start": 854, "char_end": 855, "chars": "\""}, {"char_start": 864, "char_end": 889, "chars": "cve_query = cve_query + \""}], "added": [{"char_start": 518, "char_end": 539, "chars": "ve_query = \"\"\"SELECT "}, {"char_start": 547, "char_end": 551, "chars": "cve."}, {"char_start": 563, "char_end": 567, "chars": "cve."}, {"char_start": 605, "char_end": 610, "chars": ",\n   "}, {"char_start": 634, "char_end": 661, "chars": "   cve.published_date, cve."}, {"char_start": 676, "char_end": 680, "chars": "cve."}, {"char_start": 686, "char_end": 690, "chars": "cve."}, {"char_start": 710, "char_end": 760, "chars": "                 FROM cve\n                        "}, {"char_start": 783, "char_end": 787, "chars": "cve."}, {"char_start": 821, "char_end": 836, "chars": "               "}, {"char_start": 858, "char_end": 860, "chars": "\"\""}]}, "commit_link": "github.com/RedHatInsights/vmaas/commit/49603ff9d29a9d411a681b3cc8096a6585ec1272", "file_name": "webapp/cve.py", "vul_type": "cwe-089"}
{"func_name": "get_cve_cwe_map", "func_src_before": "    def get_cve_cwe_map(self, ids):\n        \"\"\"\n        For givers CVE ids find CWE in DB\n        :param ids: CVE ids\n        :return: cve_cwe mapping\n        \"\"\"\n        if not ids:\n            return []\n        query = \"SELECT cve_id, cwe.name, cwe.link FROM cve_cwe map JOIN cwe ON map.cwe_id = cwe.id WHERE map.cve_id IN %s\"\n        self.cursor.execute(query, [tuple(ids)])\n        return self.cursor.fetchall()", "func_src_after": "    def get_cve_cwe_map(self, ids):\n        \"\"\"\n        For givers CVE ids find CWE in DB\n        :param ids: CVE ids\n        :return: cve_cwe mapping\n        \"\"\"\n        if not ids:\n            return []\n        query = \"\"\"SELECT cve_id, cwe.name, cwe.link\n                     FROM cve_cwe map\n                     JOIN cwe ON map.cwe_id = cwe.id\n                    WHERE map.cve_id IN %s\"\"\"\n        self.cursor.execute(query, [tuple(ids)])\n        return self.cursor.fetchall()", "line_changes": {"deleted": [{"line_no": 9, "char_start": 205, "char_end": 329, "line": "        query = \"SELECT cve_id, cwe.name, cwe.link FROM cve_cwe map JOIN cwe ON map.cwe_id = cwe.id WHERE map.cve_id IN %s\"\n"}], "added": [{"line_no": 9, "char_start": 205, "char_end": 258, "line": "        query = \"\"\"SELECT cve_id, cwe.name, cwe.link\n"}, {"line_no": 10, "char_start": 258, "char_end": 296, "line": "                     FROM cve_cwe map\n"}, {"line_no": 11, "char_start": 296, "char_end": 349, "line": "                     JOIN cwe ON map.cwe_id = cwe.id\n"}, {"line_no": 12, "char_start": 349, "char_end": 395, "line": "                    WHERE map.cve_id IN %s\"\"\"\n"}]}, "char_changes": {"deleted": [{"char_start": 255, "char_end": 272, "chars": " FROM cve_cwe map"}], "added": [{"char_start": 221, "char_end": 223, "chars": "\"\""}, {"char_start": 257, "char_end": 316, "chars": "\n                     FROM cve_cwe map\n                    "}, {"char_start": 348, "char_end": 368, "chars": "\n                   "}, {"char_start": 392, "char_end": 394, "chars": "\"\""}]}, "commit_link": "github.com/RedHatInsights/vmaas/commit/49603ff9d29a9d411a681b3cc8096a6585ec1272", "file_name": "webapp/cve.py", "vul_type": "cwe-089"}
{"func_name": "get_cve_names_for_erratum_id", "func_src_before": "    def get_cve_names_for_erratum_id(self, id):\n        \"\"\"\n        Get the list of cves for the given erratum id\n        \"\"\"\n        cve_query = \"SELECT name FROM cve\"\n        cve_query += \" JOIN errata_cve ON cve_id = cve.id\"\n        cve_query += \" WHERE errata_cve.errata_id = %s\" % str(id)\n        self.cursor.execute(cve_query)\n        cve_names = self.cursor.fetchall()\n        cve_name_list = []\n        for cve_name in cve_names:\n            cve_name_list.append(cve_name[0])\n        return cve_name_list", "func_src_after": "    def get_cve_names_for_erratum_id(self, id):\n        \"\"\"\n        Get the list of cves for the given erratum id\n        \"\"\"\n        cve_query = \"\"\"SELECT name FROM cve\n                         JOIN errata_cve ON cve_id = cve.id\n                        WHERE errata_cve.errata_id = %s\"\"\"\n        self.cursor.execute(cve_query, (id,))\n        cve_names = self.cursor.fetchall()\n        cve_name_list = []\n        for cve_name in cve_names:\n            cve_name_list.append(cve_name[0])\n        return cve_name_list", "line_changes": {"deleted": [{"line_no": 5, "char_start": 126, "char_end": 169, "line": "        cve_query = \"SELECT name FROM cve\"\n"}, {"line_no": 6, "char_start": 169, "char_end": 228, "line": "        cve_query += \" JOIN errata_cve ON cve_id = cve.id\"\n"}, {"line_no": 7, "char_start": 228, "char_end": 294, "line": "        cve_query += \" WHERE errata_cve.errata_id = %s\" % str(id)\n"}, {"line_no": 8, "char_start": 294, "char_end": 333, "line": "        self.cursor.execute(cve_query)\n"}], "added": [{"line_no": 5, "char_start": 126, "char_end": 170, "line": "        cve_query = \"\"\"SELECT name FROM cve\n"}, {"line_no": 6, "char_start": 170, "char_end": 230, "line": "                         JOIN errata_cve ON cve_id = cve.id\n"}, {"line_no": 7, "char_start": 230, "char_end": 289, "line": "                        WHERE errata_cve.errata_id = %s\"\"\"\n"}, {"line_no": 8, "char_start": 289, "char_end": 335, "line": "        self.cursor.execute(cve_query, (id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 167, "char_end": 191, "chars": "\"\n        cve_query += \""}, {"char_start": 226, "char_end": 227, "chars": "\""}, {"char_start": 236, "char_end": 250, "chars": "cve_query += \""}, {"char_start": 283, "char_end": 293, "chars": " % str(id)"}], "added": [{"char_start": 146, "char_end": 148, "chars": "\"\""}, {"char_start": 178, "char_end": 194, "chars": "                "}, {"char_start": 229, "char_end": 253, "chars": "\n                       "}, {"char_start": 286, "char_end": 288, "chars": "\"\""}, {"char_start": 326, "char_end": 333, "chars": ", (id,)"}]}, "commit_link": "github.com/RedHatInsights/vmaas/commit/49603ff9d29a9d411a681b3cc8096a6585ec1272", "file_name": "webapp/errata.py", "vul_type": "cwe-089"}
{"func_name": "get_package_list_for_erratum_id", "func_src_before": "    def get_package_list_for_erratum_id(self, id):\n        \"\"\"\n        Get the list of packages for the given erratum id\n        \"\"\"\n        pkg_query = \"SELECT package.name, evr.epoch, evr.version, evr.release, arch.name\"\n        pkg_query += \" FROM pkg_errata\"\n        pkg_query += \" JOIN package ON package.id = pkg_errata.pkg_id\"\n        pkg_query += \" JOIN evr ON evr.id = package.evr_id\"\n        pkg_query += \" JOIN arch ON arch.id = package.arch_id\"\n        pkg_query += \" WHERE pkg_errata.errata_id = %s\" % str(id)\n        self.cursor.execute(pkg_query)\n        result = self.cursor.fetchall()\n        package_list = []\n        for name, epoch, version, release, arch in result:\n            package_list.append(self.build_package_name(name, epoch, version, release, arch))\n        return package_list", "func_src_after": "    def get_package_list_for_erratum_id(self, id):\n        \"\"\"\n        Get the list of packages for the given erratum id\n        \"\"\"\n        pkg_query = \"\"\"SELECT package.name, evr.epoch, evr.version, evr.release, arch.name\n                         FROM pkg_errata\n                         JOIN package ON package.id = pkg_errata.pkg_id\n                         JOIN evr ON evr.id = package.evr_id\n                         JOIN arch ON arch.id = package.arch_id\n                        WHERE pkg_errata.errata_id = %s\"\"\"\n        self.cursor.execute(pkg_query, (id,))\n        result = self.cursor.fetchall()\n        package_list = []\n        for name, epoch, version, release, arch in result:\n            package_list.append(self.build_package_name(name, epoch, version, release, arch))\n        return package_list", "line_changes": {"deleted": [{"line_no": 5, "char_start": 133, "char_end": 223, "line": "        pkg_query = \"SELECT package.name, evr.epoch, evr.version, evr.release, arch.name\"\n"}, {"line_no": 6, "char_start": 223, "char_end": 263, "line": "        pkg_query += \" FROM pkg_errata\"\n"}, {"line_no": 7, "char_start": 263, "char_end": 334, "line": "        pkg_query += \" JOIN package ON package.id = pkg_errata.pkg_id\"\n"}, {"line_no": 8, "char_start": 334, "char_end": 394, "line": "        pkg_query += \" JOIN evr ON evr.id = package.evr_id\"\n"}, {"line_no": 9, "char_start": 394, "char_end": 457, "line": "        pkg_query += \" JOIN arch ON arch.id = package.arch_id\"\n"}, {"line_no": 10, "char_start": 457, "char_end": 523, "line": "        pkg_query += \" WHERE pkg_errata.errata_id = %s\" % str(id)\n"}, {"line_no": 11, "char_start": 523, "char_end": 562, "line": "        self.cursor.execute(pkg_query)\n"}], "added": [{"line_no": 5, "char_start": 133, "char_end": 224, "line": "        pkg_query = \"\"\"SELECT package.name, evr.epoch, evr.version, evr.release, arch.name\n"}, {"line_no": 6, "char_start": 224, "char_end": 265, "line": "                         FROM pkg_errata\n"}, {"line_no": 7, "char_start": 265, "char_end": 337, "line": "                         JOIN package ON package.id = pkg_errata.pkg_id\n"}, {"line_no": 8, "char_start": 337, "char_end": 398, "line": "                         JOIN evr ON evr.id = package.evr_id\n"}, {"line_no": 9, "char_start": 398, "char_end": 462, "line": "                         JOIN arch ON arch.id = package.arch_id\n"}, {"line_no": 10, "char_start": 462, "char_end": 521, "line": "                        WHERE pkg_errata.errata_id = %s\"\"\"\n"}, {"line_no": 11, "char_start": 521, "char_end": 567, "line": "        self.cursor.execute(pkg_query, (id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 221, "char_end": 222, "chars": "\""}, {"char_start": 231, "char_end": 245, "chars": "pkg_query += \""}, {"char_start": 261, "char_end": 262, "chars": "\""}, {"char_start": 271, "char_end": 285, "chars": "pkg_query += \""}, {"char_start": 332, "char_end": 333, "chars": "\""}, {"char_start": 342, "char_end": 356, "chars": "pkg_query += \""}, {"char_start": 392, "char_end": 393, "chars": "\""}, {"char_start": 402, "char_end": 416, "chars": "pkg_query += \""}, {"char_start": 455, "char_end": 456, "chars": "\""}, {"char_start": 465, "char_end": 479, "chars": "pkg_query += \""}, {"char_start": 512, "char_end": 522, "chars": " % str(id)"}], "added": [{"char_start": 153, "char_end": 155, "chars": "\"\""}, {"char_start": 232, "char_end": 248, "chars": "                "}, {"char_start": 273, "char_end": 289, "chars": "                "}, {"char_start": 345, "char_end": 361, "chars": "                "}, {"char_start": 406, "char_end": 422, "chars": "                "}, {"char_start": 470, "char_end": 485, "chars": "               "}, {"char_start": 518, "char_end": 520, "chars": "\"\""}, {"char_start": 558, "char_end": 565, "chars": ", (id,)"}]}, "commit_link": "github.com/RedHatInsights/vmaas/commit/49603ff9d29a9d411a681b3cc8096a6585ec1272", "file_name": "webapp/errata.py", "vul_type": "cwe-089"}
{"func_name": "process_list", "func_src_before": "    def process_list(self, data):\n        \"\"\"\n        This method returns details for given set of Errata.\n\n        :param cursor: psycopg2 connection cursor\n        :param data: data obtained from api, we're interested in data[\"errata_list\"]\n\n        :returns: dictionary containing detailed information for given errata list}\n\n        \"\"\"\n\n        errata_to_process = data[\"errata_list\"]\n        errata_to_process = filter(None, errata_to_process)\n        answer = {}\n\n        if not errata_to_process:\n            return answer\n\n        # Select all errata in request\n        errata_query = \"SELECT errata.id, errata.name, synopsis, severity.name, description,\"\n        errata_query += \" solution, issued, updated\"\n        errata_query += \" FROM errata\"\n        errata_query += \" LEFT JOIN severity ON severity_id = severity.id\"\n        errata_query += \" WHERE errata.name IN %s\"\n        self.cursor.execute(errata_query, [tuple(errata_to_process)])\n        errata = self.cursor.fetchall()\n\n        erratum_list = []\n        for id, name, synopsis, severity, description, solution, issued, updated in errata:\n            new_erratum = Errata(id, name, synopsis, severity, description, solution, issued, updated)\n            new_erratum.set_cve_names(self.get_cve_names_for_erratum_id(id))\n            new_erratum.set_packages(self.get_package_list_for_erratum_id(id))\n            erratum_list.append(new_erratum)\n\n        errata_dict = {}\n        for e in erratum_list:\n            errata_dict[e.get_val(\"name\")] = e.get_val(\"mydict\")\n        answer[\"errata_list\"] = errata_dict\n        return answer", "func_src_after": "    def process_list(self, data):\n        \"\"\"\n        This method returns details for given set of Errata.\n\n        :param cursor: psycopg2 connection cursor\n        :param data: data obtained from api, we're interested in data[\"errata_list\"]\n\n        :returns: dictionary containing detailed information for given errata list}\n\n        \"\"\"\n\n        errata_to_process = data[\"errata_list\"]\n        errata_to_process = filter(None, errata_to_process)\n        answer = {}\n\n        if not errata_to_process:\n            return answer\n\n        # Select all errata in request\n        errata_query = \"\"\"SELECT errata.id, errata.name, synopsis, severity.name, description,\n                                 solution, issued, updated\n                            FROM errata\n                            LEFT JOIN severity ON severity_id = severity.id\n                           WHERE errata.name IN %s\"\"\"\n        self.cursor.execute(errata_query, [tuple(errata_to_process)])\n        errata = self.cursor.fetchall()\n\n        erratum_list = []\n        for id, name, synopsis, severity, description, solution, issued, updated in errata:\n            new_erratum = Errata(id, name, synopsis, severity, description, solution, issued, updated)\n            new_erratum.set_cve_names(self.get_cve_names_for_erratum_id(id))\n            new_erratum.set_packages(self.get_package_list_for_erratum_id(id))\n            erratum_list.append(new_erratum)\n\n        errata_dict = {}\n        for e in erratum_list:\n            errata_dict[e.get_val(\"name\")] = e.get_val(\"mydict\")\n        answer[\"errata_list\"] = errata_dict\n        return answer", "line_changes": {"deleted": [{"line_no": 20, "char_start": 571, "char_end": 665, "line": "        errata_query = \"SELECT errata.id, errata.name, synopsis, severity.name, description,\"\n"}, {"line_no": 21, "char_start": 665, "char_end": 718, "line": "        errata_query += \" solution, issued, updated\"\n"}, {"line_no": 22, "char_start": 718, "char_end": 757, "line": "        errata_query += \" FROM errata\"\n"}, {"line_no": 23, "char_start": 757, "char_end": 832, "line": "        errata_query += \" LEFT JOIN severity ON severity_id = severity.id\"\n"}, {"line_no": 24, "char_start": 832, "char_end": 883, "line": "        errata_query += \" WHERE errata.name IN %s\"\n"}], "added": [{"line_no": 20, "char_start": 571, "char_end": 666, "line": "        errata_query = \"\"\"SELECT errata.id, errata.name, synopsis, severity.name, description,\n"}, {"line_no": 21, "char_start": 666, "char_end": 725, "line": "                                 solution, issued, updated\n"}, {"line_no": 22, "char_start": 725, "char_end": 765, "line": "                            FROM errata\n"}, {"line_no": 23, "char_start": 765, "char_end": 841, "line": "                            LEFT JOIN severity ON severity_id = severity.id\n"}, {"line_no": 24, "char_start": 841, "char_end": 895, "line": "                           WHERE errata.name IN %s\"\"\"\n"}]}, "char_changes": {"deleted": [{"char_start": 663, "char_end": 664, "chars": "\""}, {"char_start": 673, "char_end": 690, "chars": "errata_query += \""}, {"char_start": 716, "char_end": 717, "chars": "\""}, {"char_start": 726, "char_end": 743, "chars": "errata_query += \""}, {"char_start": 755, "char_end": 756, "chars": "\""}, {"char_start": 765, "char_end": 782, "chars": "errata_query += \""}, {"char_start": 830, "char_end": 831, "chars": "\""}, {"char_start": 840, "char_end": 857, "chars": "errata_query += \""}], "added": [{"char_start": 594, "char_end": 596, "chars": "\"\""}, {"char_start": 674, "char_end": 698, "chars": "                        "}, {"char_start": 733, "char_end": 752, "chars": "                   "}, {"char_start": 773, "char_end": 792, "chars": "                   "}, {"char_start": 849, "char_end": 867, "chars": "                  "}, {"char_start": 892, "char_end": 894, "chars": "\"\""}]}, "commit_link": "github.com/RedHatInsights/vmaas/commit/49603ff9d29a9d411a681b3cc8096a6585ec1272", "file_name": "webapp/errata.py", "vul_type": "cwe-089"}
{"func_name": "process_list", "func_src_before": "    def process_list(self, data):\n        \"\"\"\n        This method is looking for updates of a package, including name of package to update to,\n        associated erratum and repository this erratum is from.\n\n        :param packages_to_process: list of package to find updates for every of them\n\n        :returns: updates for a package in format of list of dictionaries {'package': <p_name>, 'erratum': <e_name>,\n        'repository': <r_name>}\n\n        \"\"\"\n\n        packages_to_process = data['package_list']\n        auxiliary_dict = {}\n        answer = {}\n\n        if not packages_to_process:\n            return answer\n\n        provided_repo_ids = None\n        provided_repo_names = None\n\n        if 'repository_list' in data:\n            provided_repo_names = data['repository_list']\n            provided_repo_ids = []\n            self.cursor.execute(\"select id from repo where name in %s;\", [tuple(provided_repo_names)])\n            for id_tuple in self.cursor.fetchall():\n                for id in id_tuple:\n                    provided_repo_ids.append(id)\n\n        # Select all evrs and put them into dictionary\n        self.cursor.execute(\"SELECT id, epoch, version, release from evr\")\n        evrs = self.cursor.fetchall()\n        evr2id_dict = {}\n        id2evr_dict = {}\n        for id, e, v, r in evrs:\n            key = e + ':' + v + ':' + r\n            evr2id_dict[key] = id\n            id2evr_dict[id] = {'epoch': e, 'version': v, 'release': r}\n\n        # Select all archs and put them into dictionary\n        self.cursor.execute(\"SELECT id, name from arch\")\n        archs = self.cursor.fetchall()\n        arch2id_dict = {}\n        id2arch_dict = {}\n        for id, name in archs:\n            arch2id_dict[name] = id\n            id2arch_dict[id] = name\n\n        packages_names = []\n        packages_evrids = []\n\n        for pkg in packages_to_process:\n            pkg = str(pkg)\n\n            # process all packages form input\n            if pkg not in auxiliary_dict:\n                n, v, r, e, a = split_filename(str(pkg))\n                auxiliary_dict[pkg] = {}  # create dictionary with aux data for pkg\n\n                evr_key = e + ':' + v + ':' + r\n                if evr_key in evr2id_dict:\n                    packages_names.append(n)\n                    auxiliary_dict[pkg][n] = []\n\n                    evr_id = evr2id_dict[evr_key]\n                    packages_evrids.append(evr_id)\n                    auxiliary_dict[pkg]['evr_id'] = evr_id\n                    auxiliary_dict[pkg]['arch_id'] = arch2id_dict[a]\n                    auxiliary_dict[pkg]['repo_id'] = []\n                    auxiliary_dict[pkg]['pkg_id'] = []\n                    auxiliary_dict[pkg]['update_id'] = []\n\n        # Select all packages with given evrs ids and put them into dictionary\n        self.cursor.execute(\"select id, name, evr_id, arch_id from package where evr_id in %s;\",  [tuple(packages_evrids)])\n        packs = self.cursor.fetchall()\n        nevra2pkg_id = {}\n        for id, name, evr_id, arch_id in packs:\n            key = name + ':' + str(evr_id) + ':' + str(arch_id)\n            if key not in nevra2pkg_id:\n                nevra2pkg_id[key] = [id]\n            else:\n                nevra2pkg_id[key].append(id)\n\n        pkg_ids = []\n        for pkg in auxiliary_dict.keys():\n            n, v, r, e, a = split_filename(str(pkg))\n\n            try:\n                key = str(n + ':' + str(auxiliary_dict[pkg]['evr_id']) + ':' + str(auxiliary_dict[pkg]['arch_id']))\n                pkg_ids.extend(nevra2pkg_id[key])\n                auxiliary_dict[pkg]['pkg_id'].extend(nevra2pkg_id[key])\n            except KeyError:\n                pass\n\n        # Select all repo_id and add mapping to package id\n        self.cursor.execute(\"select pkg_id, repo_id from pkg_repo where pkg_id in %s;\", [tuple(pkg_ids)])\n        pack_repo_ids = self.cursor.fetchall()\n        pkg_id2repo_id = {}\n\n        repo_ids = []\n\n        for pkg_id, repo_id in pack_repo_ids:\n            repo_ids.append(repo_id)\n\n            if pkg_id in pkg_id2repo_id:\n                pkg_id2repo_id[pkg_id].append(repo_id)\n            else:\n                pkg_id2repo_id[pkg_id] = [repo_id]\n\n        for pkg in auxiliary_dict.keys():\n                try:\n                    for pkg_id in auxiliary_dict[pkg]['pkg_id']:\n                        auxiliary_dict[pkg]['repo_id'].extend(pkg_id2repo_id[pkg_id])\n                except KeyError:\n                    pass\n\n        self.cursor.execute(\"select name, id from package where name in %s;\", [tuple(packages_names)])\n        sql_result = self.cursor.fetchall()\n        names2ids = {}\n        for name, id in sql_result:\n\n            if name in names2ids:\n                names2ids[name].append(id)\n            else:\n                names2ids[name] = [id]\n\n        for pkg in auxiliary_dict.keys():\n            n, v, r, e, a = split_filename(str(pkg))\n\n            try:\n                auxiliary_dict[pkg][n].extend(names2ids[n])\n            except KeyError:\n                pass\n\n        update_pkg_ids = []\n\n        for pkg in auxiliary_dict:\n            n, v, r, e, a = split_filename(str(pkg))\n\n            if n in auxiliary_dict[pkg] and auxiliary_dict[pkg][n]:\n                sql = \"\"\"\n                select package.id from package join evr on package.evr_id = evr.id where package.id in %s and evr.evr > (select evr from evr where id = %s);\n                \"\"\" % ('%s', str(auxiliary_dict[pkg]['evr_id']))\n\n                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n])])\n\n                for id in self.cursor.fetchall():\n                    auxiliary_dict[pkg]['update_id'].append(id[0])\n                    update_pkg_ids.append(id[0])\n\n        # Select all info about repos\n        self.cursor.execute(\"select id, name, url from repo where id in %s;\", [tuple(repo_ids)])\n        all_repos = self.cursor.fetchall()\n        repoinfo_dict = {}\n        for id, name, url in all_repos:\n            repoinfo_dict[id] = {'name': name, 'url': url}\n\n        # Select all info about pkg_id to repo_id\n        self.cursor.execute(\"select pkg_id, repo_id from pkg_repo where pkg_id in %s;\", [tuple(update_pkg_ids)])\n        all_pkg_repos = self.cursor.fetchall()\n        pkg_id2repo_id = {}\n        for pkg_id, repo_id in all_pkg_repos:\n\n            if pkg_id not in pkg_id2repo_id:\n                pkg_id2repo_id[pkg_id] = [repo_id]\n            else:\n                pkg_id2repo_id[pkg_id].append(repo_id)\n\n        # Select all info about pkg_id to errata_id\n        self.cursor.execute(\"select pkg_id, errata_id from pkg_errata where pkg_id in %s;\", [tuple(update_pkg_ids)])\n        all_pkg_errata = self.cursor.fetchall()\n        pkg_id2errata_id = {}\n        all_errata = []\n        for pkg_id, errata_id in all_pkg_errata:\n            all_errata.append(errata_id)\n            if pkg_id not in pkg_id2errata_id:\n                pkg_id2errata_id[pkg_id] = [errata_id]\n            else:\n                pkg_id2errata_id[pkg_id].append(errata_id)\n\n        # Select all info about errata\n        self.cursor.execute(\"SELECT id, name from errata where id in %s;\", [tuple(all_errata)])\n        errata = self.cursor.fetchall()\n        id2errata_dict = {}\n        all_errata_id = []\n        for id, name in errata:\n            id2errata_dict[id] = name\n            all_errata_id.append(id)\n\n        self.cursor.execute(\"SELECT errata_id, repo_id from errata_repo where errata_id in %s;\", [tuple(all_errata_id)])\n        sql_result = self.cursor.fetchall()\n        errata_id2repo_id = {}\n        for errata_id, repo_id in sql_result:\n            if errata_id not in errata_id2repo_id:\n                errata_id2repo_id[errata_id] = [repo_id]\n            else:\n                errata_id2repo_id[errata_id].append(repo_id)\n\n        # Select all info about packages\n        self.cursor.execute(\"SELECT id, name, evr_id, arch_id from package where id in %s;\", [tuple(update_pkg_ids)])\n        packages = self.cursor.fetchall()\n        pkg_id2full_name = {}\n        pkg_id2arch_id = {}\n        for id, name, evr_id, arch_id in packages:\n            full_rpm_name = name + '-'\n            if id2evr_dict[evr_id]['epoch'] != '0':\n                full_rpm_name += id2evr_dict[evr_id]['epoch'] + ':'\n            full_rpm_name += id2evr_dict[evr_id]['version'] + '-' + id2evr_dict[evr_id]['release'] + '.' + id2arch_dict[arch_id]\n\n            pkg_id2full_name[id] = full_rpm_name\n            pkg_id2arch_id[id] = arch_id\n\n        for pkg in auxiliary_dict:\n            answer[pkg] = []\n\n            if 'update_id' not in auxiliary_dict[pkg]:\n                continue\n\n            for upd_pkg_id in auxiliary_dict[pkg]['update_id']:\n                # FIXME: use compatibility tables instead of exact matching\n                if auxiliary_dict[pkg]['arch_id'] == pkg_id2arch_id[upd_pkg_id]:\n                    for r_id in pkg_id2repo_id[upd_pkg_id]:\n                        # check if update package in the same repo with original one\n                        # and if the list of repositories for updates is provided, also check repo id in this list\n                        if r_id in auxiliary_dict[pkg]['repo_id'] and \\\n                                (provided_repo_ids is None or r_id in provided_repo_ids):\n                            # Some pkgs don't have associated errata (eg, original-repo-content)\n                            if upd_pkg_id in pkg_id2errata_id:\n                                errata_ids = pkg_id2errata_id[upd_pkg_id]\n                                for e_id in errata_ids:\n                                    # check current errata in the same repo with update pkg\n                                    if r_id in errata_id2repo_id[e_id]:\n                                        e_name = id2errata_dict[e_id]\n                                        r_name = repoinfo_dict[r_id]['name']\n\n                                        answer[pkg].append({\n                                            'package': pkg_id2full_name[upd_pkg_id],\n                                            'erratum': e_name,\n                                            'repository': r_name})\n        response = {\n            'update_list': answer,\n        }\n\n        if provided_repo_ids is not None:\n            response.update({'repository_list': provided_repo_names})\n\n        return response", "func_src_after": "    def process_list(self, data):\n        \"\"\"\n        This method is looking for updates of a package, including name of package to update to,\n        associated erratum and repository this erratum is from.\n\n        :param packages_to_process: list of package to find updates for every of them\n\n        :returns: updates for a package in format of list of dictionaries {'package': <p_name>, 'erratum': <e_name>,\n        'repository': <r_name>}\n\n        \"\"\"\n\n        packages_to_process = data['package_list']\n        auxiliary_dict = {}\n        answer = {}\n\n        if not packages_to_process:\n            return answer\n\n        provided_repo_ids = None\n        provided_repo_names = None\n\n        if 'repository_list' in data:\n            provided_repo_names = data['repository_list']\n            provided_repo_ids = []\n            self.cursor.execute(\"select id from repo where name in %s;\", [tuple(provided_repo_names)])\n            for id_tuple in self.cursor.fetchall():\n                for id in id_tuple:\n                    provided_repo_ids.append(id)\n\n        # Select all evrs and put them into dictionary\n        self.cursor.execute(\"SELECT id, epoch, version, release from evr\")\n        evrs = self.cursor.fetchall()\n        evr2id_dict = {}\n        id2evr_dict = {}\n        for id, e, v, r in evrs:\n            key = e + ':' + v + ':' + r\n            evr2id_dict[key] = id\n            id2evr_dict[id] = {'epoch': e, 'version': v, 'release': r}\n\n        # Select all archs and put them into dictionary\n        self.cursor.execute(\"SELECT id, name from arch\")\n        archs = self.cursor.fetchall()\n        arch2id_dict = {}\n        id2arch_dict = {}\n        for id, name in archs:\n            arch2id_dict[name] = id\n            id2arch_dict[id] = name\n\n        packages_names = []\n        packages_evrids = []\n\n        for pkg in packages_to_process:\n            pkg = str(pkg)\n\n            # process all packages form input\n            if pkg not in auxiliary_dict:\n                n, v, r, e, a = split_filename(str(pkg))\n                auxiliary_dict[pkg] = {}  # create dictionary with aux data for pkg\n\n                evr_key = e + ':' + v + ':' + r\n                if evr_key in evr2id_dict:\n                    packages_names.append(n)\n                    auxiliary_dict[pkg][n] = []\n\n                    evr_id = evr2id_dict[evr_key]\n                    packages_evrids.append(evr_id)\n                    auxiliary_dict[pkg]['evr_id'] = evr_id\n                    auxiliary_dict[pkg]['arch_id'] = arch2id_dict[a]\n                    auxiliary_dict[pkg]['repo_id'] = []\n                    auxiliary_dict[pkg]['pkg_id'] = []\n                    auxiliary_dict[pkg]['update_id'] = []\n\n        # Select all packages with given evrs ids and put them into dictionary\n        self.cursor.execute(\"select id, name, evr_id, arch_id from package where evr_id in %s;\",  [tuple(packages_evrids)])\n        packs = self.cursor.fetchall()\n        nevra2pkg_id = {}\n        for id, name, evr_id, arch_id in packs:\n            key = name + ':' + str(evr_id) + ':' + str(arch_id)\n            if key not in nevra2pkg_id:\n                nevra2pkg_id[key] = [id]\n            else:\n                nevra2pkg_id[key].append(id)\n\n        pkg_ids = []\n        for pkg in auxiliary_dict.keys():\n            n, v, r, e, a = split_filename(str(pkg))\n\n            try:\n                key = str(n + ':' + str(auxiliary_dict[pkg]['evr_id']) + ':' + str(auxiliary_dict[pkg]['arch_id']))\n                pkg_ids.extend(nevra2pkg_id[key])\n                auxiliary_dict[pkg]['pkg_id'].extend(nevra2pkg_id[key])\n            except KeyError:\n                pass\n\n        # Select all repo_id and add mapping to package id\n        self.cursor.execute(\"select pkg_id, repo_id from pkg_repo where pkg_id in %s;\", [tuple(pkg_ids)])\n        pack_repo_ids = self.cursor.fetchall()\n        pkg_id2repo_id = {}\n\n        repo_ids = []\n\n        for pkg_id, repo_id in pack_repo_ids:\n            repo_ids.append(repo_id)\n\n            if pkg_id in pkg_id2repo_id:\n                pkg_id2repo_id[pkg_id].append(repo_id)\n            else:\n                pkg_id2repo_id[pkg_id] = [repo_id]\n\n        for pkg in auxiliary_dict.keys():\n                try:\n                    for pkg_id in auxiliary_dict[pkg]['pkg_id']:\n                        auxiliary_dict[pkg]['repo_id'].extend(pkg_id2repo_id[pkg_id])\n                except KeyError:\n                    pass\n\n        self.cursor.execute(\"select name, id from package where name in %s;\", [tuple(packages_names)])\n        sql_result = self.cursor.fetchall()\n        names2ids = {}\n        for name, id in sql_result:\n\n            if name in names2ids:\n                names2ids[name].append(id)\n            else:\n                names2ids[name] = [id]\n\n        for pkg in auxiliary_dict.keys():\n            n, v, r, e, a = split_filename(str(pkg))\n\n            try:\n                auxiliary_dict[pkg][n].extend(names2ids[n])\n            except KeyError:\n                pass\n\n        update_pkg_ids = []\n\n        sql = \"\"\"SELECT package.id\n                   FROM package\n                   JOIN evr ON package.evr_id = evr.id\n                  WHERE package.id in %s and evr.evr > (select evr from evr where id = %s)\"\"\"\n        for pkg in auxiliary_dict:\n            n, v, r, e, a = split_filename(str(pkg))\n\n            if n in auxiliary_dict[pkg] and auxiliary_dict[pkg][n]:\n                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n]),\n                                          auxiliary_dict[pkg]['evr_id']])\n\n                for id in self.cursor.fetchall():\n                    auxiliary_dict[pkg]['update_id'].append(id[0])\n                    update_pkg_ids.append(id[0])\n\n        # Select all info about repos\n        self.cursor.execute(\"select id, name, url from repo where id in %s;\", [tuple(repo_ids)])\n        all_repos = self.cursor.fetchall()\n        repoinfo_dict = {}\n        for id, name, url in all_repos:\n            repoinfo_dict[id] = {'name': name, 'url': url}\n\n        # Select all info about pkg_id to repo_id\n        self.cursor.execute(\"select pkg_id, repo_id from pkg_repo where pkg_id in %s;\", [tuple(update_pkg_ids)])\n        all_pkg_repos = self.cursor.fetchall()\n        pkg_id2repo_id = {}\n        for pkg_id, repo_id in all_pkg_repos:\n\n            if pkg_id not in pkg_id2repo_id:\n                pkg_id2repo_id[pkg_id] = [repo_id]\n            else:\n                pkg_id2repo_id[pkg_id].append(repo_id)\n\n        # Select all info about pkg_id to errata_id\n        self.cursor.execute(\"select pkg_id, errata_id from pkg_errata where pkg_id in %s;\", [tuple(update_pkg_ids)])\n        all_pkg_errata = self.cursor.fetchall()\n        pkg_id2errata_id = {}\n        all_errata = []\n        for pkg_id, errata_id in all_pkg_errata:\n            all_errata.append(errata_id)\n            if pkg_id not in pkg_id2errata_id:\n                pkg_id2errata_id[pkg_id] = [errata_id]\n            else:\n                pkg_id2errata_id[pkg_id].append(errata_id)\n\n        # Select all info about errata\n        self.cursor.execute(\"SELECT id, name from errata where id in %s;\", [tuple(all_errata)])\n        errata = self.cursor.fetchall()\n        id2errata_dict = {}\n        all_errata_id = []\n        for id, name in errata:\n            id2errata_dict[id] = name\n            all_errata_id.append(id)\n\n        self.cursor.execute(\"SELECT errata_id, repo_id from errata_repo where errata_id in %s;\", [tuple(all_errata_id)])\n        sql_result = self.cursor.fetchall()\n        errata_id2repo_id = {}\n        for errata_id, repo_id in sql_result:\n            if errata_id not in errata_id2repo_id:\n                errata_id2repo_id[errata_id] = [repo_id]\n            else:\n                errata_id2repo_id[errata_id].append(repo_id)\n\n        # Select all info about packages\n        self.cursor.execute(\"SELECT id, name, evr_id, arch_id from package where id in %s;\", [tuple(update_pkg_ids)])\n        packages = self.cursor.fetchall()\n        pkg_id2full_name = {}\n        pkg_id2arch_id = {}\n        for id, name, evr_id, arch_id in packages:\n            full_rpm_name = name + '-'\n            if id2evr_dict[evr_id]['epoch'] != '0':\n                full_rpm_name += id2evr_dict[evr_id]['epoch'] + ':'\n            full_rpm_name += id2evr_dict[evr_id]['version'] + '-' + id2evr_dict[evr_id]['release'] + '.' + id2arch_dict[arch_id]\n\n            pkg_id2full_name[id] = full_rpm_name\n            pkg_id2arch_id[id] = arch_id\n\n        for pkg in auxiliary_dict:\n            answer[pkg] = []\n\n            if 'update_id' not in auxiliary_dict[pkg]:\n                continue\n\n            for upd_pkg_id in auxiliary_dict[pkg]['update_id']:\n                # FIXME: use compatibility tables instead of exact matching\n                if auxiliary_dict[pkg]['arch_id'] == pkg_id2arch_id[upd_pkg_id]:\n                    for r_id in pkg_id2repo_id[upd_pkg_id]:\n                        # check if update package in the same repo with original one\n                        # and if the list of repositories for updates is provided, also check repo id in this list\n                        if r_id in auxiliary_dict[pkg]['repo_id'] and \\\n                                (provided_repo_ids is None or r_id in provided_repo_ids):\n                            # Some pkgs don't have associated errata (eg, original-repo-content)\n                            if upd_pkg_id in pkg_id2errata_id:\n                                errata_ids = pkg_id2errata_id[upd_pkg_id]\n                                for e_id in errata_ids:\n                                    # check current errata in the same repo with update pkg\n                                    if r_id in errata_id2repo_id[e_id]:\n                                        e_name = id2errata_dict[e_id]\n                                        r_name = repoinfo_dict[r_id]['name']\n\n                                        answer[pkg].append({\n                                            'package': pkg_id2full_name[upd_pkg_id],\n                                            'erratum': e_name,\n                                            'repository': r_name})\n        response = {\n            'update_list': answer,\n        }\n\n        if provided_repo_ids is not None:\n            response.update({'repository_list': provided_repo_names})\n\n        return response", "line_changes": {"deleted": [{"line_no": 142, "char_start": 5194, "char_end": 5220, "line": "                sql = \"\"\"\n"}, {"line_no": 143, "char_start": 5220, "char_end": 5377, "line": "                select package.id from package join evr on package.evr_id = evr.id where package.id in %s and evr.evr > (select evr from evr where id = %s);\n"}, {"line_no": 144, "char_start": 5377, "char_end": 5442, "line": "                \"\"\" % ('%s', str(auxiliary_dict[pkg]['evr_id']))\n"}, {"line_no": 145, "char_start": 5442, "char_end": 5443, "line": "\n"}, {"line_no": 146, "char_start": 5443, "char_end": 5517, "line": "                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n])])\n"}], "added": [{"line_no": 138, "char_start": 5037, "char_end": 5072, "line": "        sql = \"\"\"SELECT package.id\n"}, {"line_no": 139, "char_start": 5072, "char_end": 5104, "line": "                   FROM package\n"}, {"line_no": 140, "char_start": 5104, "char_end": 5159, "line": "                   JOIN evr ON package.evr_id = evr.id\n"}, {"line_no": 141, "char_start": 5159, "char_end": 5253, "line": "                  WHERE package.id in %s and evr.evr > (select evr from evr where id = %s)\"\"\"\n"}, {"line_no": 146, "char_start": 5410, "char_end": 5483, "line": "                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n]),\n"}, {"line_no": 147, "char_start": 5483, "char_end": 5557, "line": "                                          auxiliary_dict[pkg]['evr_id']])\n"}]}, "char_changes": {"deleted": [{"char_start": 5045, "char_end": 5271, "chars": "for pkg in auxiliary_dict:\n            n, v, r, e, a = split_filename(str(pkg))\n\n            if n in auxiliary_dict[pkg] and auxiliary_dict[pkg][n]:\n                sql = \"\"\"\n                select package.id from package join"}, {"char_start": 5276, "char_end": 5278, "chars": "on"}, {"char_start": 5302, "char_end": 5308, "chars": " where"}, {"char_start": 5375, "char_end": 5376, "chars": ";"}, {"char_start": 5385, "char_end": 5514, "chars": "        \"\"\" % ('%s', str(auxiliary_dict[pkg]['evr_id']))\n\n                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n])"}], "added": [{"char_start": 5045, "char_end": 5127, "chars": "sql = \"\"\"SELECT package.id\n                   FROM package\n                   JOIN"}, {"char_start": 5132, "char_end": 5134, "chars": "ON"}, {"char_start": 5158, "char_end": 5182, "chars": "\n                  WHERE"}, {"char_start": 5249, "char_end": 5252, "chars": "\"\"\""}, {"char_start": 5261, "char_end": 5554, "chars": "for pkg in auxiliary_dict:\n            n, v, r, e, a = split_filename(str(pkg))\n\n            if n in auxiliary_dict[pkg] and auxiliary_dict[pkg][n]:\n                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n]),\n                                          auxiliary_dict[pkg]['evr_id']"}]}, "commit_link": "github.com/RedHatInsights/vmaas/commit/49603ff9d29a9d411a681b3cc8096a6585ec1272", "file_name": "webapp/updates.py", "vul_type": "cwe-089"}
{"func_name": "getEvents", "func_src_before": "@app.route('/getEvents/<userid>')\ndef getEvents(userid):\n    connection = get_db()\n\n    cursor = connection.cursor()\n\n    query = \"SELECT DISTINCT * FROM samwisedb.Event WHERE user = \\\"\" + userid + \"\\\";\"\n    cursor.execute(query)\n\n    data = [{\"eventName\": str(item[2]), \"startTime\": str(item[3]), \"endTime\": str(item[4]), \"tagId\": str(item[5])} for\n            item in cursor.fetchall()]\n\n    return json.dumps(data)", "func_src_after": "@app.route('/getEvents/<userid>')\ndef getEvents(userid):\n    connection = get_db()\n\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT * FROM samwisedb.Event WHERE user = %s', userid)\n    data = [{\"eventName\": str(item[2]), \"startTime\": str(item[3]), \"endTime\": str(item[4]), \"tagId\": str(item[5])} for\n            item in cursor.fetchall()]\n\n    return jsonify(data)", "line_changes": {"deleted": [{"line_no": 6, "char_start": 117, "char_end": 118, "line": "\n"}, {"line_no": 7, "char_start": 118, "char_end": 204, "line": "    query = \"SELECT DISTINCT * FROM samwisedb.Event WHERE user = \\\"\" + userid + \"\\\";\"\n"}, {"line_no": 8, "char_start": 204, "char_end": 230, "line": "    cursor.execute(query)\n"}, {"line_no": 9, "char_start": 230, "char_end": 231, "line": "\n"}, {"line_no": 13, "char_start": 390, "char_end": 417, "line": "    return json.dumps(data)\n"}], "added": [{"line_no": 6, "char_start": 117, "char_end": 202, "line": "    cursor.execute('SELECT DISTINCT * FROM samwisedb.Event WHERE user = %s', userid)\n"}, {"line_no": 10, "char_start": 361, "char_end": 385, "line": "    return jsonify(data)\n"}]}, "char_changes": {"deleted": [{"char_start": 117, "char_end": 118, "chars": "\n"}, {"char_start": 122, "char_end": 131, "chars": "query = \""}, {"char_start": 183, "char_end": 188, "chars": "\\\"\" +"}, {"char_start": 195, "char_end": 230, "chars": " + \"\\\";\"\n    cursor.execute(query)\n"}, {"char_start": 405, "char_end": 411, "chars": ".dumps"}], "added": [{"char_start": 121, "char_end": 137, "chars": "cursor.execute('"}, {"char_start": 189, "char_end": 193, "chars": "%s',"}, {"char_start": 200, "char_end": 201, "chars": ")"}, {"char_start": 376, "char_end": 379, "chars": "ify"}]}, "commit_link": "github.com/cornell-dti/project-samwise/commit/650b26c48bcb7824775ff269d4badf27666b611e", "file_name": "app/run.py", "vul_type": "cwe-089"}
{"func_name": "removeEvent", "func_src_before": "@app.route('/removeEvent/', methods=['POST'])\ndef removeEvent():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        eventId = data['eventId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            query = \"DELETE FROM samwisedb.Event WHERE eventId = \\\"\" + eventId + \"\\\";\"\n            print(query)\n            cursor.execute(query)\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return json.dumps([])", "func_src_after": "@app.route('/removeEvent/', methods=['POST'])\ndef removeEvent():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        eventId = data['eventId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute('DELETE FROM samwisedb.Event WHERE eventId = %s', eventId)\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return jsonify([])", "line_changes": {"deleted": [{"line_no": 11, "char_start": 262, "char_end": 349, "line": "            query = \"DELETE FROM samwisedb.Event WHERE eventId = \\\"\" + eventId + \"\\\";\"\n"}, {"line_no": 12, "char_start": 349, "char_end": 374, "line": "            print(query)\n"}, {"line_no": 13, "char_start": 374, "char_end": 408, "line": "            cursor.execute(query)\n"}, {"line_no": 18, "char_start": 485, "char_end": 510, "line": "    return json.dumps([])\n"}], "added": [{"line_no": 11, "char_start": 262, "char_end": 348, "line": "            cursor.execute('DELETE FROM samwisedb.Event WHERE eventId = %s', eventId)\n"}, {"line_no": 16, "char_start": 425, "char_end": 447, "line": "    return jsonify([])\n"}]}, "char_changes": {"deleted": [{"char_start": 274, "char_end": 283, "chars": "query = \""}, {"char_start": 327, "char_end": 332, "chars": "\\\"\" +"}, {"char_start": 340, "char_end": 406, "chars": " + \"\\\";\"\n            print(query)\n            cursor.execute(query"}, {"char_start": 500, "char_end": 506, "chars": ".dumps"}], "added": [{"char_start": 274, "char_end": 290, "chars": "cursor.execute('"}, {"char_start": 334, "char_end": 338, "chars": "%s',"}, {"char_start": 440, "char_end": 443, "chars": "ify"}]}, "commit_link": "github.com/cornell-dti/project-samwise/commit/650b26c48bcb7824775ff269d4badf27666b611e", "file_name": "app/run.py", "vul_type": "cwe-089"}
{"func_name": "addEvent", "func_src_before": "@app.route('/addEvent/', methods=['POST'])\ndef addEvent():\n    event_id = -1\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        user = data['user']\n        eventName = data['eventName']\n        startTime = data['startTime']\n        endTime = data['endTime']\n        tagId = data['tagId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            query = \"insert into samwisedb.Event(user, eventName, startTime, endTime, tagId) values (\\\"\" + user + \"\\\", \\\"\" + eventName + \"\\\", \\\"\" + startTime + \"\\\", \\\"\" + endTime + \"\\\", \\\"\" + tagId + \"\\\");\"\n            print(query)\n            cursor.execute(query)\n            connection.commit()\n            event_id = cursor.lastrowid\n        finally:\n            print (\"DONE\")\n    return json.dumps([event_id])", "func_src_after": "@app.route('/addEvent/', methods=['POST'])\ndef addEvent():\n    event_id = -1\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        user = data['user']\n        eventName = data['eventName']\n        startTime = data['startTime']\n        endTime = data['endTime']\n        tagId = data['tagId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\n                'INSERT INTO samwisedb.Event(user, eventName, startTime, endTime, tagId) values (%s, %s, %s, %s, %s)',\n                (user, eventName, startTime, endTime, tagId))\n            connection.commit()\n            event_id = cursor.lastrowid\n        finally:\n            print (\"DONE\")\n    return jsonify([event_id])", "line_changes": {"deleted": [{"line_no": 16, "char_start": 408, "char_end": 615, "line": "            query = \"insert into samwisedb.Event(user, eventName, startTime, endTime, tagId) values (\\\"\" + user + \"\\\", \\\"\" + eventName + \"\\\", \\\"\" + startTime + \"\\\", \\\"\" + endTime + \"\\\", \\\"\" + tagId + \"\\\");\"\n"}, {"line_no": 17, "char_start": 615, "char_end": 640, "line": "            print(query)\n"}, {"line_no": 18, "char_start": 640, "char_end": 674, "line": "            cursor.execute(query)\n"}, {"line_no": 23, "char_start": 790, "char_end": 823, "line": "    return json.dumps([event_id])\n"}], "added": [{"line_no": 16, "char_start": 408, "char_end": 436, "line": "            cursor.execute(\n"}, {"line_no": 17, "char_start": 436, "char_end": 555, "line": "                'INSERT INTO samwisedb.Event(user, eventName, startTime, endTime, tagId) values (%s, %s, %s, %s, %s)',\n"}, {"line_no": 18, "char_start": 555, "char_end": 617, "line": "                (user, eventName, startTime, endTime, tagId))\n"}, {"line_no": 23, "char_start": 733, "char_end": 763, "line": "    return jsonify([event_id])\n"}]}, "char_changes": {"deleted": [{"char_start": 420, "char_end": 440, "chars": "query = \"insert into"}, {"char_start": 509, "char_end": 672, "chars": "\\\"\" + user + \"\\\", \\\"\" + eventName + \"\\\", \\\"\" + startTime + \"\\\", \\\"\" + endTime + \"\\\", \\\"\" + tagId + \"\\\");\"\n            print(query)\n            cursor.execute(query"}, {"char_start": 805, "char_end": 811, "chars": ".dumps"}], "added": [{"char_start": 420, "char_end": 464, "chars": "cursor.execute(\n                'INSERT INTO"}, {"char_start": 533, "char_end": 615, "chars": "%s, %s, %s, %s, %s)',\n                (user, eventName, startTime, endTime, tagId)"}, {"char_start": 748, "char_end": 751, "chars": "ify"}]}, "commit_link": "github.com/cornell-dti/project-samwise/commit/650b26c48bcb7824775ff269d4badf27666b611e", "file_name": "app/run.py", "vul_type": "cwe-089"}
{"func_name": "updateEvent", "func_src_before": "@app.route('/updateEvent/', methods=['POST'])\ndef updateEvent():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        eventId = data['eventId']\n        eventName = data['eventName']\n        startTime = data['startTime']\n        endTime = data['endTime']\n        tagId = data['tagId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\"\"\"\n               UPDATE samwisedb.Event\n               SET eventName=%s, startTime=%s, endTime=%s, tagId=%s\n               WHERE eventId=%s\n            \"\"\", (eventName, startTime, endTime, tagId, eventId))\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return json.dumps([])", "func_src_after": "@app.route('/updateEvent/', methods=['POST'])\ndef updateEvent():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        eventId = data['eventId']\n        eventName = data['eventName']\n        startTime = data['startTime']\n        endTime = data['endTime']\n        tagId = data['tagId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\n                'UPDATE samwisedb.Event SET eventName=%s, startTime=%s, endTime=%s, tagId=%s WHERE eventId=%s',\n                (eventName, startTime, endTime, tagId, eventId))\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return jsonify([])", "line_changes": {"deleted": [{"line_no": 15, "char_start": 402, "char_end": 433, "line": "            cursor.execute(\"\"\"\n"}, {"line_no": 16, "char_start": 433, "char_end": 471, "line": "               UPDATE samwisedb.Event\n"}, {"line_no": 17, "char_start": 471, "char_end": 539, "line": "               SET eventName=%s, startTime=%s, endTime=%s, tagId=%s\n"}, {"line_no": 18, "char_start": 539, "char_end": 571, "line": "               WHERE eventId=%s\n"}, {"line_no": 19, "char_start": 571, "char_end": 637, "line": "            \"\"\", (eventName, startTime, endTime, tagId, eventId))\n"}, {"line_no": 24, "char_start": 714, "char_end": 739, "line": "    return json.dumps([])\n"}], "added": [{"line_no": 15, "char_start": 402, "char_end": 430, "line": "            cursor.execute(\n"}, {"line_no": 16, "char_start": 430, "char_end": 542, "line": "                'UPDATE samwisedb.Event SET eventName=%s, startTime=%s, endTime=%s, tagId=%s WHERE eventId=%s',\n"}, {"line_no": 17, "char_start": 542, "char_end": 607, "line": "                (eventName, startTime, endTime, tagId, eventId))\n"}, {"line_no": 22, "char_start": 684, "char_end": 706, "line": "    return jsonify([])\n"}]}, "char_changes": {"deleted": [{"char_start": 429, "char_end": 432, "chars": "\"\"\""}, {"char_start": 470, "char_end": 485, "chars": "\n              "}, {"char_start": 538, "char_end": 553, "chars": "\n              "}, {"char_start": 570, "char_end": 571, "chars": "\n"}, {"char_start": 583, "char_end": 587, "chars": "\"\"\","}, {"char_start": 729, "char_end": 735, "chars": ".dumps"}], "added": [{"char_start": 445, "char_end": 447, "chars": " '"}, {"char_start": 539, "char_end": 541, "chars": "',"}, {"char_start": 554, "char_end": 557, "chars": "   "}, {"char_start": 699, "char_end": 702, "chars": "ify"}]}, "commit_link": "github.com/cornell-dti/project-samwise/commit/650b26c48bcb7824775ff269d4badf27666b611e", "file_name": "app/run.py", "vul_type": "cwe-089"}
{"func_name": "removeTask", "func_src_before": "@app.route('/removeTask/', methods=['POST'])\ndef removeTask():\n    data = request.get_json(force=True)\n    taskId = data['taskid']\n\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.Task WHERE taskId = %s', taskId)\n    connection.commit()\n\n    return json.dumps([])", "func_src_after": "@app.route('/removeTask/', methods=['POST'])\ndef removeTask():\n    data = request.get_json(force=True)\n    taskId = data['taskid']\n\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.Task WHERE taskId = %s', taskId)\n    connection.commit()\n\n    return jsonify([])", "line_changes": {"deleted": [{"line_no": 11, "char_start": 291, "char_end": 316, "line": "    return json.dumps([])\n"}], "added": [{"line_no": 11, "char_start": 291, "char_end": 313, "line": "    return jsonify([])\n"}]}, "char_changes": {"deleted": [{"char_start": 306, "char_end": 312, "chars": ".dumps"}], "added": [{"char_start": 306, "char_end": 309, "chars": "ify"}]}, "commit_link": "github.com/cornell-dti/project-samwise/commit/650b26c48bcb7824775ff269d4badf27666b611e", "file_name": "app/run.py", "vul_type": "cwe-089"}
{"func_name": "addTaskCourse", "func_src_before": "@app.route('/addTask/', methods=['POST'])\ndef addTaskCourse():\n    task_id = -1\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        userid = data['userid']\n        taskname = data['taskname']\n        course = data['course']\n        duedate = data['duedate']\n        details = data['details']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            query = \"INSERT into samwisedb.Task(user, taskName, courseId, dueDate, details) values (\\\"\" + userid + \"\\\", \\\"\" + taskname + \"\\\", \\\"\" + course + \"\\\", \\\"\" + duedate + \"\\\", \\\"\" + details + \"\\\");\"\n            print(query)\n            cursor.execute(query)\n            connection.commit()\n            task_id = cursor.lastrowid\n        finally:\n            print (\"DONE\")\n    return json.dumps([task_id])", "func_src_after": "@app.route('/addTask/', methods=['POST'])\ndef addTaskCourse():\n    task_id = -1\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        userid = data['userid']\n        taskname = data['taskname']\n        course = data['course']\n        duedate = data['duedate']\n        details = data['details']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute('INSERT INTO samwisedb.Task(user, taskName, courseId, dueDate, details) values (%s, %s, %s, %s, %s)', (userid, taskname, course, duedate, details))\n            connection.commit()\n            task_id = cursor.lastrowid\n        finally:\n            print (\"DONE\")\n    return jsonify([task_id])", "line_changes": {"deleted": [{"line_no": 16, "char_start": 411, "char_end": 617, "line": "            query = \"INSERT into samwisedb.Task(user, taskName, courseId, dueDate, details) values (\\\"\" + userid + \"\\\", \\\"\" + taskname + \"\\\", \\\"\" + course + \"\\\", \\\"\" + duedate + \"\\\", \\\"\" + details + \"\\\");\"\n"}, {"line_no": 17, "char_start": 617, "char_end": 642, "line": "            print(query)\n"}, {"line_no": 18, "char_start": 642, "char_end": 676, "line": "            cursor.execute(query)\n"}, {"line_no": 23, "char_start": 791, "char_end": 823, "line": "    return json.dumps([task_id])\n"}], "added": [{"line_no": 16, "char_start": 411, "char_end": 586, "line": "            cursor.execute('INSERT INTO samwisedb.Task(user, taskName, courseId, dueDate, details) values (%s, %s, %s, %s, %s)', (userid, taskname, course, duedate, details))\n"}, {"line_no": 21, "char_start": 701, "char_end": 730, "line": "    return jsonify([task_id])\n"}]}, "char_changes": {"deleted": [{"char_start": 423, "char_end": 432, "chars": "query = \""}, {"char_start": 439, "char_end": 443, "chars": "into"}, {"char_start": 511, "char_end": 674, "chars": "\\\"\" + userid + \"\\\", \\\"\" + taskname + \"\\\", \\\"\" + course + \"\\\", \\\"\" + duedate + \"\\\", \\\"\" + details + \"\\\");\"\n            print(query)\n            cursor.execute(query"}, {"char_start": 806, "char_end": 812, "chars": ".dumps"}], "added": [{"char_start": 423, "char_end": 439, "chars": "cursor.execute('"}, {"char_start": 446, "char_end": 450, "chars": "INTO"}, {"char_start": 518, "char_end": 584, "chars": "%s, %s, %s, %s, %s)', (userid, taskname, course, duedate, details)"}, {"char_start": 716, "char_end": 719, "chars": "ify"}]}, "commit_link": "github.com/cornell-dti/project-samwise/commit/650b26c48bcb7824775ff269d4badf27666b611e", "file_name": "app/run.py", "vul_type": "cwe-089"}
{"func_name": "updateTask", "func_src_before": "@app.route('/updateTask/', methods=['POST'])\ndef updateTask():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        taskid = data['taskid']\n        taskname = data['taskname']\n        details = data['details']\n        duedate = data['duedate']\n        course = data['course']\n\n        taskid = int(taskid)\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\"\"\"\n               UPDATE samwisedb.Task\n               SET taskName=%s, dueDate=%s, courseId=%s, details=%s\n               WHERE taskId=%s\n            \"\"\", (taskname, duedate, course, details, taskid))\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return json.dumps([])", "func_src_after": "@app.route('/updateTask/', methods=['POST'])\ndef updateTask():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        taskid = data['taskid']\n        taskname = data['taskname']\n        details = data['details']\n        duedate = data['duedate']\n        course = data['course']\n\n        taskid = int(taskid)\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\"\"\"\n               UPDATE samwisedb.Task\n               SET taskName=%s, dueDate=%s, courseId=%s, details=%s\n               WHERE taskId=%s\n            \"\"\", (taskname, duedate, course, details, taskid))\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return jsonify([])", "line_changes": {"deleted": [{"line_no": 26, "char_start": 731, "char_end": 756, "line": "    return json.dumps([])\n"}], "added": [{"line_no": 26, "char_start": 731, "char_end": 753, "line": "    return jsonify([])\n"}]}, "char_changes": {"deleted": [{"char_start": 746, "char_end": 752, "chars": ".dumps"}], "added": [{"char_start": 746, "char_end": 749, "chars": "ify"}]}, "commit_link": "github.com/cornell-dti/project-samwise/commit/650b26c48bcb7824775ff269d4badf27666b611e", "file_name": "app/run.py", "vul_type": "cwe-089"}
{"func_name": "getClassInfo", "func_src_before": "@app.route('/courses/<courseId>')\ndef getClassInfo(courseId):\n    # Open the connection to database\n    connection = get_db()\n\n    cursor = connection.cursor()\n    cursor.execute('SELECT startTime FROM samwisedb.Course WHERE courseId = %s', courseId)\n    data = [{\"course\": courseId + \" Class\", \"start\": str(item[0])} for item in cursor.fetchall()]\n    return json.dumps(data)", "func_src_after": "@app.route('/courses/<courseId>')\ndef getClassInfo(courseId):\n    # Open the connection to database\n    connection = get_db()\n\n    cursor = connection.cursor()\n    cursor.execute('SELECT startTime FROM samwisedb.Course WHERE courseId = %s', courseId)\n    data = [{\"course\": courseId + \" Class\", \"start\": str(item[0])} for item in cursor.fetchall()]\n    return jsonify(data)", "line_changes": {"deleted": [{"line_no": 9, "char_start": 349, "char_end": 376, "line": "    return json.dumps(data)\n"}], "added": [{"line_no": 9, "char_start": 349, "char_end": 373, "line": "    return jsonify(data)\n"}]}, "char_changes": {"deleted": [{"char_start": 364, "char_end": 370, "chars": ".dumps"}], "added": [{"char_start": 364, "char_end": 367, "chars": "ify"}]}, "commit_link": "github.com/cornell-dti/project-samwise/commit/650b26c48bcb7824775ff269d4badf27666b611e", "file_name": "app/run.py", "vul_type": "cwe-089"}
{"func_name": "getCommentsByUser", "func_src_before": "    def getCommentsByUser(self,userid):\n        sqlText=\"select comment from comments order by date desc where userid=%d\"%(userid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getCommentsByUser(self,userid):\n        sqlText=\"select comment from comments order by date desc where userid=%s\"\n        params=[userid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 40, "char_end": 131, "line": "        sqlText=\"select comment from comments order by date desc where userid=%d\"%(userid)\n"}, {"line_no": 3, "char_start": 131, "char_end": 177, "line": "        result=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 40, "char_end": 122, "line": "        sqlText=\"select comment from comments order by date desc where userid=%s\"\n"}, {"line_no": 3, "char_start": 122, "char_end": 146, "line": "        params=[userid]\n"}, {"line_no": 4, "char_start": 146, "char_end": 199, "line": "        result=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 119, "char_end": 123, "chars": "d\"%("}, {"char_start": 129, "char_end": 130, "chars": ")"}], "added": [{"char_start": 119, "char_end": 138, "chars": "s\"\n        params=["}, {"char_start": 144, "char_end": 145, "chars": "]"}, {"char_start": 190, "char_end": 197, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089"}
{"func_name": "getCommentsByPostid", "func_src_before": "    def getCommentsByPostid(self,postid,userid):\n        sqlText=\"select (select Count(*) from comment_like where comments.commentid = comment_like.commentid) as like,(select Count(*) from comment_like where comments.commentid = comment_like.commentid and comment_like.userid=%d) as flag,commentid,name,comment from users,comments where users.userid=comments.userid and postid=%d order by date desc;\"%(userid,postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getCommentsByPostid(self,postid,userid):\n        sqlText=\"select (select Count(*) from comment_like where \\\n        comments.commentid = comment_like.commentid) as like,(select Count(*) \\\n                from comment_like where comments.commentid = \\\n                comment_like.commentid and comment_like.userid=%s) as \\\n                flag,commentid,name,comment from users,comments where \\\n                users.userid=comments.userid and postid=%s order by date desc;\"\n        params=[userid,postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 49, "char_end": 417, "line": "        sqlText=\"select (select Count(*) from comment_like where comments.commentid = comment_like.commentid) as like,(select Count(*) from comment_like where comments.commentid = comment_like.commentid and comment_like.userid=%d) as flag,commentid,name,comment from users,comments where users.userid=comments.userid and postid=%d order by date desc;\"%(userid,postid)\n"}, {"line_no": 3, "char_start": 417, "char_end": 463, "line": "        result=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 49, "char_end": 116, "line": "        sqlText=\"select (select Count(*) from comment_like where \\\n"}, {"line_no": 3, "char_start": 116, "char_end": 196, "line": "        comments.commentid = comment_like.commentid) as like,(select Count(*) \\\n"}, {"line_no": 4, "char_start": 196, "char_end": 259, "line": "                from comment_like where comments.commentid = \\\n"}, {"line_no": 5, "char_start": 259, "char_end": 331, "line": "                comment_like.commentid and comment_like.userid=%s) as \\\n"}, {"line_no": 6, "char_start": 331, "char_end": 403, "line": "                flag,commentid,name,comment from users,comments where \\\n"}, {"line_no": 7, "char_start": 403, "char_end": 483, "line": "                users.userid=comments.userid and postid=%s order by date desc;\"\n"}, {"line_no": 8, "char_start": 483, "char_end": 514, "line": "        params=[userid,postid]\n"}, {"line_no": 9, "char_start": 514, "char_end": 567, "line": "        result=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 277, "char_end": 278, "chars": "d"}, {"char_start": 378, "char_end": 379, "chars": "d"}, {"char_start": 400, "char_end": 402, "chars": "%("}, {"char_start": 415, "char_end": 416, "chars": ")"}], "added": [{"char_start": 114, "char_end": 124, "chars": "\\\n        "}, {"char_start": 193, "char_end": 211, "chars": " \\\n               "}, {"char_start": 256, "char_end": 274, "chars": " \\\n               "}, {"char_start": 323, "char_end": 324, "chars": "s"}, {"char_start": 329, "char_end": 347, "chars": "\\\n                "}, {"char_start": 401, "char_end": 419, "chars": "\\\n                "}, {"char_start": 460, "char_end": 461, "chars": "s"}, {"char_start": 482, "char_end": 499, "chars": "\n        params=["}, {"char_start": 512, "char_end": 513, "chars": "]"}, {"char_start": 558, "char_end": 565, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089"}
{"func_name": "getCommentsLike", "func_src_before": "    def getCommentsLike(self,commentid):\n        sqlText=\"select userid from comment_like where commentid=%d\"%(commentid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getCommentsLike(self,commentid):\n        sqlText=\"select userid from comment_like where commentid=%s\"\n        params=[commentid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 41, "char_end": 122, "line": "        sqlText=\"select userid from comment_like where commentid=%d\"%(commentid)\n"}, {"line_no": 3, "char_start": 122, "char_end": 168, "line": "        result=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 41, "char_end": 110, "line": "        sqlText=\"select userid from comment_like where commentid=%s\"\n"}, {"line_no": 3, "char_start": 110, "char_end": 137, "line": "        params=[commentid]\n"}, {"line_no": 4, "char_start": 137, "char_end": 190, "line": "        result=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 111, "chars": "d\"%("}, {"char_start": 120, "char_end": 121, "chars": ")"}], "added": [{"char_start": 107, "char_end": 126, "chars": "s\"\n        params=["}, {"char_start": 135, "char_end": 136, "chars": "]"}, {"char_start": 181, "char_end": 188, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089"}
{"func_name": "insertData", "func_src_before": "    def insertData(self,comment,userid,postid):\n        sqlText=\"insert into comments(comment,userid,date,postid) values('%s',%d,current_timestamp(0),%d);\"%(comment,userid,postid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def insertData(self,comment,userid,postid):\n        sqlText=\"insert into comments(comment,userid,date,postid) \\\n        values(%s,%s,current_timestamp(0),%s);\"\n        params=[comment,userid,postid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 48, "char_end": 180, "line": "        sqlText=\"insert into comments(comment,userid,date,postid) values('%s',%d,current_timestamp(0),%d);\"%(comment,userid,postid)\n"}, {"line_no": 3, "char_start": 180, "char_end": 227, "line": "        result=sql.insertDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 48, "char_end": 116, "line": "        sqlText=\"insert into comments(comment,userid,date,postid) \\\n"}, {"line_no": 3, "char_start": 116, "char_end": 164, "line": "        values(%s,%s,current_timestamp(0),%s);\"\n"}, {"line_no": 4, "char_start": 164, "char_end": 203, "line": "        params=[comment,userid,postid]\n"}, {"line_no": 5, "char_start": 203, "char_end": 257, "line": "        result=sql.insertDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 121, "char_end": 122, "chars": "'"}, {"char_start": 124, "char_end": 125, "chars": "'"}, {"char_start": 127, "char_end": 128, "chars": "d"}, {"char_start": 151, "char_end": 152, "chars": "d"}, {"char_start": 155, "char_end": 157, "chars": "%("}, {"char_start": 178, "char_end": 179, "chars": ")"}], "added": [{"char_start": 113, "char_end": 123, "chars": " \\\n       "}, {"char_start": 135, "char_end": 136, "chars": "s"}, {"char_start": 159, "char_end": 160, "chars": "s"}, {"char_start": 163, "char_end": 180, "chars": "\n        params=["}, {"char_start": 201, "char_end": 202, "chars": "]"}, {"char_start": 248, "char_end": 255, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089"}
{"func_name": "deleteComment", "func_src_before": "    def deleteComment(self,commentid):\n        sqlText=\"delete from comments where commentid=%d\"%(commentid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def deleteComment(self,commentid):\n        sqlText=\"delete from comments where commentid=%s\"\n        params=[commentid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 39, "char_end": 109, "line": "        sqlText=\"delete from comments where commentid=%d\"%(commentid)\n"}, {"line_no": 3, "char_start": 109, "char_end": 156, "line": "        result=sql.deleteDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 39, "char_end": 97, "line": "        sqlText=\"delete from comments where commentid=%s\"\n"}, {"line_no": 3, "char_start": 97, "char_end": 124, "line": "        params=[commentid]\n"}, {"line_no": 4, "char_start": 124, "char_end": 178, "line": "        result=sql.deleteDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 94, "char_end": 98, "chars": "d\"%("}, {"char_start": 107, "char_end": 108, "chars": ")"}], "added": [{"char_start": 94, "char_end": 113, "chars": "s\"\n        params=["}, {"char_start": 122, "char_end": 123, "chars": "]"}, {"char_start": 169, "char_end": 176, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089"}
{"func_name": "likeComments", "func_src_before": "    def likeComments(self,commentid,userid):\n        sqlText=\"insert into comment_like values(%d,%d);\"%(userid,commentid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def likeComments(self,commentid,userid):\n        sqlText=\"insert into comment_like values(%s,%s);\"\n        params=[userid,commentid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 45, "char_end": 122, "line": "        sqlText=\"insert into comment_like values(%d,%d);\"%(userid,commentid)\n"}, {"line_no": 3, "char_start": 122, "char_end": 169, "line": "        result=sql.insertDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 45, "char_end": 103, "line": "        sqlText=\"insert into comment_like values(%s,%s);\"\n"}, {"line_no": 3, "char_start": 103, "char_end": 137, "line": "        params=[userid,commentid]\n"}, {"line_no": 4, "char_start": 137, "char_end": 191, "line": "        result=sql.insertDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 95, "char_end": 96, "chars": "d"}, {"char_start": 98, "char_end": 99, "chars": "d"}, {"char_start": 102, "char_end": 104, "chars": "%("}, {"char_start": 120, "char_end": 121, "chars": ")"}], "added": [{"char_start": 95, "char_end": 96, "chars": "s"}, {"char_start": 98, "char_end": 99, "chars": "s"}, {"char_start": 102, "char_end": 119, "chars": "\n        params=["}, {"char_start": 135, "char_end": 136, "chars": "]"}, {"char_start": 182, "char_end": 189, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089"}
{"func_name": "dislikeComments", "func_src_before": "    def dislikeComments(self,commentid,userid):\n        sqlText=\"delete from comment_like where commentid=%d and userid=%d;\"%(commentid,userid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def dislikeComments(self,commentid,userid):\n        sqlText=\"delete from comment_like where commentid=%s and userid=%s;\"\n        params=[commentid,userid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 48, "char_end": 144, "line": "        sqlText=\"delete from comment_like where commentid=%d and userid=%d;\"%(commentid,userid)\n"}, {"line_no": 3, "char_start": 144, "char_end": 191, "line": "        result=sql.deleteDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 48, "char_end": 125, "line": "        sqlText=\"delete from comment_like where commentid=%s and userid=%s;\"\n"}, {"line_no": 3, "char_start": 125, "char_end": 159, "line": "        params=[commentid,userid]\n"}, {"line_no": 4, "char_start": 159, "char_end": 213, "line": "        result=sql.deleteDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 108, "chars": "d"}, {"char_start": 121, "char_end": 122, "chars": "d"}, {"char_start": 124, "char_end": 126, "chars": "%("}, {"char_start": 142, "char_end": 143, "chars": ")"}], "added": [{"char_start": 107, "char_end": 108, "chars": "s"}, {"char_start": 121, "char_end": 122, "chars": "s"}, {"char_start": 124, "char_end": 141, "chars": "\n        params=["}, {"char_start": 157, "char_end": 158, "chars": "]"}, {"char_start": 204, "char_end": 211, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089"}
{"func_name": "getAllPosts", "func_src_before": "    def getAllPosts(self,userid):\n        sqlText=\"select users.name,post.comment,post.postid,(select Count(*) from post_like \\\n                where post.postid = post_like.postid) as like,\\\n                (select Count(*) from post_like where post.postid =post_like.postid \\\n                and post_like.userid=%d) as flag from users,post \\\n                where post.userid=users.userid and (post.userid in \\\n                (select friendid from friends where userid =%d) or post.userid=%d )\\\n                order by post.date desc;\"%(userid,userid,userid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getAllPosts(self,userid):\n        sqlText=\"select users.name,post.comment,post.postid,(select Count(*) from post_like \\\n                where post.postid = post_like.postid) as like,\\\n                (select Count(*) from post_like where post.postid =post_like.postid \\\n                and post_like.userid=%s) as flag from users,post \\\n                where post.userid=users.userid and (post.userid in \\\n                (select friendid from friends where userid =%s) or post.userid=%s)\\\n                order by post.date desc;\"\n        params=[userid,userid,userid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 5, "char_start": 278, "char_end": 345, "line": "                and post_like.userid=%d) as flag from users,post \\\n"}, {"line_no": 7, "char_start": 414, "char_end": 499, "line": "                (select friendid from friends where userid =%d) or post.userid=%d )\\\n"}, {"line_no": 8, "char_start": 499, "char_end": 564, "line": "                order by post.date desc;\"%(userid,userid,userid)\n"}, {"line_no": 9, "char_start": 564, "char_end": 610, "line": "        result=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 5, "char_start": 278, "char_end": 345, "line": "                and post_like.userid=%s) as flag from users,post \\\n"}, {"line_no": 7, "char_start": 414, "char_end": 498, "line": "                (select friendid from friends where userid =%s) or post.userid=%s)\\\n"}, {"line_no": 8, "char_start": 498, "char_end": 540, "line": "                order by post.date desc;\"\n"}, {"line_no": 9, "char_start": 540, "char_end": 578, "line": "        params=[userid,userid,userid]\n"}, {"line_no": 10, "char_start": 578, "char_end": 631, "line": "        result=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 316, "char_end": 317, "chars": "d"}, {"char_start": 475, "char_end": 476, "chars": "d"}, {"char_start": 494, "char_end": 496, "chars": "d "}, {"char_start": 540, "char_end": 542, "chars": "%("}, {"char_start": 562, "char_end": 563, "chars": ")"}], "added": [{"char_start": 316, "char_end": 317, "chars": "s"}, {"char_start": 475, "char_end": 476, "chars": "s"}, {"char_start": 494, "char_end": 495, "chars": "s"}, {"char_start": 539, "char_end": 556, "chars": "\n        params=["}, {"char_start": 576, "char_end": 577, "chars": "]"}, {"char_start": 622, "char_end": 629, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089"}
{"func_name": "getPostsByPostid", "func_src_before": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%d\"%(postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%s\"\n        params=[postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 3, "char_start": 111, "char_end": 181, "line": "                users.userid=post.userid and post.postid=%d\"%(postid)\n"}, {"line_no": 4, "char_start": 181, "char_end": 227, "line": "        result=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 3, "char_start": 111, "char_end": 172, "line": "                users.userid=post.userid and post.postid=%s\"\n"}, {"line_no": 4, "char_start": 172, "char_end": 196, "line": "        params=[postid]\n"}, {"line_no": 5, "char_start": 196, "char_end": 249, "line": "        result=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 169, "char_end": 173, "chars": "d\"%("}, {"char_start": 179, "char_end": 180, "chars": ")"}], "added": [{"char_start": 169, "char_end": 188, "chars": "s\"\n        params=["}, {"char_start": 194, "char_end": 195, "chars": "]"}, {"char_start": 240, "char_end": 247, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089"}
{"func_name": "getPostLike", "func_src_before": "    def getPostLike(self,postid):\n        sqlText=\"select userid from post_like where postid=%d\"%(postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getPostLike(self,postid):\n        sqlText=\"select userid from post_like where postid=%s\"\n        params=[postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 34, "char_end": 106, "line": "        sqlText=\"select userid from post_like where postid=%d\"%(postid)\n"}, {"line_no": 3, "char_start": 106, "char_end": 152, "line": "        result=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 97, "line": "        sqlText=\"select userid from post_like where postid=%s\"\n"}, {"line_no": 3, "char_start": 97, "char_end": 121, "line": "        params=[postid]\n"}, {"line_no": 4, "char_start": 121, "char_end": 174, "line": "        result=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 94, "char_end": 98, "chars": "d\"%("}, {"char_start": 104, "char_end": 105, "chars": ")"}], "added": [{"char_start": 94, "char_end": 113, "chars": "s\"\n        params=["}, {"char_start": 119, "char_end": 120, "chars": "]"}, {"char_start": 165, "char_end": 172, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089"}
{"func_name": "likePost", "func_src_before": "    def likePost(self,postid,userid):\n        sqlText=\"insert into post_like values(%d,%d);\"%(postid,userid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def likePost(self,postid,userid):\n        sqlText=\"insert into post_like values(%s,%s);\"\n        params=[postid,userid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 38, "char_end": 109, "line": "        sqlText=\"insert into post_like values(%d,%d);\"%(postid,userid)\n"}, {"line_no": 3, "char_start": 109, "char_end": 156, "line": "        result=sql.insertDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 38, "char_end": 93, "line": "        sqlText=\"insert into post_like values(%s,%s);\"\n"}, {"line_no": 3, "char_start": 93, "char_end": 124, "line": "        params=[postid,userid]\n"}, {"line_no": 4, "char_start": 124, "char_end": 178, "line": "        result=sql.insertDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 85, "char_end": 86, "chars": "d"}, {"char_start": 88, "char_end": 89, "chars": "d"}, {"char_start": 92, "char_end": 94, "chars": "%("}, {"char_start": 107, "char_end": 108, "chars": ")"}], "added": [{"char_start": 85, "char_end": 86, "chars": "s"}, {"char_start": 88, "char_end": 89, "chars": "s"}, {"char_start": 92, "char_end": 109, "chars": "\n        params=["}, {"char_start": 122, "char_end": 123, "chars": "]"}, {"char_start": 169, "char_end": 176, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089"}
{"func_name": "dislikePost", "func_src_before": "    def dislikePost(self,postid,userid):\n        sqlText=\"delete from post_like where postid=%d and userid=%d;\"%(postid,userid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def dislikePost(self,postid,userid):\n        sqlText=\"delete from post_like where postid=%s and userid=%s;\"\n        params=[postid,userid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 41, "char_end": 128, "line": "        sqlText=\"delete from post_like where postid=%d and userid=%d;\"%(postid,userid)\n"}, {"line_no": 3, "char_start": 128, "char_end": 175, "line": "        result=sql.deleteDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 41, "char_end": 112, "line": "        sqlText=\"delete from post_like where postid=%s and userid=%s;\"\n"}, {"line_no": 3, "char_start": 112, "char_end": 143, "line": "        params=[postid,userid]\n"}, {"line_no": 4, "char_start": 143, "char_end": 197, "line": "        result=sql.deleteDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 94, "char_end": 95, "chars": "d"}, {"char_start": 108, "char_end": 109, "chars": "d"}, {"char_start": 111, "char_end": 113, "chars": "%("}, {"char_start": 126, "char_end": 127, "chars": ")"}], "added": [{"char_start": 94, "char_end": 95, "chars": "s"}, {"char_start": 108, "char_end": 109, "chars": "s"}, {"char_start": 111, "char_end": 128, "chars": "\n        params=["}, {"char_start": 141, "char_end": 142, "chars": "]"}, {"char_start": 188, "char_end": 195, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089"}
{"func_name": "insertData", "func_src_before": "    def insertData(self,userid,post):\n        sqlText=\"insert into post(userid,date,comment) \\\n                values(%d,current_timestamp(0),'%s');\"%(userid,post);\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def insertData(self,userid,post):\n        sqlText=\"insert into post(userid,date,comment) \\\n                values(%s,current_timestamp(0),%s);\"\n        params=[userid,post];\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 3, "char_start": 95, "char_end": 165, "line": "                values(%d,current_timestamp(0),'%s');\"%(userid,post);\n"}, {"line_no": 4, "char_start": 165, "char_end": 212, "line": "        result=sql.insertDB(self.conn,sqlText)\n"}], "added": [{"line_no": 3, "char_start": 95, "char_end": 148, "line": "                values(%s,current_timestamp(0),%s);\"\n"}, {"line_no": 4, "char_start": 148, "char_end": 178, "line": "        params=[userid,post];\n"}, {"line_no": 5, "char_start": 178, "char_end": 232, "line": "        result=sql.insertDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 119, "char_end": 120, "chars": "d"}, {"char_start": 142, "char_end": 143, "chars": "'"}, {"char_start": 145, "char_end": 146, "chars": "'"}, {"char_start": 149, "char_end": 151, "chars": "%("}, {"char_start": 162, "char_end": 163, "chars": ")"}], "added": [{"char_start": 119, "char_end": 120, "chars": "s"}, {"char_start": 147, "char_end": 164, "chars": "\n        params=["}, {"char_start": 175, "char_end": 176, "chars": "]"}, {"char_start": 223, "char_end": 230, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089"}
{"func_name": "deletePost", "func_src_before": "    def deletePost(self,postid):\n        sqlText=\"delete from post where post.postid=%d\"%(postid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def deletePost(self,postid):\n        sqlText=\"delete from post where post.postid=%s\"\n        params=[postid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 33, "char_end": 98, "line": "        sqlText=\"delete from post where post.postid=%d\"%(postid)\n"}, {"line_no": 3, "char_start": 98, "char_end": 145, "line": "        result=sql.deleteDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 89, "line": "        sqlText=\"delete from post where post.postid=%s\"\n"}, {"line_no": 3, "char_start": 89, "char_end": 113, "line": "        params=[postid]\n"}, {"line_no": 4, "char_start": 113, "char_end": 167, "line": "        result=sql.deleteDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 86, "char_end": 90, "chars": "d\"%("}, {"char_start": 96, "char_end": 97, "chars": ")"}], "added": [{"char_start": 86, "char_end": 105, "chars": "s\"\n        params=["}, {"char_start": 111, "char_end": 112, "chars": "]"}, {"char_start": 158, "char_end": 165, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089"}
{"func_name": "insertDB", "func_src_before": "def insertDB(conn,sql_insert):\n    cur=conn.cursor()\n    result=cur.execute(sql_insert)\n    conn.commit()\n    print(\"insert data successfull\")\n    return result", "func_src_after": "def insertDB(conn,sql_insert,params):\n    cur=conn.cursor()\n    try:\n        cur.execute(sql_insert,params)\n        conn.commit()\n    except Exception as err:\n        closeDB(conn)\n        print(err)\n    else: \n        print(\"insert data successfull\")", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 31, "line": "def insertDB(conn,sql_insert):\n"}, {"line_no": 3, "char_start": 53, "char_end": 88, "line": "    result=cur.execute(sql_insert)\n"}, {"line_no": 4, "char_start": 88, "char_end": 106, "line": "    conn.commit()\n"}, {"line_no": 5, "char_start": 106, "char_end": 143, "line": "    print(\"insert data successfull\")\n"}, {"line_no": 6, "char_start": 143, "char_end": 160, "line": "    return result\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 38, "line": "def insertDB(conn,sql_insert,params):\n"}, {"line_no": 3, "char_start": 60, "char_end": 69, "line": "    try:\n"}, {"line_no": 4, "char_start": 69, "char_end": 108, "line": "        cur.execute(sql_insert,params)\n"}, {"line_no": 5, "char_start": 108, "char_end": 130, "line": "        conn.commit()\n"}, {"line_no": 6, "char_start": 130, "char_end": 159, "line": "    except Exception as err:\n"}, {"line_no": 7, "char_start": 159, "char_end": 181, "line": "        closeDB(conn)\n"}, {"line_no": 8, "char_start": 181, "char_end": 200, "line": "        print(err)\n"}, {"line_no": 9, "char_start": 200, "char_end": 211, "line": "    else: \n"}, {"line_no": 10, "char_start": 211, "char_end": 251, "line": "        print(\"insert data successfull\")\n"}]}, "char_changes": {"deleted": [{"char_start": 31, "char_end": 31, "chars": ""}, {"char_start": 57, "char_end": 64, "chars": "result="}, {"char_start": 142, "char_end": 160, "chars": "\n    return result"}], "added": [{"char_start": 28, "char_end": 35, "chars": ",params"}, {"char_start": 64, "char_end": 77, "chars": "try:\n        "}, {"char_start": 99, "char_end": 106, "chars": ",params"}, {"char_start": 108, "char_end": 112, "chars": "    "}, {"char_start": 130, "char_end": 215, "chars": "    except Exception as err:\n        closeDB(conn)\n        print(err)\n    else: \n    "}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/sql.py", "vul_type": "cwe-089"}
{"func_name": "updateDB", "func_src_before": "def updateDB(conn,sql_update):\n    cur=conn.cursor()\n    result=cur.execute(sql_update)\n    conn.commit()\n    print(\"update data successfull\")\n    return result", "func_src_after": "def updateDB(conn,sql_update,params):\n    cur=conn.cursor()\n    try:\n        cur.execute(sql_update,params)\n        conn.commit()\n    except Exception as err:\n        closeDB(conn)\n        print(err)\n    else: \n        print(\"update data successfull\")", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 31, "line": "def updateDB(conn,sql_update):\n"}, {"line_no": 3, "char_start": 53, "char_end": 88, "line": "    result=cur.execute(sql_update)\n"}, {"line_no": 4, "char_start": 88, "char_end": 106, "line": "    conn.commit()\n"}, {"line_no": 5, "char_start": 106, "char_end": 143, "line": "    print(\"update data successfull\")\n"}, {"line_no": 6, "char_start": 143, "char_end": 160, "line": "    return result\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 38, "line": "def updateDB(conn,sql_update,params):\n"}, {"line_no": 3, "char_start": 60, "char_end": 69, "line": "    try:\n"}, {"line_no": 4, "char_start": 69, "char_end": 108, "line": "        cur.execute(sql_update,params)\n"}, {"line_no": 5, "char_start": 108, "char_end": 130, "line": "        conn.commit()\n"}, {"line_no": 6, "char_start": 130, "char_end": 159, "line": "    except Exception as err:\n"}, {"line_no": 7, "char_start": 159, "char_end": 181, "line": "        closeDB(conn)\n"}, {"line_no": 8, "char_start": 181, "char_end": 200, "line": "        print(err)\n"}, {"line_no": 9, "char_start": 200, "char_end": 211, "line": "    else: \n"}, {"line_no": 10, "char_start": 211, "char_end": 251, "line": "        print(\"update data successfull\")\n"}]}, "char_changes": {"deleted": [{"char_start": 31, "char_end": 31, "chars": ""}, {"char_start": 57, "char_end": 64, "chars": "result="}, {"char_start": 142, "char_end": 160, "chars": "\n    return result"}], "added": [{"char_start": 28, "char_end": 35, "chars": ",params"}, {"char_start": 64, "char_end": 77, "chars": "try:\n        "}, {"char_start": 99, "char_end": 106, "chars": ",params"}, {"char_start": 108, "char_end": 112, "chars": "    "}, {"char_start": 130, "char_end": 215, "chars": "    except Exception as err:\n        closeDB(conn)\n        print(err)\n    else: \n    "}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/sql.py", "vul_type": "cwe-089"}
{"func_name": "userLogin", "func_src_before": "    def userLogin(self):\n\n        sqlName=\"select count(*) from users where name='%s' and \\\n                password='%s';\"%(self.name,self.password)\n        checkName=sql.queryDB(self.conn,sqlName)\n\n        result=checkName[0][0]\n        if result == 0:\n            self.clean()\n            return False\n        else:\n            return True", "func_src_after": "    def userLogin(self):\n\n        sqlName=\"select count(*) from users where name=%s and password=%s;\"\n        params = [self.name,self.password]\n        checkName=sql.queryDB(self.conn,sqlName,params)\n        result=checkName[0][0]\n        if result == 0:\n            self.clean()\n            return False\n        else:\n            return True", "line_changes": {"deleted": [{"line_no": 3, "char_start": 26, "char_end": 92, "line": "        sqlName=\"select count(*) from users where name='%s' and \\\n"}, {"line_no": 4, "char_start": 92, "char_end": 150, "line": "                password='%s';\"%(self.name,self.password)\n"}, {"line_no": 5, "char_start": 150, "char_end": 199, "line": "        checkName=sql.queryDB(self.conn,sqlName)\n"}, {"line_no": 6, "char_start": 199, "char_end": 200, "line": "\n"}], "added": [{"line_no": 3, "char_start": 26, "char_end": 102, "line": "        sqlName=\"select count(*) from users where name=%s and password=%s;\"\n"}, {"line_no": 4, "char_start": 102, "char_end": 145, "line": "        params = [self.name,self.password]\n"}, {"line_no": 5, "char_start": 145, "char_end": 201, "line": "        checkName=sql.queryDB(self.conn,sqlName,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 81, "char_end": 82, "chars": "'"}, {"char_start": 84, "char_end": 85, "chars": "'"}, {"char_start": 90, "char_end": 125, "chars": "\\\n                password='%s';\"%("}, {"char_start": 148, "char_end": 149, "chars": ")"}, {"char_start": 198, "char_end": 199, "chars": "\n"}], "added": [{"char_start": 101, "char_end": 120, "chars": "\n        params = ["}, {"char_start": 143, "char_end": 144, "chars": "]"}, {"char_start": 192, "char_end": 199, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "userApply", "func_src_before": "    def userApply(self):\n        t_sql_insert=\"insert into \\\n                users(name,password,email,country,inscription_date) \\\n                values('{name}','{psw}','{email}','{country}',current_timestamp(0));\"\n        sql_insert=t_sql_insert.format(name=self.name,psw=self.password,\\\n                email=self.email,country=self.country)\n\n        sqlName=\"select count(*) from users where name='%s';\"%(self.name)\n        checkName=sql.queryDB(self.conn,sqlName)\n    \n        #no name\n        if checkName[0][0] == 0:\n            sql.insertDB(self.conn,sql_insert)\n            return True\n        else:\n            return False", "func_src_after": "    def userApply(self):\n        sql_insert=\"insert into \\\n                users(name,password,email,country,inscription_date) \\\n                values(%s,%s,%s,%s,current_timestamp(0));\"\n\n        sqlName=\"select count(*) from users where name=%s;\"\n        params = [self.name]\n        checkName=sql.queryDB(self.conn,sqlName,params)\n        #no name\n        if checkName[0][0] == 0:\n            params.extend([self.password,self.email,self.country])\n            sql.insertDB(self.conn,sql_insert,params)\n            return True\n        else:\n            return False", "line_changes": {"deleted": [{"line_no": 2, "char_start": 25, "char_end": 61, "line": "        t_sql_insert=\"insert into \\\n"}, {"line_no": 4, "char_start": 131, "char_end": 217, "line": "                values('{name}','{psw}','{email}','{country}',current_timestamp(0));\"\n"}, {"line_no": 5, "char_start": 217, "char_end": 291, "line": "        sql_insert=t_sql_insert.format(name=self.name,psw=self.password,\\\n"}, {"line_no": 6, "char_start": 291, "char_end": 346, "line": "                email=self.email,country=self.country)\n"}, {"line_no": 8, "char_start": 347, "char_end": 421, "line": "        sqlName=\"select count(*) from users where name='%s';\"%(self.name)\n"}, {"line_no": 9, "char_start": 421, "char_end": 470, "line": "        checkName=sql.queryDB(self.conn,sqlName)\n"}, {"line_no": 10, "char_start": 470, "char_end": 475, "line": "    \n"}, {"line_no": 13, "char_start": 525, "char_end": 572, "line": "            sql.insertDB(self.conn,sql_insert)\n"}], "added": [{"line_no": 2, "char_start": 25, "char_end": 59, "line": "        sql_insert=\"insert into \\\n"}, {"line_no": 4, "char_start": 129, "char_end": 188, "line": "                values(%s,%s,%s,%s,current_timestamp(0));\"\n"}, {"line_no": 6, "char_start": 189, "char_end": 249, "line": "        sqlName=\"select count(*) from users where name=%s;\"\n"}, {"line_no": 7, "char_start": 249, "char_end": 278, "line": "        params = [self.name]\n"}, {"line_no": 8, "char_start": 278, "char_end": 334, "line": "        checkName=sql.queryDB(self.conn,sqlName,params)\n"}, {"line_no": 11, "char_start": 384, "char_end": 451, "line": "            params.extend([self.password,self.email,self.country])\n"}, {"line_no": 12, "char_start": 451, "char_end": 505, "line": "            sql.insertDB(self.conn,sql_insert,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 33, "char_end": 35, "chars": "t_"}, {"char_start": 154, "char_end": 345, "chars": "'{name}','{psw}','{email}','{country}',current_timestamp(0));\"\n        sql_insert=t_sql_insert.format(name=self.name,psw=self.password,\\\n                email=self.email,country=self.country)"}, {"char_start": 402, "char_end": 403, "chars": "'"}, {"char_start": 405, "char_end": 406, "chars": "'"}, {"char_start": 408, "char_end": 410, "chars": "%("}, {"char_start": 419, "char_end": 420, "chars": ")"}, {"char_start": 468, "char_end": 474, "chars": ")\n    "}], "added": [{"char_start": 152, "char_end": 187, "chars": "%s,%s,%s,%s,current_timestamp(0));\""}, {"char_start": 248, "char_end": 267, "chars": "\n        params = ["}, {"char_start": 276, "char_end": 277, "chars": "]"}, {"char_start": 325, "char_end": 333, "chars": ",params)"}, {"char_start": 384, "char_end": 451, "chars": "            params.extend([self.password,self.email,self.country])\n"}, {"char_start": 496, "char_end": 503, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "getUserID", "func_src_before": "    def getUserID(self):\n        sqlName=\"select userid from users where name='%s';\"%(self.name)\n        userid=sql.queryDB(self.conn,sqlName)\n        return userid[0][0];", "func_src_after": "    def getUserID(self):\n        sqlName=\"select userid from users where name=%s;\"\n        params = [self.name]\n        userid=sql.queryDB(self.conn,sqlName,params)\n        return userid[0][0];", "line_changes": {"deleted": [{"line_no": 2, "char_start": 25, "char_end": 97, "line": "        sqlName=\"select userid from users where name='%s';\"%(self.name)\n"}, {"line_no": 3, "char_start": 97, "char_end": 143, "line": "        userid=sql.queryDB(self.conn,sqlName)\n"}], "added": [{"line_no": 2, "char_start": 25, "char_end": 83, "line": "        sqlName=\"select userid from users where name=%s;\"\n"}, {"line_no": 3, "char_start": 83, "char_end": 112, "line": "        params = [self.name]\n"}, {"line_no": 4, "char_start": 112, "char_end": 165, "line": "        userid=sql.queryDB(self.conn,sqlName,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 78, "char_end": 79, "chars": "'"}, {"char_start": 81, "char_end": 82, "chars": "'"}, {"char_start": 84, "char_end": 86, "chars": "%("}, {"char_start": 95, "char_end": 96, "chars": ")"}], "added": [{"char_start": 82, "char_end": 101, "chars": "\n        params = ["}, {"char_start": 110, "char_end": 111, "chars": "]"}, {"char_start": 156, "char_end": 163, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "getAllPosts", "func_src_before": "    def getAllPosts(self):\n        sqlText=\"select comment from post where userid=%d order by date;\"\n        allposts=sql.queryDB(self.conn,sqlText)\n        return allposts;", "func_src_after": "    def getAllPosts(self):\n        sqlText=\"select comment from post where userid=%s order by date;\"\n        params = [self.userid]\n        allposts=sql.queryDB(self.conn,sqlName,params)\n        return allposts;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 27, "char_end": 101, "line": "        sqlText=\"select comment from post where userid=%d order by date;\"\n"}, {"line_no": 3, "char_start": 101, "char_end": 149, "line": "        allposts=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 27, "char_end": 101, "line": "        sqlText=\"select comment from post where userid=%s order by date;\"\n"}, {"line_no": 3, "char_start": 101, "char_end": 132, "line": "        params = [self.userid]\n"}, {"line_no": 4, "char_start": 132, "char_end": 187, "line": "        allposts=sql.queryDB(self.conn,sqlName,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 83, "char_end": 84, "chars": "d"}, {"char_start": 143, "char_end": 147, "chars": "Text"}], "added": [{"char_start": 83, "char_end": 84, "chars": "s"}, {"char_start": 101, "char_end": 132, "chars": "        params = [self.userid]\n"}, {"char_start": 174, "char_end": 185, "chars": "Name,params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "getAllComments", "func_src_before": "    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%d order by date;\"\n        allposts=sql.queryDB(self.conn,sqlText)\n        return allposts;", "func_src_after": "    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%s order by date;\"\n        params = [self.userid]\n        allposts=sql.queryDB(self.conn,sqlText,params)\n        return allposts;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 30, "char_end": 108, "line": "        sqlText=\"select comment from comments where userid=%d order by date;\"\n"}, {"line_no": 3, "char_start": 108, "char_end": 156, "line": "        allposts=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 30, "char_end": 108, "line": "        sqlText=\"select comment from comments where userid=%s order by date;\"\n"}, {"line_no": 3, "char_start": 108, "char_end": 139, "line": "        params = [self.userid]\n"}, {"line_no": 4, "char_start": 139, "char_end": 194, "line": "        allposts=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 90, "char_end": 91, "chars": "d"}], "added": [{"char_start": 90, "char_end": 91, "chars": "s"}, {"char_start": 108, "char_end": 139, "chars": "        params = [self.userid]\n"}, {"char_start": 185, "char_end": 192, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "getAllInformation", "func_src_before": "    def getAllInformation(self,userid):\n        sqlText=\"select name,password,email,country from users where userid=%d;\"%(userid)\n        information=sql.queryDB(self.conn,sqlText)\n        return information;", "func_src_after": "    def getAllInformation(self,userid):\n        sqlText=\"select name,password,email,country from users where userid=%s;\"\n        params = [userid]\n        information=sql.queryDB(self.conn,sqlText,params)\n        return information;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 40, "char_end": 130, "line": "        sqlText=\"select name,password,email,country from users where userid=%d;\"%(userid)\n"}, {"line_no": 3, "char_start": 130, "char_end": 181, "line": "        information=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 40, "char_end": 121, "line": "        sqlText=\"select name,password,email,country from users where userid=%s;\"\n"}, {"line_no": 3, "char_start": 121, "char_end": 147, "line": "        params = [userid]\n"}, {"line_no": 4, "char_start": 147, "char_end": 205, "line": "        information=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 117, "char_end": 118, "chars": "d"}, {"char_start": 120, "char_end": 122, "chars": "%("}, {"char_start": 128, "char_end": 129, "chars": ")"}], "added": [{"char_start": 117, "char_end": 118, "chars": "s"}, {"char_start": 120, "char_end": 139, "chars": "\n        params = ["}, {"char_start": 145, "char_end": 146, "chars": "]"}, {"char_start": 196, "char_end": 203, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "modifyUserInfo", "func_src_before": "    def modifyUserInfo(self,userid,flag):\n        sqlText=\"update users \\\n                set name='%s',password='%s',email='%s',country='%s' \\\n                where userid='%d';\"%(self.name,self.password,self.email,self.country,userid)\n        if(flag==1): \n            sqlName=\"select count(*) from users where name='%s';\"%(self.name)\n            checkName=sql.queryDB(self.conn,sqlName)\n            #no name\n            if checkName[0][0] == 0:\n                sql.updateDB(self.conn,sqlText)\n                return True\n            else:\n                return False\n        else:\n            sql.updateDB(self.conn,sqlText)\n            return True;", "func_src_after": "    def modifyUserInfo(self,userid,flag):\n        sqlText=\"update users \\\n                set name=%s,password=%s,email=%s,country=%s where userid=%s;\"\n        if(flag==1): \n            sqlName=\"select count(*) from users where name=%s;\"\n            params = [self.name]\n            checkName=sql.queryDB(self.conn,sqlName,params)\n            #no name\n            if checkName[0][0] == 0:\n                params.extend([self.password,self.email,self.country,userid])\n                sql.updateDB(self.conn,sqlText,params)\n                return True\n            else:\n                return False\n        else:\n            params=[self.name,self.password,self.email,self.country,userid]\n            sql.updateDB(self.conn,sqlText,params)\n            return True;", "line_changes": {"deleted": [{"line_no": 3, "char_start": 74, "char_end": 144, "line": "                set name='%s',password='%s',email='%s',country='%s' \\\n"}, {"line_no": 4, "char_start": 144, "char_end": 237, "line": "                where userid='%d';\"%(self.name,self.password,self.email,self.country,userid)\n"}, {"line_no": 6, "char_start": 259, "char_end": 337, "line": "            sqlName=\"select count(*) from users where name='%s';\"%(self.name)\n"}, {"line_no": 7, "char_start": 337, "char_end": 390, "line": "            checkName=sql.queryDB(self.conn,sqlName)\n"}, {"line_no": 10, "char_start": 448, "char_end": 496, "line": "                sql.updateDB(self.conn,sqlText)\n"}, {"line_no": 15, "char_start": 585, "char_end": 629, "line": "            sql.updateDB(self.conn,sqlText)\n"}], "added": [{"line_no": 3, "char_start": 74, "char_end": 152, "line": "                set name=%s,password=%s,email=%s,country=%s where userid=%s;\"\n"}, {"line_no": 5, "char_start": 174, "char_end": 238, "line": "            sqlName=\"select count(*) from users where name=%s;\"\n"}, {"line_no": 6, "char_start": 238, "char_end": 271, "line": "            params = [self.name]\n"}, {"line_no": 7, "char_start": 271, "char_end": 331, "line": "            checkName=sql.queryDB(self.conn,sqlName,params)\n"}, {"line_no": 10, "char_start": 389, "char_end": 467, "line": "                params.extend([self.password,self.email,self.country,userid])\n"}, {"line_no": 11, "char_start": 467, "char_end": 522, "line": "                sql.updateDB(self.conn,sqlText,params)\n"}, {"line_no": 16, "char_start": 611, "char_end": 687, "line": "            params=[self.name,self.password,self.email,self.country,userid]\n"}, {"line_no": 17, "char_start": 687, "char_end": 738, "line": "            sql.updateDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 99, "char_end": 100, "chars": "'"}, {"char_start": 102, "char_end": 103, "chars": "'"}, {"char_start": 113, "char_end": 114, "chars": "'"}, {"char_start": 116, "char_end": 117, "chars": "'"}, {"char_start": 124, "char_end": 125, "chars": "'"}, {"char_start": 127, "char_end": 128, "chars": "'"}, {"char_start": 137, "char_end": 138, "chars": "'"}, {"char_start": 140, "char_end": 236, "chars": "' \\\n                where userid='%d';\"%(self.name,self.password,self.email,self.country,userid)"}, {"char_start": 318, "char_end": 319, "chars": "'"}, {"char_start": 321, "char_end": 322, "chars": "'"}, {"char_start": 324, "char_end": 326, "chars": "%("}, {"char_start": 335, "char_end": 336, "chars": ")"}], "added": [{"char_start": 133, "char_end": 151, "chars": " where userid=%s;\""}, {"char_start": 237, "char_end": 260, "chars": "\n            params = ["}, {"char_start": 269, "char_end": 270, "chars": "]"}, {"char_start": 322, "char_end": 329, "chars": ",params"}, {"char_start": 389, "char_end": 467, "chars": "                params.extend([self.password,self.email,self.country,userid])\n"}, {"char_start": 513, "char_end": 520, "chars": ",params"}, {"char_start": 611, "char_end": 687, "chars": "            params=[self.name,self.password,self.email,self.country,userid]\n"}, {"char_start": 729, "char_end": 736, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "followFriends", "func_src_before": "    def followFriends(self,userid,friendid):\n        sqlText=\"insert into friends values(%d,%d);\"%(friendid,userid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def followFriends(self,userid,friendid):\n        sqlText=\"insert into friends values(%s,%s);\"\n        params=[friendid,userid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 45, "char_end": 116, "line": "        sqlText=\"insert into friends values(%d,%d);\"%(friendid,userid)\n"}, {"line_no": 3, "char_start": 116, "char_end": 163, "line": "        result=sql.insertDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 45, "char_end": 98, "line": "        sqlText=\"insert into friends values(%s,%s);\"\n"}, {"line_no": 3, "char_start": 98, "char_end": 131, "line": "        params=[friendid,userid]\n"}, {"line_no": 4, "char_start": 131, "char_end": 185, "line": "        result=sql.insertDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 90, "char_end": 91, "chars": "d"}, {"char_start": 93, "char_end": 94, "chars": "d"}, {"char_start": 97, "char_end": 99, "chars": "%("}, {"char_start": 114, "char_end": 115, "chars": ")"}], "added": [{"char_start": 90, "char_end": 91, "chars": "s"}, {"char_start": 93, "char_end": 94, "chars": "s"}, {"char_start": 97, "char_end": 114, "chars": "\n        params=["}, {"char_start": 129, "char_end": 130, "chars": "]"}, {"char_start": 176, "char_end": 183, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "cancelFollow", "func_src_before": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%d;\"%(userid,friendid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%s;\"\n        params=[userid,friendid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 2, "char_start": 44, "char_end": 133, "line": "        sqlText=\"delete from friends where userid=%d and friendid=%d;\"%(userid,friendid)\n"}, {"line_no": 3, "char_start": 133, "char_end": 180, "line": "        result=sql.deleteDB(self.conn,sqlText)\n"}], "added": [{"line_no": 2, "char_start": 44, "char_end": 115, "line": "        sqlText=\"delete from friends where userid=%d and friendid=%s;\"\n"}, {"line_no": 3, "char_start": 115, "char_end": 148, "line": "        params=[userid,friendid]\n"}, {"line_no": 4, "char_start": 148, "char_end": 202, "line": "        result=sql.deleteDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 111, "char_end": 112, "chars": "d"}, {"char_start": 114, "char_end": 116, "chars": "%("}, {"char_start": 131, "char_end": 132, "chars": ")"}], "added": [{"char_start": 111, "char_end": 112, "chars": "s"}, {"char_start": 114, "char_end": 131, "chars": "\n        params=["}, {"char_start": 146, "char_end": 147, "chars": "]"}, {"char_start": 193, "char_end": 200, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "getUsers", "func_src_before": "    def getUsers(self,userid):\n        sqlText=\"select userid,name,country,(select Count(*) from friends \\\n                where users.userid=friends.friendid and friends.userid=%d) as follow \\\n                from users;\"%(userid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getUsers(self,userid):\n        sqlText=\"select userid,name,country,(select Count(*) from friends \\\n                where users.userid=friends.friendid and friends.userid=%s) as follow \\\n                from users;\"\n        params=[userid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 3, "char_start": 107, "char_end": 194, "line": "                where users.userid=friends.friendid and friends.userid=%d) as follow \\\n"}, {"line_no": 4, "char_start": 194, "char_end": 232, "line": "                from users;\"%(userid)\n"}, {"line_no": 5, "char_start": 232, "char_end": 278, "line": "        result=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 3, "char_start": 107, "char_end": 194, "line": "                where users.userid=friends.friendid and friends.userid=%s) as follow \\\n"}, {"line_no": 4, "char_start": 194, "char_end": 223, "line": "                from users;\"\n"}, {"line_no": 5, "char_start": 223, "char_end": 247, "line": "        params=[userid]\n"}, {"line_no": 6, "char_start": 247, "char_end": 300, "line": "        result=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 179, "char_end": 180, "chars": "d"}, {"char_start": 222, "char_end": 224, "chars": "%("}, {"char_start": 230, "char_end": 231, "chars": ")"}], "added": [{"char_start": 179, "char_end": 180, "chars": "s"}, {"char_start": 222, "char_end": 239, "chars": "\n        params=["}, {"char_start": 245, "char_end": 246, "chars": "]"}, {"char_start": 291, "char_end": 298, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "getUsersByName", "func_src_before": "    def getUsersByName(self,userid,username):\n        sqlText=\"select userid,name,country,(select Count(*) from friends \\\n                where users.userid=friends.friendid and friends.userid=%d) as follow \\\n                from users where users.name='%s';\"%(userid,username)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getUsersByName(self,userid,username):\n        sqlText=\"select userid,name,country,(select Count(*) from friends \\\n                where users.userid=friends.friendid and friends.userid=%s) as follow \\\n                from users where users.name~%s;\"\n        params=[userid,username]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "line_changes": {"deleted": [{"line_no": 3, "char_start": 122, "char_end": 209, "line": "                where users.userid=friends.friendid and friends.userid=%d) as follow \\\n"}, {"line_no": 4, "char_start": 209, "char_end": 278, "line": "                from users where users.name='%s';\"%(userid,username)\n"}, {"line_no": 5, "char_start": 278, "char_end": 324, "line": "        result=sql.queryDB(self.conn,sqlText)\n"}], "added": [{"line_no": 3, "char_start": 122, "char_end": 209, "line": "                where users.userid=friends.friendid and friends.userid=%s) as follow \\\n"}, {"line_no": 4, "char_start": 209, "char_end": 258, "line": "                from users where users.name~%s;\"\n"}, {"line_no": 5, "char_start": 258, "char_end": 291, "line": "        params=[userid,username]\n"}, {"line_no": 6, "char_start": 291, "char_end": 344, "line": "        result=sql.queryDB(self.conn,sqlText,params)\n"}]}, "char_changes": {"deleted": [{"char_start": 194, "char_end": 195, "chars": "d"}, {"char_start": 252, "char_end": 254, "chars": "='"}, {"char_start": 256, "char_end": 257, "chars": "'"}, {"char_start": 259, "char_end": 261, "chars": "%("}, {"char_start": 276, "char_end": 277, "chars": ")"}], "added": [{"char_start": 194, "char_end": 195, "chars": "s"}, {"char_start": 252, "char_end": 253, "chars": "~"}, {"char_start": 257, "char_end": 274, "chars": "\n        params=["}, {"char_start": 289, "char_end": 290, "chars": "]"}, {"char_start": 335, "char_end": 342, "chars": ",params"}]}, "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089"}
{"func_name": "get_item", "func_src_before": "@api.route('/items/<int:item_id>', methods=['GET'])\ndef get_item(item_id):\n    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = {} AND auctionable = true;'''.format(item_id)\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql)\n    data = cursor.fetchone()\n\n    if data:\n        item = {}\n        for tup in zip([column[0] for column in cursor.description], data):\n            item[tup[0]] = tup[1]\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify(item)", "func_src_after": "@api.route('/items/<int:item_id>', methods=['GET'])\ndef get_item(item_id):\n    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = %s AND auctionable = true;'''\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql, [item_id])\n    data = cursor.fetchone()\n\n    if data:\n        item = {}\n        for tup in zip([column[0] for column in cursor.description], data):\n            item[tup[0]] = tup[1]\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify(item)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 75, "char_end": 182, "line": "    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = {} AND auctionable = true;'''.format(item_id)\n"}, {"line_no": 5, "char_start": 221, "char_end": 245, "line": "    cursor.execute(sql)\n"}], "added": [{"line_no": 3, "char_start": 75, "char_end": 166, "line": "    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = %s AND auctionable = true;'''\n"}, {"line_no": 5, "char_start": 205, "char_end": 240, "line": "    cursor.execute(sql, [item_id])\n"}]}, "char_changes": {"deleted": [{"char_start": 136, "char_end": 138, "chars": "{}"}, {"char_start": 165, "char_end": 181, "chars": ".format(item_id)"}], "added": [{"char_start": 136, "char_end": 138, "chars": "%s"}, {"char_start": 227, "char_end": 238, "chars": ", [item_id]"}]}, "commit_link": "github.com/cosileone/TimeIsMoneyFriend-API/commit/3d3b5defd26ef7d205915bf643b6b1df90a15e44", "file_name": "timf/api/views.py", "vul_type": "cwe-089"}
{"func_name": "resolve_item_name", "func_src_before": "@api.route('/item/', methods=['GET'])\ndef resolve_item_name():\n    item_name = request.args.get('name')\n    sql = '''SELECT id, name_enus FROM `tblDBCItem` WHERE name_enus LIKE \"%{}%\" '''.format(item_name)\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql)\n    data = cursor.fetchall()\n\n    if data:\n        results = []\n        for row in data:\n            item = {}\n            for tup in zip([column[0] for column in cursor.description], row):\n                item[tup[0]] = tup[1]\n\n            results.append(item)\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify({\"items\": results})", "func_src_after": "@api.route('/item/', methods=['GET'])\ndef resolve_item_name():\n    data = []\n    query = request.args.get('name')\n\n    if query:\n        sql = '''SELECT id, name_enus FROM `tblDBCItem` WHERE name_enus LIKE %s;'''\n        cursor = mysql.connection.cursor()\n        cursor.execute(sql, [\"%\" + query + \"%\",])\n        data = cursor.fetchall()\n    else:\n        return jsonify({\"error\": \"No item ID or query provided\"}), 404\n\n    if data:\n        results = []\n        for row in data:\n            item = {}\n            for tup in zip([column[0] for column in cursor.description], row):\n                item[tup[0]] = tup[1]\n\n            results.append(item)\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify({\"items\": results})", "line_changes": {"deleted": [{"line_no": 3, "char_start": 63, "char_end": 104, "line": "    item_name = request.args.get('name')\n"}, {"line_no": 4, "char_start": 104, "char_end": 206, "line": "    sql = '''SELECT id, name_enus FROM `tblDBCItem` WHERE name_enus LIKE \"%{}%\" '''.format(item_name)\n"}, {"line_no": 5, "char_start": 206, "char_end": 245, "line": "    cursor = mysql.connection.cursor()\n"}, {"line_no": 6, "char_start": 245, "char_end": 269, "line": "    cursor.execute(sql)\n"}, {"line_no": 7, "char_start": 269, "char_end": 298, "line": "    data = cursor.fetchall()\n"}], "added": [{"line_no": 3, "char_start": 63, "char_end": 77, "line": "    data = []\n"}, {"line_no": 4, "char_start": 77, "char_end": 114, "line": "    query = request.args.get('name')\n"}, {"line_no": 5, "char_start": 114, "char_end": 115, "line": "\n"}, {"line_no": 6, "char_start": 115, "char_end": 129, "line": "    if query:\n"}, {"line_no": 7, "char_start": 129, "char_end": 213, "line": "        sql = '''SELECT id, name_enus FROM `tblDBCItem` WHERE name_enus LIKE %s;'''\n"}, {"line_no": 8, "char_start": 213, "char_end": 256, "line": "        cursor = mysql.connection.cursor()\n"}, {"line_no": 9, "char_start": 256, "char_end": 306, "line": "        cursor.execute(sql, [\"%\" + query + \"%\",])\n"}, {"line_no": 10, "char_start": 306, "char_end": 339, "line": "        data = cursor.fetchall()\n"}, {"line_no": 11, "char_start": 339, "char_end": 349, "line": "    else:\n"}, {"line_no": 12, "char_start": 349, "char_end": 420, "line": "        return jsonify({\"error\": \"No item ID or query provided\"}), 404\n"}]}, "char_changes": {"deleted": [{"char_start": 67, "char_end": 76, "chars": "item_name"}, {"char_start": 177, "char_end": 206, "chars": "\"%{}%\" '''.format(item_name)\n"}, {"char_start": 267, "char_end": 297, "chars": ")\n    data = cursor.fetchall()"}], "added": [{"char_start": 67, "char_end": 86, "chars": "data = []\n    query"}, {"char_start": 114, "char_end": 133, "chars": "\n    if query:\n    "}, {"char_start": 206, "char_end": 215, "chars": "%s;'''\n  "}, {"char_start": 219, "char_end": 221, "chars": "  "}, {"char_start": 256, "char_end": 260, "chars": "    "}, {"char_start": 282, "char_end": 419, "chars": ", [\"%\" + query + \"%\",])\n        data = cursor.fetchall()\n    else:\n        return jsonify({\"error\": \"No item ID or query provided\"}), 404"}]}, "commit_link": "github.com/cosileone/TimeIsMoneyFriend-API/commit/3d3b5defd26ef7d205915bf643b6b1df90a15e44", "file_name": "timf/api/views.py", "vul_type": "cwe-089"}
{"func_name": "registerPlayer", "func_src_before": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO players (name) values (%s)\", (bleach.clean(name),))\n    db.commit()\n    db.close()", "func_src_after": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n\n    db = connect()\n    c = db.cursor()\n    # remove any occurance of quotes/apostrophes to prevent sql injection\n    safe_n = name=name.translate(None, '\\'\\\"')\n    query = \"INSERT INTO players (name) values ('{name}')\".format(name=safe_n)\n    c.execute(query)\n    db.commit()\n    db.close()", "line_changes": {"deleted": [{"line_no": 13, "char_start": 343, "char_end": 422, "line": "    c.execute(\"INSERT INTO players (name) values (%s)\", (bleach.clean(name),))\n"}], "added": [{"line_no": 14, "char_start": 417, "char_end": 464, "line": "    safe_n = name=name.translate(None, '\\'\\\"')\n"}, {"line_no": 15, "char_start": 464, "char_end": 543, "line": "    query = \"INSERT INTO players (name) values ('{name}')\".format(name=safe_n)\n"}, {"line_no": 16, "char_start": 543, "char_end": 564, "line": "    c.execute(query)\n"}]}, "char_changes": {"deleted": [{"char_start": 347, "char_end": 420, "chars": "c.execute(\"INSERT INTO players (name) values (%s)\", (bleach.clean(name),)"}], "added": [{"char_start": 347, "char_end": 562, "chars": "# remove any occurance of quotes/apostrophes to prevent sql injection\n    safe_n = name=name.translate(None, '\\'\\\"')\n    query = \"INSERT INTO players (name) values ('{name}')\".format(name=safe_n)\n    c.execute(query"}]}, "commit_link": "github.com/tdnelson2/tournament-db/commit/2f26b43e26d656190a7dfa0f399e2dc7c0dd9a37", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "registerPlayer", "func_src_before": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n\n    db = connect()\n    c = db.cursor()\n    # remove any occurance of quotes/apostrophes to prevent sql injection\n    safe_n = name = name.translate(None, '\\'\\\"')\n    query = \"INSERT INTO players (name) values ('{name}')\".format(name=safe_n)\n    c.execute(query)\n    db.commit()\n    db.close()", "func_src_after": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO players (name) values (%s)\", name)\n    db.commit()\n    db.close()", "line_changes": {"deleted": [{"line_no": 14, "char_start": 417, "char_end": 466, "line": "    safe_n = name = name.translate(None, '\\'\\\"')\n"}, {"line_no": 15, "char_start": 466, "char_end": 545, "line": "    query = \"INSERT INTO players (name) values ('{name}')\".format(name=safe_n)\n"}, {"line_no": 16, "char_start": 545, "char_end": 566, "line": "    c.execute(query)\n"}], "added": [{"line_no": 13, "char_start": 343, "char_end": 405, "line": "    c.execute(\"INSERT INTO players (name) values (%s)\", name)\n"}]}, "char_changes": {"deleted": [{"char_start": 347, "char_end": 564, "chars": "# remove any occurance of quotes/apostrophes to prevent sql injection\n    safe_n = name = name.translate(None, '\\'\\\"')\n    query = \"INSERT INTO players (name) values ('{name}')\".format(name=safe_n)\n    c.execute(query"}], "added": [{"char_start": 347, "char_end": 403, "chars": "c.execute(\"INSERT INTO players (name) values (%s)\", name"}]}, "commit_link": "github.com/tdnelson2/tournament-db/commit/00f3caeed0e12e806c2808d100908698777d9e98", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    statement = \"INSERT INTO matches values ({w}, {l})\".format(w=w, l=l)\n    c.execute(statement)\n    db.commit()\n    db.close()", "func_src_after": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO matches values (%s, %s)\", (w,l))\n    db.commit()\n    db.close()", "line_changes": {"deleted": [{"line_no": 20, "char_start": 551, "char_end": 624, "line": "    statement = \"INSERT INTO matches values ({w}, {l})\".format(w=w, l=l)\n"}, {"line_no": 21, "char_start": 624, "char_end": 649, "line": "    c.execute(statement)\n"}], "added": [{"line_no": 20, "char_start": 551, "char_end": 611, "line": "    c.execute(\"INSERT INTO matches values (%s, %s)\", (w,l))\n"}]}, "char_changes": {"deleted": [{"char_start": 555, "char_end": 567, "chars": "statement = "}, {"char_start": 596, "char_end": 647, "chars": "{w}, {l})\".format(w=w, l=l)\n    c.execute(statement"}], "added": [{"char_start": 555, "char_end": 565, "chars": "c.execute("}, {"char_start": 594, "char_end": 609, "chars": "%s, %s)\", (w,l)"}]}, "commit_link": "github.com/tdnelson2/tournament-db/commit/00f3caeed0e12e806c2808d100908698777d9e98", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self,data):\n        connection = self.connect()\n\n        try:\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self,data):\n        connection = self.connect()\n\n        try:\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query,data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 80, "char_end": 163, "line": "            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n"}, {"line_no": 7, "char_start": 211, "char_end": 249, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 5, "char_start": 80, "char_end": 148, "line": "            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 7, "char_start": 196, "char_end": 239, "line": "                cursor.execute(query,data)\n"}]}, "char_changes": {"deleted": [{"char_start": 142, "char_end": 162, "chars": "'{}');\".format(data)"}], "added": [{"char_start": 142, "char_end": 147, "chars": "%s);\""}, {"char_start": 232, "char_end": 237, "chars": ",data"}]}, "commit_link": "github.com/sgnab/crime-map-app/commit/209b23bad13594c9cdf18d8788fcba7c8f68d37b", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "login", "func_src_before": "@app.route('/login', methods=['GET', 'POST'])\ndef login():\n\n\terror=None\n\n\t#The request was a POST request, i.e. user is submitting form data.\n\tif request.method == 'POST':\n\n\t\t#Get information from form.\n\t\tusername = request.form['username']\n\t\tpassword = request.form['password']\n\n\t\t#Check database.\n\t\tcursor = mysql.connect().cursor()\n\t\tcursor.execute(\"SELECT * from Users where emailAccount='\" + username + \"' and password='\" + password + \"'\")\n\t\tdata = cursor.fetchone()\n\n\t\tif data is None:\n\t\t\terror=\"Username or password is incorrect.\"\n\t\telse:\n\t\t\t#Session.\n\t\t\tsession['username'] = request.form['username']\n\t\t\treturn redirect(url_for('instructions'))\n\n\treturn render_template('login.html', error=error)", "func_src_after": "@app.route('/login', methods=['GET', 'POST'])\ndef login():\n\n\terror=None\n\n\t#The request was a POST request, i.e. user is submitting form data.\n\tif request.method == 'POST':\n\n\t\t#Get information from form.\n\t\tusername = request.form['username']\n\t\tpassword = request.form['password']\n\n\t\t#Check database.\n\t\tcursor = mysql.connect().cursor()\n\t\tcursor.execute(\"SELECT * from Users where emailAccount=%s and password=%s\", (username, password))\n\t\tdata = cursor.fetchone()\n\n\t\tif data is None:\n\t\t\terror=\"Username or password is incorrect.\"\n\t\telse:\n\t\t\t#Session.\n\t\t\tsession['username'] = request.form['username']\n\t\t\tsession['lastCourseEntered'] = None\n\t\t\treturn redirect(url_for('instructions'))\n\n\treturn render_template('login.html', error=error)", "line_changes": {"deleted": [{"line_no": 15, "char_start": 335, "char_end": 445, "line": "\t\tcursor.execute(\"SELECT * from Users where emailAccount='\" + username + \"' and password='\" + password + \"'\")\n"}], "added": [{"line_no": 15, "char_start": 335, "char_end": 435, "line": "\t\tcursor.execute(\"SELECT * from Users where emailAccount=%s and password=%s\", (username, password))\n"}, {"line_no": 23, "char_start": 599, "char_end": 638, "line": "\t\t\tsession['lastCourseEntered'] = None\n"}]}, "char_changes": {"deleted": [{"char_start": 392, "char_end": 428, "chars": "'\" + username + \"' and password='\" +"}, {"char_start": 437, "char_end": 443, "chars": " + \"'\""}], "added": [{"char_start": 392, "char_end": 423, "chars": "%s and password=%s\", (username,"}, {"char_start": 432, "char_end": 433, "chars": ")"}, {"char_start": 599, "char_end": 638, "chars": "\t\t\tsession['lastCourseEntered'] = None\n"}]}, "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089"}
{"func_name": "register", "func_src_before": "@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    error = None\n    if request.method == 'POST':\n        emailAccount = request.form['username']\n        password = request.form['password']\n\n        splitDomainName = emailAccount.split('@')[1]\n        if (splitDomainName != 'purdue.edu'):\n        \terror = \"You should use a Purdue email.\"\n    \t\treturn render_template('createAccount.html', error=error) \n        \n\n        conn = mysql.connect()\n        cursor = conn.cursor()\n    \n        cursor.execute(\"SELECT * from Users where emailAccount='\" + emailAccount + \"'\")\n        data = cursor.fetchone()\n        if data is None:\n            #this password is unique so add it to the database\n            cursor.execute('''INSERT INTO Users (emailAccount, password, isNewUser, cs180Completed, cs240Completed, cs250Completed, cs251Completed, cs314Completed, cs334Completed, cs381Completed, cs307Completed, cs448Completed, cs456Completed, cs422Completed, cs426Completed) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)''',(emailAccount, password, True, False, False, False, False, False, False, False, False, False, False, False, False))\n            conn.commit()\n\n            session['username'] = request.form['username']\n\n            return redirect(url_for('instructions'))\n        else: \n            error = \"Username is already in use.\"\n\n    #return \"You are already registered\" #render html for register page and send error message\n    return render_template('createAccount.html', error=error)", "func_src_after": "@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    error = None\n    if request.method == 'POST':\n        emailAccount = request.form['username']\n        password = request.form['password']\n\n        splitDomainName = emailAccount.split('@')[1]\n        if (splitDomainName != 'purdue.edu'):\n        \terror = \"You should use a Purdue email.\"\n    \t\treturn render_template('createAccount.html', error=error) \n        \n\n        conn = mysql.connect()\n        cursor = conn.cursor()\n    \n        cursor.execute(\"SELECT * from Users where emailAccount=%s\", (emailAccount))\n        data = cursor.fetchone()\n        if data is None:\n            #this password is unique so add it to the database\n            cursor.execute('''INSERT INTO Users (emailAccount, password, isNewUser, cs180Completed, cs240Completed, cs250Completed, cs251Completed, cs314Completed, cs334Completed, cs381Completed, cs307Completed, cs448Completed, cs456Completed, cs422Completed, cs426Completed) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)''',(emailAccount, password, True, False, False, False, False, False, False, False, False, False, False, False, False))\n            conn.commit()\n\n            session['username'] = request.form['username']\n            session['lastCourseEntered'] = None\n\n            return redirect(url_for('instructions'))\n        else: \n            error = \"Username is already in use.\"\n\n    #return \"You are already registered\" #render html for register page and send error message\n    return render_template('createAccount.html', error=error)", "line_changes": {"deleted": [{"line_no": 17, "char_start": 499, "char_end": 587, "line": "        cursor.execute(\"SELECT * from Users where emailAccount='\" + emailAccount + \"'\")\n"}], "added": [{"line_no": 17, "char_start": 499, "char_end": 583, "line": "        cursor.execute(\"SELECT * from Users where emailAccount=%s\", (emailAccount))\n"}, {"line_no": 25, "char_start": 1253, "char_end": 1301, "line": "            session['lastCourseEntered'] = None\n"}]}, "char_changes": {"deleted": [{"char_start": 562, "char_end": 567, "chars": "'\" + "}, {"char_start": 579, "char_end": 585, "chars": " + \"'\""}], "added": [{"char_start": 562, "char_end": 568, "chars": "%s\", ("}, {"char_start": 580, "char_end": 581, "chars": ")"}, {"char_start": 1252, "char_end": 1300, "chars": "\n            session['lastCourseEntered'] = None"}]}, "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089"}
{"func_name": "overview", "func_src_before": "@app.route('/overview/<classNum>')\ndef overview(classNum):\n\tif 'username' in session:\n\t\tclassNoSpace = classNum.split(' ')[0]+classNum.split(' ')[1]\n\n\t\t#Save the current course as a session variable.\n\t\tsession['currentCourse'] = classNoSpace\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT courseName,courseOverview from courses where courseAbbreviation='\" + classNoSpace + \"'\")\n\t\tdata = cursor.fetchone()\n\n\t\treturn render_template('overview.html', className = classNum, courseTitle = data[0], courseOverview = data[1])\n\n\treturn redirect(url_for('index'))", "func_src_after": "@app.route('/overview/<classNum>')\ndef overview(classNum):\n\tif 'username' in session:\n\t\tclassNoSpace = classNum.split(' ')[0]+classNum.split(' ')[1]\n\n\t\t#Save the current course as a session variable.\n\t\tsession['currentCourse'] = classNoSpace\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT courseName,courseOverview from courses where courseAbbreviation=%s\", (classNoSpace))\n\t\tdata = cursor.fetchone()\n\n\t\treturn render_template('overview.html', className = classNum, courseTitle = data[0], courseOverview = data[1])\n\n\treturn redirect(url_for('index'))", "line_changes": {"deleted": [{"line_no": 12, "char_start": 294, "char_end": 408, "line": "\t\tcursor.execute(\"SELECT courseName,courseOverview from courses where courseAbbreviation='\" + classNoSpace + \"'\")\n"}], "added": [{"line_no": 12, "char_start": 294, "char_end": 404, "line": "\t\tcursor.execute(\"SELECT courseName,courseOverview from courses where courseAbbreviation=%s\", (classNoSpace))\n"}]}, "char_changes": {"deleted": [{"char_start": 383, "char_end": 388, "chars": "'\" + "}, {"char_start": 400, "char_end": 406, "chars": " + \"'\""}], "added": [{"char_start": 383, "char_end": 389, "chars": "%s\", ("}, {"char_start": 401, "char_end": 402, "chars": ")"}]}, "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089"}
{"func_name": "quiz", "func_src_before": "@app.route('/quiz', methods=['GET', 'POST'])\ndef quiz():\n\n\terror = None\n\tanswers = None\n\tgrades = None\n\tshowSubmit = None\n\tcourse = None\n\trank = None\n\n\tif 'username' in session:\n\n\t\tif 'currentCourse' in session:\n\t\t\tcourse = session['currentCourse']\n\t\telse:\n\t\t\treturn redirect(url_for('levels'))\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\t\tcursor.execute(\"SELECT questionString, option1, option2, option3, option4, correctAnswer, courseName FROM courses join questions on questions.courseId=courses.courseId where courses.courseAbbreviation='\" + course + \"'\")\n\n\t\tquestions = []\n\t\tfor row in cursor:\n\t\t\tquestions.append(row)\n\n\t\tif request.method == 'POST':\n\t\t\t#print request.form\n\n\t\t\tif (len(request.form) != 7):\n\t\t\t\terror = \"Please answer all of the questions.\"\n\t\t\t\tshowSubmit = True\n\t\t\telse:\n\t\t\t\tgrades = []\n\t\t\t\tanswers = []\n\t\t\t\tscore = 0\n\n\t\t\t\tfor i in range(0, len(request.form) - 2):\n\t\t\t\t\tanswers.append(int(request.form[\"q\" + str(i+1)]))\n\n\t\t\t\t\tif ( int(questions[i][5]) == answers[i] ):\n\t\t\t\t\t\tgrades.append(1)\n\t\t\t\t\t\tscore = score + 1\n\t\t\t\t\telse:\n\t\t\t\t\t\tgrades.append(0)\n\n\t\t\t\trank = request.form[\"rankquiz\"]\n\n\t\t\t\ttotal = score + 3*int(rank)\n\n\t\t\t\tcursor.execute(\"SELECT courseId FROM courses WHERE courseAbbreviation='\" + course +\"'\")\n\t\t\t\tcourseId = cursor.fetchone()\n\n\t\t\t\tcursor.execute(\"SELECT courseConcentration FROM courses WHERE courseAbbreviation='\" + course +\"'\")\n\t\t\t\tcourseConcentration = cursor.fetchone()\n\n\t\t\t\tcursor.execute(\"DELETE FROM results WHERE emailAccount='\" + session['username'] + \"' and courseId=\" + str(courseId[0]))\n\n\t\t\t\t#print \"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('\" + session['username'] + \"',\" + str(courseId[0]) + \",'\" + str(courseConcentration[0]) + \"',\" + str(score) + \",\" + str(rank) + \",\" + str(total) + \")\"\n\t\t\t\tcursor.execute(\"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('\" + session['username'] + \"',\" + str(courseId[0]) + \",'\" + str(courseConcentration[0]) + \"',\" + str(score) + \",\" + str(rank) + \",\" + str(total) + \")\")\n\t\t\t\tcursor.execute(\"UPDATE users SET \" + course.lower() + \"Completed=1 WHERE emailAccount='\" + session['username'] + \"'\")\n\t\t\t\tconn.commit()\n\n\t\t\t\tsession['lastCourseEntered'] = session['currentCourse']\n\t\t\t\tsession.pop('currentCourse', None)\n\t\t\t\t\n\t\t\t\trank = int(rank)\n\t\t\treturn render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)\n\t\telse:\n\t\t\tshowSubmit = True\n\t\t\treturn render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)\n\treturn redirect(url_for('login'))", "func_src_after": "@app.route('/quiz', methods=['GET', 'POST'])\ndef quiz():\n\n\terror = None\n\tanswers = None\n\tgrades = None\n\tshowSubmit = None\n\tcourse = None\n\trank = None\n\n\tif 'username' in session:\n\n\t\tif 'currentCourse' in session:\n\t\t\tcourse = session['currentCourse']\n\t\telse:\n\t\t\treturn redirect(url_for('levels'))\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\t\tcursor.execute(\"SELECT questionString, option1, option2, option3, option4, correctAnswer, courseName FROM courses join questions on questions.courseId=courses.courseId where courses.courseAbbreviation=%s\", (course))\n\n\t\tquestions = []\n\t\tfor row in cursor:\n\t\t\tquestions.append(row)\n\n\t\tif request.method == 'POST':\n\t\t\t#print request.form\n\n\t\t\tif (len(request.form) != 7):\n\t\t\t\terror = \"Please answer all of the questions.\"\n\t\t\t\tshowSubmit = True\n\t\t\telse:\n\t\t\t\tgrades = []\n\t\t\t\tanswers = []\n\t\t\t\tscore = 0\n\n\t\t\t\tfor i in range(0, len(request.form) - 2):\n\t\t\t\t\tanswers.append(int(request.form[\"q\" + str(i+1)]))\n\n\t\t\t\t\tif ( int(questions[i][5]) == answers[i] ):\n\t\t\t\t\t\tgrades.append(1)\n\t\t\t\t\t\tscore = score + 1\n\t\t\t\t\telse:\n\t\t\t\t\t\tgrades.append(0)\n\n\t\t\t\trank = request.form[\"rankquiz\"]\n\n\t\t\t\ttotal = score + 3*int(rank)\n\n\t\t\t\tcursor.execute(\"SELECT courseId FROM courses WHERE courseAbbreviation=%s\", (course))\n\t\t\t\tcourseId = cursor.fetchone()\n\n\t\t\t\tcursor.execute(\"SELECT courseConcentration FROM courses WHERE courseAbbreviation=%s\", (course))\n\t\t\t\tcourseConcentration = cursor.fetchone()\n\n\t\t\t\tcursor.execute(\"DELETE FROM results WHERE emailAccount=%s and courseId=%s\", (session['username'], str(courseId[0])))\n\n\t\t\t\t#print \"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('\" + session['username'] + \"',\" + str(courseId[0]) + \",'\" + str(courseConcentration[0]) + \"',\" + str(score) + \",\" + str(rank) + \",\" + str(total) + \")\"\n\t\t\t\tcursor.execute(\"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES (%s, %s, %s, %s, %s, %s)\", (session['username'], str(courseId[0]), str(courseConcentration[0]), str(score), str(rank), str(total)))\n\t\t\t\tcursor.execute(\"UPDATE users SET \"+course.lower()+\"Completed=1 WHERE emailAccount=%s\", (session['username']))\n\t\t\t\tconn.commit()\n\n\t\t\t\tsession['lastCourseEntered'] = session['currentCourse']\n\t\t\t\tsession.pop('currentCourse', None)\n\t\t\t\t\n\t\t\t\trank = int(rank)\n\t\t\treturn render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)\n\t\telse:\n\t\t\tshowSubmit = True\n\t\t\treturn render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)\n\treturn redirect(url_for('login'))", "line_changes": {"deleted": [{"line_no": 20, "char_start": 346, "char_end": 568, "line": "\t\tcursor.execute(\"SELECT questionString, option1, option2, option3, option4, correctAnswer, courseName FROM courses join questions on questions.courseId=courses.courseId where courses.courseAbbreviation='\" + course + \"'\")\n"}, {"line_no": 50, "char_start": 1151, "char_end": 1243, "line": "\t\t\t\tcursor.execute(\"SELECT courseId FROM courses WHERE courseAbbreviation='\" + course +\"'\")\n"}, {"line_no": 53, "char_start": 1277, "char_end": 1380, "line": "\t\t\t\tcursor.execute(\"SELECT courseConcentration FROM courses WHERE courseAbbreviation='\" + course +\"'\")\n"}, {"line_no": 56, "char_start": 1425, "char_end": 1549, "line": "\t\t\t\tcursor.execute(\"DELETE FROM results WHERE emailAccount='\" + session['username'] + \"' and courseId=\" + str(courseId[0]))\n"}, {"line_no": 59, "char_start": 1807, "char_end": 2073, "line": "\t\t\t\tcursor.execute(\"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('\" + session['username'] + \"',\" + str(courseId[0]) + \",'\" + str(courseConcentration[0]) + \"',\" + str(score) + \",\" + str(rank) + \",\" + str(total) + \")\")\n"}, {"line_no": 60, "char_start": 2073, "char_end": 2195, "line": "\t\t\t\tcursor.execute(\"UPDATE users SET \" + course.lower() + \"Completed=1 WHERE emailAccount='\" + session['username'] + \"'\")\n"}], "added": [{"line_no": 20, "char_start": 346, "char_end": 564, "line": "\t\tcursor.execute(\"SELECT questionString, option1, option2, option3, option4, correctAnswer, courseName FROM courses join questions on questions.courseId=courses.courseId where courses.courseAbbreviation=%s\", (course))\n"}, {"line_no": 50, "char_start": 1147, "char_end": 1236, "line": "\t\t\t\tcursor.execute(\"SELECT courseId FROM courses WHERE courseAbbreviation=%s\", (course))\n"}, {"line_no": 53, "char_start": 1270, "char_end": 1370, "line": "\t\t\t\tcursor.execute(\"SELECT courseConcentration FROM courses WHERE courseAbbreviation=%s\", (course))\n"}, {"line_no": 56, "char_start": 1415, "char_end": 1536, "line": "\t\t\t\tcursor.execute(\"DELETE FROM results WHERE emailAccount=%s and courseId=%s\", (session['username'], str(courseId[0])))\n"}, {"line_no": 59, "char_start": 1794, "char_end": 2039, "line": "\t\t\t\tcursor.execute(\"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES (%s, %s, %s, %s, %s, %s)\", (session['username'], str(courseId[0]), str(courseConcentration[0]), str(score), str(rank), str(total)))\n"}, {"line_no": 60, "char_start": 2039, "char_end": 2153, "line": "\t\t\t\tcursor.execute(\"UPDATE users SET \"+course.lower()+\"Completed=1 WHERE emailAccount=%s\", (session['username']))\n"}]}, "char_changes": {"deleted": [{"char_start": 549, "char_end": 566, "chars": "'\" + course + \"'\""}, {"char_start": 1225, "char_end": 1230, "chars": "'\" + "}, {"char_start": 1236, "char_end": 1241, "chars": " +\"'\""}, {"char_start": 1362, "char_end": 1367, "chars": "'\" + "}, {"char_start": 1373, "char_end": 1378, "chars": " +\"'\""}, {"char_start": 1484, "char_end": 1530, "chars": "'\" + session['username'] + \"' and courseId=\" +"}, {"char_start": 1921, "char_end": 1926, "chars": "'\" + "}, {"char_start": 1945, "char_end": 1954, "chars": " + \"',\" +"}, {"char_start": 1971, "char_end": 1980, "chars": " + \",'\" +"}, {"char_start": 2008, "char_end": 2017, "chars": " + \"',\" +"}, {"char_start": 2028, "char_end": 2036, "chars": " + \",\" +"}, {"char_start": 2046, "char_end": 2054, "chars": " + \",\" +"}, {"char_start": 2065, "char_end": 2071, "chars": " + \")\""}, {"char_start": 2111, "char_end": 2114, "chars": " + "}, {"char_start": 2128, "char_end": 2131, "chars": " + "}, {"char_start": 2163, "char_end": 2168, "chars": "'\" + "}, {"char_start": 2187, "char_end": 2193, "chars": " + \"'\""}], "added": [{"char_start": 549, "char_end": 562, "chars": "%s\", (course)"}, {"char_start": 1221, "char_end": 1227, "chars": "%s\", ("}, {"char_start": 1233, "char_end": 1234, "chars": ")"}, {"char_start": 1355, "char_end": 1361, "chars": "%s\", ("}, {"char_start": 1367, "char_end": 1368, "chars": ")"}, {"char_start": 1474, "char_end": 1516, "chars": "%s and courseId=%s\", (session['username'],"}, {"char_start": 1534, "char_end": 1535, "chars": ")"}, {"char_start": 1908, "char_end": 1935, "chars": "%s, %s, %s, %s, %s, %s)\", ("}, {"char_start": 1954, "char_end": 1955, "chars": ","}, {"char_start": 1972, "char_end": 1973, "chars": ","}, {"char_start": 2001, "char_end": 2002, "chars": ","}, {"char_start": 2013, "char_end": 2014, "chars": ","}, {"char_start": 2024, "char_end": 2025, "chars": ","}, {"char_start": 2036, "char_end": 2037, "chars": ")"}, {"char_start": 2077, "char_end": 2078, "chars": "+"}, {"char_start": 2092, "char_end": 2093, "chars": "+"}, {"char_start": 2125, "char_end": 2131, "chars": "%s\", ("}, {"char_start": 2150, "char_end": 2151, "chars": ")"}]}, "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089"}
{"func_name": "summary", "func_src_before": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount='\" + session['username'] + \"'\");\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "func_src_after": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount=%s\", (session['username']));\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "line_changes": {"deleted": [{"line_no": 9, "char_start": 185, "char_end": 397, "line": "\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount='\" + session['username'] + \"'\");\n"}], "added": [{"line_no": 9, "char_start": 185, "char_end": 393, "line": "\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount=%s\", (session['username']));\n"}]}, "char_changes": {"deleted": [{"char_start": 364, "char_end": 369, "chars": "'\" + "}, {"char_start": 388, "char_end": 394, "chars": " + \"'\""}], "added": [{"char_start": 364, "char_end": 370, "chars": "%s\", ("}, {"char_start": 389, "char_end": 390, "chars": ")"}]}, "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089"}
{"func_name": "insert_result_log", "func_src_before": "\tdef insert_result_log(self, qid, hoax, fact, unknown, unrelated, conclusion):\n\t\tsql = \"INSERT INTO log_result (id_query, finished_at, hoax_score, fact_score, unknown_score, unrelated_score, conclusion) VALUES\" + \\\n\t\t\t\t\t\"('%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % (qid, datetime.now(), hoax, fact, unknown, unrelated, conclusion)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid", "func_src_after": "\tdef insert_result_log(self, qid, hoax, fact, unknown, unrelated, conclusion):\n\t\tsql = \"INSERT INTO log_result (id_query, finished_at, hoax_score, fact_score, unknown_score, unrelated_score, conclusion) VALUES\" + \\\n\t\t\t\t\t\"(%s, %s, %s, %s, %s, %s, %s)\"\n\t\tself.cur.execute(sql, (qid, datetime.now(), hoax, fact, unknown, unrelated, conclusion))\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid", "line_changes": {"deleted": [{"line_no": 3, "char_start": 215, "char_end": 333, "line": "\t\t\t\t\t\"('%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % (qid, datetime.now(), hoax, fact, unknown, unrelated, conclusion)\n"}, {"line_no": 4, "char_start": 333, "char_end": 357, "line": "\t\tself.cur.execute(sql)\n"}], "added": [{"line_no": 3, "char_start": 215, "char_end": 251, "line": "\t\t\t\t\t\"(%s, %s, %s, %s, %s, %s, %s)\"\n"}, {"line_no": 4, "char_start": 251, "char_end": 342, "line": "\t\tself.cur.execute(sql, (qid, datetime.now(), hoax, fact, unknown, unrelated, conclusion))\n"}]}, "char_changes": {"deleted": [{"char_start": 222, "char_end": 223, "chars": "'"}, {"char_start": 225, "char_end": 226, "chars": "'"}, {"char_start": 228, "char_end": 229, "chars": "'"}, {"char_start": 231, "char_end": 232, "chars": "'"}, {"char_start": 234, "char_end": 235, "chars": "'"}, {"char_start": 237, "char_end": 238, "chars": "'"}, {"char_start": 240, "char_end": 241, "chars": "'"}, {"char_start": 243, "char_end": 244, "chars": "'"}, {"char_start": 246, "char_end": 247, "chars": "'"}, {"char_start": 249, "char_end": 250, "chars": "'"}, {"char_start": 252, "char_end": 253, "chars": "'"}, {"char_start": 255, "char_end": 256, "chars": "'"}, {"char_start": 258, "char_end": 259, "chars": "'"}, {"char_start": 261, "char_end": 262, "chars": "'"}, {"char_start": 264, "char_end": 266, "chars": " %"}, {"char_start": 332, "char_end": 355, "chars": "\n\t\tself.cur.execute(sql"}], "added": [{"char_start": 250, "char_end": 274, "chars": "\n\t\tself.cur.execute(sql,"}]}, "commit_link": "github.com/hoaxanalyzer/hoax-search-vote/commit/b2029c81a9d2991b84e34d5b18f69bad6c8a479c", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "insert_result_feedback", "func_src_before": "\tdef insert_result_feedback(self, qhash, is_know, reason, label, ip, browser):\n\t\tsql = \"INSERT INTO feedback_result (query_hash, reported_at, is_know, reason, feedback_label, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"('%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % (qhash, datetime.now(), is_know, reason, label, ip, browser)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid", "func_src_after": "\tdef insert_result_feedback(self, qhash, is_know, reason, label, ip, browser):\n\t\tsql = \"INSERT INTO feedback_result (query_hash, reported_at, is_know, reason, feedback_label, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"(%s, %s, %s, %s, %s, %s, %s)\"\n\t\tself.cur.execute(sql, (qhash, datetime.now(), is_know, reason, label, ip, browser))\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid", "line_changes": {"deleted": [{"line_no": 3, "char_start": 214, "char_end": 327, "line": "\t\t\t\t\t\"('%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % (qhash, datetime.now(), is_know, reason, label, ip, browser)\n"}, {"line_no": 4, "char_start": 327, "char_end": 351, "line": "\t\tself.cur.execute(sql)\n"}], "added": [{"line_no": 3, "char_start": 214, "char_end": 250, "line": "\t\t\t\t\t\"(%s, %s, %s, %s, %s, %s, %s)\"\n"}, {"line_no": 4, "char_start": 250, "char_end": 336, "line": "\t\tself.cur.execute(sql, (qhash, datetime.now(), is_know, reason, label, ip, browser))\n"}]}, "char_changes": {"deleted": [{"char_start": 221, "char_end": 222, "chars": "'"}, {"char_start": 224, "char_end": 225, "chars": "'"}, {"char_start": 227, "char_end": 228, "chars": "'"}, {"char_start": 230, "char_end": 231, "chars": "'"}, {"char_start": 233, "char_end": 234, "chars": "'"}, {"char_start": 236, "char_end": 237, "chars": "'"}, {"char_start": 239, "char_end": 240, "chars": "'"}, {"char_start": 242, "char_end": 243, "chars": "'"}, {"char_start": 245, "char_end": 246, "chars": "'"}, {"char_start": 248, "char_end": 249, "chars": "'"}, {"char_start": 251, "char_end": 252, "chars": "'"}, {"char_start": 254, "char_end": 255, "chars": "'"}, {"char_start": 257, "char_end": 258, "chars": "'"}, {"char_start": 260, "char_end": 261, "chars": "'"}, {"char_start": 263, "char_end": 265, "chars": " %"}, {"char_start": 326, "char_end": 349, "chars": "\n\t\tself.cur.execute(sql"}], "added": [{"char_start": 249, "char_end": 273, "chars": "\n\t\tself.cur.execute(sql,"}]}, "commit_link": "github.com/hoaxanalyzer/hoax-search-vote/commit/b2029c81a9d2991b84e34d5b18f69bad6c8a479c", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "insert_reference_feedback", "func_src_before": "\tdef insert_reference_feedback(self, ahash, is_relevant, reason, label, ip, browser):\n\t\tprint(str(ahash))\n\t\tprint(str(is_relevant))\n\t\tsql = \"INSERT INTO feedback_reference (article_hash, reported_at, is_relevant, reason, feedback_label, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"('%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % (ahash, datetime.now(), is_relevant, reason, label, ip, browser)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid", "func_src_after": "\tdef insert_reference_feedback(self, ahash, is_relevant, reason, label, ip, browser):\n\t\tprint(str(ahash))\n\t\tprint(str(is_relevant))\n\t\tsql = \"INSERT INTO feedback_reference (article_hash, reported_at, is_relevant, reason, feedback_label, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"(%s, %s, %s, %s, %s, %s, %s)\"\n\t\tself.cur.execute(sql, (ahash, datetime.now(), is_relevant, reason, label, ip, browser))\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid", "line_changes": {"deleted": [{"line_no": 5, "char_start": 276, "char_end": 393, "line": "\t\t\t\t\t\"('%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % (ahash, datetime.now(), is_relevant, reason, label, ip, browser)\n"}, {"line_no": 6, "char_start": 393, "char_end": 417, "line": "\t\tself.cur.execute(sql)\n"}], "added": [{"line_no": 5, "char_start": 276, "char_end": 312, "line": "\t\t\t\t\t\"(%s, %s, %s, %s, %s, %s, %s)\"\n"}, {"line_no": 6, "char_start": 312, "char_end": 402, "line": "\t\tself.cur.execute(sql, (ahash, datetime.now(), is_relevant, reason, label, ip, browser))\n"}]}, "char_changes": {"deleted": [{"char_start": 283, "char_end": 284, "chars": "'"}, {"char_start": 286, "char_end": 287, "chars": "'"}, {"char_start": 289, "char_end": 290, "chars": "'"}, {"char_start": 292, "char_end": 293, "chars": "'"}, {"char_start": 295, "char_end": 296, "chars": "'"}, {"char_start": 298, "char_end": 299, "chars": "'"}, {"char_start": 301, "char_end": 302, "chars": "'"}, {"char_start": 304, "char_end": 305, "chars": "'"}, {"char_start": 307, "char_end": 308, "chars": "'"}, {"char_start": 310, "char_end": 311, "chars": "'"}, {"char_start": 313, "char_end": 314, "chars": "'"}, {"char_start": 316, "char_end": 317, "chars": "'"}, {"char_start": 319, "char_end": 320, "chars": "'"}, {"char_start": 322, "char_end": 323, "chars": "'"}, {"char_start": 325, "char_end": 327, "chars": " %"}, {"char_start": 392, "char_end": 415, "chars": "\n\t\tself.cur.execute(sql"}], "added": [{"char_start": 311, "char_end": 335, "chars": "\n\t\tself.cur.execute(sql,"}]}, "commit_link": "github.com/hoaxanalyzer/hoax-search-vote/commit/b2029c81a9d2991b84e34d5b18f69bad6c8a479c", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "delete_predicate", "func_src_before": "@_transform.route('/delete_predicate', methods=['POST'])\n@login_required\ndef delete_predicate():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    table = table_name_to_object(dataset.working_copy)\n    condition = ''\n    columns = []\n    conditions = []\n    operators = []\n    logics = []\n    for i in request.form:\n        if i.startswith('column'):\n            columns.append(i)\n        elif i.startswith('condition'):\n            conditions.append(i)\n        elif i.startswith('logical'):\n            logics.append(i)\n        elif i.startswith('operator'):\n            operators.append(i)\n    columns.sort()\n    conditions.sort()\n    logics.sort()\n    operators.sort()\n    for i in range(len(columns)):\n        if i != len(columns) - 1:\n            condition += '\"' + request.form[columns[i + 1]] + '\"'\n            if request.form[operators[i + 1]] == 'CONTAINS':\n                condition += ' ~ '\n            elif request.form[operators[i + 1]] == 'NOT CONTIANS':\n                condition += ' !~ '\n            else:\n                condition += request.form[operators[i + 1]]\n            condition += '\\'' + request.form[conditions[i + 1]] + '\\''\n            condition += ' ' + request.form[logics[i]] + ' '\n        else:\n            condition += '\"' + request.form[columns[0]] + '\"'\n            if request.form[operators[0]] == 'CONTAINS':\n                condition += ' ~ '\n            elif request.form[operators[0]] == 'NOT CONTIANS':\n                condition += ' !~ '\n            else:\n                condition += request.form[operators[0]]\n            condition += '\\'' + request.form[conditions[0]] + '\\''\n\n    try:\n        delete_rows(table.name, condition)\n        create_action('rows deleted with condition \"{0}\"'\n                      .format(condition), dataset.id, current_user.id\n                      )\n    except:\n        flash('condition \"{0}\" not valid'.format(condition), 'danger')\n    else:\n        flash('successfully deleted rows using condition \"{0}\"'\n              .format(condition), 'success'\n              )\n    return redirect(request.referrer)", "func_src_after": "@_transform.route('/delete_predicate', methods=['POST'])\n@login_required\ndef delete_predicate():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    table = table_name_to_object(dataset.working_copy)\n    condition = ''\n    columns = []\n    conditions = []\n    operators = []\n    logics = []\n    for i in request.form:\n        if i.startswith('column'):\n            columns.append(i)\n        elif i.startswith('condition'):\n            conditions.append(i)\n        elif i.startswith('logical'):\n            logics.append(i)\n        elif i.startswith('operator'):\n            operators.append(i)\n    columns.sort()\n    conditions.sort()\n    logics.sort()\n    operators.sort()\n    for i in range(len(columns)):\n        if i != len(columns) - 1:\n            condition += '\"' + request.form[columns[i + 1]] + '\"'\n            if request.form[operators[i + 1]] == 'CONTAINS':\n                condition += ' ~ '\n            elif request.form[operators[i + 1]] == 'NOT CONTIANS':\n                condition += ' !~ '\n            else:\n                condition += request.form[operators[i + 1]]\n            condition += '\\'' + request.form[conditions[i + 1]] + '\\''\n            condition += ' ' + request.form[logics[i]] + ' '\n        else:\n            condition += '\"' + request.form[columns[0]] + '\"'\n            if request.form[operators[0]] == 'CONTAINS':\n                condition += ' ~ '\n            elif request.form[operators[0]] == 'NOT CONTIANS':\n                condition += ' !~ '\n            else:\n                condition += request.form[operators[0]]\n            condition += '\\'' + escape_quotes(request.form[conditions[0]]) + '\\''\n\n    try:\n        if delete_rows(table.name, condition) is False:\n            flash('no rows found with condition \"{0}\"'.format(condition), 'warning')\n        else:\n            flash('successfully deleted rows using condition \"{0}\"'.format(condition), 'success')\n        create_action('rows deleted with condition \"{0}\"'.format(condition), dataset.id, current_user.id)\n    except Exception as e:\n        print(e)\n        flash('condition \"{0}\" not valid'.format(condition), 'danger')\n\n    return redirect(request.referrer)", "line_changes": {"deleted": [{"line_no": 43, "char_start": 1576, "char_end": 1643, "line": "            condition += '\\'' + request.form[conditions[0]] + '\\''\n"}, {"line_no": 46, "char_start": 1653, "char_end": 1696, "line": "        delete_rows(table.name, condition)\n"}, {"line_no": 47, "char_start": 1696, "char_end": 1754, "line": "        create_action('rows deleted with condition \"{0}\"'\n"}, {"line_no": 48, "char_start": 1754, "char_end": 1824, "line": "                      .format(condition), dataset.id, current_user.id\n"}, {"line_no": 49, "char_start": 1824, "char_end": 1848, "line": "                      )\n"}, {"line_no": 50, "char_start": 1848, "char_end": 1860, "line": "    except:\n"}, {"line_no": 52, "char_start": 1931, "char_end": 1941, "line": "    else:\n"}, {"line_no": 53, "char_start": 1941, "char_end": 2005, "line": "        flash('successfully deleted rows using condition \"{0}\"'\n"}, {"line_no": 54, "char_start": 2005, "char_end": 2049, "line": "              .format(condition), 'success'\n"}, {"line_no": 55, "char_start": 2049, "char_end": 2065, "line": "              )\n"}], "added": [{"line_no": 43, "char_start": 1576, "char_end": 1658, "line": "            condition += '\\'' + escape_quotes(request.form[conditions[0]]) + '\\''\n"}, {"line_no": 46, "char_start": 1668, "char_end": 1724, "line": "        if delete_rows(table.name, condition) is False:\n"}, {"line_no": 47, "char_start": 1724, "char_end": 1809, "line": "            flash('no rows found with condition \"{0}\"'.format(condition), 'warning')\n"}, {"line_no": 48, "char_start": 1809, "char_end": 1823, "line": "        else:\n"}, {"line_no": 49, "char_start": 1823, "char_end": 1921, "line": "            flash('successfully deleted rows using condition \"{0}\"'.format(condition), 'success')\n"}, {"line_no": 50, "char_start": 1921, "char_end": 2027, "line": "        create_action('rows deleted with condition \"{0}\"'.format(condition), dataset.id, current_user.id)\n"}, {"line_no": 51, "char_start": 2027, "char_end": 2054, "line": "    except Exception as e:\n"}, {"line_no": 52, "char_start": 2054, "char_end": 2071, "line": "        print(e)\n"}, {"line_no": 54, "char_start": 2142, "char_end": 2143, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 1695, "char_end": 1875, "chars": "\n        create_action('rows deleted with condition \"{0}\"'\n                      .format(condition), dataset.id, current_user.id\n                      )\n    except:\n        flash('"}, {"char_start": 1890, "char_end": 1900, "chars": " not valid"}, {"char_start": 1922, "char_end": 1987, "chars": "danger')\n    else:\n        flash('successfully deleted rows using"}, {"char_start": 2004, "char_end": 2019, "chars": "\n              "}, {"char_start": 2039, "char_end": 2064, "chars": "'success'\n              )"}], "added": [{"char_start": 1608, "char_end": 1622, "chars": "escape_quotes("}, {"char_start": 1649, "char_end": 1650, "chars": ")"}, {"char_start": 1676, "char_end": 1679, "chars": "if "}, {"char_start": 1713, "char_end": 1874, "chars": " is False:\n            flash('no rows found with condition \"{0}\"'.format(condition), 'warning')\n        else:\n            flash('successfully deleted rows using "}, {"char_start": 1911, "char_end": 1961, "chars": "success')\n        create_action('rows deleted with"}, {"char_start": 1998, "char_end": 2142, "chars": "dataset.id, current_user.id)\n    except Exception as e:\n        print(e)\n        flash('condition \"{0}\" not valid'.format(condition), 'danger')\n"}]}, "commit_link": "github.com/svissers/datacleaner/commit/48b00c7b7bb0b82bdc79167947fa9eda9f0ab8e0", "file_name": "app/Data/Transform/controllers.py", "vul_type": "cwe-089"}
{"func_name": "change_attribute_type", "func_src_before": "def change_attribute_type(table_name, table_col, new_type):\n    \"\"\"\n    Changes the type of given attribute in given table to new_type\n    :param table_name: table containing the attribute\n    :param table_col: attribute to change type of\n    :param new_type: new type\n    \"\"\"\n    current_type = db.engine.execute(\n        'SELECT data_type from information_schema.columns '\n        'where table_name = \\'{0}\\' and column_name = \\'{1}\\';'\n        .format(table_name, table_col)\n    ).fetchall()[0][0]\n    if new_type == 'INTEGER':\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'ALTER COLUMN \"{1}\" '\n            'TYPE BIGINT USING \"{1}\"::bigint'\n            .format(table_name, table_col))\n    if new_type == 'DOUBLE':\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'ALTER COLUMN \"{1}\" '\n            'TYPE DOUBLE PRECISION USING \"{1}\"::double precision'\n            .format(table_name, table_col))\n    if new_type == 'TEXT':\n        if current_type == 'date':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT USING to_char(\"{1}\", \\'DD/MM/YYYY\\')'\n                .format(table_name, table_col))\n        elif current_type == 'timestamp with time zone':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT USING to_char(\"{1}\", \\'DD/MM/YYYY HH24:MI:SS\\')'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT'\n                .format(table_name, table_col))\n    if new_type == 'DATE':\n        if current_type == 'timestamp with time zone':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE DATE'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE DATE USING to_date(\"{1}\", \\'DD/MM/YYYY\\')'\n                .format(table_name, table_col))\n    if new_type == 'TIMESTAMP':\n        if current_type == 'date':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TIMESTAMP WITH TIME ZONE'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TIMESTAMP WITH TIME ZONE '\n                'USING to_timestamp(\"{1}\", \\'DD/MM/YYYY HH24:MI:SS\\')'\n                .format(table_name, table_col))", "func_src_after": "def change_attribute_type(table_name, table_col, new_type):\n    \"\"\"\n    Changes the type of given attribute in given table to new_type\n    :param table_name: table containing the attribute\n    :param table_col: attribute to change type of\n    :param new_type: new type\n    \"\"\"\n    current_type = db.engine.execute(\n        'SELECT data_type from information_schema.columns '\n        'where table_name = \\'{0}\\' and column_name = \\'{1}\\';'\n        .format(table_name, table_col)\n    ).fetchall()[0][0]\n    if new_type == 'INTEGER':\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'ALTER COLUMN \"{1}\" '\n            'TYPE BIGINT USING \"{1}\"::bigint'\n            .format(table_name, table_col))\n    if new_type == 'DOUBLE':\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'ALTER COLUMN \"{1}\" '\n            'TYPE DOUBLE PRECISION USING \"{1}\"::double precision'\n            .format(table_name, table_col))\n    if new_type == 'TEXT':\n        if current_type == 'date':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT USING to_char(\"{1}\", \\'DD/MM/YYYY\\')'\n                .format(table_name, table_col))\n        elif current_type == 'timestamp without time zone':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT USING to_char(\"{1}\", \\'DD/MM/YYYY HH24:MI:SS\\')'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT'\n                .format(table_name, table_col))\n    if new_type == 'DATE':\n        if current_type == 'timestamp without time zone':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE DATE'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE DATE USING to_date(\"{1}\", \\'DD/MM/YYYY\\')'\n                .format(table_name, table_col))\n    if new_type == 'TIMESTAMP':\n        if current_type == 'date':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TIMESTAMP '\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TIMESTAMP '\n                'USING to_timestamp(\"{1}\", \\'DD/MM/YYYY HH24:MI:SS\\')'\n                .format(table_name, table_col))", "line_changes": {"deleted": [{"line_no": 32, "char_start": 1223, "char_end": 1280, "line": "        elif current_type == 'timestamp with time zone':\n"}, {"line_no": 45, "char_start": 1729, "char_end": 1784, "line": "        if current_type == 'timestamp with time zone':\n"}, {"line_no": 62, "char_start": 2366, "char_end": 2414, "line": "                'TYPE TIMESTAMP WITH TIME ZONE'\n"}, {"line_no": 68, "char_start": 2580, "char_end": 2629, "line": "                'TYPE TIMESTAMP WITH TIME ZONE '\n"}], "added": [{"line_no": 32, "char_start": 1223, "char_end": 1283, "line": "        elif current_type == 'timestamp without time zone':\n"}, {"line_no": 45, "char_start": 1732, "char_end": 1790, "line": "        if current_type == 'timestamp without time zone':\n"}, {"line_no": 62, "char_start": 2372, "char_end": 2406, "line": "                'TYPE TIMESTAMP '\n"}, {"line_no": 68, "char_start": 2572, "char_end": 2606, "line": "                'TYPE TIMESTAMP '\n"}]}, "char_changes": {"deleted": [{"char_start": 1280, "char_end": 1280, "chars": ""}, {"char_start": 2398, "char_end": 2412, "chars": "WITH TIME ZONE"}, {"char_start": 2612, "char_end": 2627, "chars": "WITH TIME ZONE "}], "added": [{"char_start": 1267, "char_end": 1270, "chars": "out"}, {"char_start": 1774, "char_end": 1777, "chars": "out"}, {"char_start": 2572, "char_end": 2572, "chars": ""}]}, "commit_link": "github.com/svissers/datacleaner/commit/48b00c7b7bb0b82bdc79167947fa9eda9f0ab8e0", "file_name": "app/Data/Transform/operations.py", "vul_type": "cwe-089"}
{"func_name": "delete_rows", "func_src_before": "def delete_rows(table_name, condition):\n\n    db.engine.execute(\n        'DELETE FROM \"{0}\" WHERE {1}'.format(table_name, condition)\n    )", "func_src_after": "def delete_rows(table_name, condition):\n\n    result = db.engine.execute(\n        'DELETE FROM \"{0}\" WHERE {1}'.format(table_name, condition)\n    )\n    if result.rowcount == 0:\n        return False", "line_changes": {"deleted": [{"line_no": 3, "char_start": 41, "char_end": 64, "line": "    db.engine.execute(\n"}], "added": [{"line_no": 3, "char_start": 41, "char_end": 73, "line": "    result = db.engine.execute(\n"}, {"line_no": 6, "char_start": 147, "char_end": 176, "line": "    if result.rowcount == 0:\n"}, {"line_no": 7, "char_start": 176, "char_end": 196, "line": "        return False\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 44, "char_end": 53, "chars": " result ="}, {"char_start": 146, "char_end": 196, "chars": "\n    if result.rowcount == 0:\n        return False"}]}, "commit_link": "github.com/svissers/datacleaner/commit/48b00c7b7bb0b82bdc79167947fa9eda9f0ab8e0", "file_name": "app/Data/Transform/operations.py", "vul_type": "cwe-089"}
{"func_name": "insert_user_info", "func_src_before": "    async def insert_user_info(self, member_id: int, column: str, col_value):\n        execute = (\n            f\"\"\"INSERT INTO user_info (member_id, {column}) \n                    VALUES ({member_id}, {col_value})\n                    ON CONFLICT (member_id)\n                        DO UPDATE SET {column} = {col_value};\"\"\")\n        await self.db_conn.execute(execute)", "func_src_after": "    async def insert_user_info(self, member_id: int, column: str, col_value):\n        execute = (\n            f'''INSERT INTO user_info (member_id, $1) VALUES ($2, $3)\n                    ON CONFLICT member_id DO UPDATE SET $1 = $3;''')\n        await self.db_conn.execute(execute, column, member_id, col_value)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 98, "char_end": 159, "line": "            f\"\"\"INSERT INTO user_info (member_id, {column}) \n"}, {"line_no": 4, "char_start": 159, "char_end": 213, "line": "                    VALUES ({member_id}, {col_value})\n"}, {"line_no": 5, "char_start": 213, "char_end": 257, "line": "                    ON CONFLICT (member_id)\n"}, {"line_no": 6, "char_start": 257, "char_end": 323, "line": "                        DO UPDATE SET {column} = {col_value};\"\"\")\n"}, {"line_no": 7, "char_start": 323, "char_end": 366, "line": "        await self.db_conn.execute(execute)\n"}], "added": [{"line_no": 3, "char_start": 98, "char_end": 168, "line": "            f'''INSERT INTO user_info (member_id, $1) VALUES ($2, $3)\n"}, {"line_no": 4, "char_start": 168, "char_end": 237, "line": "                    ON CONFLICT member_id DO UPDATE SET $1 = $3;''')\n"}, {"line_no": 5, "char_start": 237, "char_end": 310, "line": "        await self.db_conn.execute(execute, column, member_id, col_value)"}]}, "char_changes": {"deleted": [{"char_start": 111, "char_end": 114, "chars": "\"\"\""}, {"char_start": 148, "char_end": 211, "chars": "{column}) \n                    VALUES ({member_id}, {col_value}"}, {"char_start": 245, "char_end": 246, "chars": "("}, {"char_start": 255, "char_end": 321, "chars": ")\n                        DO UPDATE SET {column} = {col_value};\"\"\""}], "added": [{"char_start": 111, "char_end": 114, "chars": "'''"}, {"char_start": 148, "char_end": 166, "chars": "$1) VALUES ($2, $3"}, {"char_start": 209, "char_end": 235, "chars": " DO UPDATE SET $1 = $3;'''"}, {"char_start": 279, "char_end": 309, "chars": ", column, member_id, col_value"}]}, "commit_link": "github.com/Naught0/qtbot/commit/0a8d81f7ecc5a7073e57f84584e7f07557edad8b", "file_name": "utils/user_funcs.py", "vul_type": "cwe-089"}
{"func_name": "queries", "func_src_before": "@app.route('/queries', methods=['GET', 'POST'])\n@ajax\ndef queries():\n    if request.method == 'GET':\n        return render_template('queries-form.html', queries=get_queries(app, g))\n\n    # Get query and execute it\n    query_key = request.form['query-selector']\n    query = get_queries(app, g)[query_key]\n    (schema, data) = execute_query(app, g, query)\n\n    return jsonify([('', schema, data)])", "func_src_after": "@app.route('/queries', methods=['GET', 'POST'])\n@ajax\ndef queries():\n    if request.method == 'GET':\n        return render_template('queries-form.html', queries=get_queries(app, context))\n\n    # Get query and execute it\n    query_key = request.form['query-selector']\n    query = get_queries(app, context)[query_key]\n    (schema, data) = execute_query(get_db(app), query)\n\n    return jsonify([('', schema, data)])", "line_changes": {"deleted": [{"line_no": 5, "char_start": 101, "char_end": 182, "line": "        return render_template('queries-form.html', queries=get_queries(app, g))\n"}, {"line_no": 9, "char_start": 261, "char_end": 304, "line": "    query = get_queries(app, g)[query_key]\n"}, {"line_no": 10, "char_start": 304, "char_end": 354, "line": "    (schema, data) = execute_query(app, g, query)\n"}], "added": [{"line_no": 5, "char_start": 101, "char_end": 188, "line": "        return render_template('queries-form.html', queries=get_queries(app, context))\n"}, {"line_no": 9, "char_start": 267, "char_end": 316, "line": "    query = get_queries(app, context)[query_key]\n"}, {"line_no": 10, "char_start": 316, "char_end": 371, "line": "    (schema, data) = execute_query(get_db(app), query)\n"}]}, "char_changes": {"deleted": [{"char_start": 178, "char_end": 179, "chars": "g"}, {"char_start": 290, "char_end": 291, "chars": "g"}, {"char_start": 339, "char_end": 345, "chars": "app, g"}], "added": [{"char_start": 178, "char_end": 185, "chars": "context"}, {"char_start": 296, "char_end": 303, "chars": "context"}, {"char_start": 351, "char_end": 362, "chars": "get_db(app)"}]}, "commit_link": "github.com/paulnicolet/IDBS-comics/commit/f7e35633925d7f93d6ca09c635c5d85af5509f11", "file_name": "comics-app/comics.py", "vul_type": "cwe-089"}
{"func_name": "get_table_names", "func_src_before": "@app.route('/get_table_names', methods=['GET'])\n@ajax\ndef get_table_names():\n    query = 'SELECT table_name FROM user_tables'\n    data = execute_query(app, g, query)[1]\n    return jsonify(data)", "func_src_after": "@app.route('/get_table_names', methods=['GET'])\n@ajax\ndef get_table_names():\n    return jsonify(utils.get_table_names(get_db(app)))", "line_changes": {"deleted": [{"line_no": 4, "char_start": 77, "char_end": 126, "line": "    query = 'SELECT table_name FROM user_tables'\n"}, {"line_no": 5, "char_start": 126, "char_end": 169, "line": "    data = execute_query(app, g, query)[1]\n"}, {"line_no": 6, "char_start": 169, "char_end": 193, "line": "    return jsonify(data)\n"}], "added": [{"line_no": 4, "char_start": 77, "char_end": 131, "line": "    return jsonify(utils.get_table_names(get_db(app)))\n"}]}, "char_changes": {"deleted": [{"char_start": 81, "char_end": 192, "chars": "query = 'SELECT table_name FROM user_tables'\n    data = execute_query(app, g, query)[1]\n    return jsonify(data"}], "added": [{"char_start": 81, "char_end": 130, "chars": "return jsonify(utils.get_table_names(get_db(app))"}]}, "commit_link": "github.com/paulnicolet/IDBS-comics/commit/f7e35633925d7f93d6ca09c635c5d85af5509f11", "file_name": "comics-app/comics.py", "vul_type": "cwe-089"}
{"func_name": "generic_search", "func_src_before": "def generic_search(keywords, tables, app, context):\n    # List of tuples (table_name, schema, tuples)\n    result = []\n    for table in tables:\n        # Get columns for the table\n        query = 'SELECT * FROM {} WHERE 1=0'.format(table)\n        description = execute_query(app, context, query)[0]\n\n        # Build conditions\n        conditions = []\n        for col in description:\n            conditions.append('{} LIKE \\'%{}%\\''.format(col, keywords))\n\n        conditions = ' OR '.join(conditions)\n\n        # Execute query\n        query = 'SELECT * FROM {} WHERE {}'.format(table, conditions)\n        (schema, data) = execute_query(app, context, query)\n        result.append((table, schema, data))\n\n    return result", "func_src_after": "def generic_search(con, keywords, tables):\n    \"\"\" Perform a search in the given tables for containment of given keywords \"\"\"\n    # List of tuples (table_name, schema, tuples)\n    result = []\n    table_names = get_table_names(con)\n    for table in tables:\n        # Make sure user didn't cheat with table names\n        if table not in table_names:\n            raise ValueError('Invalid table name')\n\n        # Build conditions\n        conditions = []\n        for col in get_column_names(con, table):\n            conditions.append('{} LIKE \\'%\\'||:keywords||\\'%\\''.format(col))\n\n        conditions = ' OR '.join(conditions)\n\n        # Execute query\n        query = 'SELECT * FROM {} WHERE {}'.format(table, conditions)\n        (schema, data) = execute_query(con, query, keywords=keywords)\n\n        if len(data) > 0:\n            result.append((table, schema, data))\n\n    return result", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 52, "line": "def generic_search(keywords, tables, app, context):\n"}, {"line_no": 6, "char_start": 179, "char_end": 238, "line": "        query = 'SELECT * FROM {} WHERE 1=0'.format(table)\n"}, {"line_no": 7, "char_start": 238, "char_end": 298, "line": "        description = execute_query(app, context, query)[0]\n"}, {"line_no": 11, "char_start": 350, "char_end": 382, "line": "        for col in description:\n"}, {"line_no": 12, "char_start": 382, "char_end": 454, "line": "            conditions.append('{} LIKE \\'%{}%\\''.format(col, keywords))\n"}, {"line_no": 18, "char_start": 595, "char_end": 655, "line": "        (schema, data) = execute_query(app, context, query)\n"}, {"line_no": 19, "char_start": 655, "char_end": 700, "line": "        result.append((table, schema, data))\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 43, "line": "def generic_search(con, keywords, tables):\n"}, {"line_no": 2, "char_start": 43, "char_end": 126, "line": "    \"\"\" Perform a search in the given tables for containment of given keywords \"\"\"\n"}, {"line_no": 5, "char_start": 192, "char_end": 231, "line": "    table_names = get_table_names(con)\n"}, {"line_no": 8, "char_start": 311, "char_end": 348, "line": "        if table not in table_names:\n"}, {"line_no": 9, "char_start": 348, "char_end": 399, "line": "            raise ValueError('Invalid table name')\n"}, {"line_no": 13, "char_start": 451, "char_end": 500, "line": "        for col in get_column_names(con, table):\n"}, {"line_no": 14, "char_start": 500, "char_end": 577, "line": "            conditions.append('{} LIKE \\'%\\'||:keywords||\\'%\\''.format(col))\n"}, {"line_no": 20, "char_start": 718, "char_end": 788, "line": "        (schema, data) = execute_query(con, query, keywords=keywords)\n"}, {"line_no": 21, "char_start": 788, "char_end": 789, "line": "\n"}, {"line_no": 22, "char_start": 789, "char_end": 815, "line": "        if len(data) > 0:\n"}, {"line_no": 23, "char_start": 815, "char_end": 864, "line": "            result.append((table, schema, data))\n"}]}, "char_changes": {"deleted": [{"char_start": 35, "char_end": 297, "chars": ", app, context):\n    # List of tuples (table_name, schema, tuples)\n    result = []\n    for table in tables:\n        # Get columns for the table\n        query = 'SELECT * FROM {} WHERE 1=0'.format(table)\n        description = execute_query(app, context, query)[0]"}, {"char_start": 369, "char_end": 380, "chars": "description"}, {"char_start": 424, "char_end": 426, "chars": "{}"}, {"char_start": 441, "char_end": 451, "chars": ", keywords"}, {"char_start": 634, "char_end": 655, "chars": "app, context, query)\n"}], "added": [{"char_start": 19, "char_end": 24, "chars": "con, "}, {"char_start": 40, "char_end": 398, "chars": "):\n    \"\"\" Perform a search in the given tables for containment of given keywords \"\"\"\n    # List of tuples (table_name, schema, tuples)\n    result = []\n    table_names = get_table_names(con)\n    for table in tables:\n        # Make sure user didn't cheat with table names\n        if table not in table_names:\n            raise ValueError('Invalid table name')"}, {"char_start": 470, "char_end": 498, "chars": "get_column_names(con, table)"}, {"char_start": 542, "char_end": 559, "chars": "\\'||:keywords||\\'"}, {"char_start": 757, "char_end": 819, "chars": "con, query, keywords=keywords)\n\n        if len(data) > 0:\n    "}]}, "commit_link": "github.com/paulnicolet/IDBS-comics/commit/f7e35633925d7f93d6ca09c635c5d85af5509f11", "file_name": "comics-app/utils.py", "vul_type": "cwe-089"}
{"func_name": "ex_me", "func_src_before": "async def ex_me(dclient, channel, mention, con, con_ex, author_id, a, log_file, cmd_char):\n    a = a.split(' ')\n    if len(a) >= 2:\n        time = a[0].lower()\n        msg = ''\n        for i in range(1, len(a)):\n            msg += a[i] + ' '\n        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:\n            date = get_date(time)\n            try:\n                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('0', {}, '{}', '{}');\"\n                               .format(author_id, msg, date.strftime('%Y-%m-%d %X')))\n                con.commit()\n                await dclient.send_message(channel, '{}, will remind you.'.format(mention))\n            except sqlite3.Error as e:\n                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '\n                                                    'the admins!'.format(mention))\n                print('[{}]: {} - {}'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                             'Error when trying to insert data: ' + e.args[0]))\n                log_file.write('[{}]: {} - {}\\n'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                                        'Error when trying to insert data: ' + e.args[0]))\n        else:\n            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'\n                                       .format(mention, cmd_char))\n    else:\n        await dclient.send_message(channel, '{}, **USAGE:** {}remindme <time> <message...>'.format(mention, cmd_char))\n        print('')", "func_src_after": "async def ex_me(dclient, channel, mention, con, con_ex, author_id, a, log_file, cmd_char):\n    a = a.split(' ')\n    if len(a) >= 2:\n        time = a[0].lower()\n        msg = ''\n        for i in range(1, len(a)):\n            msg += a[i] + ' '\n        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:\n            date = get_date(time)\n            try:\n                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('0', ?, ?, ?);\",\n                               (author_id, msg, date.strftime('%Y-%m-%d %X')))\n                con.commit()\n                await dclient.send_message(channel, '{}, will remind you.'.format(mention))\n            except sqlite3.Error as e:\n                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '\n                                                    'the admins!'.format(mention))\n                print('[{}]: {} - {}'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                             'Error when trying to insert data: ' + e.args[0]))\n                log_file.write('[{}]: {} - {}\\n'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                                        'Error when trying to insert data: ' + e.args[0]))\n        else:\n            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'\n                                       .format(mention, cmd_char))\n    else:\n        await dclient.send_message(channel, '{}, **USAGE:** {}remindme <time> <message...>'.format(mention, cmd_char))", "line_changes": {"deleted": [{"line_no": 11, "char_start": 377, "char_end": 492, "line": "                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('0', {}, '{}', '{}');\"\n"}, {"line_no": 12, "char_start": 492, "char_end": 578, "line": "                               .format(author_id, msg, date.strftime('%Y-%m-%d %X')))\n"}, {"line_no": 27, "char_start": 1656, "char_end": 1673, "line": "        print('')\n"}], "added": [{"line_no": 11, "char_start": 377, "char_end": 486, "line": "                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('0', ?, ?, ?);\",\n"}, {"line_no": 12, "char_start": 486, "char_end": 565, "line": "                               (author_id, msg, date.strftime('%Y-%m-%d %X')))\n"}]}, "char_changes": {"deleted": [{"char_start": 474, "char_end": 488, "chars": "{}, '{}', '{}'"}, {"char_start": 523, "char_end": 530, "chars": ".format"}, {"char_start": 1655, "char_end": 1673, "chars": "\n        print('')"}], "added": [{"char_start": 474, "char_end": 481, "chars": "?, ?, ?"}, {"char_start": 484, "char_end": 485, "chars": ","}]}, "commit_link": "github.com/Atomicbeast101/jinux-discord/commit/10908191888bd37f31242bfd7d71c15c6f6fb10b", "file_name": "cmds/remindme.py", "vul_type": "cwe-089"}
{"func_name": "ex_all", "func_src_before": "async def ex_all(dclient, channel, mention, con, con_ex, channel_id, a, log_file, cmd_char):\n    a = a.split(' ')\n    if len(a) >= 2:\n        time = a[0].lower()\n        msg = ''\n        for i in range(1, len(a)):\n            msg += a[i] + ' '\n        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:\n            date = get_date(time)\n            try:\n                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('1', {}, '{}', '{}');\"\n                               .format(channel_id, msg, str(date)))\n                con.commit()\n                await dclient.send_message(channel, '{}, will remind you.'.format(mention))\n            except sqlite3.Error as e:\n                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '\n                                                    'the admins!'.format(mention))\n                print('[{}]: {} - {}'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                             'Error when trying to insert data: ' + e.args[0]))\n                log_file.write('[{}]: {} - {}\\n'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                                        'Error when trying to insert data: ' + e.args[0]))\n        else:\n            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'\n                                       .format(mention, cmd_char))\n    else:\n        await dclient.send_message(channel, '{}, **USAGE:** {}remindall <time> <message...>'.format(mention, cmd_char))\n        print('')", "func_src_after": "async def ex_all(dclient, channel, mention, con, con_ex, channel_id, a, log_file, cmd_char):\n    a = a.split(' ')\n    if len(a) >= 2:\n        time = a[0].lower()\n        msg = ''\n        for i in range(1, len(a)):\n            msg += a[i] + ' '\n        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:\n            date = get_date(time)\n            try:\n                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('1', ?, ?, ?);\",\n                               (channel_id, msg, str(date)))\n                con.commit()\n                await dclient.send_message(channel, '{}, will remind you.'.format(mention))\n            except sqlite3.Error as e:\n                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '\n                                                    'the admins!'.format(mention))\n                print('[{}]: {} - {}'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                             'Error when trying to insert data: ' + e.args[0]))\n                log_file.write('[{}]: {} - {}\\n'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                                        'Error when trying to insert data: ' + e.args[0]))\n        else:\n            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'\n                                       .format(mention, cmd_char))\n    else:\n        await dclient.send_message(channel, '{}, **USAGE:** {}remindall <time> <message...>'.format(mention, cmd_char))", "line_changes": {"deleted": [{"line_no": 11, "char_start": 379, "char_end": 494, "line": "                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('1', {}, '{}', '{}');\"\n"}, {"line_no": 12, "char_start": 494, "char_end": 562, "line": "                               .format(channel_id, msg, str(date)))\n"}, {"line_no": 27, "char_start": 1641, "char_end": 1658, "line": "        print('')"}], "added": [{"line_no": 11, "char_start": 379, "char_end": 488, "line": "                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('1', ?, ?, ?);\",\n"}, {"line_no": 12, "char_start": 488, "char_end": 549, "line": "                               (channel_id, msg, str(date)))\n"}]}, "char_changes": {"deleted": [{"char_start": 476, "char_end": 490, "chars": "{}, '{}', '{}'"}, {"char_start": 525, "char_end": 532, "chars": ".format"}, {"char_start": 1640, "char_end": 1658, "chars": "\n        print('')"}], "added": [{"char_start": 476, "char_end": 483, "chars": "?, ?, ?"}, {"char_start": 486, "char_end": 487, "chars": ","}]}, "commit_link": "github.com/Atomicbeast101/jinux-discord/commit/10908191888bd37f31242bfd7d71c15c6f6fb10b", "file_name": "cmds/remindme.py", "vul_type": "cwe-089"}
{"func_name": "get_order_args", "func_src_before": "def get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))\n    return orders", "func_src_after": "def get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            order_direction = request.args.get('_od_' + re_match[0])\n            if order_direction in ('asc', 'desc'):\n                orders[re_match[0]] = (request.args.get(arg), order_direction)\n    return orders", "line_changes": {"deleted": [{"line_no": 13, "char_start": 347, "char_end": 445, "line": "            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))\n"}], "added": [{"line_no": 13, "char_start": 347, "char_end": 416, "line": "            order_direction = request.args.get('_od_' + re_match[0])\n"}, {"line_no": 14, "char_start": 416, "char_end": 467, "line": "            if order_direction in ('asc', 'desc'):\n"}, {"line_no": 15, "char_start": 467, "char_end": 546, "line": "                orders[re_match[0]] = (request.args.get(arg), order_direction)\n"}]}, "char_changes": {"deleted": [{"char_start": 364, "char_end": 378, "chars": "s[re_match[0]]"}, {"char_start": 381, "char_end": 382, "chars": "("}, {"char_start": 399, "char_end": 443, "chars": "arg), request.args.get('_od_' + re_match[0])"}], "added": [{"char_start": 364, "char_end": 374, "chars": "_direction"}, {"char_start": 394, "char_end": 544, "chars": "'_od_' + re_match[0])\n            if order_direction in ('asc', 'desc'):\n                orders[re_match[0]] = (request.args.get(arg), order_direction"}]}, "commit_link": "github.com/zwj2017-NK/FAB/commit/2158db051408e0d66210a99b17c121be008e20b6", "file_name": "flask_appbuilder/urltools.py", "vul_type": "cwe-089"}
{"func_name": "get_admin_stat", "func_src_before": "def get_admin_stat(command):\n    # Function that returns statistics to admin by command\n    error_answer = \"Can't execute your command. Check logs\"\n    answer = 'There is some statistics for you: \\n'\n\n    # Set to a beginning of the day\n    today = (datetime\n             .today()\n             .replace(hour=0, minute=0, second=0, microsecond=0)\n             .strftime('%Y-%m-%d %H:%M:%S'))\n\n    # Last users with date of last time when they used bot\n    if command == 'last active users':\n\n        try:\n            last_active_users = users.get_last_active_users(100)\n        except DatabaseConnectionError:\n            return error_answer\n\n        bot_users = ''\n        # Makes a human readable list of last active users\n        for usr, index in zip(last_active_users,\n                              range(len(last_active_users))):\n            user = User(*usr)\n            bot_users += f'{index + 1}. {user}\\n'\n\n        answer = ('Up to 100 last active users by the time when they sent '\n                  'picture last time:\\n')\n        answer += bot_users\n        log.info('Done.')\n        return answer\n\n    elif command == 'total number photos sent':\n        log.info('Evaluating total number of photo queries in database...')\n        query = ('SELECT COUNT(chat_id) '\n                 'FROM photo_queries_table2')\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += '{} times users sent photos.'.format(cursor.fetchone()[0])\n        query = ('SELECT COUNT(chat_id) '\n                 'FROM photo_queries_table2 '\n                 'WHERE chat_id !={}'.format(config.MY_TELEGRAM))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            answer += (\"\\nCannot calculate number of photos that were send \"\n                       \"excluding your photos. Check logs\")\n            return answer\n\n        answer += '\\nExcept you: {} times.'.format(cursor.fetchone()[0])\n        log.info('Done.')\n        return answer\n\n    elif command == 'photos today':\n        # Show how many photos have been sent since 00:00:00 of today\n        log.info('Evaluating number of photos which were sent today.')\n        query = (\"SELECT COUNT(chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > '{}'\".format(today))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += f'{cursor.fetchone()[0]} times users sent photos today.'\n        query = (\"SELECT COUNT(chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > '{}' \"\n                 \"AND chat_id !={}\".format(today, config.MY_TELEGRAM))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n\n        answer += '\\nExcept you: {} times.'.format(cursor.fetchone()[0])\n        log.info('Done.')\n        return answer\n\n    elif command == 'number of users':\n        # Show number of users who has used bot at leas\"\n        # once or more (first for the whole time, then today)\n        log.info('Evaluating number of users that use bot '\n                 'since the first day and today...')\n        try:\n            num_of_users = users.get_total_number()\n        except DatabaseConnectionError:\n            return error_answer\n\n        answer += f'There are totally {num_of_users} users.'\n\n        query = (\"SELECT COUNT(DISTINCT chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > '{}'\".format(today))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            answer += (\"\\nCannot calculate how many user have sent their \"\n                       \"photos today\")\n            return answer\n\n        answer += f'\\n{cursor.fetchone()[0]} users have sent photos today.'\n        log.info('Done.')\n        return answer\n\n    elif command == 'number of gadgets':\n        # To show you number smartphones + cameras in database\n        log.info('Evaluating number of cameras and smartphones in database...')\n        query = ('SELECT COUNT(DISTINCT camera_name) '\n                 'FROM photo_queries_table2')\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += (f'There are totally {cursor.fetchone()[0]} '\n                   f'cameras/smartphones.')\n        query = (\"SELECT COUNT(DISTINCT camera_name) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > '{}'\".format(today))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            answer += (\"Cannot calculate the number of gadgets that have been \"\n                       \"used today so far\")\n            return answer\n\n        answer += (f'\\n{cursor.fetchone()[0]} cameras/smartphones '\n                   'were used today.')\n        log.info('Done.')\n        return answer\n\n    elif command == 'uptime':\n        fmt = 'Uptime: {} days, {} hours, {} minutes and {} seconds.'\n        td = datetime.now() - bot.start_time\n        # datetime.timedelta.seconds returns you total number of seconds\n        # since given time, so you need to perform\n        # a little bit of math to make whole hours, minutes and seconds from it\n        # And there isn't any normal way to do it in Python unfortunately\n        uptime = fmt.format(td.days, td.seconds // 3600, td.seconds % 3600 //\n                            60, td.seconds % 60)\n        log.info(uptime)\n        return uptime", "func_src_after": "def get_admin_stat(command):\n    # Function that returns statistics to admin by command\n    error_answer = \"Can't execute your command. Check logs\"\n    answer = 'There is some statistics for you: \\n'\n\n    # Set to a beginning of the day\n    today = (datetime\n             .today()\n             .replace(hour=0, minute=0, second=0, microsecond=0)\n             .strftime('%Y-%m-%d %H:%M:%S'))\n\n    # Last users with date of last time when they used bot\n    if command == 'last active users':\n\n        try:\n            last_active_users = users.get_last_active_users(100)\n        except DatabaseConnectionError:\n            return error_answer\n\n        bot_users = ''\n        # Makes a human readable list of last active users\n        for usr, index in zip(last_active_users,\n                              range(len(last_active_users))):\n            user = User(*usr)\n            bot_users += f'{index + 1}. {user}\\n'\n\n        answer = ('Up to 100 last active users by the time when they sent '\n                  'picture last time:\\n')\n        answer += bot_users\n        log.info('Done.')\n        return answer\n\n    elif command == 'total number photos sent':\n        log.info('Evaluating total number of photo queries in database...')\n        query = ('SELECT COUNT(chat_id) '\n                 'FROM photo_queries_table2')\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += '{} times users sent photos.'.format(cursor.fetchone()[0])\n        query = ('SELECT COUNT(chat_id) '\n                 'FROM photo_queries_table2 '\n                 'WHERE chat_id !=%s')\n        parameters = (config.MY_TELEGRAM,)\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            answer += (\"\\nCannot calculate number of photos that were send \"\n                       \"excluding your photos. Check logs\")\n            return answer\n\n        answer += '\\nExcept you: {} times.'.format(cursor.fetchone()[0])\n        log.info('Done.')\n        return answer\n\n    elif command == 'photos today':\n        # Show how many photos have been sent since 00:00:00 of today\n        log.info('Evaluating number of photos which were sent today.')\n        query = (\"SELECT COUNT(chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > %s\")\n\n        parameters = (today,)\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += f'{cursor.fetchone()[0]} times users sent photos today.'\n        query = (\"SELECT COUNT(chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > %s \"\n                 \"AND chat_id !=%s\")\n\n        parameters = today, config.MY_TELEGRAM\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            return error_answer\n\n        answer += '\\nExcept you: {} times.'.format(cursor.fetchone()[0])\n        log.info('Done.')\n        return answer\n\n    elif command == 'number of users':\n        # Show number of users who has used bot at leas\"\n        # once or more (first for the whole time, then today)\n        log.info('Evaluating number of users that use bot '\n                 'since the first day and today...')\n        try:\n            num_of_users = users.get_total_number()\n        except DatabaseConnectionError:\n            return error_answer\n\n        answer += f'There are totally {num_of_users} users.'\n\n        query = (\"SELECT COUNT(DISTINCT chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > %s\")\n\n        parameters = (today,)\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            answer += (\"\\nCannot calculate how many user have sent their \"\n                       \"photos today\")\n            return answer\n\n        answer += f'\\n{cursor.fetchone()[0]} users have sent photos today.'\n        log.info('Done.')\n        return answer\n\n    elif command == 'number of gadgets':\n        # To show you number smartphones + cameras in database\n        log.info('Evaluating number of cameras and smartphones in database...')\n        query = ('SELECT COUNT(DISTINCT camera_name) '\n                 'FROM photo_queries_table2')\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += (f'There are totally {cursor.fetchone()[0]} '\n                   f'cameras/smartphones.')\n        query = (\"SELECT COUNT(DISTINCT camera_name) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > %s\")\n        parameters = (today,)\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            answer += (\"Cannot calculate the number of gadgets that have been \"\n                       \"used today so far\")\n            return answer\n\n        answer += (f'\\n{cursor.fetchone()[0]} cameras/smartphones '\n                   'were used today.')\n        log.info('Done.')\n        return answer\n\n    elif command == 'uptime':\n        fmt = 'Uptime: {} days, {} hours, {} minutes and {} seconds.'\n        td = datetime.now() - bot.start_time\n        # datetime.timedelta.seconds returns you total number of seconds\n        # since given time, so you need to perform\n        # a little bit of math to make whole hours, minutes and seconds from it\n        # And there isn't any normal way to do it in Python unfortunately\n        uptime = fmt.format(td.days, td.seconds // 3600, td.seconds % 3600 //\n                            60, td.seconds % 60)\n        log.info(uptime)\n        return uptime", "line_changes": {"deleted": [{"line_no": 44, "char_start": 1618, "char_end": 1684, "line": "                 'WHERE chat_id !={}'.format(config.MY_TELEGRAM))\n"}, {"line_no": 46, "char_start": 1697, "char_end": 1742, "line": "            cursor = db.execute_query(query)\n"}, {"line_no": 61, "char_start": 2333, "char_end": 2385, "line": "                 \"WHERE time > '{}'\".format(today))\n"}, {"line_no": 63, "char_start": 2398, "char_end": 2443, "line": "            cursor = db.execute_query(query)\n"}, {"line_no": 69, "char_start": 2678, "char_end": 2716, "line": "                 \"WHERE time > '{}' \"\n"}, {"line_no": 70, "char_start": 2716, "char_end": 2787, "line": "                 \"AND chat_id !={}\".format(today, config.MY_TELEGRAM))\n"}, {"line_no": 72, "char_start": 2800, "char_end": 2845, "line": "            cursor = db.execute_query(query)\n"}, {"line_no": 94, "char_start": 3608, "char_end": 3660, "line": "                 \"WHERE time > '{}'\".format(today))\n"}, {"line_no": 96, "char_start": 3673, "char_end": 3718, "line": "            cursor = db.execute_query(query)\n"}, {"line_no": 119, "char_start": 4648, "char_end": 4700, "line": "                 \"WHERE time > '{}'\".format(today))\n"}, {"line_no": 121, "char_start": 4713, "char_end": 4758, "line": "            cursor = db.execute_query(query)\n"}], "added": [{"line_no": 44, "char_start": 1618, "char_end": 1657, "line": "                 'WHERE chat_id !=%s')\n"}, {"line_no": 45, "char_start": 1657, "char_end": 1700, "line": "        parameters = (config.MY_TELEGRAM,)\n"}, {"line_no": 47, "char_start": 1713, "char_end": 1770, "line": "            cursor = db.execute_query(query, parameters)\n"}, {"line_no": 62, "char_start": 2361, "char_end": 2397, "line": "                 \"WHERE time > %s\")\n"}, {"line_no": 63, "char_start": 2397, "char_end": 2398, "line": "\n"}, {"line_no": 64, "char_start": 2398, "char_end": 2428, "line": "        parameters = (today,)\n"}, {"line_no": 65, "char_start": 2428, "char_end": 2429, "line": "\n"}, {"line_no": 67, "char_start": 2442, "char_end": 2499, "line": "            cursor = db.execute_query(query, parameters)\n"}, {"line_no": 73, "char_start": 2734, "char_end": 2770, "line": "                 \"WHERE time > %s \"\n"}, {"line_no": 74, "char_start": 2770, "char_end": 2807, "line": "                 \"AND chat_id !=%s\")\n"}, {"line_no": 75, "char_start": 2807, "char_end": 2808, "line": "\n"}, {"line_no": 76, "char_start": 2808, "char_end": 2855, "line": "        parameters = today, config.MY_TELEGRAM\n"}, {"line_no": 77, "char_start": 2855, "char_end": 2856, "line": "\n"}, {"line_no": 79, "char_start": 2869, "char_end": 2926, "line": "            cursor = db.execute_query(query, parameters)\n"}, {"line_no": 101, "char_start": 3689, "char_end": 3725, "line": "                 \"WHERE time > %s\")\n"}, {"line_no": 102, "char_start": 3725, "char_end": 3726, "line": "\n"}, {"line_no": 103, "char_start": 3726, "char_end": 3756, "line": "        parameters = (today,)\n"}, {"line_no": 105, "char_start": 3769, "char_end": 3826, "line": "            cursor = db.execute_query(query, parameters)\n"}, {"line_no": 128, "char_start": 4756, "char_end": 4792, "line": "                 \"WHERE time > %s\")\n"}, {"line_no": 129, "char_start": 4792, "char_end": 4822, "line": "        parameters = (today,)\n"}, {"line_no": 131, "char_start": 4835, "char_end": 4892, "line": "            cursor = db.execute_query(query, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 1652, "char_end": 1662, "chars": "{}'.format"}, {"char_start": 1681, "char_end": 1682, "chars": ")"}, {"char_start": 2364, "char_end": 2376, "chars": "'{}'\".format"}, {"char_start": 2382, "char_end": 2384, "chars": "))"}, {"char_start": 2709, "char_end": 2713, "chars": "'{}'"}, {"char_start": 2748, "char_end": 2759, "chars": "{}\".format("}, {"char_start": 2784, "char_end": 2786, "chars": "))"}, {"char_start": 3639, "char_end": 3651, "chars": "'{}'\".format"}, {"char_start": 3657, "char_end": 3658, "chars": ")"}, {"char_start": 4679, "char_end": 4691, "chars": "'{}'\".format"}, {"char_start": 4697, "char_end": 4698, "chars": ")"}], "added": [{"char_start": 1652, "char_end": 1678, "chars": "%s')\n        parameters = "}, {"char_start": 1697, "char_end": 1698, "chars": ","}, {"char_start": 1756, "char_end": 1768, "chars": ", parameters"}, {"char_start": 2392, "char_end": 2419, "chars": "%s\")\n\n        parameters = "}, {"char_start": 2425, "char_end": 2428, "chars": ",)\n"}, {"char_start": 2485, "char_end": 2497, "chars": ", parameters"}, {"char_start": 2765, "char_end": 2767, "chars": "%s"}, {"char_start": 2802, "char_end": 2829, "chars": "%s\")\n\n        parameters = "}, {"char_start": 2854, "char_end": 2855, "chars": "\n"}, {"char_start": 2912, "char_end": 2924, "chars": ", parameters"}, {"char_start": 3720, "char_end": 3747, "chars": "%s\")\n\n        parameters = "}, {"char_start": 3753, "char_end": 3754, "chars": ","}, {"char_start": 3812, "char_end": 3824, "chars": ", parameters"}, {"char_start": 4787, "char_end": 4813, "chars": "%s\")\n        parameters = "}, {"char_start": 4819, "char_end": 4820, "chars": ","}, {"char_start": 4878, "char_end": 4890, "chars": ", parameters"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/__main__.py", "vul_type": "cwe-089"}
{"func_name": "get_most_popular_items", "func_src_before": "@cache_most_popular_items\ndef get_most_popular_items(item_type, message):\n    \"\"\"\n    Get most common cameras/lenses/countries from database and\n    make list of them\n    :param item_type: string with column name to choose between cameras,\n    lenses and countries\n    :param message: telebot object with info about user and his message\n    :return: string which is either list of most common\n    cameras/lenses/countries or message which states that list is\n    empty\n    \"\"\"\n\n    user = users.find_one(message)\n\n    def list_to_ordered_str_list(list_of_gadgets):\n        # Make Python list to be string like roster with indexes and\n        # new line characters like:\n        # 1. Canon 80D\n        # 2. iPhone 4S\n\n        string_roaster = ''\n        index = 1\n        for item in list_of_gadgets:\n            if not item[0]:\n                continue\n            string_roaster += '{}. {}\\n'.format(index, item[0])\n            index += 1\n        return string_roaster\n\n    log.debug('Evaluating most popular things...')\n\n    # This query returns item types in order where the first one item\n    # has the highest number of occurrences\n    # in a given column\n    query = ('SELECT {0} FROM photo_queries_table2 '\n             'GROUP BY {0} '\n             'ORDER BY count({0}) '\n             'DESC'.format(item_type))\n    try:\n        cursor = db.execute_query(query)\n    except DatabaseConnectionError:\n        log.error(\"Can't evaluate a list of the most popular items\")\n        return messages[user.language]['doesnt work']\n\n    # Almost impossible case but still\n    if not cursor.rowcount:\n        log.warning('There is nothing in the main database table')\n        bot.send_message(chat_id=config.MY_TELEGRAM,\n                         text='There is nothing in the main database table')\n        return messages[user.language]['no_top']\n\n    popular_items = cursor.fetchall()\n    log.info('Finish evaluating the most popular items')\n    return list_to_ordered_str_list(popular_items[:30])", "func_src_after": "@cache_most_popular_items\ndef get_most_popular_items(item_type, message):\n    \"\"\"\n    Get most common cameras/lenses/countries from database and\n    make list of them\n    :param item_type: string with column name to choose between cameras,\n    lenses and countries\n    :param message: telebot object with info about user and his message\n    :return: string which is either list of most common\n    cameras/lenses/countries or message which states that list is\n    empty\n    \"\"\"\n\n    user = users.find_one(message)\n\n    def list_to_ordered_str_list(list_of_gadgets):\n        # Make Python list to be string like roster with indexes and\n        # new line characters like:\n        # 1. Canon 80D\n        # 2. iPhone 4S\n\n        string_roaster = ''\n        index = 1\n        for item in list_of_gadgets:\n            if not item[0]:\n                continue\n            string_roaster += '{}. {}\\n'.format(index, item[0])\n            index += 1\n        return string_roaster\n\n    log.debug('Evaluating most popular things...')\n\n    # This query returns item types in order where the first one item\n    # has the highest number of occurrences\n    # in a given column\n\n    query = (f'SELECT {item_type} FROM photo_queries_table2 '\n             f'GROUP BY {item_type} '\n             f'ORDER BY count({item_type}) '\n             'DESC')\n\n    try:\n        cursor = db.execute_query(query)\n    except DatabaseConnectionError:\n        log.error(\"Can't evaluate a list of the most popular items\")\n        return messages[user.language]['doesnt work']\n\n    # Almost impossible case but still\n    if not cursor.rowcount:\n        log.warning('There is nothing in the main database table')\n        bot.send_message(chat_id=config.MY_TELEGRAM,\n                         text='There is nothing in the main database table')\n        return messages[user.language]['no_top']\n\n    popular_items = cursor.fetchall()\n    log.info('Finish evaluating the most popular items')\n    return list_to_ordered_str_list(popular_items[:30])", "line_changes": {"deleted": [{"line_no": 36, "char_start": 1161, "char_end": 1214, "line": "    query = ('SELECT {0} FROM photo_queries_table2 '\n"}, {"line_no": 37, "char_start": 1214, "char_end": 1243, "line": "             'GROUP BY {0} '\n"}, {"line_no": 38, "char_start": 1243, "char_end": 1279, "line": "             'ORDER BY count({0}) '\n"}, {"line_no": 39, "char_start": 1279, "char_end": 1318, "line": "             'DESC'.format(item_type))\n"}], "added": [{"line_no": 36, "char_start": 1161, "char_end": 1162, "line": "\n"}, {"line_no": 37, "char_start": 1162, "char_end": 1224, "line": "    query = (f'SELECT {item_type} FROM photo_queries_table2 '\n"}, {"line_no": 38, "char_start": 1224, "char_end": 1262, "line": "             f'GROUP BY {item_type} '\n"}, {"line_no": 39, "char_start": 1262, "char_end": 1307, "line": "             f'ORDER BY count({item_type}) '\n"}, {"line_no": 40, "char_start": 1307, "char_end": 1328, "line": "             'DESC')\n"}, {"line_no": 41, "char_start": 1328, "char_end": 1329, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 1183, "char_end": 1184, "chars": "0"}, {"char_start": 1238, "char_end": 1239, "chars": "0"}, {"char_start": 1273, "char_end": 1274, "chars": "0"}, {"char_start": 1298, "char_end": 1316, "chars": ".format(item_type)"}], "added": [{"char_start": 1161, "char_end": 1162, "chars": "\n"}, {"char_start": 1175, "char_end": 1176, "chars": "f"}, {"char_start": 1185, "char_end": 1194, "chars": "item_type"}, {"char_start": 1237, "char_end": 1238, "chars": "f"}, {"char_start": 1249, "char_end": 1258, "chars": "item_type"}, {"char_start": 1275, "char_end": 1276, "chars": "f"}, {"char_start": 1293, "char_end": 1302, "chars": "item_type"}, {"char_start": 1327, "char_end": 1328, "chars": "\n"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/__main__.py", "vul_type": "cwe-089"}
{"func_name": "get_number_users_by_feature", "func_src_before": "@cache_number_users_with_same_feature\ndef get_number_users_by_feature(feature, feature_type):\n    \"\"\"\n    Get number of users that have same smartphone, camera, lens or that\n    have been to the same country\n    :param feature: string which is name of a particular feature e.g.\n    camera name or country name\n    :param feature_type: string which is name of the column in database\n    :param message: telebot object with info about message and its sender\n    :return: string which is message to user\n    \"\"\"\n    log.debug('Check how many users also have this feature: %s...',\n              feature)\n\n    query = (\"SELECT DISTINCT chat_id \"\n             \"FROM photo_queries_table2 \"\n             \"WHERE {}='{}'\".format(feature_type, feature))\n    try:\n        cursor = db.execute_query(query)\n    except DatabaseConnectionError:\n        log.error(\"Cannot check how many users also have this feature: %s...\",\n                  feature)\n        return None\n\n    if not cursor.rowcount:\n        log.debug('There were no users with %s...', feature)\n        return None\n\n    log.debug('There is %d users with %s', cursor.rowcount, feature)\n    return cursor.rowcount - 1", "func_src_after": "@cache_number_users_with_same_feature\ndef get_number_users_by_feature(feature, feature_type):\n    \"\"\"\n    Get number of users that have same smartphone, camera, lens or that\n    have been to the same country\n    :param feature: string which is name of a particular feature e.g.\n    camera name or country name\n    :param feature_type: string which is name of the column in database\n    :return: string which is message to user\n    \"\"\"\n    log.debug('Check how many users also have this feature: %s...',\n              feature)\n\n    query = (\"SELECT DISTINCT chat_id \"\n             \"FROM photo_queries_table2 \"\n             \"WHERE %s=%s\")\n\n    parameters = (feature_type, feature)\n\n    try:\n        cursor = db.execute_query(query, parameters)\n    except DatabaseConnectionError:\n        log.error(\"Cannot check how many users also have this feature: %s...\",\n                  feature)\n        return None\n\n    if not cursor.rowcount:\n        log.debug('There were no users with %s...', feature)\n        return None\n\n    log.debug('There is %d users with %s', cursor.rowcount, feature)\n    return cursor.rowcount - 1", "line_changes": {"deleted": [{"line_no": 9, "char_start": 382, "char_end": 456, "line": "    :param message: telebot object with info about message and its sender\n"}, {"line_no": 17, "char_start": 683, "char_end": 743, "line": "             \"WHERE {}='{}'\".format(feature_type, feature))\n"}, {"line_no": 19, "char_start": 752, "char_end": 793, "line": "        cursor = db.execute_query(query)\n"}], "added": [{"line_no": 16, "char_start": 609, "char_end": 637, "line": "             \"WHERE %s=%s\")\n"}, {"line_no": 17, "char_start": 637, "char_end": 638, "line": "\n"}, {"line_no": 18, "char_start": 638, "char_end": 679, "line": "    parameters = (feature_type, feature)\n"}, {"line_no": 19, "char_start": 679, "char_end": 680, "line": "\n"}, {"line_no": 21, "char_start": 689, "char_end": 742, "line": "        cursor = db.execute_query(query, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 382, "char_end": 456, "chars": "    :param message: telebot object with info about message and its sender\n"}, {"char_start": 703, "char_end": 718, "chars": "{}='{}'\".format"}, {"char_start": 741, "char_end": 742, "chars": ")"}], "added": [{"char_start": 629, "char_end": 655, "chars": "%s=%s\")\n\n    parameters = "}, {"char_start": 678, "char_end": 679, "chars": "\n"}, {"char_start": 728, "char_end": 740, "chars": ", parameters"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/__main__.py", "vul_type": "cwe-089"}
{"func_name": "_check_camera_tags", "func_src_before": "    @staticmethod\n    def _check_camera_tags(tags):\n        \"\"\"\n        Function that convert stupid code name of a smartphone or camera\n        from EXIF to meaningful one by looking a collation in a special MySQL\n        table For example instead of just Nikon there can be\n        NIKON CORPORATION in EXIF\n\n        :param tags: name of a camera and lens from EXIF\n        :return: list with one or two strings which are name of\n        camera and/or lens. If there is not better name for the gadget\n        in database, function just returns name how it is\n        \"\"\"\n        checked_tags = []\n\n        for tag in tags:\n            if tag:  # If there was this information inside EXIF of the photo\n                tag = str(tag).strip()\n                log.info('Looking up collation for %s', tag)\n                query = ('SELECT right_tag '\n                         'FROM tag_table '\n                         'WHERE wrong_tag=\"{}\"'.format(tag))\n                cursor = db.execute_query(query)\n                if not cursor:\n                    log.error(\"Can't check the tag because of the db error\")\n                    log.warning(\"Tag will stay as is.\")\n                    continue\n                if cursor.rowcount:\n                    # Get appropriate tag from the table\n                    tag = cursor.fetchone()[0]\n                    log.info('Tag after looking up in tag_tables - %s.', tag)\n\n            checked_tags.append(tag)\n        return checked_tags", "func_src_after": "    @staticmethod\n    def _check_camera_tags(tags):\n        \"\"\"\n        Function that convert stupid code name of a smartphone or camera\n        from EXIF to meaningful one by looking a collation in a special MySQL\n        table For example instead of just Nikon there can be\n        NIKON CORPORATION in EXIF\n\n        :param tags: name of a camera and lens from EXIF\n        :return: list with one or two strings which are name of\n        camera and/or lens. If there is not better name for the gadget\n        in database, function just returns name how it is\n        \"\"\"\n        checked_tags = []\n\n        for tag in tags:\n            if tag:  # If there was this information inside EXIF of the photo\n                tag = str(tag).strip()\n                log.info('Looking up collation for %s', tag)\n                query = ('SELECT right_tag '\n                         'FROM tag_table '\n                         'WHERE wrong_tag=%s')\n                parameters = tag,\n                cursor = db.execute_query(query, parameters)\n                if not cursor:\n                    log.error(\"Can't check the tag because of the db error\")\n                    log.warning(\"Tag will stay as is.\")\n                    continue\n                if cursor.rowcount:\n                    # Get appropriate tag from the table\n                    tag = cursor.fetchone()[0]\n                    log.info('Tag after looking up in tag_tables - %s.', tag)\n\n            checked_tags.append(tag)\n        return checked_tags", "line_changes": {"deleted": [{"line_no": 22, "char_start": 891, "char_end": 952, "line": "                         'WHERE wrong_tag=\"{}\"'.format(tag))\n"}, {"line_no": 23, "char_start": 952, "char_end": 1001, "line": "                cursor = db.execute_query(query)\n"}], "added": [{"line_no": 22, "char_start": 891, "char_end": 938, "line": "                         'WHERE wrong_tag=%s')\n"}, {"line_no": 23, "char_start": 938, "char_end": 972, "line": "                parameters = tag,\n"}, {"line_no": 24, "char_start": 972, "char_end": 1033, "line": "                cursor = db.execute_query(query, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 933, "char_end": 946, "chars": "\"{}\"'.format("}, {"char_start": 949, "char_end": 951, "chars": "))"}], "added": [{"char_start": 933, "char_end": 967, "chars": "%s')\n                parameters = "}, {"char_start": 970, "char_end": 971, "chars": ","}, {"char_start": 1019, "char_end": 1031, "chars": ", parameters"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/process_image.py", "vul_type": "cwe-089"}
{"func_name": "set_language", "func_src_before": "    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language='{self.language}' \"\n                 f\"WHERE chat_id='{self.chat_id}'\")\n\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')", "func_src_after": "    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language=%s \"\n                 f\"WHERE chat_id=%s\")\n\n        parameters = self.language, self.chat_id\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')", "line_changes": {"deleted": [{"line_no": 13, "char_start": 383, "char_end": 435, "line": "                 f\"SET language='{self.language}' \"\n"}, {"line_no": 14, "char_start": 435, "char_end": 487, "line": "                 f\"WHERE chat_id='{self.chat_id}'\")\n"}, {"line_no": 17, "char_start": 501, "char_end": 527, "line": "            db.add(query)\n"}], "added": [{"line_no": 13, "char_start": 383, "char_end": 420, "line": "                 f\"SET language=%s \"\n"}, {"line_no": 14, "char_start": 420, "char_end": 458, "line": "                 f\"WHERE chat_id=%s\")\n"}, {"line_no": 16, "char_start": 459, "char_end": 508, "line": "        parameters = self.language, self.chat_id\n"}, {"line_no": 18, "char_start": 521, "char_end": 559, "line": "            db.add(query, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 415, "char_end": 432, "chars": "'{self.language}'"}, {"char_start": 468, "char_end": 470, "chars": "'{"}, {"char_start": 482, "char_end": 487, "chars": "}'\")\n"}], "added": [{"char_start": 415, "char_end": 417, "chars": "%s"}, {"char_start": 453, "char_end": 495, "chars": "%s\")\n\n        parameters = self.language, "}, {"char_start": 545, "char_end": 557, "chars": ", parameters"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089"}
{"func_name": "get_last_active_users", "func_src_before": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "func_src_after": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "line_changes": {"deleted": [{"line_no": 23, "char_start": 976, "char_end": 1016, "line": "                 f'DESC LIMIT {limit}')\n"}, {"line_no": 26, "char_start": 1030, "char_end": 1075, "line": "            cursor = db.execute_query(query)\n"}], "added": [{"line_no": 23, "char_start": 976, "char_end": 1011, "line": "                 f'DESC LIMIT %s')\n"}, {"line_no": 24, "char_start": 1011, "char_end": 1012, "line": "\n"}, {"line_no": 25, "char_start": 1012, "char_end": 1040, "line": "        parameters = limit,\n"}, {"line_no": 28, "char_start": 1054, "char_end": 1111, "line": "            cursor = db.execute_query(query, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 1006, "char_end": 1007, "chars": "{"}, {"char_start": 1012, "char_end": 1015, "chars": "}')"}], "added": [{"char_start": 1006, "char_end": 1033, "chars": "%s')\n\n        parameters = "}, {"char_start": 1038, "char_end": 1039, "chars": ","}, {"char_start": 1097, "char_end": 1109, "chars": ", parameters"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089"}
{"func_name": "clean_cache", "func_src_before": "    def clean_cache(self, limit):\n        \"\"\"\n        Method that remove several User objects from cache - the least \n        active users\n        :param limit: number of the users that the method should remove\n        from cache\n        :return: None\n        \"\"\"\n\n        log.info('Figuring out the least active users...')\n        # Select users that the least active recently\n        user_ids = tuple(self.users.keys())\n        query = ('SELECT chat_id '\n                 'FROM photo_queries_table2 '\n                 f'WHERE chat_id in {user_ids} '\n                 'GROUP BY chat_id '\n                 'ORDER BY MAX(time) '\n                 f'LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Can't figure out the least active users...\")\n            return\n\n        if not cursor.rowcount:\n            log.warning(\"There are no users in the db\")\n            return\n\n        # Make list out of tuple of tuples that is returned by MySQL\n        least_active_users = [chat_id[0] for chat_id in cursor.fetchall()]\n        log.info('Removing %d least active users from cache...', limit)\n        num_deleted_entries = 0\n        for entry in least_active_users:\n            log.debug('Deleting %s...', entry)\n            deleted_entry = self.users.pop(entry, None)\n            if deleted_entry:\n                num_deleted_entries += 1\n        log.debug(\"%d users were removed from cache.\", num_deleted_entries)", "func_src_after": "    def clean_cache(self, limit):\n        \"\"\"\n        Method that remove several User objects from cache - the least \n        active users\n        :param limit: number of the users that the method should remove\n        from cache\n        :return: None\n        \"\"\"\n\n        log.info('Figuring out the least active users...')\n        # Select users that the least active recently\n        user_ids = tuple(self.users.keys())\n        query = ('SELECT chat_id '\n                 'FROM photo_queries_table2 '\n                 f'WHERE chat_id in {user_ids} '\n                 'GROUP BY chat_id '\n                 'ORDER BY MAX(time) '\n                 f'LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Can't figure out the least active users...\")\n            return\n\n        if not cursor.rowcount:\n            log.warning(\"There are no users in the db\")\n            return\n\n        # Make list out of tuple of tuples that is returned by MySQL\n        least_active_users = [chat_id[0] for chat_id in cursor.fetchall()]\n        log.info('Removing %d least active users from cache...', limit)\n        num_deleted_entries = 0\n        for entry in least_active_users:\n            log.debug('Deleting %s...', entry)\n            deleted_entry = self.users.pop(entry, None)\n            if deleted_entry:\n                num_deleted_entries += 1\n        log.debug(\"%d users were removed from cache.\", num_deleted_entries)", "line_changes": {"deleted": [{"line_no": 18, "char_start": 628, "char_end": 663, "line": "                 f'LIMIT {limit}')\n"}, {"line_no": 21, "char_start": 677, "char_end": 722, "line": "            cursor = db.execute_query(query)\n"}], "added": [{"line_no": 18, "char_start": 628, "char_end": 658, "line": "                 f'LIMIT %s')\n"}, {"line_no": 19, "char_start": 658, "char_end": 659, "line": "\n"}, {"line_no": 20, "char_start": 659, "char_end": 687, "line": "        parameters = limit,\n"}, {"line_no": 23, "char_start": 701, "char_end": 758, "line": "            cursor = db.execute_query(query, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 653, "char_end": 654, "chars": "{"}, {"char_start": 659, "char_end": 662, "chars": "}')"}], "added": [{"char_start": 653, "char_end": 680, "chars": "%s')\n\n        parameters = "}, {"char_start": 685, "char_end": 686, "chars": ","}, {"char_start": 744, "char_end": 756, "chars": ", parameters"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089"}
{"func_name": "_add_to_db", "func_src_before": "    @staticmethod\n    def _add_to_db(user):\n        \"\"\"\n        Adds User object to the database\n        :param user: User object with info about user\n        :return: None\n        \"\"\"\n        query = (\"INSERT INTO users (chat_id, first_name, nickname, \"\n                 \"last_name, language) \"\n                 f\"VALUES ({user.chat_id}, '{user.first_name}', \"\n                 f\"'{user.nickname}', '{user.last_name}', '{user.language}')\")\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Cannot add user to the database\")\n        else:\n            log.info(f\"User {user} was successfully added to the users db\")", "func_src_after": "    @staticmethod\n    def _add_to_db(user):\n        \"\"\"\n        Adds User object to the database\n        :param user: User object with info about user\n        :return: None\n        \"\"\"\n        query = (\"INSERT INTO users (chat_id, first_name, nickname, \"\n                 \"last_name, language) \"\n                 f\"VALUES (%s, %s, %s, %s, %s)\")\n\n        parameters = (user.chat_id, user.first_name, user.nickname,\n                      user.last_name, user.language)\n\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Cannot add user to the database\")\n        else:\n            log.info(f\"User {user} was successfully added to the users db\")", "line_changes": {"deleted": [{"line_no": 10, "char_start": 296, "char_end": 362, "line": "                 f\"VALUES ({user.chat_id}, '{user.first_name}', \"\n"}, {"line_no": 11, "char_start": 362, "char_end": 441, "line": "                 f\"'{user.nickname}', '{user.last_name}', '{user.language}')\")\n"}, {"line_no": 13, "char_start": 454, "char_end": 480, "line": "            db.add(query)\n"}], "added": [{"line_no": 10, "char_start": 296, "char_end": 345, "line": "                 f\"VALUES (%s, %s, %s, %s, %s)\")\n"}, {"line_no": 11, "char_start": 345, "char_end": 346, "line": "\n"}, {"line_no": 12, "char_start": 346, "char_end": 414, "line": "        parameters = (user.chat_id, user.first_name, user.nickname,\n"}, {"line_no": 13, "char_start": 414, "char_end": 467, "line": "                      user.last_name, user.language)\n"}, {"line_no": 14, "char_start": 467, "char_end": 468, "line": "\n"}, {"line_no": 16, "char_start": 481, "char_end": 519, "line": "            db.add(query, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 323, "char_end": 324, "chars": "{"}, {"char_start": 336, "char_end": 337, "chars": "}"}, {"char_start": 339, "char_end": 341, "chars": "'{"}, {"char_start": 356, "char_end": 361, "chars": "}', \""}, {"char_start": 379, "char_end": 402, "chars": "f\"'{user.nickname}', '{"}, {"char_start": 416, "char_end": 422, "chars": "}', '{"}, {"char_start": 435, "char_end": 439, "chars": "}')\""}], "added": [{"char_start": 323, "char_end": 368, "chars": "%s, %s, %s, %s, %s)\")\n\n        parameters = ("}, {"char_start": 397, "char_end": 413, "chars": ", user.nickname,"}, {"char_start": 431, "char_end": 436, "chars": "     "}, {"char_start": 450, "char_end": 452, "chars": ", "}, {"char_start": 466, "char_end": 467, "chars": "\n"}, {"char_start": 505, "char_end": 517, "chars": ", parameters"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089"}
{"func_name": "compare_and_update", "func_src_before": "    @staticmethod\n    def compare_and_update(user, message):\n        \"\"\"\n        This method compare a user object from the bot and his info from\n        the Telegram message to check whether a user has changed his bio\n        or not. If yes, the user object that represents him in the bot will\n        be updated accordingly. Now this function is called only when a user\n        asks the bot for showing the most popular cams\n\n        :param user: user object that represents a Telegram user in this bot\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: None\n        \"\"\"\n\n        log.info('Checking whether user have changed his info or not...')\n        msg = message.from_user\n        usr_from_message = User(message.chat.id, msg.first_name, msg.username,\n                                msg.last_name)\n\n        if user.chat_id != usr_from_message.chat_id:\n            log.error(\"Wrong user to compare!\")\n            return\n\n        if user.first_name != usr_from_message.first_name:\n            user.first_name = usr_from_message.first_name\n\n        elif user.nickname != usr_from_message.nickname:\n            user.nickname = usr_from_message.nickname\n\n        elif user.last_name != usr_from_message.last_name:\n            user.last_name = usr_from_message.last_name\n\n        else:\n            log.debug(\"User's info hasn't changed\")\n            return\n\n        log.info(\"User has changed his info\")\n        log.debug(\"Updating user's info in the database...\")\n        query = (f\"UPDATE users \"\n                 f\"SET first_name='{user.first_name}', \"\n                 f\"nickname='{user.nickname}', \"\n                 f\"last_name='{user.last_name}' \"\n                 f\"WHERE chat_id={user.chat_id}\")\n\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Could not update info about %s in the database\",\n                      user)\n        else:\n            log.debug(\"User's info has been updated\")", "func_src_after": "    @staticmethod\n    def compare_and_update(user, message):\n        \"\"\"\n        This method compare a user object from the bot and his info from\n        the Telegram message to check whether a user has changed his bio\n        or not. If yes, the user object that represents him in the bot will\n        be updated accordingly. Now this function is called only when a user\n        asks the bot for showing the most popular cams\n\n        :param user: user object that represents a Telegram user in this bot\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: None\n        \"\"\"\n\n        log.info('Checking whether user have changed his info or not...')\n        msg = message.from_user\n        usr_from_message = User(message.chat.id, msg.first_name, msg.username,\n                                msg.last_name)\n\n        if user.chat_id != usr_from_message.chat_id:\n            log.error(\"Wrong user to compare!\")\n            return\n\n        if user.first_name != usr_from_message.first_name:\n            user.first_name = usr_from_message.first_name\n\n        elif user.nickname != usr_from_message.nickname:\n            user.nickname = usr_from_message.nickname\n\n        elif user.last_name != usr_from_message.last_name:\n            user.last_name = usr_from_message.last_name\n\n        else:\n            log.debug(\"User's info hasn't changed\")\n            return\n\n        log.info(\"User has changed his info\")\n        log.debug(\"Updating user's info in the database...\")\n        query = (f\"UPDATE users \"\n                 f\"SET first_name=%s, \"\n                 f\"nickname=%s, \"\n                 f\"last_name=%s \"\n                 f\"WHERE chat_id=%s\")\n\n        parameters = (user.first_name, user.nickname, user.last_name,\n                      user.chat_id)\n\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Could not update info about %s in the database\",\n                      user)\n        else:\n            log.debug(\"User's info has been updated\")", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1578, "char_end": 1635, "line": "                 f\"SET first_name='{user.first_name}', \"\n"}, {"line_no": 42, "char_start": 1635, "char_end": 1684, "line": "                 f\"nickname='{user.nickname}', \"\n"}, {"line_no": 43, "char_start": 1684, "char_end": 1734, "line": "                 f\"last_name='{user.last_name}' \"\n"}, {"line_no": 44, "char_start": 1734, "char_end": 1784, "line": "                 f\"WHERE chat_id={user.chat_id}\")\n"}, {"line_no": 47, "char_start": 1798, "char_end": 1824, "line": "            db.add(query)\n"}], "added": [{"line_no": 41, "char_start": 1578, "char_end": 1618, "line": "                 f\"SET first_name=%s, \"\n"}, {"line_no": 42, "char_start": 1618, "char_end": 1652, "line": "                 f\"nickname=%s, \"\n"}, {"line_no": 43, "char_start": 1652, "char_end": 1686, "line": "                 f\"last_name=%s \"\n"}, {"line_no": 44, "char_start": 1686, "char_end": 1724, "line": "                 f\"WHERE chat_id=%s\")\n"}, {"line_no": 45, "char_start": 1724, "char_end": 1725, "line": "\n"}, {"line_no": 46, "char_start": 1725, "char_end": 1795, "line": "        parameters = (user.first_name, user.nickname, user.last_name,\n"}, {"line_no": 47, "char_start": 1795, "char_end": 1831, "line": "                      user.chat_id)\n"}, {"line_no": 50, "char_start": 1845, "char_end": 1883, "line": "            db.add(query, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 1612, "char_end": 1631, "chars": "'{user.first_name}'"}, {"char_start": 1663, "char_end": 1680, "chars": "'{user.nickname}'"}, {"char_start": 1713, "char_end": 1731, "chars": "'{user.last_name}'"}, {"char_start": 1767, "char_end": 1768, "chars": "{"}, {"char_start": 1780, "char_end": 1782, "chars": "}\""}], "added": [{"char_start": 1612, "char_end": 1614, "chars": "%s"}, {"char_start": 1646, "char_end": 1648, "chars": "%s"}, {"char_start": 1681, "char_end": 1683, "chars": "%s"}, {"char_start": 1719, "char_end": 1817, "chars": "%s\")\n\n        parameters = (user.first_name, user.nickname, user.last_name,\n                      "}, {"char_start": 1869, "char_end": 1881, "chars": ", parameters"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089"}
{"func_name": "find_one", "func_src_before": "    def find_one(self, message: Message) -> User:\n        \"\"\"\n        Look up a user by a message which we get together with request\n        from Telegram\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: user object that represents a Telegram user in this bot\n        \"\"\"\n\n        # look up user in the cache of the bot\n        user = self.users.get(message.chat.id, None)\n\n        if user:\n            return user\n\n        # otherwise look up the user in the database\n        log.debug(\"Looking up the user in the database as it doesn't \"\n                  \"appear in cache\")\n        query = (f'SELECT first_name, nickname, last_name, language '\n                 f'FROM users '\n                 f'WHERE chat_id={message.chat.id}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n\n            # Even if the database in unreachable add user to dictionary\n            # with users otherwise the bot will crash requesting this\n            # user's info\n            log.error('Cannot lookup the user with chat_id %d in database',\n                      message.chat.id)\n            msg = message.from_user\n            user = self.add_new_one(message.chat.id, msg.first_name,\n                                    msg.last_name, msg.username,\n                                    language='en-US', add_to_db=False)\n            return user\n\n        if not cursor.rowcount:\n            # This user uses our photoGPSbot for the first time as we\n            # can't find him in the database\n            log.info('Adding totally new user to the system...')\n            msg = message.from_user\n            user = self.add_new_one(message.chat.id, msg.first_name,\n                                    msg.last_name, msg.username,\n                                    language='en-US')\n            bot.send_message(config.MY_TELEGRAM,\n                             text=f'You have a new user! {user}')\n            log.info('You have a new user! Welcome %s', user)\n\n        # finally if the user wasn't found in the cache of the bot, but was\n        # found in the database\n        else:\n            log.debug('User %d has been found in the database',\n                      message.chat.id)\n\n            user_data = cursor.fetchall()[0]\n            user = self.add_new_one(message.chat.id, *user_data,\n                                    add_to_db=False)\n\n        return user", "func_src_after": "    def find_one(self, message: Message) -> User:\n        \"\"\"\n        Look up a user by a message which we get together with request\n        from Telegram\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: user object that represents a Telegram user in this bot\n        \"\"\"\n\n        # look up user in the cache of the bot\n        user = self.users.get(message.chat.id, None)\n\n        if user:\n            return user\n\n        # otherwise look up the user in the database\n        log.debug(\"Looking up the user in the database as it doesn't \"\n                  \"appear in cache\")\n        query = (f'SELECT first_name, nickname, last_name, language '\n                 f'FROM users '\n                 f'WHERE chat_id=%s')\n\n        parameters = message.chat.id,\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n\n            # Even if the database in unreachable add user to dictionary\n            # with users otherwise the bot will crash requesting this\n            # user's info\n            log.error('Cannot lookup the user with chat_id %d in database',\n                      message.chat.id)\n            msg = message.from_user\n            user = self.add_new_one(message.chat.id, msg.first_name,\n                                    msg.last_name, msg.username,\n                                    language='en-US', add_to_db=False)\n            return user\n\n        if not cursor.rowcount:\n            # This user uses our photoGPSbot for the first time as we\n            # can't find him in the database\n            log.info('Adding totally new user to the system...')\n            msg = message.from_user\n            user = self.add_new_one(message.chat.id, msg.first_name,\n                                    msg.last_name, msg.username,\n                                    language='en-US')\n            bot.send_message(config.MY_TELEGRAM,\n                             text=f'You have a new user! {user}')\n            log.info('You have a new user! Welcome %s', user)\n\n        # finally if the user wasn't found in the cache of the bot, but was\n        # found in the database\n        else:\n            log.debug('User %d has been found in the database',\n                      message.chat.id)\n\n            user_data = cursor.fetchall()[0]\n            user = self.add_new_one(message.chat.id, *user_data,\n                                    add_to_db=False)\n\n        return user", "line_changes": {"deleted": [{"line_no": 21, "char_start": 758, "char_end": 811, "line": "                 f'WHERE chat_id={message.chat.id}')\n"}, {"line_no": 24, "char_start": 825, "char_end": 870, "line": "            cursor = db.execute_query(query)\n"}], "added": [{"line_no": 21, "char_start": 758, "char_end": 796, "line": "                 f'WHERE chat_id=%s')\n"}, {"line_no": 23, "char_start": 797, "char_end": 835, "line": "        parameters = message.chat.id,\n"}, {"line_no": 25, "char_start": 848, "char_end": 905, "line": "            cursor = db.execute_query(query, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 791, "char_end": 792, "chars": "{"}, {"char_start": 807, "char_end": 811, "chars": "}')\n"}], "added": [{"char_start": 791, "char_end": 818, "chars": "%s')\n\n        parameters = "}, {"char_start": 833, "char_end": 834, "chars": ","}, {"char_start": 891, "char_end": 903, "chars": ", parameters"}]}, "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089"}
{"func_name": "_init_column", "func_src_before": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            query = 'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL' % (\n                self._table, column_name)\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(\n                    self, values={'name': stage[1]})\n\n                query = 'UPDATE \"%s\" SET \"%s\"=%%s WHERE id = %s' % (\n                    self._table, column_name, stage[0])\n                logging.error(\"TADAAA: %s\" % query)\n                self.env.cr.execute(query, (default_value,))", "func_src_after": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            query = 'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL' % (  # pylint: disable=sql-injection\n                self._table, column_name)\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(\n                    self, values={'name': stage[1]})\n\n                query = 'UPDATE \"%s\" SET \"%s\"=%%s WHERE id = %s' % (  # pylint: disable=sql-injection\n                    self._table, column_name, stage[0])\n                logging.error(\"TADAAA: %s\" % query)\n                self.env.cr.execute(query, (default_value,))", "line_changes": {"deleted": [{"line_no": 12, "char_start": 488, "char_end": 559, "line": "            query = 'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL' % (\n"}, {"line_no": 21, "char_start": 821, "char_end": 890, "line": "                query = 'UPDATE \"%s\" SET \"%s\"=%%s WHERE id = %s' % (\n"}], "added": [{"line_no": 12, "char_start": 488, "char_end": 592, "line": "            query = 'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL' % (  # pylint: disable=sql-injection\n"}, {"line_no": 21, "char_start": 854, "char_end": 956, "line": "                query = 'UPDATE \"%s\" SET \"%s\"=%%s WHERE id = %s' % (  # pylint: disable=sql-injection\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 558, "char_end": 591, "chars": "  # pylint: disable=sql-injection"}, {"char_start": 922, "char_end": 955, "chars": "  # pylint: disable=sql-injection"}]}, "commit_link": "github.com/article714/crapo/commit/3e639e33ad53338d9142d700b59ca68dd5c81c27", "file_name": "crapo_tests/models/crm_stage.py", "vul_type": "cwe-089"}
{"func_name": "_init_column", "func_src_before": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            query = 'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL' % (\n                self._table,\n                column_name,\n            )\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n\n                query = 'UPDATE \"%s\" SET \"%s\"=%%s WHERE id = %s' % (\n                    self._table,\n                    column_name,\n                    stage[0],\n                )\n                self.env.cr.execute(query, (default_value.id,))", "func_src_after": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            self.env.cr.execute(\n                'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL',\n                (self._table, column_name),\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n\n                self.env.cr.execute(\n                    'UPDATE \"%s\" SET \"%s\"=%s WHERE id = %s',\n                    (self._table, column_name, default_value.id, stage[0]),\n                )", "line_changes": {"deleted": [{"line_no": 12, "char_start": 488, "char_end": 559, "line": "            query = 'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL' % (\n"}, {"line_no": 13, "char_start": 559, "char_end": 588, "line": "                self._table,\n"}, {"line_no": 14, "char_start": 588, "char_end": 617, "line": "                column_name,\n"}, {"line_no": 16, "char_start": 631, "char_end": 670, "line": "            self.env.cr.execute(query)\n"}, {"line_no": 22, "char_start": 824, "char_end": 893, "line": "                query = 'UPDATE \"%s\" SET \"%s\"=%%s WHERE id = %s' % (\n"}, {"line_no": 23, "char_start": 893, "char_end": 926, "line": "                    self._table,\n"}, {"line_no": 24, "char_start": 926, "char_end": 959, "line": "                    column_name,\n"}, {"line_no": 25, "char_start": 959, "char_end": 989, "line": "                    stage[0],\n"}, {"line_no": 27, "char_start": 1007, "char_end": 1070, "line": "                self.env.cr.execute(query, (default_value.id,))"}], "added": [{"line_no": 12, "char_start": 488, "char_end": 521, "line": "            self.env.cr.execute(\n"}, {"line_no": 13, "char_start": 521, "char_end": 585, "line": "                'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL',\n"}, {"line_no": 14, "char_start": 585, "char_end": 629, "line": "                (self._table, column_name),\n"}, {"line_no": 21, "char_start": 797, "char_end": 834, "line": "                self.env.cr.execute(\n"}, {"line_no": 22, "char_start": 834, "char_end": 895, "line": "                    'UPDATE \"%s\" SET \"%s\"=%s WHERE id = %s',\n"}, {"line_no": 23, "char_start": 895, "char_end": 971, "line": "                    (self._table, column_name, default_value.id, stage[0]),\n"}]}, "char_changes": {"deleted": [{"char_start": 500, "char_end": 507, "chars": "query ="}, {"char_start": 554, "char_end": 558, "chars": " % ("}, {"char_start": 587, "char_end": 668, "chars": "\n                column_name,\n            )\n            self.env.cr.execute(query"}, {"char_start": 840, "char_end": 847, "chars": "query ="}, {"char_start": 871, "char_end": 872, "chars": "%"}, {"char_start": 888, "char_end": 892, "chars": " % ("}, {"char_start": 925, "char_end": 1069, "chars": "\n                    column_name,\n                    stage[0],\n                )\n                self.env.cr.execute(query, (default_value.id,)"}], "added": [{"char_start": 500, "char_end": 536, "chars": "self.env.cr.execute(\n               "}, {"char_start": 583, "char_end": 584, "chars": ","}, {"char_start": 601, "char_end": 602, "chars": "("}, {"char_start": 626, "char_end": 627, "chars": ")"}, {"char_start": 813, "char_end": 853, "chars": "self.env.cr.execute(\n                   "}, {"char_start": 893, "char_end": 894, "chars": ","}, {"char_start": 915, "char_end": 916, "chars": "("}, {"char_start": 928, "char_end": 959, "chars": " column_name, default_value.id,"}, {"char_start": 968, "char_end": 969, "chars": ")"}]}, "commit_link": "github.com/article714/crapo/commit/521850b74dd7c2a7e21bfde6d362db605c478a91", "file_name": "crapo_tests/models/crm_stage.py", "vul_type": "cwe-089"}
{"func_name": "_init_column", "func_src_before": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            self.env.cr.execute(\n                \"SELECT id, name FROM %s WHERE %s is NULL\",\n                (self._table, column_name),\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n\n                self.env.cr.execute(\n                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n                    (self._table, column_name, default_value.id, stage[0]),\n                )", "func_src_after": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n            query = SQL(\n                \"SELECT id, name FROM {} WHERE {} is NULL\".format(\n                    Identifier(self._table), Identifier(column_name)\n                )\n            )\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n                query = SQL(\n                    \"UPDATE {} SET {}=%s WHERE id = %s\".format(\n                        Identifier(self._table), Identifier(column_name)\n                    )\n                )\n                self.env.cr.execute(query, (default_value.id, stage[0]))", "line_changes": {"deleted": [{"line_no": 11, "char_start": 487, "char_end": 488, "line": "\n"}, {"line_no": 12, "char_start": 488, "char_end": 521, "line": "            self.env.cr.execute(\n"}, {"line_no": 13, "char_start": 521, "char_end": 581, "line": "                \"SELECT id, name FROM %s WHERE %s is NULL\",\n"}, {"line_no": 14, "char_start": 581, "char_end": 625, "line": "                (self._table, column_name),\n"}, {"line_no": 20, "char_start": 792, "char_end": 793, "line": "\n"}, {"line_no": 21, "char_start": 793, "char_end": 830, "line": "                self.env.cr.execute(\n"}, {"line_no": 22, "char_start": 830, "char_end": 887, "line": "                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n"}, {"line_no": 23, "char_start": 887, "char_end": 963, "line": "                    (self._table, column_name, default_value.id, stage[0]),\n"}], "added": [{"line_no": 11, "char_start": 487, "char_end": 512, "line": "            query = SQL(\n"}, {"line_no": 12, "char_start": 512, "char_end": 579, "line": "                \"SELECT id, name FROM {} WHERE {} is NULL\".format(\n"}, {"line_no": 13, "char_start": 579, "char_end": 648, "line": "                    Identifier(self._table), Identifier(column_name)\n"}, {"line_no": 14, "char_start": 648, "char_end": 666, "line": "                )\n"}, {"line_no": 16, "char_start": 680, "char_end": 719, "line": "            self.env.cr.execute(query)\n"}, {"line_no": 21, "char_start": 872, "char_end": 901, "line": "                query = SQL(\n"}, {"line_no": 22, "char_start": 901, "char_end": 965, "line": "                    \"UPDATE {} SET {}=%s WHERE id = %s\".format(\n"}, {"line_no": 23, "char_start": 965, "char_end": 1038, "line": "                        Identifier(self._table), Identifier(column_name)\n"}, {"line_no": 24, "char_start": 1038, "char_end": 1060, "line": "                    )\n"}, {"line_no": 26, "char_start": 1078, "char_end": 1150, "line": "                self.env.cr.execute(query, (default_value.id, stage[0]))"}]}, "char_changes": {"deleted": [{"char_start": 487, "char_end": 488, "chars": "\n"}, {"char_start": 500, "char_end": 519, "chars": "self.env.cr.execute"}, {"char_start": 559, "char_end": 561, "chars": "%s"}, {"char_start": 568, "char_end": 570, "chars": "%s"}, {"char_start": 579, "char_end": 581, "chars": ",\n"}, {"char_start": 623, "char_end": 624, "chars": ","}, {"char_start": 792, "char_end": 793, "chars": "\n"}, {"char_start": 809, "char_end": 828, "chars": "self.env.cr.execute"}, {"char_start": 858, "char_end": 860, "chars": "%s"}, {"char_start": 865, "char_end": 867, "chars": "%s"}, {"char_start": 885, "char_end": 886, "chars": ","}, {"char_start": 921, "char_end": 932, "chars": "column_name"}, {"char_start": 961, "char_end": 979, "chars": ",\n                "}], "added": [{"char_start": 499, "char_end": 510, "chars": "query = SQL"}, {"char_start": 550, "char_end": 552, "chars": "{}"}, {"char_start": 559, "char_end": 561, "chars": "{}"}, {"char_start": 570, "char_end": 578, "chars": ".format("}, {"char_start": 595, "char_end": 609, "chars": "    Identifier"}, {"char_start": 621, "char_end": 622, "chars": ")"}, {"char_start": 624, "char_end": 635, "chars": "Identifier("}, {"char_start": 660, "char_end": 717, "chars": "    )\n            )\n            self.env.cr.execute(query"}, {"char_start": 888, "char_end": 899, "chars": "query = SQL"}, {"char_start": 929, "char_end": 931, "chars": "{}"}, {"char_start": 936, "char_end": 938, "chars": "{}"}, {"char_start": 956, "char_end": 964, "chars": ".format("}, {"char_start": 985, "char_end": 999, "chars": "    Identifier"}, {"char_start": 1011, "char_end": 1012, "chars": ")"}, {"char_start": 1014, "char_end": 1119, "chars": "Identifier(column_name)\n                    )\n                )\n                self.env.cr.execute(query"}, {"char_start": 1121, "char_end": 1122, "chars": "("}]}, "commit_link": "github.com/article714/crapo/commit/91513ef7bbe60014dacab709be582eb0b10fcaab", "file_name": "crapo_tests/models/crm_stage.py", "vul_type": "cwe-089"}
{"func_name": "_init_column", "func_src_before": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            return super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            tname = Identifier(self._table).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n            cname = Identifier(column_name).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n\n            logging.error(\n                \"MMMMMAIS %s (%s) -> %s\", tname, type(tname), str(tname)\n            )\n\n            self.env.cr.execute(\n                \"SELECT id, name FROM %s WHERE %s is NULL\", (tname, cname)\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n                self.env.cr.execute(\n                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n                    (tname, cname, default_value.id, stage[0]),\n                )\n        return True", "func_src_after": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            return super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            tname = Identifier(self._table.replace('\"', \"\")).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n            cname = Identifier(column_name.replace('\"', \"\")).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n\n            logging.error(\n                \"MMMMMAIS %s ==> %s (%s) -> %s\",\n                self._table,\n                tname,\n                type(tname),\n                str(tname),\n            )\n\n            self.env.cr.execute(\n                \"SELECT id, name FROM %s WHERE %s is NULL\",\n                (self._table, cname),\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n                self.env.cr.execute(\n                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n                    (self._table, cname, default_value.id, stage[0]),\n                )\n        return True", "line_changes": {"deleted": [{"line_no": 12, "char_start": 495, "char_end": 550, "line": "            tname = Identifier(self._table).as_string(\n"}, {"line_no": 15, "char_start": 633, "char_end": 688, "line": "            cname = Identifier(column_name).as_string(\n"}, {"line_no": 20, "char_start": 799, "char_end": 872, "line": "                \"MMMMMAIS %s (%s) -> %s\", tname, type(tname), str(tname)\n"}, {"line_no": 24, "char_start": 920, "char_end": 995, "line": "                \"SELECT id, name FROM %s WHERE %s is NULL\", (tname, cname)\n"}, {"line_no": 32, "char_start": 1256, "char_end": 1320, "line": "                    (tname, cname, default_value.id, stage[0]),\n"}], "added": [{"line_no": 12, "char_start": 495, "char_end": 567, "line": "            tname = Identifier(self._table.replace('\"', \"\")).as_string(\n"}, {"line_no": 15, "char_start": 650, "char_end": 722, "line": "            cname = Identifier(column_name.replace('\"', \"\")).as_string(\n"}, {"line_no": 20, "char_start": 833, "char_end": 882, "line": "                \"MMMMMAIS %s ==> %s (%s) -> %s\",\n"}, {"line_no": 21, "char_start": 882, "char_end": 911, "line": "                self._table,\n"}, {"line_no": 22, "char_start": 911, "char_end": 934, "line": "                tname,\n"}, {"line_no": 23, "char_start": 934, "char_end": 963, "line": "                type(tname),\n"}, {"line_no": 24, "char_start": 963, "char_end": 991, "line": "                str(tname),\n"}, {"line_no": 28, "char_start": 1039, "char_end": 1099, "line": "                \"SELECT id, name FROM %s WHERE %s is NULL\",\n"}, {"line_no": 29, "char_start": 1099, "char_end": 1137, "line": "                (self._table, cname),\n"}, {"line_no": 37, "char_start": 1398, "char_end": 1468, "line": "                    (self._table, cname, default_value.id, stage[0]),\n"}]}, "char_changes": {"deleted": [{"char_start": 840, "char_end": 860, "chars": " tname, type(tname),"}, {"char_start": 979, "char_end": 985, "chars": " (tnam"}, {"char_start": 1277, "char_end": 1281, "chars": "tnam"}], "added": [{"char_start": 537, "char_end": 554, "chars": ".replace('\"', \"\")"}, {"char_start": 692, "char_end": 709, "chars": ".replace('\"', \"\")"}, {"char_start": 858, "char_end": 865, "chars": " %s ==>"}, {"char_start": 881, "char_end": 978, "chars": "\n                self._table,\n                tname,\n                type(tname),\n               "}, {"char_start": 989, "char_end": 990, "chars": ","}, {"char_start": 1098, "char_end": 1126, "chars": "\n                (self._tabl"}, {"char_start": 1135, "char_end": 1136, "chars": ","}, {"char_start": 1419, "char_end": 1429, "chars": "self._tabl"}]}, "commit_link": "github.com/article714/crapo/commit/ee2f15e316ef7b29e25944dfc24f035b92924cba", "file_name": "crapo_tests/models/crm_stage.py", "vul_type": "cwe-089"}
{"func_name": "_init_column", "func_src_before": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            return super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            tname = Identifier(self._table.replace('\"', \"\")).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n            cname = Identifier(column_name.replace('\"', \"\")).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n\n            logging.error(\n                \"MMMMMAIS %s ==> %s (%s) -> %s\",\n                self._table,\n                tname,\n                type(tname),\n                str(tname),\n            )\n\n            self.env.cr.execute(\n                \"SELECT id, name FROM %s WHERE %s is NULL\",\n                (self._table, cname),\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n                self.env.cr.execute(\n                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n                    (self._table, cname, default_value.id, stage[0]),\n                )\n        return True", "func_src_after": "    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            return super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            tname = Identifier(self._table.replace('\"', \"\"))\n            cname = Identifier(column_name.replace('\"', \"\"))\n\n            query = SQL(  # pylint: disable=sql-injection\n                \"SELECT id, name FROM {} WHERE {} is NULL\"\n            ).format(tname, cname)\n\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                query = SQL(  # pylint: disable=sql-injection\n                    \"UPDATE {} SET {}=%s WHERE id = %s\"\n                ).format(tname, cname)\n\n                default_value = default_compute(values={\"name\": stage[1]})\n                self.env.cr.execute(query, (default_value.id, stage[0]))\n        return True", "line_changes": {"deleted": [{"line_no": 12, "char_start": 495, "char_end": 567, "line": "            tname = Identifier(self._table.replace('\"', \"\")).as_string(\n"}, {"line_no": 13, "char_start": 567, "char_end": 636, "line": "                self.env.cr._obj  # pylint: disable=protected-access\n"}, {"line_no": 14, "char_start": 636, "char_end": 650, "line": "            )\n"}, {"line_no": 15, "char_start": 650, "char_end": 722, "line": "            cname = Identifier(column_name.replace('\"', \"\")).as_string(\n"}, {"line_no": 16, "char_start": 722, "char_end": 791, "line": "                self.env.cr._obj  # pylint: disable=protected-access\n"}, {"line_no": 17, "char_start": 791, "char_end": 805, "line": "            )\n"}, {"line_no": 18, "char_start": 805, "char_end": 806, "line": "\n"}, {"line_no": 19, "char_start": 806, "char_end": 833, "line": "            logging.error(\n"}, {"line_no": 20, "char_start": 833, "char_end": 882, "line": "                \"MMMMMAIS %s ==> %s (%s) -> %s\",\n"}, {"line_no": 21, "char_start": 882, "char_end": 911, "line": "                self._table,\n"}, {"line_no": 22, "char_start": 911, "char_end": 934, "line": "                tname,\n"}, {"line_no": 23, "char_start": 934, "char_end": 963, "line": "                type(tname),\n"}, {"line_no": 24, "char_start": 963, "char_end": 991, "line": "                str(tname),\n"}, {"line_no": 25, "char_start": 991, "char_end": 1005, "line": "            )\n"}, {"line_no": 26, "char_start": 1005, "char_end": 1006, "line": "\n"}, {"line_no": 27, "char_start": 1006, "char_end": 1039, "line": "            self.env.cr.execute(\n"}, {"line_no": 28, "char_start": 1039, "char_end": 1099, "line": "                \"SELECT id, name FROM %s WHERE %s is NULL\",\n"}, {"line_no": 29, "char_start": 1099, "char_end": 1137, "line": "                (self._table, cname),\n"}, {"line_no": 30, "char_start": 1137, "char_end": 1151, "line": "            )\n"}, {"line_no": 35, "char_start": 1304, "char_end": 1341, "line": "                self.env.cr.execute(\n"}, {"line_no": 36, "char_start": 1341, "char_end": 1398, "line": "                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n"}, {"line_no": 37, "char_start": 1398, "char_end": 1468, "line": "                    (self._table, cname, default_value.id, stage[0]),\n"}, {"line_no": 38, "char_start": 1468, "char_end": 1486, "line": "                )\n"}], "added": [{"line_no": 12, "char_start": 495, "char_end": 556, "line": "            tname = Identifier(self._table.replace('\"', \"\"))\n"}, {"line_no": 13, "char_start": 556, "char_end": 617, "line": "            cname = Identifier(column_name.replace('\"', \"\"))\n"}, {"line_no": 14, "char_start": 617, "char_end": 618, "line": "\n"}, {"line_no": 15, "char_start": 618, "char_end": 676, "line": "            query = SQL(  # pylint: disable=sql-injection\n"}, {"line_no": 16, "char_start": 676, "char_end": 735, "line": "                \"SELECT id, name FROM {} WHERE {} is NULL\"\n"}, {"line_no": 17, "char_start": 735, "char_end": 770, "line": "            ).format(tname, cname)\n"}, {"line_no": 18, "char_start": 770, "char_end": 771, "line": "\n"}, {"line_no": 19, "char_start": 771, "char_end": 810, "line": "            self.env.cr.execute(query)\n"}, {"line_no": 23, "char_start": 888, "char_end": 950, "line": "                query = SQL(  # pylint: disable=sql-injection\n"}, {"line_no": 24, "char_start": 950, "char_end": 1006, "line": "                    \"UPDATE {} SET {}=%s WHERE id = %s\"\n"}, {"line_no": 25, "char_start": 1006, "char_end": 1045, "line": "                ).format(tname, cname)\n"}, {"line_no": 26, "char_start": 1045, "char_end": 1046, "line": "\n"}, {"line_no": 28, "char_start": 1121, "char_end": 1194, "line": "                self.env.cr.execute(query, (default_value.id, stage[0]))\n"}]}, "char_changes": {"deleted": [{"char_start": 555, "char_end": 649, "chars": ".as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )"}, {"char_start": 710, "char_end": 754, "chars": ".as_string(\n                self.env.cr._obj"}, {"char_start": 774, "char_end": 790, "chars": "protected-access"}, {"char_start": 803, "char_end": 806, "chars": ")\n\n"}, {"char_start": 810, "char_end": 1017, "chars": "        logging.error(\n                \"MMMMMAIS %s ==> %s (%s) -> %s\",\n                self._table,\n                tname,\n                type(tname),\n                str(tname),\n            )\n\n           "}, {"char_start": 1030, "char_end": 1038, "chars": "execute("}, {"char_start": 1051, "char_end": 1136, "chars": "    \"SELECT id, name FROM %s WHERE %s is NULL\",\n                (self._table, cname),"}, {"char_start": 1149, "char_end": 1151, "chars": ")\n"}, {"char_start": 1159, "char_end": 1196, "chars": "    stages = self.env.cr.fetchall()\n\n"}, {"char_start": 1211, "char_end": 1228, "chars": " stage in stages:"}, {"char_start": 1340, "char_end": 1437, "chars": "\n                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n                    (self._table, cname"}, {"char_start": 1466, "char_end": 1484, "chars": ",\n                "}], "added": [{"char_start": 616, "char_end": 617, "chars": "\n"}, {"char_start": 630, "char_end": 764, "chars": "query = SQL(  # pylint: disable=sql-injection\n                \"SELECT id, name FROM {} WHERE {} is NULL\"\n            ).format(tname, c"}, {"char_start": 768, "char_end": 770, "chars": ")\n"}, {"char_start": 783, "char_end": 830, "chars": "self.env.cr.execute(query)\n            stages ="}, {"char_start": 843, "char_end": 854, "chars": "fetchall()\n"}, {"char_start": 867, "char_end": 949, "chars": "for stage in stages:\n                query = SQL(  # pylint: disable=sql-injection"}, {"char_start": 970, "char_end": 1045, "chars": "\"UPDATE {} SET {}=%s WHERE id = %s\"\n                ).format(tname, cname)\n"}, {"char_start": 1157, "char_end": 1165, "chars": "query, ("}]}, "commit_link": "github.com/article714/crapo/commit/5ea8146ab38da79bad4daefdd0be9bb244dfff41", "file_name": "crapo_tests/models/crm_stage.py", "vul_type": "cwe-089"}
{"func_name": "list_zeros", "func_src_before": "@FirstZeros.route(\"/list\")\ndef list_zeros(start=None,\n               end=None,\n               limit=None,\n               fmt=None,\n               download=None,\n               degree=None):\n               # signature_r = None,\n               # signature_c = None):\n    if start is None:\n        start = request.args.get('start', None, float)\n    if end is None:\n        end = request.args.get('end', None, float)\n    if limit is None:\n        limit = request.args.get('limit', 100, int)\n    if fmt is None:\n        fmt = request.args.get('format', 'plain', str)\n    if download is None:\n        fmt = request.args.get('download', 'no')\n    if degree is None:\n        degree = request.args.get('degree', None, int)\n    # if signature_r is None:\n    #    signature_r = request.arts.get(\"signature_r\", None, int)\n    # if signature_c is None:\n    #    signature_c = request.arts.get(\"signature_c\", None, int)\n    if limit > 1000:\n        limit = 1000\n    if limit < 0:\n        limit = 100\n\n    if start is None and end is None:\n        end = 1000\n\n    limit = int(limit)\n\n    where_clause = 'WHERE 1=1 '\n\n    if end is not None:\n        end = str(end)\n        # fix up rounding errors, otherwise each time you resubmit the page you will lose one line\n        if('.' in end): end = end+'999'\n\n    if start is None:\n        where_clause += ' AND zero <= ' + end\n    elif end is None:\n        start = float(start)\n        where_clause += ' AND zero >= ' + str(start)\n    else:\n        where_clause += ' AND zero >= {} AND zero <= {}'.format(start, end)\n\n    if degree is not None and degree != '':\n        where_clause += ' AND degree = ' + str(degree)\n\n    if end is None:\n        query = 'SELECT * FROM (SELECT * FROM zeros {} ORDER BY zero ASC LIMIT {}) ORDER BY zero DESC'.format(\n            where_clause, limit)\n    else:\n        query = 'SELECT * FROM zeros {} ORDER BY zero DESC LIMIT {}'.format(where_clause, limit)\n\n    #print query\n    c = sqlite3.connect(data_location + 'first_zeros.db').cursor()\n    c.execute(query)\n\n    response = flask.Response((\" \".join([str(x) for x in row]) + \"\\n\" for row in c))\n    response.headers['content-type'] = 'text/plain'\n    if download == \"yes\":\n        response.headers['content-disposition'] = 'attachment; filename=zetazeros'\n    # response = flask.Response( (\"1 %s\\n\" % (str(row[0]),) for row in c) )\n    return response", "func_src_after": "@FirstZeros.route(\"/list\")\ndef list_zeros(start=None,\n               end=None,\n               limit=None,\n               fmt=None,\n               download=None,\n               degree=None):\n               # signature_r = None,\n               # signature_c = None):\n    if start is None:\n        start = request.args.get('start', None, float)\n    if end is None:\n        end = request.args.get('end', None, float)\n    if limit is None:\n        limit = request.args.get('limit', 100, int)\n    if fmt is None:\n        fmt = request.args.get('format', 'plain', str)\n    if download is None:\n        fmt = request.args.get('download', 'no')\n    if degree is None:\n        degree = request.args.get('degree', None, int)\n    # if signature_r is None:\n    #    signature_r = request.arts.get(\"signature_r\", None, int)\n    # if signature_c is None:\n    #    signature_c = request.arts.get(\"signature_c\", None, int)\n    if limit > 1000:\n        limit = 1000\n    if limit < 0:\n        limit = 100\n\n    if start is None and end is None:\n        end = 1000\n\n    limit = int(limit)\n\n    where_clause = 'WHERE 1=1 '\n\n    values = []\n    if end is not None:\n        # fix up rounding errors, otherwise each time you resubmit the page you will lose one line\n        if('.' in str(end)):\n            end = float(str(end)+'999')\n\n    if start is None:\n        end = float(end)\n        where_clause += ' AND zero <= ?'\n        values.append(end)\n    elif end is None:\n        start = float(start)\n        where_clause += ' AND zero >= ?'\n        values.append(start)\n    else:\n        start = float(start)\n        end = float(end)\n        where_clause += ' AND zero >= ? AND zero <= ?'\n        values.extend([start, end])\n\n    if degree is not None and degree != '':\n        degree = int(degree)\n        where_clause += ' AND degree = ?'\n        values.append(degree)\n\n    if end is None:\n        query = 'SELECT * FROM (SELECT * FROM zeros {} ORDER BY zero ASC LIMIT {}) ORDER BY zero DESC'.format(\n            where_clause, limit)\n    else:\n        query = 'SELECT * FROM zeros {} ORDER BY zero DESC LIMIT {}'.format(where_clause, limit)\n\n    #print query\n    c = sqlite3.connect(data_location + 'first_zeros.db').cursor()\n    c.execute(query, values)\n\n    response = flask.Response((\" \".join([str(x) for x in row]) + \"\\n\" for row in c))\n    response.headers['content-type'] = 'text/plain'\n    if download == \"yes\":\n        response.headers['content-disposition'] = 'attachment; filename=zetazeros'\n    # response = flask.Response( (\"1 %s\\n\" % (str(row[0]),) for row in c) )\n    return response", "line_changes": {"deleted": [{"line_no": 39, "char_start": 1126, "char_end": 1149, "line": "        end = str(end)\n"}, {"line_no": 41, "char_start": 1248, "char_end": 1288, "line": "        if('.' in end): end = end+'999'\n"}, {"line_no": 44, "char_start": 1311, "char_end": 1357, "line": "        where_clause += ' AND zero <= ' + end\n"}, {"line_no": 47, "char_start": 1408, "char_end": 1461, "line": "        where_clause += ' AND zero >= ' + str(start)\n"}, {"line_no": 49, "char_start": 1471, "char_end": 1547, "line": "        where_clause += ' AND zero >= {} AND zero <= {}'.format(start, end)\n"}, {"line_no": 52, "char_start": 1592, "char_end": 1647, "line": "        where_clause += ' AND degree = ' + str(degree)\n"}, {"line_no": 62, "char_start": 2004, "char_end": 2025, "line": "    c.execute(query)\n"}], "added": [{"line_no": 38, "char_start": 1102, "char_end": 1118, "line": "    values = []\n"}, {"line_no": 41, "char_start": 1241, "char_end": 1270, "line": "        if('.' in str(end)):\n"}, {"line_no": 42, "char_start": 1270, "char_end": 1310, "line": "            end = float(str(end)+'999')\n"}, {"line_no": 45, "char_start": 1333, "char_end": 1358, "line": "        end = float(end)\n"}, {"line_no": 46, "char_start": 1358, "char_end": 1399, "line": "        where_clause += ' AND zero <= ?'\n"}, {"line_no": 47, "char_start": 1399, "char_end": 1426, "line": "        values.append(end)\n"}, {"line_no": 50, "char_start": 1477, "char_end": 1518, "line": "        where_clause += ' AND zero >= ?'\n"}, {"line_no": 51, "char_start": 1518, "char_end": 1547, "line": "        values.append(start)\n"}, {"line_no": 53, "char_start": 1557, "char_end": 1586, "line": "        start = float(start)\n"}, {"line_no": 54, "char_start": 1586, "char_end": 1611, "line": "        end = float(end)\n"}, {"line_no": 55, "char_start": 1611, "char_end": 1666, "line": "        where_clause += ' AND zero >= ? AND zero <= ?'\n"}, {"line_no": 56, "char_start": 1666, "char_end": 1702, "line": "        values.extend([start, end])\n"}, {"line_no": 59, "char_start": 1747, "char_end": 1776, "line": "        degree = int(degree)\n"}, {"line_no": 60, "char_start": 1776, "char_end": 1818, "line": "        where_clause += ' AND degree = ?'\n"}, {"line_no": 61, "char_start": 1818, "char_end": 1848, "line": "        values.append(degree)\n"}, {"line_no": 71, "char_start": 2205, "char_end": 2234, "line": "    c.execute(query, values)\n"}]}, "char_changes": {"deleted": [{"char_start": 1126, "char_end": 1149, "chars": "        end = str(end)\n"}, {"char_start": 1266, "char_end": 1278, "chars": "end): end = "}, {"char_start": 1349, "char_end": 1356, "chars": "' + end"}, {"char_start": 1446, "char_end": 1453, "chars": "' + str"}, {"char_start": 1509, "char_end": 1511, "chars": "{}"}, {"char_start": 1524, "char_end": 1535, "chars": "{}'.format("}, {"char_start": 1631, "char_end": 1638, "chars": "' + str"}], "added": [{"char_start": 1102, "char_end": 1118, "chars": "    values = []\n"}, {"char_start": 1259, "char_end": 1298, "chars": "str(end)):\n            end = float(str("}, {"char_start": 1301, "char_end": 1302, "chars": ")"}, {"char_start": 1308, "char_end": 1309, "chars": ")"}, {"char_start": 1333, "char_end": 1358, "chars": "        end = float(end)\n"}, {"char_start": 1396, "char_end": 1425, "chars": "?'\n        values.append(end)"}, {"char_start": 1515, "char_end": 1610, "chars": "?'\n        values.append(start)\n    else:\n        start = float(start)\n        end = float(end)"}, {"char_start": 1649, "char_end": 1650, "chars": "?"}, {"char_start": 1663, "char_end": 1689, "chars": "?'\n        values.extend(["}, {"char_start": 1699, "char_end": 1700, "chars": "]"}, {"char_start": 1747, "char_end": 1776, "chars": "        degree = int(degree)\n"}, {"char_start": 1815, "char_end": 1839, "chars": "?'\n        values.append"}, {"char_start": 2224, "char_end": 2232, "chars": ", values"}]}, "commit_link": "github.com/LMFDB/lmfdb/commit/c66e035419698ea0d7a491f65f7e6fc31d9afb28", "file_name": "lmfdb/zeros/first/firstzeros.py", "vul_type": "cwe-089"}
{"func_name": "search", "func_src_before": "@app.route('/search')\ndef search():\n\n    limit = 10\n    offset = 0\n\n    user_term = request.args.get('term')\n    page = request.args.get('page')\n    term = user_term\n\n    if not page:\n        page = 1\n\n    offset = limit*(int(page) - 1)\n\n    transliterate_regex = re.compile('.*[a-zA-Z].*')\n    if (transliterate_regex.match(term)):\n        term = transliterate(term, sanscript.ITRANS, sanscript.DEVANAGARI)\n\n    term = term.replace(\"*\", \"%\")\n    term_words = term.split()\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n\n            if len(term_words) == 1:\n                cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada like '%s' or artha like '%s' order by id limit %d offset %d;\" % (term, term, limit, offset))\n                rows = cur.fetchall();\n            else:\n                query = \"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada in (%s) order by pada limit 100;\" % ','.join('?' for i in term_words)\n                rows = cur.execute(query, term_words)\n\n            return render_template('search.html', rows=rows, user_term=user_term, term=term, page=page)\n    finally:\n        con.close()", "func_src_after": "@app.route('/search')\ndef search():\n\n    limit = 10\n    offset = 0\n\n    user_term = request.args.get('term')\n    page = request.args.get('page')\n    term = user_term\n\n    if not page:\n        page = 1\n\n    offset = limit*(int(page) - 1)\n\n    transliterate_regex = re.compile('.*[a-zA-Z].*')\n    if (transliterate_regex.match(term)):\n        term = transliterate(term, sanscript.ITRANS, sanscript.DEVANAGARI)\n\n    term = term.replace(\"*\", \"%\")\n    term_words = term.split()\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n\n            if len(term_words) == 1:\n                cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada like ? or artha like ? order by id limit ? offset ?;\", [term, term, limit, offset])\n                rows = cur.fetchall();\n            else:\n                query = \"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada in (%s) order by pada limit 100;\" % ','.join('?' for i in term_words)\n                rows = cur.execute(query, term_words)\n\n            return render_template('search.html', rows=rows, user_term=user_term, term=term, page=page)\n    finally:\n        con.close()", "line_changes": {"deleted": [{"line_no": 29, "char_start": 635, "char_end": 840, "line": "                cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada like '%s' or artha like '%s' order by id limit %d offset %d;\" % (term, term, limit, offset))\n"}], "added": [{"line_no": 29, "char_start": 635, "char_end": 831, "line": "                cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada like ? or artha like ? order by id limit ? offset ?;\", [term, term, limit, offset])\n"}]}, "char_changes": {"deleted": [{"char_start": 752, "char_end": 756, "chars": "'%s'"}, {"char_start": 771, "char_end": 775, "chars": "'%s'"}, {"char_start": 794, "char_end": 796, "chars": "%d"}, {"char_start": 804, "char_end": 812, "chars": "%d;\" % ("}, {"char_start": 837, "char_end": 838, "chars": ")"}], "added": [{"char_start": 752, "char_end": 753, "chars": "?"}, {"char_start": 768, "char_end": 769, "chars": "?"}, {"char_start": 788, "char_end": 789, "chars": "?"}, {"char_start": 797, "char_end": 803, "chars": "?;\", ["}, {"char_start": 828, "char_end": 829, "chars": "]"}]}, "commit_link": "github.com/aupasana/amara-quiz/commit/6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "file_name": "docker/app.py", "vul_type": "cwe-089"}
{"func_name": "sloka", "func_src_before": "@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = '%s' order by sloka_line;\" % sloka_number)\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = '%s' order by id;\" % sloka_number)\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()", "func_src_after": "@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = ? order by sloka_line;\", [sloka_number])\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = ? order by id;\", [sloka_number])\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()", "line_changes": {"deleted": [{"line_no": 15, "char_start": 494, "char_end": 602, "line": "            cur.execute(\"select * from mula where sloka_number = '%s' order by sloka_line;\" % sloka_number)\n"}, {"line_no": 18, "char_start": 638, "char_end": 738, "line": "            cur.execute(\"select * from pada where sloka_number = '%s' order by id;\" % sloka_number)\n"}], "added": [{"line_no": 15, "char_start": 494, "char_end": 600, "line": "            cur.execute(\"select * from mula where sloka_number = ? order by sloka_line;\", [sloka_number])\n"}, {"line_no": 18, "char_start": 636, "char_end": 734, "line": "            cur.execute(\"select * from pada where sloka_number = ? order by id;\", [sloka_number])\n"}]}, "char_changes": {"deleted": [{"char_start": 559, "char_end": 563, "chars": "'%s'"}, {"char_start": 585, "char_end": 588, "chars": " % "}, {"char_start": 703, "char_end": 707, "chars": "'%s'"}, {"char_start": 721, "char_end": 724, "chars": " % "}], "added": [{"char_start": 559, "char_end": 560, "chars": "?"}, {"char_start": 582, "char_end": 585, "chars": ", ["}, {"char_start": 597, "char_end": 598, "chars": "]"}, {"char_start": 701, "char_end": 702, "chars": "?"}, {"char_start": 716, "char_end": 719, "chars": ", ["}, {"char_start": 731, "char_end": 732, "chars": "]"}]}, "commit_link": "github.com/aupasana/amara-quiz/commit/6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "file_name": "docker/app.py", "vul_type": "cwe-089"}
{"func_name": "quiz", "func_src_before": "@app.route('/quiz')\ndef quiz():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = '%s' order by random() limit 1;\" % varga)\n            rows = cur.fetchall();\n\n            artha = rows[0][\"artha\"];\n            cur.execute(\"select pada from pada where varga = '%s' and artha = '%s' order by id\" % (varga, artha));\n            paryaya = cur.fetchall();\n\n            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)\n    finally:\n        con.close()", "func_src_after": "@app.route('/quiz')\ndef quiz():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = ? order by random() limit 1;\", [varga])\n            rows = cur.fetchall();\n\n            artha = rows[0][\"artha\"];\n            cur.execute(\"select pada from pada where varga = ? and artha = ? order by id\", [varga, artha]);\n            paryaya = cur.fetchall();\n\n            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)\n    finally:\n        con.close()", "line_changes": {"deleted": [{"line_no": 12, "char_start": 213, "char_end": 371, "line": "            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = '%s' order by random() limit 1;\" % varga)\n"}, {"line_no": 16, "char_start": 445, "char_end": 560, "line": "            cur.execute(\"select pada from pada where varga = '%s' and artha = '%s' order by id\" % (varga, artha));\n"}], "added": [{"line_no": 12, "char_start": 213, "char_end": 369, "line": "            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = ? order by random() limit 1;\", [varga])\n"}, {"line_no": 16, "char_start": 443, "char_end": 551, "line": "            cur.execute(\"select pada from pada where varga = ? and artha = ? order by id\", [varga, artha]);\n"}]}, "char_changes": {"deleted": [{"char_start": 329, "char_end": 333, "chars": "'%s'"}, {"char_start": 361, "char_end": 364, "chars": " % "}, {"char_start": 506, "char_end": 510, "chars": "'%s'"}, {"char_start": 523, "char_end": 527, "chars": "'%s'"}, {"char_start": 540, "char_end": 544, "chars": " % ("}, {"char_start": 556, "char_end": 557, "chars": ")"}], "added": [{"char_start": 329, "char_end": 330, "chars": "?"}, {"char_start": 358, "char_end": 361, "chars": ", ["}, {"char_start": 366, "char_end": 367, "chars": "]"}, {"char_start": 504, "char_end": 505, "chars": "?"}, {"char_start": 518, "char_end": 519, "chars": "?"}, {"char_start": 532, "char_end": 535, "chars": ", ["}, {"char_start": 547, "char_end": 548, "chars": "]"}]}, "commit_link": "github.com/aupasana/amara-quiz/commit/6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "file_name": "docker/app.py", "vul_type": "cwe-089"}
{"func_name": "varga", "func_src_before": "@app.route('/varga')\ndef varga():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where varga = '%s';\" % varga)\n            # cur.execute(\"select * from mula where sloka_number in (select distinct sloka_number from pada where varga='%s');\" % varga)\n            mula = cur.fetchall();\n\n\n\n            return render_template('varga.html', mula=mula, varga=varga)\n    finally:\n        con.close()", "func_src_after": "@app.route('/varga')\ndef varga():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n\n            if varga:\n                cur.execute(\"select * from mula where varga = ?;\", [varga])\n                # cur.execute(\"select * from mula where sloka_number in (select distinct sloka_number from pada where varga='%s');\" % varga)\n            else:\n                cur.execute(\"select * from mula\")\n            mula = cur.fetchall();\n\n            return render_template('varga.html', mula=mula, varga=varga)\n    finally:\n        con.close()", "line_changes": {"deleted": [{"line_no": 12, "char_start": 215, "char_end": 289, "line": "            cur.execute(\"select * from mula where varga = '%s';\" % varga)\n"}, {"line_no": 14, "char_start": 426, "char_end": 461, "line": "            mula = cur.fetchall();\n"}, {"line_no": 15, "char_start": 461, "char_end": 462, "line": "\n"}], "added": [{"line_no": 13, "char_start": 216, "char_end": 238, "line": "            if varga:\n"}, {"line_no": 14, "char_start": 238, "char_end": 314, "line": "                cur.execute(\"select * from mula where varga = ?;\", [varga])\n"}, {"line_no": 16, "char_start": 455, "char_end": 473, "line": "            else:\n"}, {"line_no": 17, "char_start": 473, "char_end": 523, "line": "                cur.execute(\"select * from mula\")\n"}, {"line_no": 18, "char_start": 523, "char_end": 558, "line": "            mula = cur.fetchall();\n"}]}, "char_changes": {"deleted": [{"char_start": 273, "char_end": 282, "chars": "'%s';\" % "}, {"char_start": 462, "char_end": 464, "chars": "\n\n"}], "added": [{"char_start": 215, "char_end": 242, "chars": "\n            if varga:\n    "}, {"char_start": 300, "char_end": 306, "chars": "?;\", ["}, {"char_start": 311, "char_end": 312, "chars": "]"}, {"char_start": 314, "char_end": 318, "chars": "    "}, {"char_start": 455, "char_end": 523, "chars": "            else:\n                cur.execute(\"select * from mula\")\n"}]}, "commit_link": "github.com/aupasana/amara-quiz/commit/6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "file_name": "docker/app.py", "vul_type": "cwe-089"}
{"func_name": "init", "func_src_before": "    @api.model_cr\n    def init(self):\n        tools.drop_view_if_exists(self.env.cr, self._table)\n        self.env.cr.execute(\"\"\"CREATE or REPLACE VIEW %s as (\n            %s\n            FROM ( %s )\n            %s\n            )\"\"\" % (self._table,\n                    self._select(),\n                    self._from(),\n                    self._group_by()))", "func_src_after": "    @api.model_cr\n    def init(self):\n        tools.drop_view_if_exists(self.env.cr, self._table)\n        self.env.cr.execute(\n            \"\"\"\n            CREATE or REPLACE VIEW %s as (%s\n            FROM ( %s )\n            %s)\"\"\",\n            (AsIs(self._table), AsIs(self._select()),\n             AsIs(self._from()), AsIs(self._group_by())),\n        )", "line_changes": {"deleted": [{"line_no": 4, "char_start": 98, "char_end": 160, "line": "        self.env.cr.execute(\"\"\"CREATE or REPLACE VIEW %s as (\n"}, {"line_no": 5, "char_start": 160, "char_end": 175, "line": "            %s\n"}, {"line_no": 7, "char_start": 199, "char_end": 214, "line": "            %s\n"}, {"line_no": 8, "char_start": 214, "char_end": 247, "line": "            )\"\"\" % (self._table,\n"}, {"line_no": 9, "char_start": 247, "char_end": 283, "line": "                    self._select(),\n"}, {"line_no": 10, "char_start": 283, "char_end": 317, "line": "                    self._from(),\n"}, {"line_no": 11, "char_start": 317, "char_end": 355, "line": "                    self._group_by()))\n"}], "added": [{"line_no": 4, "char_start": 98, "char_end": 127, "line": "        self.env.cr.execute(\n"}, {"line_no": 5, "char_start": 127, "char_end": 143, "line": "            \"\"\"\n"}, {"line_no": 6, "char_start": 143, "char_end": 188, "line": "            CREATE or REPLACE VIEW %s as (%s\n"}, {"line_no": 8, "char_start": 212, "char_end": 232, "line": "            %s)\"\"\",\n"}, {"line_no": 9, "char_start": 232, "char_end": 286, "line": "            (AsIs(self._table), AsIs(self._select()),\n"}, {"line_no": 10, "char_start": 286, "char_end": 344, "line": "             AsIs(self._from()), AsIs(self._group_by())),\n"}, {"line_no": 11, "char_start": 344, "char_end": 353, "line": "        )"}]}, "char_changes": {"deleted": [{"char_start": 126, "char_end": 129, "chars": "\"\"\""}, {"char_start": 159, "char_end": 172, "chars": "\n            "}, {"char_start": 226, "char_end": 233, "chars": ")\"\"\" % "}, {"char_start": 245, "char_end": 267, "chars": ",\n                    "}, {"char_start": 296, "char_end": 303, "chars": "       "}, {"char_start": 315, "char_end": 337, "chars": ",\n                    "}], "added": [{"char_start": 126, "char_end": 155, "chars": "\n            \"\"\"\n            "}, {"char_start": 226, "char_end": 231, "chars": ")\"\"\","}, {"char_start": 244, "char_end": 249, "chars": "(AsIs"}, {"char_start": 261, "char_end": 269, "chars": "), AsIs("}, {"char_start": 283, "char_end": 284, "chars": ")"}, {"char_start": 299, "char_end": 304, "chars": "AsIs("}, {"char_start": 316, "char_end": 324, "chars": "), AsIs("}, {"char_start": 342, "char_end": 353, "chars": ",\n        )"}]}, "commit_link": "github.com/Eficent/ao-odoo/commit/8e9dfe3698a6a8c747d5a1f0e719eaae8fc8c855", "file_name": "ao_crm_helpdesk_problem_track/reports/qc_problem_track_report.py", "vul_type": "cwe-089"}
{"func_name": "queryQuestion", "func_src_before": "def queryQuestion(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT question from {} WHERE name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    tmp = queryOne(c, req)\n    conn.close()\n    return tmp", "func_src_after": "def queryQuestion(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT question from {} WHERE name = ?\".format(CFG(\"poll_table_name\"))\n    tmp = queryOne(c, req, (poll_name,))\n    conn.close()\n    return tmp", "line_changes": {"deleted": [{"line_no": 3, "char_start": 56, "char_end": 152, "line": "    req = \"SELECT question from {} WHERE name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n"}, {"line_no": 4, "char_start": 152, "char_end": 179, "line": "    tmp = queryOne(c, req)\n"}], "added": [{"line_no": 3, "char_start": 56, "char_end": 138, "line": "    req = \"SELECT question from {} WHERE name = ?\".format(CFG(\"poll_table_name\"))\n"}, {"line_no": 4, "char_start": 138, "char_end": 179, "line": "    tmp = queryOne(c, req, (poll_name,))\n"}]}, "char_changes": {"deleted": [{"char_start": 104, "char_end": 108, "chars": "'{}'"}, {"char_start": 139, "char_end": 150, "chars": ", poll_name"}], "added": [{"char_start": 104, "char_end": 105, "chars": "?"}, {"char_start": 163, "char_end": 177, "chars": ", (poll_name,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "markTokenUsedExternal", "func_src_before": "def markTokenUsedExternal(token, optStr=\"\"):\n    conn, c = connectDB()\n    req = \"UPDATE {} SET \\\"options_selected\\\"='{}' WHERE token='{}'\".format(CFG(\"tokens_table_name\"), \\\n                    optStr, token)\n    c.execute(req)\n    closeDB(conn)", "func_src_after": "def markTokenUsedExternal(token, optStr=\"\"):\n    conn, c = connectDB()\n    req = \"UPDATE {} SET \\\"options_selected\\\"=? WHERE token=?\".format(CFG(\"tokens_table_name\"))\n    c.execute(req, (optStr, token,))\n    closeDB(conn)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 71, "char_end": 175, "line": "    req = \"UPDATE {} SET \\\"options_selected\\\"='{}' WHERE token='{}'\".format(CFG(\"tokens_table_name\"), \\\n"}, {"line_no": 4, "char_start": 175, "char_end": 210, "line": "                    optStr, token)\n"}, {"line_no": 5, "char_start": 210, "char_end": 229, "line": "    c.execute(req)\n"}], "added": [{"line_no": 3, "char_start": 71, "char_end": 167, "line": "    req = \"UPDATE {} SET \\\"options_selected\\\"=? WHERE token=?\".format(CFG(\"tokens_table_name\"))\n"}, {"line_no": 4, "char_start": 167, "char_end": 204, "line": "    c.execute(req, (optStr, token,))\n"}]}, "char_changes": {"deleted": [{"char_start": 117, "char_end": 121, "chars": "'{}'"}, {"char_start": 134, "char_end": 138, "chars": "'{}'"}, {"char_start": 171, "char_end": 208, "chars": ", \\\n                    optStr, token"}], "added": [{"char_start": 117, "char_end": 118, "chars": "?"}, {"char_start": 131, "char_end": 132, "chars": "?"}, {"char_start": 165, "char_end": 166, "chars": ")"}, {"char_start": 171, "char_end": 202, "chars": "c.execute(req, (optStr, token,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "checkTokenValid", "func_src_before": "def checkTokenValid(cursor, token, poll_name):\n    req = \"SELECT name, options_selected from {} where token='{}'\".format(CFG(\"tokens_table_name\"), token)\n    answer = queryAll(cursor, req)\n    return answer and answer[0][0] == poll_name and answer[0][1] == 'NONE'", "func_src_after": "def checkTokenValid(cursor, token, poll_name):\n    req = \"SELECT name, options_selected from {} where token=?\".format(CFG(\"tokens_table_name\"))\n    answer = queryAll(cursor, req, (token,))\n    return answer and answer[0][0] == poll_name and answer[0][1] == 'NONE'", "line_changes": {"deleted": [{"line_no": 2, "char_start": 47, "char_end": 154, "line": "    req = \"SELECT name, options_selected from {} where token='{}'\".format(CFG(\"tokens_table_name\"), token)\n"}, {"line_no": 3, "char_start": 154, "char_end": 189, "line": "    answer = queryAll(cursor, req)\n"}], "added": [{"line_no": 2, "char_start": 47, "char_end": 144, "line": "    req = \"SELECT name, options_selected from {} where token=?\".format(CFG(\"tokens_table_name\"))\n"}, {"line_no": 3, "char_start": 144, "char_end": 189, "line": "    answer = queryAll(cursor, req, (token,))\n"}]}, "char_changes": {"deleted": [{"char_start": 108, "char_end": 112, "chars": "'{}'"}, {"char_start": 145, "char_end": 152, "chars": ", token"}], "added": [{"char_start": 108, "char_end": 109, "chars": "?"}, {"char_start": 177, "char_end": 187, "chars": ", (token,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "checkAdmTokenValid", "func_src_before": "def checkAdmTokenValid(poll_name, adm_token):\n    conn, c = connectDB()\n    req = \"SELECT poll_name from {} where adm_token = \\\"{}\\\"\".format(CFG(\"admintoken_table_name\"), adm_token)\n    answer = queryOne(c, req)\n    closeDB(conn)\n    return answer == poll_name", "func_src_after": "def checkAdmTokenValid(poll_name, adm_token):\n    conn, c = connectDB()\n    req = \"SELECT poll_name from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n    answer = queryOne(c, req, (adm_token,))\n    closeDB(conn)\n    return answer == poll_name", "line_changes": {"deleted": [{"line_no": 3, "char_start": 72, "char_end": 182, "line": "    req = \"SELECT poll_name from {} where adm_token = \\\"{}\\\"\".format(CFG(\"admintoken_table_name\"), adm_token)\n"}, {"line_no": 4, "char_start": 182, "char_end": 212, "line": "    answer = queryOne(c, req)\n"}], "added": [{"line_no": 3, "char_start": 72, "char_end": 164, "line": "    req = \"SELECT poll_name from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n"}, {"line_no": 4, "char_start": 164, "char_end": 208, "line": "    answer = queryOne(c, req, (adm_token,))\n"}]}, "char_changes": {"deleted": [{"char_start": 123, "char_end": 132, "chars": " = \\\"{}\\\""}, {"char_start": 169, "char_end": 180, "chars": ", adm_token"}], "added": [{"char_start": 123, "char_end": 125, "chars": "=?"}, {"char_start": 192, "char_end": 206, "chars": ", (adm_token,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "isValidAdmToken", "func_src_before": "def isValidAdmToken(adm_token):\n    conn, c = connectDB()\n    req = \"SELECT *  from {} where adm_token='{}'\".format(CFG(\"admintoken_table_name\"), adm_token)\n    answer = bool(queryOne(c, req))\n    closeDB(conn)\n    return answer", "func_src_after": "def isValidAdmToken(adm_token):\n    conn, c = connectDB()\n    req = \"SELECT *  from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n    answer = bool(queryOne(c, req, (adm_token,)))\n    closeDB(conn)\n    return answer", "line_changes": {"deleted": [{"line_no": 3, "char_start": 58, "char_end": 157, "line": "    req = \"SELECT *  from {} where adm_token='{}'\".format(CFG(\"admintoken_table_name\"), adm_token)\n"}, {"line_no": 4, "char_start": 157, "char_end": 193, "line": "    answer = bool(queryOne(c, req))\n"}], "added": [{"line_no": 3, "char_start": 58, "char_end": 143, "line": "    req = \"SELECT *  from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n"}, {"line_no": 4, "char_start": 143, "char_end": 193, "line": "    answer = bool(queryOne(c, req, (adm_token,)))\n"}]}, "char_changes": {"deleted": [{"char_start": 103, "char_end": 107, "chars": "'{}'"}, {"char_start": 144, "char_end": 155, "chars": ", adm_token"}], "added": [{"char_start": 103, "char_end": 104, "chars": "?"}, {"char_start": 176, "char_end": 190, "chars": ", (adm_token,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "isValidToken", "func_src_before": "def isValidToken(token):\n    conn, c = connectDB()\n    req = \"SELECT * from {} where token='{}'\".format(CFG(\"tokens_table_name\"), token)\n    answer = bool(queryOne(c, req))\n    closeDB(conn)\n    return answer", "func_src_after": "def isValidToken(token):\n    conn, c = connectDB()\n    req = \"SELECT * from {} where token=?\".format(CFG(\"tokens_table_name\"))\n    answer = bool(queryOne(c, req, (token,)))\n    closeDB(conn)\n    return answer", "line_changes": {"deleted": [{"line_no": 3, "char_start": 51, "char_end": 137, "line": "    req = \"SELECT * from {} where token='{}'\".format(CFG(\"tokens_table_name\"), token)\n"}, {"line_no": 4, "char_start": 137, "char_end": 173, "line": "    answer = bool(queryOne(c, req))\n"}], "added": [{"line_no": 3, "char_start": 51, "char_end": 127, "line": "    req = \"SELECT * from {} where token=?\".format(CFG(\"tokens_table_name\"))\n"}, {"line_no": 4, "char_start": 127, "char_end": 173, "line": "    answer = bool(queryOne(c, req, (token,)))\n"}]}, "char_changes": {"deleted": [{"char_start": 91, "char_end": 95, "chars": "'{}'"}, {"char_start": 128, "char_end": 135, "chars": ", token"}], "added": [{"char_start": 91, "char_end": 92, "chars": "?"}, {"char_start": 160, "char_end": 170, "chars": ", (token,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "pollNameFromToken", "func_src_before": "def pollNameFromToken(token):\n    conn, c = connectDB()\n    req = \"SELECT name from {} where token='{}'\".format(CFG(\"tokens_table_name\"), token)\n    answer = queryOne(c, req)\n    if not answer:\n        req = \"SELECT poll_name from {} where adm_token='{}'\".format(CFG(\"admintoken_table_name\"), token)\n        answer = queryOne(c, req)\n    closeDB(conn)\n    return answer", "func_src_after": "def pollNameFromToken(token):\n    conn, c = connectDB()\n    req = \"SELECT name from {} where token=?\".format(CFG(\"tokens_table_name\"))\n    answer = queryOne(c, req, (token,))\n    if not answer:\n        req = \"SELECT poll_name from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n        answer = queryOne(c, req, (token,))\n    closeDB(conn)\n    return answer", "line_changes": {"deleted": [{"line_no": 3, "char_start": 56, "char_end": 145, "line": "    req = \"SELECT name from {} where token='{}'\".format(CFG(\"tokens_table_name\"), token)\n"}, {"line_no": 4, "char_start": 145, "char_end": 175, "line": "    answer = queryOne(c, req)\n"}, {"line_no": 6, "char_start": 194, "char_end": 300, "line": "        req = \"SELECT poll_name from {} where adm_token='{}'\".format(CFG(\"admintoken_table_name\"), token)\n"}, {"line_no": 7, "char_start": 300, "char_end": 334, "line": "        answer = queryOne(c, req)\n"}], "added": [{"line_no": 3, "char_start": 56, "char_end": 135, "line": "    req = \"SELECT name from {} where token=?\".format(CFG(\"tokens_table_name\"))\n"}, {"line_no": 4, "char_start": 135, "char_end": 175, "line": "    answer = queryOne(c, req, (token,))\n"}, {"line_no": 6, "char_start": 194, "char_end": 290, "line": "        req = \"SELECT poll_name from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n"}, {"line_no": 7, "char_start": 290, "char_end": 334, "line": "        answer = queryOne(c, req, (token,))\n"}]}, "char_changes": {"deleted": [{"char_start": 99, "char_end": 103, "chars": "'{}'"}, {"char_start": 136, "char_end": 143, "chars": ", token"}, {"char_start": 250, "char_end": 254, "chars": "'{}'"}, {"char_start": 291, "char_end": 298, "chars": ", token"}], "added": [{"char_start": 99, "char_end": 100, "chars": "?"}, {"char_start": 163, "char_end": 173, "chars": ", (token,)"}, {"char_start": 250, "char_end": 251, "chars": "?"}, {"char_start": 322, "char_end": 332, "chars": ", (token,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "checkTokenNeeded", "func_src_before": "def checkTokenNeeded(cursor, poll_name):\n    req = \"SELECT has_tokens FROM {} WHERE name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    return queryOne(cursor, req) == 1;", "func_src_after": "def checkTokenNeeded(cursor, poll_name):\n    req = \"SELECT has_tokens FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n    return queryOne(cursor, req, (poll_name,)) == 1", "line_changes": {"deleted": [{"line_no": 2, "char_start": 41, "char_end": 139, "line": "    req = \"SELECT has_tokens FROM {} WHERE name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n"}, {"line_no": 3, "char_start": 139, "char_end": 177, "line": "    return queryOne(cursor, req) == 1;\n"}], "added": [{"line_no": 2, "char_start": 41, "char_end": 123, "line": "    req = \"SELECT has_tokens FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n"}, {"line_no": 3, "char_start": 123, "char_end": 174, "line": "    return queryOne(cursor, req, (poll_name,)) == 1\n"}]}, "char_changes": {"deleted": [{"char_start": 88, "char_end": 95, "chars": " = '{}'"}, {"char_start": 126, "char_end": 137, "chars": ", poll_name"}, {"char_start": 176, "char_end": 177, "chars": ";"}], "added": [{"char_start": 88, "char_end": 90, "chars": "=?"}, {"char_start": 154, "char_end": 168, "chars": ", (poll_name,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "incrementOption", "func_src_before": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option = '{}';\".format(CFG(\"options_table_name\"), key)\n    cursor.execute(req)", "func_src_after": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option=?\".format(CFG(\"options_table_name\"))\n    cursor.execute(req, (key,))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 79, "char_end": 184, "line": "    req = \"UPDATE {} SET count=count+1 WHERE name_option = '{}';\".format(CFG(\"options_table_name\"), key)\n"}, {"line_no": 4, "char_start": 184, "char_end": 207, "line": "    cursor.execute(req)\n"}], "added": [{"line_no": 3, "char_start": 79, "char_end": 173, "line": "    req = \"UPDATE {} SET count=count+1 WHERE name_option=?\".format(CFG(\"options_table_name\"))\n"}, {"line_no": 4, "char_start": 173, "char_end": 204, "line": "    cursor.execute(req, (key,))\n"}]}, "char_changes": {"deleted": [{"char_start": 135, "char_end": 143, "chars": " = '{}';"}, {"char_start": 177, "char_end": 182, "chars": ", key"}], "added": [{"char_start": 135, "char_end": 137, "chars": "=?"}, {"char_start": 195, "char_end": 203, "chars": ", (key,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "isMultiChoice", "func_src_before": "def isMultiChoice(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT multi FROM {} WHERE name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    ret = queryOne(c, req) == 1\n    closeDB(conn)\n    return ret", "func_src_after": "def isMultiChoice(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT multi FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n    ret = queryOne(c, req, (poll_name,)) == 1\n    closeDB(conn)\n    return ret", "line_changes": {"deleted": [{"line_no": 3, "char_start": 56, "char_end": 149, "line": "    req = \"SELECT multi FROM {} WHERE name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n"}, {"line_no": 4, "char_start": 149, "char_end": 181, "line": "    ret = queryOne(c, req) == 1\n"}], "added": [{"line_no": 3, "char_start": 56, "char_end": 133, "line": "    req = \"SELECT multi FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n"}, {"line_no": 4, "char_start": 133, "char_end": 179, "line": "    ret = queryOne(c, req, (poll_name,)) == 1\n"}]}, "char_changes": {"deleted": [{"char_start": 98, "char_end": 105, "chars": " = '{}'"}, {"char_start": 136, "char_end": 147, "chars": ", poll_name"}], "added": [{"char_start": 98, "char_end": 100, "chars": "=?"}, {"char_start": 158, "char_end": 172, "chars": ", (poll_name,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "getOptionCount", "func_src_before": "def getOptionCount(c, poll_name, option):\n    key = poll_name + \"-\" + option\n    req = \"SELECT \\\"count\\\" FROM {table} WHERE \\\"name_option\\\" = '{key}'\".format(\n                    table=CFG(\"options_table_name\"),key=key)\n    count = queryOne(c, req)\n    if count == None:\n        raise AssertionError(\"Unknown answer for poll. WTF?\")\n    return count;", "func_src_after": "def getOptionCount(c, poll_name, option):\n    key = poll_name + \"-\" + option\n    req = \"SELECT count FROM {table} WHERE name_option=?\".format(table=CFG(\"options_table_name\"))\n    count = queryOne(c, req, (key,))\n    if count == None:\n        raise AssertionError(\"Unknown answer for poll. WTF?\")\n    return count;", "line_changes": {"deleted": [{"line_no": 3, "char_start": 77, "char_end": 159, "line": "    req = \"SELECT \\\"count\\\" FROM {table} WHERE \\\"name_option\\\" = '{key}'\".format(\n"}, {"line_no": 4, "char_start": 159, "char_end": 220, "line": "                    table=CFG(\"options_table_name\"),key=key)\n"}, {"line_no": 5, "char_start": 220, "char_end": 249, "line": "    count = queryOne(c, req)\n"}], "added": [{"line_no": 3, "char_start": 77, "char_end": 175, "line": "    req = \"SELECT count FROM {table} WHERE name_option=?\".format(table=CFG(\"options_table_name\"))\n"}, {"line_no": 4, "char_start": 175, "char_end": 212, "line": "    count = queryOne(c, req, (key,))\n"}]}, "char_changes": {"deleted": [{"char_start": 95, "char_end": 97, "chars": "\\\""}, {"char_start": 102, "char_end": 104, "chars": "\\\""}, {"char_start": 124, "char_end": 126, "chars": "\\\""}, {"char_start": 137, "char_end": 179, "chars": "\\\" = '{key}'\".format(\n                    "}, {"char_start": 210, "char_end": 218, "chars": ",key=key"}], "added": [{"char_start": 131, "char_end": 142, "chars": "=?\".format("}, {"char_start": 202, "char_end": 210, "chars": ", (key,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "getResults", "func_src_before": "def getResults(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options from {} where name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    options_str = queryOne(c, req)\n\n    if not options_str:\n        raise LookupError(\"Poll '{}' not found in DB\".format(poll_name))\n\n    total = 0\n    options = options_str.split(\",\")\n    results = dict()\n    for opt in options:\n        count = getOptionCount(c, poll_name, opt)\n        total += int(count)\n        results.update({opt:count})\n\n    conn.close()\n    return (results, total)", "func_src_after": "def getResults(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options from {} where name=?\".format(CFG(\"poll_table_name\"))\n    options_str = queryOne(c, req, (poll_name,))\n\n    if not options_str:\n        raise LookupError(\"Poll '{}' not found in DB\".format(poll_name))\n\n    total = 0\n    options = options_str.split(\",\")\n    results = dict()\n    for opt in options:\n        count = getOptionCount(c, poll_name, opt)\n        total += int(count)\n        results.update({opt:count})\n\n    conn.close()\n    return (results, total)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 148, "line": "    req = \"SELECT options from {} where name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n"}, {"line_no": 4, "char_start": 148, "char_end": 183, "line": "    options_str = queryOne(c, req)\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 132, "line": "    req = \"SELECT options from {} where name=?\".format(CFG(\"poll_table_name\"))\n"}, {"line_no": 4, "char_start": 132, "char_end": 181, "line": "    options_str = queryOne(c, req, (poll_name,))\n"}]}, "char_changes": {"deleted": [{"char_start": 97, "char_end": 104, "chars": " = '{}'"}, {"char_start": 135, "char_end": 146, "chars": ", poll_name"}], "added": [{"char_start": 97, "char_end": 99, "chars": "=?"}, {"char_start": 165, "char_end": 179, "chars": ", (poll_name,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "getTokensExternal", "func_src_before": "def getTokensExternal(poll_name):\n    req = \"SELECT token FROM {} WHERE name='{}'\".format(CFG(\"tokens_table_name\"), poll_name)\n    conn, c = connectDB()\n    tmp = queryAll(c, req)\n    conn.close()\n    return tmp", "func_src_after": "def getTokensExternal(poll_name):\n    req = \"SELECT token FROM {} WHERE name=?\".format(CFG(\"tokens_table_name\"))\n    conn, c = connectDB()\n    tmp = queryAll(c, req, (poll_name,))\n    conn.close()\n    return tmp", "line_changes": {"deleted": [{"line_no": 2, "char_start": 34, "char_end": 127, "line": "    req = \"SELECT token FROM {} WHERE name='{}'\".format(CFG(\"tokens_table_name\"), poll_name)\n"}, {"line_no": 4, "char_start": 153, "char_end": 180, "line": "    tmp = queryAll(c, req)\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 113, "line": "    req = \"SELECT token FROM {} WHERE name=?\".format(CFG(\"tokens_table_name\"))\n"}, {"line_no": 4, "char_start": 139, "char_end": 180, "line": "    tmp = queryAll(c, req, (poll_name,))\n"}]}, "char_changes": {"deleted": [{"char_start": 77, "char_end": 81, "chars": "'{}'"}, {"char_start": 114, "char_end": 125, "chars": ", poll_name"}], "added": [{"char_start": 77, "char_end": 78, "chars": "?"}, {"char_start": 164, "char_end": 178, "chars": ", (poll_name,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "getAdmToken", "func_src_before": "def getAdmToken(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT adm_token FROM {} WHERE poll_name='{}'\".format(CFG(\"admintoken_table_name\"), poll_name)\n    admtok = queryOne(c, req)\n    closeDB(conn)\n    return admtok", "func_src_after": "def getAdmToken(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT adm_token FROM {} WHERE poll_name=?\".format(CFG(\"admintoken_table_name\"))\n    admtok = queryOne(c, req, (poll_name,))\n    closeDB(conn)\n    return admtok", "line_changes": {"deleted": [{"line_no": 3, "char_start": 54, "char_end": 160, "line": "    req = \"SELECT adm_token FROM {} WHERE poll_name='{}'\".format(CFG(\"admintoken_table_name\"), poll_name)\n"}, {"line_no": 4, "char_start": 160, "char_end": 190, "line": "    admtok = queryOne(c, req)\n"}], "added": [{"line_no": 3, "char_start": 54, "char_end": 146, "line": "    req = \"SELECT adm_token FROM {} WHERE poll_name=?\".format(CFG(\"admintoken_table_name\"))\n"}, {"line_no": 4, "char_start": 146, "char_end": 190, "line": "    admtok = queryOne(c, req, (poll_name,))\n"}]}, "char_changes": {"deleted": [{"char_start": 106, "char_end": 110, "chars": "'{}'"}, {"char_start": 147, "char_end": 158, "chars": ", poll_name"}], "added": [{"char_start": 106, "char_end": 107, "chars": "?"}, {"char_start": 174, "char_end": 188, "chars": ", (poll_name,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "checkPollExists", "func_src_before": "def checkPollExists(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT EXISTS( SELECT 1 FROM {} WHERE name='{}')\".format(CFG(\"poll_table_name\"), poll_name)\n    tmp = queryOne(c, req)\n    conn.close()\n    return tmp", "func_src_after": "def checkPollExists(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT EXISTS( SELECT 1 FROM {} WHERE name=?)\".format(CFG(\"poll_table_name\"))\n    tmp = queryOne(c, req, (poll_name,))\n    conn.close()\n    return tmp", "line_changes": {"deleted": [{"line_no": 3, "char_start": 58, "char_end": 161, "line": "    req = \"SELECT EXISTS( SELECT 1 FROM {} WHERE name='{}')\".format(CFG(\"poll_table_name\"), poll_name)\n"}, {"line_no": 4, "char_start": 161, "char_end": 188, "line": "    tmp = queryOne(c, req)\n"}], "added": [{"line_no": 3, "char_start": 58, "char_end": 147, "line": "    req = \"SELECT EXISTS( SELECT 1 FROM {} WHERE name=?)\".format(CFG(\"poll_table_name\"))\n"}, {"line_no": 4, "char_start": 147, "char_end": 188, "line": "    tmp = queryOne(c, req, (poll_name,))\n"}]}, "char_changes": {"deleted": [{"char_start": 112, "char_end": 116, "chars": "'{}'"}, {"char_start": 148, "char_end": 159, "chars": ", poll_name"}], "added": [{"char_start": 112, "char_end": 113, "chars": "?"}, {"char_start": 172, "char_end": 186, "chars": ", (poll_name,)"}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "getOptions", "func_src_before": "def getOptions(poll_name):\n    conn, c = connectDB()\n    options_str = queryOne(c, \"SELECT options FROM {} WHERE name='{}'\".format(CFG(\"poll_table_name\"), poll_name))\n    if options_str == None:\n        return None\n    options = options_str.split(\",\")\n    closeDB(conn)\n    return options", "func_src_after": "def getOptions(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n    options_str = queryOne(c, req, (poll_name,))\n    if options_str == None:\n        return None\n    options = options_str.split(\",\")\n    closeDB(conn)\n    return options", "line_changes": {"deleted": [{"line_no": 3, "char_start": 53, "char_end": 167, "line": "    options_str = queryOne(c, \"SELECT options FROM {} WHERE name='{}'\".format(CFG(\"poll_table_name\"), poll_name))\n"}], "added": [{"line_no": 3, "char_start": 53, "char_end": 132, "line": "    req = \"SELECT options FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n"}, {"line_no": 4, "char_start": 132, "char_end": 181, "line": "    options_str = queryOne(c, req, (poll_name,))\n"}]}, "char_changes": {"deleted": [{"char_start": 57, "char_end": 82, "chars": "options_str = queryOne(c,"}, {"char_start": 118, "char_end": 122, "chars": "'{}'"}, {"char_start": 153, "char_end": 155, "chars": ", "}], "added": [{"char_start": 57, "char_end": 62, "chars": "req ="}, {"char_start": 98, "char_end": 99, "chars": "?"}, {"char_start": 130, "char_end": 168, "chars": ")\n    options_str = queryOne(c, req, ("}, {"char_start": 177, "char_end": 178, "chars": ","}]}, "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw\n            # See section on SQL injection below\n            query = \"INSERT INTO crimes (description) VALUES \\\n                    ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 6, "char_start": 195, "char_end": 258, "line": "            query = \"INSERT INTO crimes (description) VALUES \\\n"}, {"line_no": 7, "char_start": 258, "char_end": 300, "line": "                    ('{}');\".format(data)\n"}, {"line_no": 9, "char_start": 348, "char_end": 386, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 4, "char_start": 80, "char_end": 148, "line": "            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 6, "char_start": 196, "char_end": 240, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 80, "char_end": 195, "chars": "            # The following introduces a deliberate security flaw\n            # See section on SQL injection below\n"}, {"char_start": 256, "char_end": 299, "chars": "\\\n                    ('{}');\".format(data)"}, {"char_start": 348, "char_end": 348, "chars": ""}], "added": [{"char_start": 141, "char_end": 147, "chars": "(%s);\""}, {"char_start": 232, "char_end": 238, "chars": ", data"}]}, "commit_link": "github.com/alejochg/crimemap/commit/d54c54c41c6f6fc9a1430eb7f6b8b663540400e0", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "generate_active_ebay_data", "func_src_before": "@frappe.whitelist()\ndef generate_active_ebay_data():\n    \"\"\"Get all the active eBay listings and save them to table\"\"\"\n\n    # set up the zEbayListings table\n    create_ebay_listings_table()\n\n    page = 1\n    listings_dict = get_myebay_selling_request(page)\n    pages = int(listings_dict['ActiveList']['PaginationResult']['TotalNumberOfPages'])\n    #timestamp = listings_dict['Timestamp']\n\n    while pages >= page:\n\n        for item in listings_dict['ActiveList']['ItemArray']['Item']:\n            ebay_id = item['ItemID']\n            qty = int(item['QuantityAvailable'])\n            try:\n                sku = item['SKU']\n            except:\n                sku = ''\n            #price = item['BuyItNowPrice']['value']\n            #THSI IS 0        print(item['BuyItNowPrice']['value'])\n            #Example: {'_currencyID': 'USD', 'value': '0.0'}   print(item['BuyItNowPrice'])\n            curr_ebay_price = float(item['SellingStatus']['CurrentPrice']['value'])\n            curr_ex_vat = curr_ebay_price / ugssettings.VAT\n            #currency = item['SellingStatus']['CurrentPrice']['_currencyID']  # or ['Currency']\n            #converted_price = item['ListingDetails]['ConvertedBuyItNowPrice']['value']\n            #description = item['Description']\n            hit_count = 0 #int(item['HitCount'])\n            watch_count = 0 #int(item['WatchCount'])\n            question_count = 0 # int(item['TotalQuestionCount'])\n            #title = item['Title']\n            #conv_title = title.encode('ascii', 'ignore').decode('ascii')\n            #new_title = MySQLdb.escape_string(conv_title)\n            site = ''\n            insert_ebay_listing(\n                sku, ebay_id, qty, curr_ebay_price, site, hit_count, watch_count, question_count)\n\n        page += 1\n        if pages >= page:\n            listings_dict = get_myebay_selling_request(page)\n        else:\n            break", "func_src_after": "@frappe.whitelist()\ndef generate_active_ebay_data():\n    \"\"\"Get all the active eBay listings and save them to table\"\"\"\n\n    # set up the zEbayListings table\n    create_ebay_listings_table()\n\n    page = 1\n    listings_dict = get_myebay_selling_request(page)\n    pages = int(listings_dict['ActiveList']['PaginationResult']['TotalNumberOfPages'])\n    #timestamp = listings_dict['Timestamp']\n\n    while pages >= page:\n\n        for item in listings_dict['ActiveList']['ItemArray']['Item']:\n            ebay_id = item['ItemID']\n            qty = int(item['QuantityAvailable'])\n            sku = item.get('SKU', '')\n            #price = item['BuyItNowPrice']['value']\n            #THSI IS 0        print(item['BuyItNowPrice']['value'])\n            #Example: {'_currencyID': 'USD', 'value': '0.0'}   print(item['BuyItNowPrice'])\n            curr_ebay_price = float(item['SellingStatus']['CurrentPrice']['value'])\n            curr_ex_vat = curr_ebay_price / 1.2  # TODO VAT RATE\n            #currency = item['SellingStatus']['CurrentPrice']['_currencyID']  # or ['Currency']\n            #converted_price = item['ListingDetails]['ConvertedBuyItNowPrice']['value']\n            #description = item['Description']\n            hit_count = 0  # int(item['HitCount'])\n            watch_count = 0  # int(item['WatchCount'])\n            question_count = 0  # int(item['TotalQuestionCount'])\n            #title = item['Title']\n            #conv_title = title.encode('ascii', 'ignore').decode('ascii')\n            #new_title = MySQLdb.escape_string(conv_title)\n            site = ''\n            insert_ebay_listing(\n                sku, ebay_id, qty, curr_ebay_price, site, hit_count, watch_count, question_count)\n\n        page += 1\n        if pages >= page:\n            listings_dict = get_myebay_selling_request(page)\n        else:\n            break", "line_changes": {"deleted": [{"line_no": 18, "char_start": 571, "char_end": 588, "line": "            try:\n"}, {"line_no": 19, "char_start": 588, "char_end": 622, "line": "                sku = item['SKU']\n"}, {"line_no": 20, "char_start": 622, "char_end": 642, "line": "            except:\n"}, {"line_no": 21, "char_start": 642, "char_end": 667, "line": "                sku = ''\n"}, {"line_no": 26, "char_start": 963, "char_end": 1023, "line": "            curr_ex_vat = curr_ebay_price / ugssettings.VAT\n"}, {"line_no": 30, "char_start": 1254, "char_end": 1303, "line": "            hit_count = 0 #int(item['HitCount'])\n"}, {"line_no": 31, "char_start": 1303, "char_end": 1356, "line": "            watch_count = 0 #int(item['WatchCount'])\n"}, {"line_no": 32, "char_start": 1356, "char_end": 1421, "line": "            question_count = 0 # int(item['TotalQuestionCount'])\n"}], "added": [{"line_no": 18, "char_start": 571, "char_end": 609, "line": "            sku = item.get('SKU', '')\n"}, {"line_no": 23, "char_start": 905, "char_end": 970, "line": "            curr_ex_vat = curr_ebay_price / 1.2  # TODO VAT RATE\n"}, {"line_no": 27, "char_start": 1201, "char_end": 1252, "line": "            hit_count = 0  # int(item['HitCount'])\n"}, {"line_no": 28, "char_start": 1252, "char_end": 1307, "line": "            watch_count = 0  # int(item['WatchCount'])\n"}, {"line_no": 29, "char_start": 1307, "char_end": 1373, "line": "            question_count = 0  # int(item['TotalQuestionCount'])\n"}]}, "char_changes": {"deleted": [{"char_start": 583, "char_end": 663, "chars": "try:\n                sku = item['SKU']\n            except:\n                sku ="}, {"char_start": 1007, "char_end": 1022, "chars": "ugssettings.VAT"}, {"char_start": 1280, "char_end": 1281, "chars": "#"}], "added": [{"char_start": 583, "char_end": 604, "chars": "sku = item.get('SKU',"}, {"char_start": 607, "char_end": 608, "chars": ")"}, {"char_start": 949, "char_end": 969, "chars": "1.2  # TODO VAT RATE"}, {"char_start": 1227, "char_end": 1230, "chars": " # "}, {"char_start": 1280, "char_end": 1281, "chars": " "}, {"char_start": 1282, "char_end": 1283, "chars": " "}, {"char_start": 1338, "char_end": 1339, "chars": " "}]}, "commit_link": "github.com/bglazier/erpnext_ebay/commit/090e492d02ed75ff8b39c9460a105da1c0b221e9", "file_name": "erpnext_ebay/ebay_active_listings.py", "vul_type": "cwe-089"}
{"func_name": "create_ebay_listings_table", "func_src_before": "def create_ebay_listings_table():\n    \"\"\"Set up the zEbayListings temp table\"\"\"\n\n    sql = \"\"\"\n        create table if not exists `zEbayListings` (\n        `sku` varchar(20),\n        `ebay_id` varchar(38),\n        `qty` integer,\n        `price` decimal(18,6),\n        `site` varchar(6),\n        `hit_count` integer,\n        `watch_count` integer,\n        `question_count` integer\n        )\n    \"\"\"\n\n    frappe.db.sql(sql, auto_commit=True)\n\n    sql2 = \"\"\"truncate table `zEbayListings` \"\"\"\n\n    frappe.db.sql(sql2, auto_commit=True)", "func_src_after": "def create_ebay_listings_table():\n    \"\"\"Set up the zEbayListings temp table\"\"\"\n\n    sql = \"\"\"\n        create table if not exists `zEbayListings` (\n        `sku` varchar(20),\n        `ebay_id` varchar(38),\n        `qty` integer,\n        `price` decimal(18,6),\n        `site` varchar(6),\n        `hit_count` integer,\n        `watch_count` integer,\n        `question_count` integer\n        );\n    \"\"\"\n\n    frappe.db.sql(sql, auto_commit=True)\n\n    sql2 = \"\"\"truncate table `zEbayListings`;\"\"\"\n\n    frappe.db.sql(sql2, auto_commit=True)", "line_changes": {"deleted": [{"line_no": 14, "char_start": 380, "char_end": 390, "line": "        )\n"}, {"line_no": 19, "char_start": 441, "char_end": 490, "line": "    sql2 = \"\"\"truncate table `zEbayListings` \"\"\"\n"}], "added": [{"line_no": 14, "char_start": 380, "char_end": 391, "line": "        );\n"}, {"line_no": 19, "char_start": 442, "char_end": 491, "line": "    sql2 = \"\"\"truncate table `zEbayListings`;\"\"\"\n"}]}, "char_changes": {"deleted": [{"char_start": 485, "char_end": 486, "chars": " "}], "added": [{"char_start": 389, "char_end": 390, "chars": ";"}, {"char_start": 486, "char_end": 487, "chars": ";"}]}, "commit_link": "github.com/bglazier/erpnext_ebay/commit/090e492d02ed75ff8b39c9460a105da1c0b221e9", "file_name": "erpnext_ebay/ebay_active_listings.py", "vul_type": "cwe-089"}
{"func_name": "insert_ebay_listing", "func_src_before": "def insert_ebay_listing(sku, ebay_id, qty, price,\n                        site, hits, watches, questions):\n    \"\"\"insert ebay listings into a temp table\"\"\"\n\n    sql = \"\"\"\n    insert into `zEbayListings`\n    values('{sku}', '{ebay_id}', {qty}, {price}, '{site}', {hit_count}, {watch_count}, {question_count})\n    \"\"\".format(sku=sku, ebay_id=ebay_id, qty=qty, price=price, site=site,\n               hit_count=hits, watch_count=watches, question_count=questions)\n\n\n    frappe.db.sql(sql, auto_commit=True)", "func_src_after": "def insert_ebay_listing(sku, ebay_id, qty, price,\n                        site, hits, watches, questions):\n    \"\"\"insert ebay listings into a temp table\"\"\"\n\n    sql = \"\"\"\n        INSERT INTO `zEbayListings`\n            VALUES (%s, %s, %s, %s, %s, %s, %s, %s);\n        \"\"\"\n    parameters = (sku, ebay_id, qty, price, site, hits, watches, questions)\n\n    frappe.db.sql(sql, parameters, auto_commit=True)", "line_changes": {"deleted": [{"line_no": 6, "char_start": 171, "char_end": 203, "line": "    insert into `zEbayListings`\n"}, {"line_no": 7, "char_start": 203, "char_end": 308, "line": "    values('{sku}', '{ebay_id}', {qty}, {price}, '{site}', {hit_count}, {watch_count}, {question_count})\n"}, {"line_no": 8, "char_start": 308, "char_end": 382, "line": "    \"\"\".format(sku=sku, ebay_id=ebay_id, qty=qty, price=price, site=site,\n"}, {"line_no": 9, "char_start": 382, "char_end": 460, "line": "               hit_count=hits, watch_count=watches, question_count=questions)\n"}, {"line_no": 10, "char_start": 460, "char_end": 461, "line": "\n"}, {"line_no": 11, "char_start": 461, "char_end": 462, "line": "\n"}, {"line_no": 12, "char_start": 462, "char_end": 502, "line": "    frappe.db.sql(sql, auto_commit=True)\n"}], "added": [{"line_no": 6, "char_start": 171, "char_end": 207, "line": "        INSERT INTO `zEbayListings`\n"}, {"line_no": 7, "char_start": 207, "char_end": 260, "line": "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s);\n"}, {"line_no": 8, "char_start": 260, "char_end": 272, "line": "        \"\"\"\n"}, {"line_no": 9, "char_start": 272, "char_end": 348, "line": "    parameters = (sku, ebay_id, qty, price, site, hits, watches, questions)\n"}]}, "char_changes": {"deleted": [{"char_start": 175, "char_end": 186, "chars": "insert into"}, {"char_start": 207, "char_end": 308, "chars": "values('{sku}', '{ebay_id}', {qty}, {price}, '{site}', {hit_count}, {watch_count}, {question_count})\n"}, {"char_start": 315, "char_end": 449, "chars": ".format(sku=sku, ebay_id=ebay_id, qty=qty, price=price, site=site,\n               hit_count=hits, watch_count=watches, question_count="}, {"char_start": 461, "char_end": 462, "chars": "\n"}], "added": [{"char_start": 175, "char_end": 190, "chars": "    INSERT INTO"}, {"char_start": 211, "char_end": 337, "chars": "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s);\n        \"\"\"\n    parameters = (sku, ebay_id, qty, price, site, hits, watches, "}, {"char_start": 371, "char_end": 383, "chars": " parameters,"}]}, "commit_link": "github.com/bglazier/erpnext_ebay/commit/090e492d02ed75ff8b39c9460a105da1c0b221e9", "file_name": "erpnext_ebay/ebay_active_listings.py", "vul_type": "cwe-089"}
{"func_name": "set_item_ebay_first_listed_date", "func_src_before": "@frappe.whitelist()\ndef set_item_ebay_first_listed_date():\n    \"\"\"\n    Given an ebay_id set the first listed on date.\n    \n    select it.item_code from `tabItem` it\n    where it.on_sale_from_date is NULL\n    and it.ebay_id REGEXP '^[0-9]+$';\n    \"\"\"\n\n    date_today = date.today()\n\n    sql = \"\"\"\n    update `tabItem` it\n    set it.on_sale_from_date = '%s'\n    where it.on_sale_from_date is NULL\n    and it.ebay_id REGEXP '^[0-9]+$';\n    \"\"\"%date_today.isoformat()\n\n    try:\n        frappe.db.sql(sql, auto_commit=True)\n\n    except Exception as inst:\n        print(\"Unexpected error setting first listed date.\")\n        raise", "func_src_after": "@frappe.whitelist()\ndef set_item_ebay_first_listed_date():\n    \"\"\"\n    Given an ebay_id set the first listed on date.\n    \n    select it.item_code from `tabItem` it\n    where it.on_sale_from_date is NULL\n    and it.ebay_id REGEXP '^[0-9]+$';\n    \"\"\"\n\n    date_today = date.today()\n\n    sql = \"\"\"\n        UPDATE `tabItem` it\n            SET it.on_sale_from_date = %s\n            WHERE it.on_sale_from_date is NULL\n                AND it.ebay_id REGEXP '^[0-9]+$';\n    \"\"\"\n\n    try:\n        frappe.db.sql(sql, (date_today.isoformat()), auto_commit=True)\n\n    except Exception as inst:\n        print(\"Unexpected error setting first listed date.\")\n        raise", "line_changes": {"deleted": [{"line_no": 14, "char_start": 296, "char_end": 320, "line": "    update `tabItem` it\n"}, {"line_no": 15, "char_start": 320, "char_end": 356, "line": "    set it.on_sale_from_date = '%s'\n"}, {"line_no": 16, "char_start": 356, "char_end": 395, "line": "    where it.on_sale_from_date is NULL\n"}, {"line_no": 17, "char_start": 395, "char_end": 433, "line": "    and it.ebay_id REGEXP '^[0-9]+$';\n"}, {"line_no": 18, "char_start": 433, "char_end": 464, "line": "    \"\"\"%date_today.isoformat()\n"}, {"line_no": 21, "char_start": 474, "char_end": 519, "line": "        frappe.db.sql(sql, auto_commit=True)\n"}], "added": [{"line_no": 14, "char_start": 296, "char_end": 324, "line": "        UPDATE `tabItem` it\n"}, {"line_no": 15, "char_start": 324, "char_end": 366, "line": "            SET it.on_sale_from_date = %s\n"}, {"line_no": 16, "char_start": 366, "char_end": 413, "line": "            WHERE it.on_sale_from_date is NULL\n"}, {"line_no": 17, "char_start": 413, "char_end": 463, "line": "                AND it.ebay_id REGEXP '^[0-9]+$';\n"}, {"line_no": 18, "char_start": 463, "char_end": 471, "line": "    \"\"\"\n"}, {"line_no": 21, "char_start": 481, "char_end": 552, "line": "        frappe.db.sql(sql, (date_today.isoformat()), auto_commit=True)\n"}]}, "char_changes": {"deleted": [{"char_start": 300, "char_end": 306, "chars": "update"}, {"char_start": 324, "char_end": 327, "chars": "set"}, {"char_start": 351, "char_end": 352, "chars": "'"}, {"char_start": 354, "char_end": 355, "chars": "'"}, {"char_start": 360, "char_end": 365, "chars": "where"}, {"char_start": 399, "char_end": 402, "chars": "and"}, {"char_start": 440, "char_end": 463, "chars": "%date_today.isoformat()"}], "added": [{"char_start": 300, "char_end": 310, "chars": "    UPDATE"}, {"char_start": 328, "char_end": 339, "chars": "        SET"}, {"char_start": 370, "char_end": 383, "chars": "        WHERE"}, {"char_start": 417, "char_end": 432, "chars": "            AND"}, {"char_start": 507, "char_end": 533, "chars": " (date_today.isoformat()),"}]}, "commit_link": "github.com/bglazier/erpnext_ebay/commit/090e492d02ed75ff8b39c9460a105da1c0b221e9", "file_name": "erpnext_ebay/ebay_active_listings.py", "vul_type": "cwe-089"}
{"func_name": "sync_ebay_ids", "func_src_before": "def sync_ebay_ids():\n    \"\"\"Return only items that don't match\"\"\"\n\n    sql = \"\"\"\n    select * from (\n        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,\n        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1\n        LEFT JOIN `tabItem` t2 ON t1.sku = t2.item_code\n        UNION\n        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,\n        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1\n        RIGHT JOIN `tabItem` t2 ON t1.sku = t2.item_code\n    ) as t\n    where t.live_ebay_id <> t.dead_ebay_id\n    \"\"\"\n\n    records = frappe.db.sql(sql, as_dict=True)\n\n\n    for r in records:\n\n        # If not live id then clear any value on system (unless Awaiting Garagaesale)\n        if r.live_ebay_id == '':\n            set_item_ebay_id(r.item_code, '')\n        else:\n            # ok so item is live but id's don't match so update system with live version\n            if r.item_code:\n                set_item_ebay_id(r.sku, r.live_ebay_id)\n\n            else:\n                msgprint(\n                    'The ebay item cannot be found on ERPNEXT so unable to record ebay id', r.live_ebay_id)", "func_src_after": "def sync_ebay_ids():\n    \"\"\"Return only items that don't match\"\"\"\n\n    sql = \"\"\"\n    select * from (\n        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,\n        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1\n        LEFT JOIN `tabItem` t2 ON t1.sku = t2.item_code\n        UNION\n        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,\n        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1\n        RIGHT JOIN `tabItem` t2 ON t1.sku = t2.item_code\n    ) as t\n    where t.live_ebay_id <> t.dead_ebay_id\n    \"\"\"\n\n    records = frappe.db.sql(sql, as_dict=True)\n\n    for r in records:\n\n        # If not live id then clear any value on system (unless Awaiting Garagaesale)\n        if r.live_ebay_id == '':\n            set_item_ebay_id(r.item_code, '')\n        else:\n            # ok so item is live but id's don't match so update system with live version\n            if r.item_code:\n                set_item_ebay_id(r.sku, r.live_ebay_id)\n            else:\n                msgprint(\n                    'The ebay item cannot be found on ERPNEXT so unable to record ebay id',\n                    r.live_ebay_id)", "line_changes": {"deleted": [{"line_no": 19, "char_start": 635, "char_end": 636, "line": "\n"}, {"line_no": 29, "char_start": 1011, "char_end": 1012, "line": "\n"}, {"line_no": 32, "char_start": 1056, "char_end": 1163, "line": "                    'The ebay item cannot be found on ERPNEXT so unable to record ebay id', r.live_ebay_id)\n"}], "added": [{"line_no": 30, "char_start": 1054, "char_end": 1146, "line": "                    'The ebay item cannot be found on ERPNEXT so unable to record ebay id',\n"}, {"line_no": 31, "char_start": 1146, "char_end": 1181, "line": "                    r.live_ebay_id)"}]}, "char_changes": {"deleted": [{"char_start": 635, "char_end": 636, "chars": "\n"}, {"char_start": 1011, "char_end": 1012, "chars": "\n"}], "added": [{"char_start": 1145, "char_end": 1165, "chars": "\n                   "}]}, "commit_link": "github.com/bglazier/erpnext_ebay/commit/090e492d02ed75ff8b39c9460a105da1c0b221e9", "file_name": "erpnext_ebay/ebay_active_listings.py", "vul_type": "cwe-089"}
{"func_name": "register", "func_src_before": "@app.route(\"/register\", methods=[\"GET\", \"POST\"])\r\ndef register():\r\n    if 'user' in session:\r\n        return redirect(url_for('dashboard'))\r\n\r\n    message = None\r\n\r\n    if request.method == \"POST\":\r\n        try: \r\n            usern = request.form.get(\"username\")\r\n            passw = request.form.get(\"password\")\r\n            passw_hash = bcrypt.generate_password_hash(passw).decode('utf-8')\r\n\r\n            result = db.execute(\"INSERT INTO accounts (username, password) VALUES (:u, :p)\", {\"u\": usern, \"p\": passw_hash})\r\n            db.commit()\r\n\r\n            if result.rowcount > 0:\r\n                session['user'] = usern\r\n                return redirect(url_for('dashboard'))\r\n\r\n        except exc.IntegrityError:\r\n            message = \"Username already exists.\"\r\n            db.execute(\"ROLLBACK\")\r\n            db.commit()\r\n\r\n    return render_template(\"registration.html\", message=message)", "func_src_after": "@app.route(\"/register\", methods=[\"GET\", \"POST\"])\r\ndef register():\r\n    if 'user' in session:\r\n        return redirect(url_for('dashboard'))\r\n\r\n    message = None\r\n\r\n    if request.method == \"POST\":\r\n        try: \r\n            usern = request.form.get(\"username\")\r\n            passw = request.form.get(\"password\")\r\n            passw_hash = bcrypt.generate_password_hash(passw).decode('utf-8')\r\n\r\n            result = db.execute(\"INSERT INTO user (username, password) VALUES (:u, :p)\", {\"u\": usern, \"p\": passw_hash})\r\n            db.commit()\r\n\r\n            if result.rowcount > 0:\r\n                session['user'] = usern\r\n                return redirect(url_for('dashboard'))\r\n\r\n        except exc.IntegrityError:\r\n            message = \"Username already exists.\"\r\n            db.execute(\"ROLLBACK\")\r\n            db.commit()\r\n\r\n    return render_template(\"registration.html\", message=message)", "line_changes": {"deleted": [{"line_no": 14, "char_start": 395, "char_end": 520, "line": "            result = db.execute(\"INSERT INTO accounts (username, password) VALUES (:u, :p)\", {\"u\": usern, \"p\": passw_hash})\r\n"}], "added": [{"line_no": 14, "char_start": 395, "char_end": 516, "line": "            result = db.execute(\"INSERT INTO user (username, password) VALUES (:u, :p)\", {\"u\": usern, \"p\": passw_hash})\r\n"}]}, "char_changes": {"deleted": [{"char_start": 440, "char_end": 448, "chars": "accounts"}], "added": [{"char_start": 440, "char_end": 444, "chars": "user"}]}, "commit_link": "github.com/bentrab/music-reviewer-name-will-change/commit/ae8497f08cf390130db238bda6af40cf96f7b00a", "file_name": "run.py", "vul_type": "cwe-089"}
{"func_name": "put", "func_src_before": "    @jwt_required\n    def put(self, question_id=None, answer_id=None):\n        data = request.get_json(force=True)\n        response = Table.update(question_id, answer_id, data)\n        if response == 200:\n            response_object = {\n                'status': 'success',\n                'message': 'Update successful'\n            }\n            return make_response(jsonify(response_object)), 200\n        if response == 302:\n            response_object = {\n                'status': 'fail',\n                'message': 'Please provide correct answer and question id'\n            }\n            return make_response(jsonify(response_object)), 400\n        if response == 203:\n            response_object = {\n                'status': 'fail',\n                'message': 'Unauthorized request.'\n            }\n            return make_response(jsonify(response_object)), 401\n\n        else:\n            response_object = {\n                'status': 'fail',\n                'message': 'Please provide correct answer and question id'\n            }\n            return make_response(jsonify(response_object)), 400", "func_src_after": "    @jwt_required\n    def put(self, question_id=None, answer_id=None):\n        data = request.get_json(force=True)\n        data['question_id'] = question_id\n        data['answer_id'] = answer_id\n        data['user_id'] = session.get('user_id')\n\n        response = Table(data).update()\n        if response == 200:\n            response_object = {\n                'status': 'success',\n                'message': 'Update successful'\n            }\n            return make_response(jsonify(response_object)), 200\n        if response == 302:\n            response_object = {\n                'status': 'fail',\n                'message': 'Please provide correct answer and question id'\n            }\n            return make_response(jsonify(response_object)), 400\n        if response == 203:\n            response_object = {\n                'status': 'fail',\n                'message': 'Unauthorized request.'\n            }\n            return make_response(jsonify(response_object)), 401\n\n        else:\n            response_object = {\n                'status': 'fail',\n                'message': 'Please provide correct answer and question id'\n            }\n            return make_response(jsonify(response_object)), 400", "line_changes": {"deleted": [{"line_no": 4, "char_start": 115, "char_end": 177, "line": "        response = Table.update(question_id, answer_id, data)\n"}], "added": [{"line_no": 4, "char_start": 115, "char_end": 157, "line": "        data['question_id'] = question_id\n"}, {"line_no": 5, "char_start": 157, "char_end": 195, "line": "        data['answer_id'] = answer_id\n"}, {"line_no": 6, "char_start": 195, "char_end": 244, "line": "        data['user_id'] = session.get('user_id')\n"}, {"line_no": 7, "char_start": 244, "char_end": 245, "line": "\n"}, {"line_no": 8, "char_start": 245, "char_end": 285, "line": "        response = Table(data).update()\n"}]}, "char_changes": {"deleted": [{"char_start": 123, "char_end": 175, "chars": "response = Table.update(question_id, answer_id, data"}], "added": [{"char_start": 123, "char_end": 283, "chars": "data['question_id'] = question_id\n        data['answer_id'] = answer_id\n        data['user_id'] = session.get('user_id')\n\n        response = Table(data).update("}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/answers/api/v1/view.py", "vul_type": "cwe-089"}
{"func_name": "save", "func_src_before": "    def save(self, question_id, data):\n        \"\"\"\n        Creates an answer record in answers table\n        :param question_id: string: question id\n        :param data: dict: answer values\n        :return: None of inserted record\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\n                \"\"\"\n                INSERT INTO \n                    answers (user_id, answer_body, question_id)\n                values(\n                    '\"\"\" + str(session.get('user_id')) + \"\"\"',\n                    '\"\"\" + data.get('answer_body') + \"\"\"',\n                    '\"\"\" + question_id + \"\"\"'\n                )\n                \"\"\"\n            )\n\n            con.commit()\n            con.close()\n        except Exception as e:\n            print(e)\n            return None\n        con.close()\n        return data", "func_src_after": "    def save(self):\n        \"\"\"\n        Creates an answer record in answers table\n        :return: None of inserted record\n        \"\"\"\n        con, response = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"INSERT INTO answers (user_id, answer_body, question_id) VALUES (%s, %s, %s) RETURNING *; \"\n            cur.execute(query, (self.user_id, self.answer_body, self.question_id))\n            con.commit()\n            response = cur.fetchone()\n        except Exception as e:\n            print(e)\n        con.close()\n        return response", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 39, "line": "    def save(self, question_id, data):\n"}, {"line_no": 4, "char_start": 101, "char_end": 149, "line": "        :param question_id: string: question id\n"}, {"line_no": 5, "char_start": 149, "char_end": 190, "line": "        :param data: dict: answer values\n"}, {"line_no": 8, "char_start": 243, "char_end": 289, "line": "        con = psycopg2.connect(**self.config)\n"}, {"line_no": 11, "char_start": 358, "char_end": 383, "line": "            cur.execute(\n"}, {"line_no": 12, "char_start": 383, "char_end": 403, "line": "                \"\"\"\n"}, {"line_no": 13, "char_start": 403, "char_end": 432, "line": "                INSERT INTO \n"}, {"line_no": 14, "char_start": 432, "char_end": 496, "line": "                    answers (user_id, answer_body, question_id)\n"}, {"line_no": 15, "char_start": 496, "char_end": 520, "line": "                values(\n"}, {"line_no": 16, "char_start": 520, "char_end": 583, "line": "                    '\"\"\" + str(session.get('user_id')) + \"\"\"',\n"}, {"line_no": 17, "char_start": 583, "char_end": 642, "line": "                    '\"\"\" + data.get('answer_body') + \"\"\"',\n"}, {"line_no": 18, "char_start": 642, "char_end": 688, "line": "                    '\"\"\" + question_id + \"\"\"'\n"}, {"line_no": 19, "char_start": 688, "char_end": 706, "line": "                )\n"}, {"line_no": 20, "char_start": 706, "char_end": 726, "line": "                \"\"\"\n"}, {"line_no": 21, "char_start": 726, "char_end": 740, "line": "            )\n"}, {"line_no": 22, "char_start": 740, "char_end": 741, "line": "\n"}, {"line_no": 24, "char_start": 766, "char_end": 790, "line": "            con.close()\n"}, {"line_no": 27, "char_start": 842, "char_end": 866, "line": "            return None\n"}, {"line_no": 29, "char_start": 886, "char_end": 905, "line": "        return data\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 20, "line": "    def save(self):\n"}, {"line_no": 6, "char_start": 135, "char_end": 197, "line": "        con, response = psycopg2.connect(**self.config), None\n"}, {"line_no": 9, "char_start": 266, "char_end": 378, "line": "            query = \"INSERT INTO answers (user_id, answer_body, question_id) VALUES (%s, %s, %s) RETURNING *; \"\n"}, {"line_no": 10, "char_start": 378, "char_end": 461, "line": "            cur.execute(query, (self.user_id, self.answer_body, self.question_id))\n"}, {"line_no": 12, "char_start": 486, "char_end": 524, "line": "            response = cur.fetchone()\n"}, {"line_no": 16, "char_start": 596, "char_end": 619, "line": "        return response\n"}]}, "char_changes": {"deleted": [{"char_start": 17, "char_end": 36, "chars": ", question_id, data"}, {"char_start": 101, "char_end": 190, "chars": "        :param question_id: string: question id\n        :param data: dict: answer values\n"}, {"char_start": 370, "char_end": 740, "chars": "cur.execute(\n                \"\"\"\n                INSERT INTO \n                    answers (user_id, answer_body, question_id)\n                values(\n                    '\"\"\" + str(session.get('user_id')) + \"\"\"',\n                    '\"\"\" + data.get('answer_body') + \"\"\"',\n                    '\"\"\" + question_id + \"\"\"'\n                )\n                \"\"\"\n            )\n"}, {"char_start": 778, "char_end": 786, "chars": "con.clos"}, {"char_start": 842, "char_end": 866, "chars": "            return None\n"}, {"char_start": 901, "char_end": 905, "chars": "data"}], "added": [{"char_start": 146, "char_end": 156, "chars": ", response"}, {"char_start": 190, "char_end": 196, "chars": ", None"}, {"char_start": 278, "char_end": 460, "chars": "query = \"INSERT INTO answers (user_id, answer_body, question_id) VALUES (%s, %s, %s) RETURNING *; \"\n            cur.execute(query, (self.user_id, self.answer_body, self.question_id))"}, {"char_start": 498, "char_end": 520, "chars": "response = cur.fetchon"}, {"char_start": 611, "char_end": 619, "chars": "response"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/answers/models.py", "vul_type": "cwe-089"}
{"func_name": "query", "func_src_before": "    def query(self):\n        \"\"\"\n        Fetch all records from a answers table\n        :return: list: query set\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        cur.execute(\n            \"\"\"\n            SELECT\n               *,\n               ( \n                SELECT \n                    count(*) from votes \n                WHERE \n                    votes.answer_id=answers.answer_id\n                AND\n                    vote=true\n                ) as upVotes,\n                ( \n                SELECT \n                    count(*) from votes \n                WHERE \n                    votes.answer_id=answers.answer_id\n                AND\n                    vote=false\n                ) as downVotes\n            FROM \n                answers\n            \"\"\"\n        )\n        queryset_list = cur.fetchall()\n        con.close()\n        return queryset_list", "func_src_after": "    def query(self):\n        \"\"\"\n        Fetch all records from a answers table\n        :return: list: query set\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        cur.execute(\n            \"\"\" SELECT *, ( SELECT  count(*) from votes \n                WHERE votes.answer_id=answers.answer_id AND vote=true ) as upVotes,\n                ( SELECT count(*) from votes WHERE votes.answer_id=answers.answer_id\n                AND vote=false ) as downVotes FROM  answers\n            \"\"\"\n        )\n        queryset_list = cur.fetchall()\n        con.close()\n        return queryset_list", "line_changes": {"deleted": [{"line_no": 9, "char_start": 248, "char_end": 264, "line": "            \"\"\"\n"}, {"line_no": 10, "char_start": 264, "char_end": 283, "line": "            SELECT\n"}, {"line_no": 11, "char_start": 283, "char_end": 301, "line": "               *,\n"}, {"line_no": 12, "char_start": 301, "char_end": 319, "line": "               ( \n"}, {"line_no": 13, "char_start": 319, "char_end": 343, "line": "                SELECT \n"}, {"line_no": 14, "char_start": 343, "char_end": 384, "line": "                    count(*) from votes \n"}, {"line_no": 15, "char_start": 384, "char_end": 407, "line": "                WHERE \n"}, {"line_no": 16, "char_start": 407, "char_end": 461, "line": "                    votes.answer_id=answers.answer_id\n"}, {"line_no": 17, "char_start": 461, "char_end": 481, "line": "                AND\n"}, {"line_no": 18, "char_start": 481, "char_end": 511, "line": "                    vote=true\n"}, {"line_no": 19, "char_start": 511, "char_end": 541, "line": "                ) as upVotes,\n"}, {"line_no": 20, "char_start": 541, "char_end": 560, "line": "                ( \n"}, {"line_no": 21, "char_start": 560, "char_end": 584, "line": "                SELECT \n"}, {"line_no": 22, "char_start": 584, "char_end": 625, "line": "                    count(*) from votes \n"}, {"line_no": 23, "char_start": 625, "char_end": 648, "line": "                WHERE \n"}, {"line_no": 24, "char_start": 648, "char_end": 702, "line": "                    votes.answer_id=answers.answer_id\n"}, {"line_no": 25, "char_start": 702, "char_end": 722, "line": "                AND\n"}, {"line_no": 26, "char_start": 722, "char_end": 753, "line": "                    vote=false\n"}, {"line_no": 27, "char_start": 753, "char_end": 784, "line": "                ) as downVotes\n"}, {"line_no": 28, "char_start": 784, "char_end": 802, "line": "            FROM \n"}, {"line_no": 29, "char_start": 802, "char_end": 826, "line": "                answers\n"}], "added": [{"line_no": 9, "char_start": 248, "char_end": 305, "line": "            \"\"\" SELECT *, ( SELECT  count(*) from votes \n"}, {"line_no": 10, "char_start": 305, "char_end": 389, "line": "                WHERE votes.answer_id=answers.answer_id AND vote=true ) as upVotes,\n"}, {"line_no": 11, "char_start": 389, "char_end": 474, "line": "                ( SELECT count(*) from votes WHERE votes.answer_id=answers.answer_id\n"}, {"line_no": 12, "char_start": 474, "char_end": 534, "line": "                AND vote=false ) as downVotes FROM  answers\n"}]}, "char_changes": {"deleted": [{"char_start": 263, "char_end": 361, "chars": "\n            SELECT\n               *,\n               ( \n                SELECT \n                  "}, {"char_start": 406, "char_end": 427, "chars": "\n                    "}, {"char_start": 460, "char_end": 816, "chars": "\n                AND\n                    vote=true\n                ) as upVotes,\n                ( \n                SELECT \n                    count(*) from votes \n                WHERE \n                    votes.answer_id=answers.answer_id\n                AND\n                    vote=false\n                ) as downVotes\n            FROM \n              "}], "added": [{"char_start": 263, "char_end": 282, "chars": " SELECT *, ( SELECT"}, {"char_start": 360, "char_end": 524, "chars": " AND vote=true ) as upVotes,\n                ( SELECT count(*) from votes WHERE votes.answer_id=answers.answer_id\n                AND vote=false ) as downVotes FROM"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/answers/models.py", "vul_type": "cwe-089"}
{"func_name": "filter_by", "func_src_before": "    def filter_by(self, instance_id=None, user_id=None):\n        \"\"\"\n        Select a column(s) from answer table\n        :param instance_id: string: answer id\n        :param user_id: string: user id\n        :return: list: queryset list\n        \"\"\"\n        filter_column = 'question_id' if instance_id else 'user_id'\n        filter_value = instance_id if instance_id else user_id\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n        cur.execute(\"select * from {} WHERE {}= '{}'\".format(self.table, filter_column, filter_value))\n        queryset_list = cur.fetchall()\n        con.close()\n        return queryset_list", "func_src_after": "    def filter_by(self):\n        \"\"\"\n        Select a column(s) from answer table\n        :return: list: queryset list\n        \"\"\"\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            query = \"SELECT * FROM answers WHERE answer_id=%s\"\n            cur.execute(query, self.answer_id)\n            queryset_list = cur.fetchall()\n            con.close()\n            return queryset_list\n        except:\n            return []", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 57, "line": "    def filter_by(self, instance_id=None, user_id=None):\n"}, {"line_no": 4, "char_start": 114, "char_end": 160, "line": "        :param instance_id: string: answer id\n"}, {"line_no": 5, "char_start": 160, "char_end": 200, "line": "        :param user_id: string: user id\n"}, {"line_no": 8, "char_start": 249, "char_end": 317, "line": "        filter_column = 'question_id' if instance_id else 'user_id'\n"}, {"line_no": 9, "char_start": 317, "char_end": 380, "line": "        filter_value = instance_id if instance_id else user_id\n"}, {"line_no": 10, "char_start": 380, "char_end": 426, "line": "        con = psycopg2.connect(**self.config)\n"}, {"line_no": 11, "char_start": 426, "char_end": 494, "line": "        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n"}, {"line_no": 12, "char_start": 494, "char_end": 597, "line": "        cur.execute(\"select * from {} WHERE {}= '{}'\".format(self.table, filter_column, filter_value))\n"}, {"line_no": 13, "char_start": 597, "char_end": 636, "line": "        queryset_list = cur.fetchall()\n"}, {"line_no": 14, "char_start": 636, "char_end": 656, "line": "        con.close()\n"}, {"line_no": 15, "char_start": 656, "char_end": 684, "line": "        return queryset_list\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 25, "line": "    def filter_by(self):\n"}, {"line_no": 6, "char_start": 131, "char_end": 144, "line": "        try:\n"}, {"line_no": 7, "char_start": 144, "char_end": 194, "line": "            con = psycopg2.connect(**self.config)\n"}, {"line_no": 8, "char_start": 194, "char_end": 254, "line": "            cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 9, "char_start": 254, "char_end": 317, "line": "            query = \"SELECT * FROM answers WHERE answer_id=%s\"\n"}, {"line_no": 10, "char_start": 317, "char_end": 364, "line": "            cur.execute(query, self.answer_id)\n"}, {"line_no": 11, "char_start": 364, "char_end": 407, "line": "            queryset_list = cur.fetchall()\n"}, {"line_no": 12, "char_start": 407, "char_end": 431, "line": "            con.close()\n"}, {"line_no": 13, "char_start": 431, "char_end": 464, "line": "            return queryset_list\n"}, {"line_no": 14, "char_start": 464, "char_end": 480, "line": "        except:\n"}, {"line_no": 15, "char_start": 480, "char_end": 501, "line": "            return []\n"}]}, "char_changes": {"deleted": [{"char_start": 22, "char_end": 54, "chars": ", instance_id=None, user_id=None"}, {"char_start": 123, "char_end": 380, "chars": "param instance_id: string: answer id\n        :param user_id: string: user id\n        :return: list: queryset list\n        \"\"\"\n        filter_column = 'question_id' if instance_id else 'user_id'\n        filter_value = instance_id if instance_id else user_id\n"}, {"char_start": 466, "char_end": 482, "chars": "psycopg2.extras."}, {"char_start": 502, "char_end": 597, "chars": "cur.execute(\"select * from {} WHERE {}= '{}'\".format(self.table, filter_column, filter_value))\n"}], "added": [{"char_start": 91, "char_end": 148, "chars": "return: list: queryset list\n        \"\"\"\n        try:\n    "}, {"char_start": 202, "char_end": 203, "chars": " "}, {"char_start": 203, "char_end": 206, "chars": "   "}, {"char_start": 238, "char_end": 242, "chars": "Real"}, {"char_start": 262, "char_end": 368, "chars": "    query = \"SELECT * FROM answers WHERE answer_id=%s\"\n            cur.execute(query, self.answer_id)\n    "}, {"char_start": 415, "char_end": 419, "chars": "    "}, {"char_start": 431, "char_end": 435, "chars": "    "}, {"char_start": 463, "char_end": 501, "chars": "\n        except:\n            return []"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/answers/models.py", "vul_type": "cwe-089"}
{"func_name": "question_author", "func_src_before": "    def question_author(self, question_id):\n        con = psycopg2.connect(**self.config)\n        try:\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            cur.execute(\n                \"\"\" \n                SELECT \n                    user_id \n                FROM \n                    questions \n                WHERE \n                    question_id=\"\"\" + question_id + \"\"\"\n                \"\"\"\n            )\n            return cur.fetchall()\n\n        except Exception as e:\n            print(e)\n        con.close()\n        return False", "func_src_after": "    def question_author(self):\n        con = psycopg2.connect(**self.config)\n        try:\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            query = \"SELECT user_id FROM questions WHERE question_id=%s\"\n            cur.execute(query, self.question_id)\n            return cur.fetchall()\n\n        except Exception as e:\n            print(e)\n        con.close()\n        return False", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 44, "line": "    def question_author(self, question_id):\n"}, {"line_no": 5, "char_start": 163, "char_end": 188, "line": "            cur.execute(\n"}, {"line_no": 6, "char_start": 188, "char_end": 209, "line": "                \"\"\" \n"}, {"line_no": 7, "char_start": 209, "char_end": 233, "line": "                SELECT \n"}, {"line_no": 8, "char_start": 233, "char_end": 262, "line": "                    user_id \n"}, {"line_no": 9, "char_start": 262, "char_end": 284, "line": "                FROM \n"}, {"line_no": 10, "char_start": 284, "char_end": 315, "line": "                    questions \n"}, {"line_no": 11, "char_start": 315, "char_end": 338, "line": "                WHERE \n"}, {"line_no": 12, "char_start": 338, "char_end": 394, "line": "                    question_id=\"\"\" + question_id + \"\"\"\n"}, {"line_no": 13, "char_start": 394, "char_end": 414, "line": "                \"\"\"\n"}, {"line_no": 14, "char_start": 414, "char_end": 428, "line": "            )\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 31, "line": "    def question_author(self):\n"}, {"line_no": 5, "char_start": 150, "char_end": 223, "line": "            query = \"SELECT user_id FROM questions WHERE question_id=%s\"\n"}, {"line_no": 6, "char_start": 223, "char_end": 272, "line": "            cur.execute(query, self.question_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 28, "char_end": 41, "chars": ", question_id"}, {"char_start": 175, "char_end": 426, "chars": "cur.execute(\n                \"\"\" \n                SELECT \n                    user_id \n                FROM \n                    questions \n                WHERE \n                    question_id=\"\"\" + question_id + \"\"\"\n                \"\"\"\n            "}], "added": [{"char_start": 31, "char_end": 31, "chars": ""}, {"char_start": 162, "char_end": 270, "chars": "query = \"SELECT user_id FROM questions WHERE question_id=%s\"\n            cur.execute(query, self.question_id"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/answers/models.py", "vul_type": "cwe-089"}
{"func_name": "answer_author", "func_src_before": "    def answer_author(self, answer_id):\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            cur.execute(\n                \"\"\" \n                SELECT \n                    user_id \n                FROM \n                    answers \n                WHERE \n                    answer_id=\"\"\" + answer_id + \"\"\"\n                \"\"\"\n            )\n            queryset_list = cur.fetchall()\n            con.close()\n            return queryset_list\n        except Exception as e:\n            print(e)\n            return False", "func_src_after": "    def answer_author(self):\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            query = \"SELECT user_id FROM answers WHERE answer_id=%s\"\n            cur.execute(query, self.answer_id)\n            queryset_list = cur.fetchall()\n            con.close()\n            return queryset_list\n        except Exception as e:\n            return False", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 40, "line": "    def answer_author(self, answer_id):\n"}, {"line_no": 5, "char_start": 163, "char_end": 188, "line": "            cur.execute(\n"}, {"line_no": 6, "char_start": 188, "char_end": 209, "line": "                \"\"\" \n"}, {"line_no": 7, "char_start": 209, "char_end": 233, "line": "                SELECT \n"}, {"line_no": 8, "char_start": 233, "char_end": 262, "line": "                    user_id \n"}, {"line_no": 9, "char_start": 262, "char_end": 284, "line": "                FROM \n"}, {"line_no": 10, "char_start": 284, "char_end": 313, "line": "                    answers \n"}, {"line_no": 11, "char_start": 313, "char_end": 336, "line": "                WHERE \n"}, {"line_no": 12, "char_start": 336, "char_end": 388, "line": "                    answer_id=\"\"\" + answer_id + \"\"\"\n"}, {"line_no": 13, "char_start": 388, "char_end": 408, "line": "                \"\"\"\n"}, {"line_no": 14, "char_start": 408, "char_end": 422, "line": "            )\n"}, {"line_no": 19, "char_start": 553, "char_end": 574, "line": "            print(e)\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 29, "line": "    def answer_author(self):\n"}, {"line_no": 5, "char_start": 152, "char_end": 221, "line": "            query = \"SELECT user_id FROM answers WHERE answer_id=%s\"\n"}, {"line_no": 6, "char_start": 221, "char_end": 268, "line": "            cur.execute(query, self.answer_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 26, "char_end": 37, "chars": ", answer_id"}, {"char_start": 175, "char_end": 420, "chars": "cur.execute(\n                \"\"\" \n                SELECT \n                    user_id \n                FROM \n                    answers \n                WHERE \n                    answer_id=\"\"\" + answer_id + \"\"\"\n                \"\"\"\n            "}, {"char_start": 553, "char_end": 574, "chars": "            print(e)\n"}], "added": [{"char_start": 29, "char_end": 29, "chars": ""}, {"char_start": 164, "char_end": 266, "chars": "query = \"SELECT user_id FROM answers WHERE answer_id=%s\"\n            cur.execute(query, self.answer_id"}, {"char_start": 368, "char_end": 368, "chars": ""}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/answers/models.py", "vul_type": "cwe-089"}
{"func_name": "update_accept_field", "func_src_before": "    def update_accept_field(self, question_id, answer_id, data=None):\n        \"\"\"\n        Update an answer column\n        :param question_id: string: question id\n        :param answer_id: string: answer id\n        :param data: dict: updated values\n        :return: bool:\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\n                \"\"\"\n                UPDATE answers SET \n                    accepted='\"\"\" + data.get('accepted') + \"\"\"'\n                WHERE \n                    answer_id=\"\"\" + answer_id + \"\"\"\n                AND question_id=\"\"\" + question_id + \"\"\"\n                \"\"\"\n            )\n\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        con.close()\n        return True", "func_src_after": "    def update_accept_field(self):\n        \"\"\"\n        Update an answer column\n        :return: bool:\n        \"\"\"\n        con, result = psycopg2.connect(**self.config), True\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"UPDATE answers SET accepted=%s WHERE answer_id=%s AND question_id=%s\"\n            cur.execute(query, (self.accepted, self.answer_id, self.question_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            result = False\n        con.close()\n        return result", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 70, "line": "    def update_accept_field(self, question_id, answer_id, data=None):\n"}, {"line_no": 4, "char_start": 114, "char_end": 162, "line": "        :param question_id: string: question id\n"}, {"line_no": 5, "char_start": 162, "char_end": 206, "line": "        :param answer_id: string: answer id\n"}, {"line_no": 6, "char_start": 206, "char_end": 248, "line": "        :param data: dict: updated values\n"}, {"line_no": 9, "char_start": 283, "char_end": 329, "line": "        con = psycopg2.connect(**self.config)\n"}, {"line_no": 12, "char_start": 398, "char_end": 423, "line": "            cur.execute(\n"}, {"line_no": 13, "char_start": 423, "char_end": 443, "line": "                \"\"\"\n"}, {"line_no": 14, "char_start": 443, "char_end": 479, "line": "                UPDATE answers SET \n"}, {"line_no": 15, "char_start": 479, "char_end": 543, "line": "                    accepted='\"\"\" + data.get('accepted') + \"\"\"'\n"}, {"line_no": 16, "char_start": 543, "char_end": 566, "line": "                WHERE \n"}, {"line_no": 17, "char_start": 566, "char_end": 618, "line": "                    answer_id=\"\"\" + answer_id + \"\"\"\n"}, {"line_no": 18, "char_start": 618, "char_end": 674, "line": "                AND question_id=\"\"\" + question_id + \"\"\"\n"}, {"line_no": 19, "char_start": 674, "char_end": 694, "line": "                \"\"\"\n"}, {"line_no": 20, "char_start": 694, "char_end": 708, "line": "            )\n"}, {"line_no": 21, "char_start": 708, "char_end": 709, "line": "\n"}, {"line_no": 25, "char_start": 786, "char_end": 810, "line": "            con.close()\n"}, {"line_no": 26, "char_start": 810, "char_end": 835, "line": "            return False\n"}, {"line_no": 28, "char_start": 855, "char_end": 874, "line": "        return True\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 35, "line": "    def update_accept_field(self):\n"}, {"line_no": 6, "char_start": 114, "char_end": 174, "line": "        con, result = psycopg2.connect(**self.config), True\n"}, {"line_no": 9, "char_start": 243, "char_end": 334, "line": "            query = \"UPDATE answers SET accepted=%s WHERE answer_id=%s AND question_id=%s\"\n"}, {"line_no": 10, "char_start": 334, "char_end": 416, "line": "            cur.execute(query, (self.accepted, self.answer_id, self.question_id))\n"}, {"line_no": 14, "char_start": 493, "char_end": 520, "line": "            result = False\n"}, {"line_no": 16, "char_start": 540, "char_end": 561, "line": "        return result\n"}]}, "char_changes": {"deleted": [{"char_start": 32, "char_end": 67, "chars": ", question_id, answer_id, data=None"}, {"char_start": 114, "char_end": 248, "chars": "        :param question_id: string: question id\n        :param answer_id: string: answer id\n        :param data: dict: updated values\n"}, {"char_start": 410, "char_end": 708, "chars": "cur.execute(\n                \"\"\"\n                UPDATE answers SET \n                    accepted='\"\"\" + data.get('accepted') + \"\"\"'\n                WHERE \n                    answer_id=\"\"\" + answer_id + \"\"\"\n                AND question_id=\"\"\" + question_id + \"\"\"\n                \"\"\"\n            )\n"}, {"char_start": 798, "char_end": 828, "chars": "con.close()\n            return"}, {"char_start": 870, "char_end": 874, "chars": "True"}], "added": [{"char_start": 125, "char_end": 133, "chars": ", result"}, {"char_start": 167, "char_end": 173, "chars": ", True"}, {"char_start": 255, "char_end": 415, "chars": "query = \"UPDATE answers SET accepted=%s WHERE answer_id=%s AND question_id=%s\"\n            cur.execute(query, (self.accepted, self.answer_id, self.question_id))"}, {"char_start": 505, "char_end": 513, "chars": "result ="}, {"char_start": 555, "char_end": 561, "chars": "result"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/answers/models.py", "vul_type": "cwe-089"}
{"func_name": "update_answer", "func_src_before": "    def update_answer(self, answer_id, data=None):\n        \"\"\"\n        Update an answer column\n        :param question_id: string: question id\n        :param answer_id: string: answer id\n        :param data: dict: updated values\n        :return: bool:\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\n                \"\"\"\n                UPDATE answers SET \n                    answer_body='\"\"\" + data.get('body') + \"\"\"'\n                WHERE \n                    answer_id=\"\"\" + answer_id + \"\"\"\n                \"\"\"\n            )\n\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        con.close()\n        return True", "func_src_after": "    def update_answer(self):\n        \"\"\"\n        Update an answer column\n        :return: bool:\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"UPDATE answers SET answer_body=%s WHERE answer_id=%s\"\n            cur.execute(query, (self.answer_body, self.answer_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        con.close()\n        return True", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 51, "line": "    def update_answer(self, answer_id, data=None):\n"}, {"line_no": 4, "char_start": 95, "char_end": 143, "line": "        :param question_id: string: question id\n"}, {"line_no": 5, "char_start": 143, "char_end": 187, "line": "        :param answer_id: string: answer id\n"}, {"line_no": 6, "char_start": 187, "char_end": 229, "line": "        :param data: dict: updated values\n"}, {"line_no": 12, "char_start": 379, "char_end": 404, "line": "            cur.execute(\n"}, {"line_no": 13, "char_start": 404, "char_end": 424, "line": "                \"\"\"\n"}, {"line_no": 14, "char_start": 424, "char_end": 460, "line": "                UPDATE answers SET \n"}, {"line_no": 15, "char_start": 460, "char_end": 523, "line": "                    answer_body='\"\"\" + data.get('body') + \"\"\"'\n"}, {"line_no": 16, "char_start": 523, "char_end": 546, "line": "                WHERE \n"}, {"line_no": 17, "char_start": 546, "char_end": 598, "line": "                    answer_id=\"\"\" + answer_id + \"\"\"\n"}, {"line_no": 18, "char_start": 598, "char_end": 618, "line": "                \"\"\"\n"}, {"line_no": 19, "char_start": 618, "char_end": 632, "line": "            )\n"}, {"line_no": 20, "char_start": 632, "char_end": 633, "line": "\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 29, "line": "    def update_answer(self):\n"}, {"line_no": 9, "char_start": 223, "char_end": 298, "line": "            query = \"UPDATE answers SET answer_body=%s WHERE answer_id=%s\"\n"}, {"line_no": 10, "char_start": 298, "char_end": 365, "line": "            cur.execute(query, (self.answer_body, self.answer_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 26, "char_end": 48, "chars": ", answer_id, data=None"}, {"char_start": 95, "char_end": 229, "chars": "        :param question_id: string: question id\n        :param answer_id: string: answer id\n        :param data: dict: updated values\n"}, {"char_start": 391, "char_end": 632, "chars": "cur.execute(\n                \"\"\"\n                UPDATE answers SET \n                    answer_body='\"\"\" + data.get('body') + \"\"\"'\n                WHERE \n                    answer_id=\"\"\" + answer_id + \"\"\"\n                \"\"\"\n            )\n"}], "added": [{"char_start": 29, "char_end": 29, "chars": ""}, {"char_start": 235, "char_end": 364, "chars": "query = \"UPDATE answers SET answer_body=%s WHERE answer_id=%s\"\n            cur.execute(query, (self.answer_body, self.answer_id))"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/answers/models.py", "vul_type": "cwe-089"}
{"func_name": "filter_by", "func_src_before": "    def filter_by(self, email=None, user_id=None):\n        # filter user by email or id\n        filter_column = 'user_id' if user_id else 'email'\n        filter_value = user_id if user_id else email\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n        cur.execute(\"select * from {} WHERE {}='{}'\".format(self.table, filter_column, filter_value))\n        queryset_list = cur.fetchall()\n        con.close()\n        return queryset_list", "func_src_after": "    def filter_by(self):\n        con, queryset_list = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\"select * from {} WHERE user_id='{}'\".format(self.table, self.user_id))\n            queryset_list = cur.fetchall()\n        except Exception as e:\n            print(e)\n        con.close()\n        return queryset_list", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 51, "line": "    def filter_by(self, email=None, user_id=None):\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 25, "line": "    def filter_by(self):\n"}, {"line_no": 2, "char_start": 25, "char_end": 92, "line": "        con, queryset_list = psycopg2.connect(**self.config), None\n"}, {"line_no": 3, "char_start": 92, "char_end": 148, "line": "        cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 4, "char_start": 148, "char_end": 161, "line": "        try:\n"}, {"line_no": 5, "char_start": 161, "char_end": 257, "line": "            cur.execute(\"select * from {} WHERE user_id='{}'\".format(self.table, self.user_id))\n"}, {"line_no": 6, "char_start": 257, "char_end": 300, "line": "            queryset_list = cur.fetchall()\n"}, {"line_no": 7, "char_start": 300, "char_end": 331, "line": "        except Exception as e:\n"}, {"line_no": 8, "char_start": 331, "char_end": 352, "line": "            print(e)\n"}, {"line_no": 9, "char_start": 352, "char_end": 372, "line": "        con.close()\n"}, {"line_no": 10, "char_start": 372, "char_end": 400, "line": "        return queryset_list\n"}]}, "char_changes": {"deleted": [{"char_start": 22, "char_end": 210, "chars": ", email=None, user_id=None):\n        # filter user by email or id\n        filter_column = 'user_id' if user_id else 'email'\n        filter_value = user_id if user_id else email\n        con"}, {"char_start": 285, "char_end": 313, "chars": "psycopg2.extras.DictCursor)\n"}, {"char_start": 357, "char_end": 359, "chars": "{}"}, {"char_start": 385, "char_end": 415, "chars": "filter_column, filter_value))\n"}], "added": [{"char_start": 22, "char_end": 51, "chars": "):\n        con, queryset_list"}, {"char_start": 85, "char_end": 91, "chars": ", None"}, {"char_start": 132, "char_end": 165, "chars": "RealDictCursor)\n        try:\n    "}, {"char_start": 209, "char_end": 216, "chars": "user_id"}, {"char_start": 242, "char_end": 261, "chars": "self.user_id))\n    "}, {"char_start": 300, "char_end": 352, "chars": "        except Exception as e:\n            print(e)\n"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/auth/models.py", "vul_type": "cwe-089"}
{"func_name": "delete", "func_src_before": "    def delete(self, instance_id, data=None):\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n\n            cur.execute(\n                \"\"\"\n                    DELETE FROM \n                        users \n                    WHERE\n                        email='\"\"\" + data.get('email') + \"\"\"'\n                \"\"\"\n            )\n            con.commit()\n            con.close()\n        except Exception as e:\n            print(e)\n            con.close()\n        return True", "func_src_after": "    def delete(self):\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n        try:\n            query = \"DELETE FROM users WHERE email=%s\"\n            cur.execute(query, self.email)\n            con.commit()\n            con.close()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 46, "line": "    def delete(self, instance_id, data=None):\n"}, {"line_no": 3, "char_start": 59, "char_end": 109, "line": "            con = psycopg2.connect(**self.config)\n"}, {"line_no": 4, "char_start": 109, "char_end": 181, "line": "            cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n"}, {"line_no": 5, "char_start": 181, "char_end": 182, "line": "\n"}, {"line_no": 6, "char_start": 182, "char_end": 207, "line": "            cur.execute(\n"}, {"line_no": 7, "char_start": 207, "char_end": 227, "line": "                \"\"\"\n"}, {"line_no": 8, "char_start": 227, "char_end": 260, "line": "                    DELETE FROM \n"}, {"line_no": 9, "char_start": 260, "char_end": 291, "line": "                        users \n"}, {"line_no": 10, "char_start": 291, "char_end": 317, "line": "                    WHERE\n"}, {"line_no": 11, "char_start": 317, "char_end": 379, "line": "                        email='\"\"\" + data.get('email') + \"\"\"'\n"}, {"line_no": 12, "char_start": 379, "char_end": 399, "line": "                \"\"\"\n"}, {"line_no": 13, "char_start": 399, "char_end": 413, "line": "            )\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 22, "line": "    def delete(self):\n"}, {"line_no": 2, "char_start": 22, "char_end": 68, "line": "        con = psycopg2.connect(**self.config)\n"}, {"line_no": 3, "char_start": 68, "char_end": 136, "line": "        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n"}, {"line_no": 5, "char_start": 149, "char_end": 204, "line": "            query = \"DELETE FROM users WHERE email=%s\"\n"}, {"line_no": 6, "char_start": 204, "char_end": 247, "line": "            cur.execute(query, self.email)\n"}, {"line_no": 12, "char_start": 372, "char_end": 397, "line": "            return False\n"}]}, "char_changes": {"deleted": [{"char_start": 19, "char_end": 63, "chars": ", instance_id, data=None):\n        try:\n    "}, {"char_start": 109, "char_end": 113, "chars": "    "}, {"char_start": 181, "char_end": 182, "chars": "\n"}, {"char_start": 190, "char_end": 411, "chars": "    cur.execute(\n                \"\"\"\n                    DELETE FROM \n                        users \n                    WHERE\n                        email='\"\"\" + data.get('email') + \"\"\"'\n                \"\"\"\n            "}], "added": [{"char_start": 19, "char_end": 22, "chars": "):\n"}, {"char_start": 144, "char_end": 245, "chars": "try:\n            query = \"DELETE FROM users WHERE email=%s\"\n            cur.execute(query, self.email"}, {"char_start": 372, "char_end": 397, "chars": "            return False\n"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/auth/models.py", "vul_type": "cwe-089"}
{"func_name": "save", "func_src_before": "    def save(self, data):\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n\n        cur.execute(\n            \"\"\"\n            INSERT INTO users (username, email, password)\n            values(\n                '\"\"\" + data.get('username') + \"\"\"',\n                '\"\"\" + data.get('email') + \"\"\"',\n                '\"\"\" + data.get('password') + \"\"\"'\n            )\n            \"\"\"\n        )\n        con.commit()\n        con.close()\n        return data", "func_src_after": "    def save(self):\n        con, response = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"INSERT INTO users (username, email, password) values(%s, %s, %s) RETURNING *\"\n            cur.execute(query, (self.username, self.email, self.password))\n            con.commit()\n            response = cur.fetchone()\n        except Exception as e:\n            print(e)\n        con.close()\n        return response", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 26, "line": "    def save(self, data):\n"}, {"line_no": 17, "char_start": 489, "char_end": 508, "line": "        return data\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 20, "line": "    def save(self):\n"}, {"line_no": 2, "char_start": 20, "char_end": 82, "line": "        con, response = psycopg2.connect(**self.config), None\n"}, {"line_no": 3, "char_start": 82, "char_end": 138, "line": "        cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 4, "char_start": 138, "char_end": 151, "line": "        try:\n"}, {"line_no": 5, "char_start": 151, "char_end": 250, "line": "            query = \"INSERT INTO users (username, email, password) values(%s, %s, %s) RETURNING *\"\n"}, {"line_no": 6, "char_start": 250, "char_end": 325, "line": "            cur.execute(query, (self.username, self.email, self.password))\n"}, {"line_no": 7, "char_start": 325, "char_end": 350, "line": "            con.commit()\n"}, {"line_no": 8, "char_start": 350, "char_end": 388, "line": "            response = cur.fetchone()\n"}, {"line_no": 9, "char_start": 388, "char_end": 419, "line": "        except Exception as e:\n"}, {"line_no": 10, "char_start": 419, "char_end": 440, "line": "            print(e)\n"}]}, "char_changes": {"deleted": [{"char_start": 17, "char_end": 23, "chars": ", data"}, {"char_start": 112, "char_end": 128, "chars": "psycopg2.extras."}, {"char_start": 140, "char_end": 141, "chars": "\n"}, {"char_start": 149, "char_end": 161, "chars": "cur.execute("}, {"char_start": 174, "char_end": 190, "chars": "\"\"\"\n            "}, {"char_start": 235, "char_end": 465, "chars": "\n            values(\n                '\"\"\" + data.get('username') + \"\"\"',\n                '\"\"\" + data.get('email') + \"\"\"',\n                '\"\"\" + data.get('password') + \"\"\"'\n            )\n            \"\"\"\n        )\n        con.commi"}, {"char_start": 504, "char_end": 508, "chars": "data"}], "added": [{"char_start": 31, "char_end": 41, "chars": ", response"}, {"char_start": 75, "char_end": 81, "chars": ", None"}, {"char_start": 122, "char_end": 126, "chars": "Real"}, {"char_start": 146, "char_end": 150, "chars": "try:"}, {"char_start": 163, "char_end": 172, "chars": "query = \""}, {"char_start": 217, "char_end": 418, "chars": " values(%s, %s, %s) RETURNING *\"\n            cur.execute(query, (self.username, self.email, self.password))\n            con.commit()\n            response = cur.fetchone()\n        except Exception as e:"}, {"char_start": 431, "char_end": 435, "chars": "prin"}, {"char_start": 437, "char_end": 438, "chars": "e"}, {"char_start": 475, "char_end": 483, "chars": "response"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/auth/models.py", "vul_type": "cwe-089"}
{"func_name": "save", "func_src_before": "    def save(self, answer_id=None, data=None):\n        \"\"\"\n        Insert a comment in comments table\n        :param answer_id: string: answer id\n        :param data: dict: comment values\n        :return: True if record values are inserted successfully else false\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\n                \"\"\"\n                INSERT INTO \n                    comments(user_id, answer_id, comment_body)\n                values(\n                    \"\"\" + str(session.get('user_id')) + \"\"\",\n                    \"\"\" + str(answer_id) + \"\"\",\n                    '\"\"\" + str(data.get('comment_body')) + \"\"\"'\n                )\n                \"\"\"\n            )\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True", "func_src_after": "    def save(self):\n        \"\"\"\n        Insert a comment in comments table\n        :return: True if record values are inserted successfully else false\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"INSERT INTO comments(user_id, answer_id, comment_body) values(%s, %s, %s) \"\n            cur.execute(query, (session.get('user_id'), self.answer_id, self.comment_body))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 47, "line": "    def save(self, answer_id=None, data=None):\n"}, {"line_no": 4, "char_start": 102, "char_end": 146, "line": "        :param answer_id: string: answer id\n"}, {"line_no": 5, "char_start": 146, "char_end": 188, "line": "        :param data: dict: comment values\n"}, {"line_no": 11, "char_start": 391, "char_end": 416, "line": "            cur.execute(\n"}, {"line_no": 12, "char_start": 416, "char_end": 436, "line": "                \"\"\"\n"}, {"line_no": 13, "char_start": 436, "char_end": 465, "line": "                INSERT INTO \n"}, {"line_no": 14, "char_start": 465, "char_end": 528, "line": "                    comments(user_id, answer_id, comment_body)\n"}, {"line_no": 15, "char_start": 528, "char_end": 552, "line": "                values(\n"}, {"line_no": 16, "char_start": 552, "char_end": 613, "line": "                    \"\"\" + str(session.get('user_id')) + \"\"\",\n"}, {"line_no": 17, "char_start": 613, "char_end": 661, "line": "                    \"\"\" + str(answer_id) + \"\"\",\n"}, {"line_no": 18, "char_start": 661, "char_end": 725, "line": "                    '\"\"\" + str(data.get('comment_body')) + \"\"\"'\n"}, {"line_no": 19, "char_start": 725, "char_end": 743, "line": "                )\n"}, {"line_no": 20, "char_start": 743, "char_end": 763, "line": "                \"\"\"\n"}, {"line_no": 21, "char_start": 763, "char_end": 777, "line": "            )\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 20, "line": "    def save(self):\n"}, {"line_no": 9, "char_start": 278, "char_end": 375, "line": "            query = \"INSERT INTO comments(user_id, answer_id, comment_body) values(%s, %s, %s) \"\n"}, {"line_no": 10, "char_start": 375, "char_end": 467, "line": "            cur.execute(query, (session.get('user_id'), self.answer_id, self.comment_body))\n"}]}, "char_changes": {"deleted": [{"char_start": 17, "char_end": 44, "chars": ", answer_id=None, data=None"}, {"char_start": 102, "char_end": 188, "chars": "        :param answer_id: string: answer id\n        :param data: dict: comment values\n"}, {"char_start": 403, "char_end": 775, "chars": "cur.execute(\n                \"\"\"\n                INSERT INTO \n                    comments(user_id, answer_id, comment_body)\n                values(\n                    \"\"\" + str(session.get('user_id')) + \"\"\",\n                    \"\"\" + str(answer_id) + \"\"\",\n                    '\"\"\" + str(data.get('comment_body')) + \"\"\"'\n                )\n                \"\"\"\n            "}], "added": [{"char_start": 20, "char_end": 20, "chars": ""}, {"char_start": 290, "char_end": 465, "chars": "query = \"INSERT INTO comments(user_id, answer_id, comment_body) values(%s, %s, %s) \"\n            cur.execute(query, (session.get('user_id'), self.answer_id, self.comment_body)"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/comments/models.py", "vul_type": "cwe-089"}
{"func_name": "save", "func_src_before": "    def save(self, data):\n        \"\"\"\n        Create a question record in questions table\n        :param data: dict: question values\n        :return: None or record values\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\n                \"\"\"\n                INSERT INTO questions(title, body, user_id)\n                values(\n                    '\"\"\" + data.get('title') + \"\"\"',\n                    '\"\"\" + data.get('body') + \"\"\"',\n                    '\"\"\" + data.get('user') + \"\"\"'\n                )\n                \"\"\"\n            )\n\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return None\n        con.close()\n        return data", "func_src_after": "    def save(self):\n        \"\"\" Create a question record in questions table\n        :return: None or record values\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur, response = con.cursor(cursor_factory=RealDictCursor), None\n        try:\n            query = \"INSERT INTO questions (title, body, user_id) VALUES (%s, %s, %s) RETURNING *\"\n            cur.execute(query, (self.title, self.body, self.user_id))\n            con.commit()\n            response = cur.fetchone()\n        except Exception as e:\n            print(e)\n        con.close()\n        return response", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 26, "line": "    def save(self, data):\n"}, {"line_no": 8, "char_start": 230, "char_end": 286, "line": "        cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 10, "char_start": 299, "char_end": 324, "line": "            cur.execute(\n"}, {"line_no": 11, "char_start": 324, "char_end": 344, "line": "                \"\"\"\n"}, {"line_no": 12, "char_start": 344, "char_end": 404, "line": "                INSERT INTO questions(title, body, user_id)\n"}, {"line_no": 13, "char_start": 404, "char_end": 428, "line": "                values(\n"}, {"line_no": 14, "char_start": 428, "char_end": 481, "line": "                    '\"\"\" + data.get('title') + \"\"\"',\n"}, {"line_no": 15, "char_start": 481, "char_end": 533, "line": "                    '\"\"\" + data.get('body') + \"\"\"',\n"}, {"line_no": 16, "char_start": 533, "char_end": 584, "line": "                    '\"\"\" + data.get('user') + \"\"\"'\n"}, {"line_no": 17, "char_start": 584, "char_end": 602, "line": "                )\n"}, {"line_no": 18, "char_start": 602, "char_end": 622, "line": "                \"\"\"\n"}, {"line_no": 19, "char_start": 622, "char_end": 636, "line": "            )\n"}, {"line_no": 20, "char_start": 636, "char_end": 637, "line": "\n"}, {"line_no": 24, "char_start": 714, "char_end": 738, "line": "            con.close()\n"}, {"line_no": 25, "char_start": 738, "char_end": 762, "line": "            return None\n"}, {"line_no": 27, "char_start": 782, "char_end": 801, "line": "        return data\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 20, "line": "    def save(self):\n"}, {"line_no": 2, "char_start": 20, "char_end": 76, "line": "        \"\"\" Create a question record in questions table\n"}, {"line_no": 6, "char_start": 173, "char_end": 245, "line": "        cur, response = con.cursor(cursor_factory=RealDictCursor), None\n"}, {"line_no": 8, "char_start": 258, "char_end": 357, "line": "            query = \"INSERT INTO questions (title, body, user_id) VALUES (%s, %s, %s) RETURNING *\"\n"}, {"line_no": 9, "char_start": 357, "char_end": 427, "line": "            cur.execute(query, (self.title, self.body, self.user_id))\n"}, {"line_no": 11, "char_start": 452, "char_end": 490, "line": "            response = cur.fetchone()\n"}, {"line_no": 15, "char_start": 562, "char_end": 585, "line": "        return response\n"}]}, "char_changes": {"deleted": [{"char_start": 17, "char_end": 23, "chars": ", data"}, {"char_start": 37, "char_end": 45, "chars": "\n       "}, {"char_start": 90, "char_end": 133, "chars": "        :param data: dict: question values\n"}, {"char_start": 311, "char_end": 360, "chars": "cur.execute(\n                \"\"\"\n                "}, {"char_start": 403, "char_end": 600, "chars": "\n                values(\n                    '\"\"\" + data.get('title') + \"\"\"',\n                    '\"\"\" + data.get('body') + \"\"\"',\n                    '\"\"\" + data.get('user') + \"\"\"'\n                "}, {"char_start": 614, "char_end": 621, "chars": "    \"\"\""}, {"char_start": 634, "char_end": 659, "chars": ")\n\n            con.commit"}, {"char_start": 722, "char_end": 726, "chars": "    "}, {"char_start": 746, "char_end": 750, "chars": "    "}, {"char_start": 757, "char_end": 801, "chars": "None\n        con.close()\n        return data"}], "added": [{"char_start": 184, "char_end": 194, "chars": ", response"}, {"char_start": 238, "char_end": 244, "chars": ", None"}, {"char_start": 270, "char_end": 279, "chars": "query = \""}, {"char_start": 300, "char_end": 301, "chars": " "}, {"char_start": 323, "char_end": 426, "chars": " VALUES (%s, %s, %s) RETURNING *\"\n            cur.execute(query, (self.title, self.body, self.user_id))"}, {"char_start": 439, "char_end": 450, "chars": "con.commit("}, {"char_start": 464, "char_end": 487, "chars": "response = cur.fetchone"}, {"char_start": 577, "char_end": 585, "chars": "response"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/questions/models.py", "vul_type": "cwe-089"}
{"func_name": "query", "func_src_before": "    def query(self, q):\n        \"\"\"\n        Query the data in question table\n        :return: list: query set list\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        if not q:\n            cur.execute(\n                \"\"\"\n                SELECT\n                   *,\n                   ( \n                    select count(*) from answers \n                    where answers.question_id=questions.question_id\n                    ) as answers_count\n                FROM \n                    questions\n                \"\"\"\n            )\n        else:\n            cur.execute(\n                \"\"\"\n                SELECT\n                   *,\n                   ( \n                    select count(*) from answers \n                    where answers.question_id=questions.question_id\n                    ) as answers_count\n                FROM \n                    questions\n                WHERE\n                    body LIKE \n                    '%\"\"\" + q + \"\"\"%'\n                OR\n                    title LIKE \n                    '%\"\"\" + q + \"\"\"%'\n                \n                \"\"\"\n            )\n        queryset_list = cur.fetchall()\n        con.close()\n        return queryset_list", "func_src_after": "    def query(self):\n        \"\"\"Query the data in question table :return: list: query set list\"\"\"\n        con, queryset_list = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            if not self.q:\n                cur.execute(\n                    \" SELECT *,( SELECT count(*) FROM \"\n                    \"answers WHERE answers.question_id=questions.question_id ) as \"\n                    \"answers_count FROM questions \"\n                    \" ORDER BY questions.created_at DESC\"\n                )\n            else:\n                query = \"SELECT *, ( SELECT count(*) FROM answers WHERE \"\n                query += \" answers.question_id=questions.question_id ) as answers_count \"\n                query += \" FROM questions WHERE  body LIKE %s OR title LIKE %s  \"\n                query += \" ORDER BY questions.created_at\"\n                cur.execute(query, (self.q, self.q))\n            queryset_list = cur.fetchall()\n        except Exception as e:\n            print(e)\n        con.close()\n        return queryset_list", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 24, "line": "    def query(self, q):\n"}, {"line_no": 8, "char_start": 229, "char_end": 247, "line": "        if not q:\n"}, {"line_no": 9, "char_start": 247, "char_end": 272, "line": "            cur.execute(\n"}, {"line_no": 10, "char_start": 272, "char_end": 292, "line": "                \"\"\"\n"}, {"line_no": 11, "char_start": 292, "char_end": 315, "line": "                SELECT\n"}, {"line_no": 12, "char_start": 315, "char_end": 337, "line": "                   *,\n"}, {"line_no": 13, "char_start": 337, "char_end": 359, "line": "                   ( \n"}, {"line_no": 14, "char_start": 359, "char_end": 409, "line": "                    select count(*) from answers \n"}, {"line_no": 15, "char_start": 409, "char_end": 477, "line": "                    where answers.question_id=questions.question_id\n"}, {"line_no": 16, "char_start": 477, "char_end": 516, "line": "                    ) as answers_count\n"}, {"line_no": 17, "char_start": 516, "char_end": 538, "line": "                FROM \n"}, {"line_no": 18, "char_start": 538, "char_end": 568, "line": "                    questions\n"}, {"line_no": 19, "char_start": 568, "char_end": 588, "line": "                \"\"\"\n"}, {"line_no": 20, "char_start": 588, "char_end": 602, "line": "            )\n"}, {"line_no": 21, "char_start": 602, "char_end": 616, "line": "        else:\n"}, {"line_no": 22, "char_start": 616, "char_end": 641, "line": "            cur.execute(\n"}, {"line_no": 23, "char_start": 641, "char_end": 661, "line": "                \"\"\"\n"}, {"line_no": 24, "char_start": 661, "char_end": 684, "line": "                SELECT\n"}, {"line_no": 25, "char_start": 684, "char_end": 706, "line": "                   *,\n"}, {"line_no": 26, "char_start": 706, "char_end": 728, "line": "                   ( \n"}, {"line_no": 27, "char_start": 728, "char_end": 778, "line": "                    select count(*) from answers \n"}, {"line_no": 28, "char_start": 778, "char_end": 846, "line": "                    where answers.question_id=questions.question_id\n"}, {"line_no": 29, "char_start": 846, "char_end": 885, "line": "                    ) as answers_count\n"}, {"line_no": 30, "char_start": 885, "char_end": 907, "line": "                FROM \n"}, {"line_no": 31, "char_start": 907, "char_end": 937, "line": "                    questions\n"}, {"line_no": 32, "char_start": 937, "char_end": 959, "line": "                WHERE\n"}, {"line_no": 33, "char_start": 959, "char_end": 990, "line": "                    body LIKE \n"}, {"line_no": 34, "char_start": 990, "char_end": 1028, "line": "                    '%\"\"\" + q + \"\"\"%'\n"}, {"line_no": 35, "char_start": 1028, "char_end": 1047, "line": "                OR\n"}, {"line_no": 36, "char_start": 1047, "char_end": 1079, "line": "                    title LIKE \n"}, {"line_no": 37, "char_start": 1079, "char_end": 1117, "line": "                    '%\"\"\" + q + \"\"\"%'\n"}, {"line_no": 38, "char_start": 1117, "char_end": 1134, "line": "                \n"}, {"line_no": 39, "char_start": 1134, "char_end": 1154, "line": "                \"\"\"\n"}, {"line_no": 40, "char_start": 1154, "char_end": 1168, "line": "            )\n"}, {"line_no": 41, "char_start": 1168, "char_end": 1207, "line": "        queryset_list = cur.fetchall()\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 21, "line": "    def query(self):\n"}, {"line_no": 2, "char_start": 21, "char_end": 98, "line": "        \"\"\"Query the data in question table :return: list: query set list\"\"\"\n"}, {"line_no": 3, "char_start": 98, "char_end": 165, "line": "        con, queryset_list = psycopg2.connect(**self.config), None\n"}, {"line_no": 5, "char_start": 221, "char_end": 234, "line": "        try:\n"}, {"line_no": 6, "char_start": 234, "char_end": 261, "line": "            if not self.q:\n"}, {"line_no": 7, "char_start": 261, "char_end": 290, "line": "                cur.execute(\n"}, {"line_no": 8, "char_start": 290, "char_end": 346, "line": "                    \" SELECT *,( SELECT count(*) FROM \"\n"}, {"line_no": 9, "char_start": 346, "char_end": 430, "line": "                    \"answers WHERE answers.question_id=questions.question_id ) as \"\n"}, {"line_no": 10, "char_start": 430, "char_end": 482, "line": "                    \"answers_count FROM questions \"\n"}, {"line_no": 11, "char_start": 482, "char_end": 540, "line": "                    \" ORDER BY questions.created_at DESC\"\n"}, {"line_no": 12, "char_start": 540, "char_end": 558, "line": "                )\n"}, {"line_no": 13, "char_start": 558, "char_end": 576, "line": "            else:\n"}, {"line_no": 14, "char_start": 576, "char_end": 650, "line": "                query = \"SELECT *, ( SELECT count(*) FROM answers WHERE \"\n"}, {"line_no": 15, "char_start": 650, "char_end": 740, "line": "                query += \" answers.question_id=questions.question_id ) as answers_count \"\n"}, {"line_no": 16, "char_start": 740, "char_end": 822, "line": "                query += \" FROM questions WHERE  body LIKE %s OR title LIKE %s  \"\n"}, {"line_no": 17, "char_start": 822, "char_end": 880, "line": "                query += \" ORDER BY questions.created_at\"\n"}, {"line_no": 18, "char_start": 880, "char_end": 933, "line": "                cur.execute(query, (self.q, self.q))\n"}, {"line_no": 19, "char_start": 933, "char_end": 976, "line": "            queryset_list = cur.fetchall()\n"}, {"line_no": 20, "char_start": 976, "char_end": 1007, "line": "        except Exception as e:\n"}, {"line_no": 21, "char_start": 1007, "char_end": 1028, "line": "            print(e)\n"}]}, "char_changes": {"deleted": [{"char_start": 18, "char_end": 21, "chars": ", q"}, {"char_start": 35, "char_end": 44, "chars": "\n        "}, {"char_start": 76, "char_end": 84, "chars": "\n       "}, {"char_start": 114, "char_end": 123, "chars": "\n        "}, {"char_start": 237, "char_end": 247, "chars": "if not q:\n"}, {"char_start": 288, "char_end": 408, "chars": "\"\"\"\n                SELECT\n                   *,\n                   ( \n                    select count(*) from answers "}, {"char_start": 429, "char_end": 434, "chars": "where"}, {"char_start": 476, "char_end": 480, "chars": "\n   "}, {"char_start": 497, "char_end": 502, "chars": ") as "}, {"char_start": 515, "char_end": 567, "chars": "\n                FROM \n                    questions"}, {"char_start": 584, "char_end": 589, "chars": "\"\"\"\n "}, {"char_start": 596, "char_end": 602, "chars": "    )\n"}, {"char_start": 607, "char_end": 610, "chars": "   "}, {"char_start": 628, "char_end": 754, "chars": "cur.execute(\n                \"\"\"\n                SELECT\n                   *,\n                   ( \n                    select"}, {"char_start": 764, "char_end": 768, "chars": "from"}, {"char_start": 794, "char_end": 803, "chars": "    where"}, {"char_start": 845, "char_end": 1066, "chars": "\n                    ) as answers_count\n                FROM \n                    questions\n                WHERE\n                    body LIKE \n                    '%\"\"\" + q + \"\"\"%'\n                OR\n                   "}, {"char_start": 1095, "char_end": 1205, "chars": "    '%\"\"\" + q + \"\"\"%'\n                \n                \"\"\"\n            )\n        queryset_list = cur.fetchall("}], "added": [{"char_start": 109, "char_end": 124, "chars": ", queryset_list"}, {"char_start": 158, "char_end": 164, "chars": ", None"}, {"char_start": 229, "char_end": 265, "chars": "try:\n            if not self.q:\n    "}, {"char_start": 306, "char_end": 345, "chars": "    \" SELECT *,( SELECT count(*) FROM \""}, {"char_start": 366, "char_end": 380, "chars": "\"answers WHERE"}, {"char_start": 422, "char_end": 430, "chars": " ) as \"\n"}, {"char_start": 447, "char_end": 451, "chars": "   \""}, {"char_start": 464, "char_end": 539, "chars": " FROM questions \"\n                    \" ORDER BY questions.created_at DESC\""}, {"char_start": 556, "char_end": 558, "chars": ")\n"}, {"char_start": 588, "char_end": 619, "chars": "    query = \"SELECT *, ( SELECT"}, {"char_start": 629, "char_end": 633, "chars": "FROM"}, {"char_start": 642, "char_end": 650, "chars": "WHERE \"\n"}, {"char_start": 666, "char_end": 676, "chars": "query += \""}, {"char_start": 737, "char_end": 739, "chars": " \""}, {"char_start": 756, "char_end": 804, "chars": "query += \" FROM questions WHERE  body LIKE %s OR"}, {"char_start": 816, "char_end": 822, "chars": "%s  \"\n"}, {"char_start": 838, "char_end": 843, "chars": "query"}, {"char_start": 845, "char_end": 846, "chars": "="}, {"char_start": 848, "char_end": 933, "chars": " ORDER BY questions.created_at\"\n                cur.execute(query, (self.q, self.q))\n"}, {"char_start": 976, "char_end": 1028, "chars": "        except Exception as e:\n            print(e)\n"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/questions/models.py", "vul_type": "cwe-089"}
{"func_name": "filter_by", "func_src_before": "    def filter_by(self, instance_id=None):\n        \"\"\"\n        Selects a question by id\n        :param instance_id: string: question id\n        :return: False if record is not found else query list of found record\n        \"\"\"\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            cur2 = con.cursor(cursor_factory=RealDictCursor)\n            cur.execute(\n                \"\"\"\n                SELECT * FROM\n                    questions\n                WHERE \n                    questions.question_id=\"\"\" + instance_id + \"\"\"\n                ORDER BY questions.created_at\n                \"\"\"\n            )\n            questions_queryset_list = cur.fetchall()\n            cur2.execute(\n                \"\"\"\n                SELECT * FROM\n                    answers\n                WHERE \n                    answers.question_id=\"\"\" + instance_id + \"\"\"\n                \"\"\"\n            )\n            answers_queryset_list = cur2.fetchall()\n            result = {\n                'question': questions_queryset_list,\n                'answers': answers_queryset_list\n            }\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        con.close()\n        return result", "func_src_after": "    def filter_by(self):\n        \"\"\"\n        Selects a question by id\n        :return: False if record is not found else query list of found record\n        \"\"\"\n        con, queryset_list = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        cur2 = con.cursor(cursor_factory=RealDictCursor)\n        try:\n\n            query = \"\"\" SELECT * FROM questions WHERE questions.question_id=%s ORDER BY questions.created_at\"\"\"\n            cur.execute(query % self.question_id)\n            questions_queryset_list = cur.fetchall()\n            cur2.execute(\"SELECT * FROM answers WHERE answers.question_id=%s\" % self.question_id)\n            answers_queryset_list = cur2.fetchall()\n            queryset_list = {\n                'question': questions_queryset_list,\n                'answers': answers_queryset_list\n            }\n        except Exception as e:\n            print(e)\n        con.close()\n        return queryset_list", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 43, "line": "    def filter_by(self, instance_id=None):\n"}, {"line_no": 4, "char_start": 88, "char_end": 136, "line": "        :param instance_id: string: question id\n"}, {"line_no": 8, "char_start": 239, "char_end": 289, "line": "            con = psycopg2.connect(**self.config)\n"}, {"line_no": 9, "char_start": 289, "char_end": 349, "line": "            cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 10, "char_start": 349, "char_end": 410, "line": "            cur2 = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 11, "char_start": 410, "char_end": 435, "line": "            cur.execute(\n"}, {"line_no": 12, "char_start": 435, "char_end": 455, "line": "                \"\"\"\n"}, {"line_no": 13, "char_start": 455, "char_end": 485, "line": "                SELECT * FROM\n"}, {"line_no": 14, "char_start": 485, "char_end": 515, "line": "                    questions\n"}, {"line_no": 15, "char_start": 515, "char_end": 538, "line": "                WHERE \n"}, {"line_no": 16, "char_start": 538, "char_end": 604, "line": "                    questions.question_id=\"\"\" + instance_id + \"\"\"\n"}, {"line_no": 17, "char_start": 604, "char_end": 650, "line": "                ORDER BY questions.created_at\n"}, {"line_no": 18, "char_start": 650, "char_end": 670, "line": "                \"\"\"\n"}, {"line_no": 19, "char_start": 670, "char_end": 684, "line": "            )\n"}, {"line_no": 21, "char_start": 737, "char_end": 763, "line": "            cur2.execute(\n"}, {"line_no": 22, "char_start": 763, "char_end": 783, "line": "                \"\"\"\n"}, {"line_no": 23, "char_start": 783, "char_end": 813, "line": "                SELECT * FROM\n"}, {"line_no": 24, "char_start": 813, "char_end": 841, "line": "                    answers\n"}, {"line_no": 25, "char_start": 841, "char_end": 864, "line": "                WHERE \n"}, {"line_no": 26, "char_start": 864, "char_end": 928, "line": "                    answers.question_id=\"\"\" + instance_id + \"\"\"\n"}, {"line_no": 27, "char_start": 928, "char_end": 948, "line": "                \"\"\"\n"}, {"line_no": 28, "char_start": 948, "char_end": 962, "line": "            )\n"}, {"line_no": 30, "char_start": 1014, "char_end": 1037, "line": "            result = {\n"}, {"line_no": 36, "char_start": 1205, "char_end": 1229, "line": "            con.close()\n"}, {"line_no": 37, "char_start": 1229, "char_end": 1254, "line": "            return False\n"}, {"line_no": 39, "char_start": 1274, "char_end": 1295, "line": "        return result\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 25, "line": "    def filter_by(self):\n"}, {"line_no": 6, "char_start": 160, "char_end": 227, "line": "        con, queryset_list = psycopg2.connect(**self.config), None\n"}, {"line_no": 7, "char_start": 227, "char_end": 283, "line": "        cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 8, "char_start": 283, "char_end": 340, "line": "        cur2 = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 10, "char_start": 353, "char_end": 354, "line": "\n"}, {"line_no": 11, "char_start": 354, "char_end": 466, "line": "            query = \"\"\" SELECT * FROM questions WHERE questions.question_id=%s ORDER BY questions.created_at\"\"\"\n"}, {"line_no": 12, "char_start": 466, "char_end": 516, "line": "            cur.execute(query % self.question_id)\n"}, {"line_no": 14, "char_start": 569, "char_end": 667, "line": "            cur2.execute(\"SELECT * FROM answers WHERE answers.question_id=%s\" % self.question_id)\n"}, {"line_no": 16, "char_start": 719, "char_end": 749, "line": "            queryset_list = {\n"}, {"line_no": 23, "char_start": 937, "char_end": 965, "line": "        return queryset_list\n"}]}, "char_changes": {"deleted": [{"char_start": 22, "char_end": 40, "chars": ", instance_id=None"}, {"char_start": 88, "char_end": 136, "chars": "        :param instance_id: string: question id\n"}, {"char_start": 234, "char_end": 254, "chars": "try:\n            con"}, {"char_start": 288, "char_end": 293, "chars": "\n    "}, {"char_start": 357, "char_end": 361, "chars": "    "}, {"char_start": 418, "char_end": 421, "chars": "   "}, {"char_start": 421, "char_end": 960, "chars": " cur.execute(\n                \"\"\"\n                SELECT * FROM\n                    questions\n                WHERE \n                    questions.question_id=\"\"\" + instance_id + \"\"\"\n                ORDER BY questions.created_at\n                \"\"\"\n            )\n            questions_queryset_list = cur.fetchall()\n            cur2.execute(\n                \"\"\"\n                SELECT * FROM\n                    answers\n                WHERE \n                    answers.question_id=\"\"\" + instance_id + \"\"\"\n                \"\"\"\n            "}, {"char_start": 1026, "char_end": 1031, "chars": "resul"}, {"char_start": 1213, "char_end": 1217, "chars": "    "}, {"char_start": 1237, "char_end": 1240, "chars": "   "}, {"char_start": 1240, "char_end": 1241, "chars": " "}, {"char_start": 1248, "char_end": 1294, "chars": "False\n        con.close()\n        return resul"}], "added": [{"char_start": 168, "char_end": 186, "chars": "con, queryset_list"}, {"char_start": 220, "char_end": 227, "chars": ", None\n"}, {"char_start": 348, "char_end": 665, "chars": "try:\n\n            query = \"\"\" SELECT * FROM questions WHERE questions.question_id=%s ORDER BY questions.created_at\"\"\"\n            cur.execute(query % self.question_id)\n            questions_queryset_list = cur.fetchall()\n            cur2.execute(\"SELECT * FROM answers WHERE answers.question_id=%s\" % self.question_id"}, {"char_start": 731, "char_end": 743, "chars": "queryset_lis"}, {"char_start": 952, "char_end": 964, "chars": "queryset_lis"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/questions/models.py", "vul_type": "cwe-089"}
{"func_name": "filter_by_user", "func_src_before": "    def filter_by_user(self, user_id=None):\n        \"\"\"\n        Selects question for specific user:default filters by current logged in user\n        :param user_id: string: question id\n        :return: False if record is not found else query list of found record\n        \"\"\"\n        if not user_id:\n            user_id = session.get('user_id')\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            cur.execute(\n                \"\"\"\n                SELECT * FROM\n                    questions\n                WHERE \n                    questions.user_id=\"\"\" + user_id + \"\"\"\n                ORDER BY questions.created_at\n                \"\"\"\n            )\n            questions_queryset_list = cur.fetchall()\n\n            result = {\n                'question': questions_queryset_list\n            }\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        con.close()\n        return result", "func_src_after": "    def filter_by_user(self):\n        \"\"\"\n        Selects question for specific user:default filters by current logged in user\n        :return: False if record is not found else query list of found record\n        \"\"\"\n        con, queryset_list = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\n                \"\"\" SELECT * FROM questions \n                    WHERE questions.user_id=\"\"\" + self.user_id + \"\"\" ORDER BY questions.created_at \"\"\"\n            )\n            questions_queryset_list = cur.fetchall()\n            queryset_list = {'question': questions_queryset_list}\n        except Exception as e:\n            print(e)\n        con.close()\n        return queryset_list", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 44, "line": "    def filter_by_user(self, user_id=None):\n"}, {"line_no": 4, "char_start": 141, "char_end": 185, "line": "        :param user_id: string: question id\n"}, {"line_no": 7, "char_start": 275, "char_end": 299, "line": "        if not user_id:\n"}, {"line_no": 8, "char_start": 299, "char_end": 344, "line": "            user_id = session.get('user_id')\n"}, {"line_no": 10, "char_start": 357, "char_end": 407, "line": "            con = psycopg2.connect(**self.config)\n"}, {"line_no": 11, "char_start": 407, "char_end": 467, "line": "            cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 13, "char_start": 492, "char_end": 512, "line": "                \"\"\"\n"}, {"line_no": 14, "char_start": 512, "char_end": 542, "line": "                SELECT * FROM\n"}, {"line_no": 15, "char_start": 542, "char_end": 572, "line": "                    questions\n"}, {"line_no": 16, "char_start": 572, "char_end": 595, "line": "                WHERE \n"}, {"line_no": 17, "char_start": 595, "char_end": 653, "line": "                    questions.user_id=\"\"\" + user_id + \"\"\"\n"}, {"line_no": 18, "char_start": 653, "char_end": 699, "line": "                ORDER BY questions.created_at\n"}, {"line_no": 19, "char_start": 699, "char_end": 719, "line": "                \"\"\"\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 30, "line": "    def filter_by_user(self):\n"}, {"line_no": 6, "char_start": 217, "char_end": 284, "line": "        con, queryset_list = psycopg2.connect(**self.config), None\n"}, {"line_no": 7, "char_start": 284, "char_end": 340, "line": "        cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 10, "char_start": 378, "char_end": 423, "line": "                \"\"\" SELECT * FROM questions \n"}, {"line_no": 11, "char_start": 423, "char_end": 526, "line": "                    WHERE questions.user_id=\"\"\" + self.user_id + \"\"\" ORDER BY questions.created_at \"\"\"\n"}, {"line_no": 14, "char_start": 593, "char_end": 659, "line": "            queryset_list = {'question': questions_queryset_list}\n"}, {"line_no": 15, "char_start": 659, "char_end": 690, "line": "        except Exception as e:\n"}, {"line_no": 16, "char_start": 690, "char_end": 711, "line": "            print(e)\n"}, {"line_no": 17, "char_start": 711, "char_end": 731, "line": "        con.close()\n"}, {"line_no": 18, "char_start": 731, "char_end": 759, "line": "        return queryset_list\n"}]}, "char_changes": {"deleted": [{"char_start": 27, "char_end": 41, "chars": ", user_id=None"}, {"char_start": 141, "char_end": 185, "chars": "        :param user_id: string: question id\n"}, {"char_start": 283, "char_end": 372, "chars": "if not user_id:\n            user_id = session.get('user_id')\n        try:\n            con"}, {"char_start": 406, "char_end": 411, "chars": "\n    "}, {"char_start": 511, "char_end": 561, "chars": "\n                SELECT * FROM\n                   "}, {"char_start": 571, "char_end": 572, "chars": "\n"}, {"char_start": 594, "char_end": 615, "chars": "\n                    "}, {"char_start": 652, "char_end": 668, "chars": "\n               "}, {"char_start": 698, "char_end": 714, "chars": "\n               "}, {"char_start": 786, "char_end": 787, "chars": "\n"}, {"char_start": 799, "char_end": 826, "chars": "result = {\n                "}, {"char_start": 861, "char_end": 874, "chars": "\n            "}, {"char_start": 936, "char_end": 940, "chars": "    "}, {"char_start": 960, "char_end": 964, "chars": "    "}, {"char_start": 971, "char_end": 1017, "chars": "False\n        con.close()\n        return resul"}], "added": [{"char_start": 225, "char_end": 243, "chars": "con, queryset_list"}, {"char_start": 277, "char_end": 284, "chars": ", None\n"}, {"char_start": 340, "char_end": 353, "chars": "        try:\n"}, {"char_start": 397, "char_end": 411, "chars": " SELECT * FROM"}, {"char_start": 421, "char_end": 427, "chars": " \n    "}, {"char_start": 473, "char_end": 478, "chars": "self."}, {"char_start": 605, "char_end": 622, "chars": "queryset_list = {"}, {"char_start": 746, "char_end": 758, "chars": "queryset_lis"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/questions/models.py", "vul_type": "cwe-089"}
{"func_name": "record_exists", "func_src_before": "    def record_exists(self, question_id=None):\n        \"\"\"\n        checks whether a question was asked by the user\n        :param question_id: string: question id\n        :return: bool: False if record is not found else True\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        cur.execute(\n            \"\"\" SELECT question_id, user_id FROM questions WHERE \n                    question_id=\"\"\" + question_id + \"\"\"\n                AND \n                    user_id=\"\"\" + str(session.get('user_id')) + \"\"\"\n            \"\"\"\n        )\n        queryset_list = cur.fetchall()\n        con.close()\n        if len(queryset_list) < 1:\n            return False\n        return True", "func_src_after": "    def record_exists(self):\n        \"\"\"\n        checks whether a question was asked by the user\n        :return: bool: False if record is not found else True\n        \"\"\"\n        con, exists = psycopg2.connect(**self.config), False\n        cur, queryset_list = con.cursor(cursor_factory=RealDictCursor), None\n        try:\n            query = \"SELECT question_id, user_id FROM questions WHERE question_id=%s AND user_id=%s\"\n            cur.execute(query, (self.question_id, self.user_id))\n            queryset_list = cur.fetchall()\n            con.close()\n            exists = True if len(queryset_list) > 1 else False\n        except Exception as e:\n            print(e)\n        return exists", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 47, "line": "    def record_exists(self, question_id=None):\n"}, {"line_no": 4, "char_start": 115, "char_end": 163, "line": "        :param question_id: string: question id\n"}, {"line_no": 7, "char_start": 237, "char_end": 283, "line": "        con = psycopg2.connect(**self.config)\n"}, {"line_no": 8, "char_start": 283, "char_end": 339, "line": "        cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 9, "char_start": 339, "char_end": 360, "line": "        cur.execute(\n"}, {"line_no": 10, "char_start": 360, "char_end": 426, "line": "            \"\"\" SELECT question_id, user_id FROM questions WHERE \n"}, {"line_no": 11, "char_start": 426, "char_end": 482, "line": "                    question_id=\"\"\" + question_id + \"\"\"\n"}, {"line_no": 12, "char_start": 482, "char_end": 503, "line": "                AND \n"}, {"line_no": 13, "char_start": 503, "char_end": 571, "line": "                    user_id=\"\"\" + str(session.get('user_id')) + \"\"\"\n"}, {"line_no": 14, "char_start": 571, "char_end": 587, "line": "            \"\"\"\n"}, {"line_no": 15, "char_start": 587, "char_end": 597, "line": "        )\n"}, {"line_no": 16, "char_start": 597, "char_end": 636, "line": "        queryset_list = cur.fetchall()\n"}, {"line_no": 17, "char_start": 636, "char_end": 656, "line": "        con.close()\n"}, {"line_no": 18, "char_start": 656, "char_end": 691, "line": "        if len(queryset_list) < 1:\n"}, {"line_no": 19, "char_start": 691, "char_end": 716, "line": "            return False\n"}, {"line_no": 20, "char_start": 716, "char_end": 735, "line": "        return True\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 29, "line": "    def record_exists(self):\n"}, {"line_no": 6, "char_start": 171, "char_end": 232, "line": "        con, exists = psycopg2.connect(**self.config), False\n"}, {"line_no": 7, "char_start": 232, "char_end": 309, "line": "        cur, queryset_list = con.cursor(cursor_factory=RealDictCursor), None\n"}, {"line_no": 8, "char_start": 309, "char_end": 322, "line": "        try:\n"}, {"line_no": 9, "char_start": 322, "char_end": 423, "line": "            query = \"SELECT question_id, user_id FROM questions WHERE question_id=%s AND user_id=%s\"\n"}, {"line_no": 10, "char_start": 423, "char_end": 488, "line": "            cur.execute(query, (self.question_id, self.user_id))\n"}, {"line_no": 11, "char_start": 488, "char_end": 531, "line": "            queryset_list = cur.fetchall()\n"}, {"line_no": 12, "char_start": 531, "char_end": 555, "line": "            con.close()\n"}, {"line_no": 13, "char_start": 555, "char_end": 618, "line": "            exists = True if len(queryset_list) > 1 else False\n"}, {"line_no": 14, "char_start": 618, "char_end": 649, "line": "        except Exception as e:\n"}, {"line_no": 15, "char_start": 649, "char_end": 670, "line": "            print(e)\n"}, {"line_no": 16, "char_start": 670, "char_end": 691, "line": "        return exists\n"}]}, "char_changes": {"deleted": [{"char_start": 26, "char_end": 44, "chars": ", question_id=None"}, {"char_start": 115, "char_end": 163, "chars": "        :param question_id: string: question id\n"}, {"char_start": 347, "char_end": 359, "chars": "cur.execute("}, {"char_start": 372, "char_end": 376, "chars": "\"\"\" "}, {"char_start": 425, "char_end": 554, "chars": "\n                    question_id=\"\"\" + question_id + \"\"\"\n                AND \n                    user_id=\"\"\" + str(session.get('"}, {"char_start": 561, "char_end": 562, "chars": "'"}, {"char_start": 564, "char_end": 570, "chars": " + \"\"\""}, {"char_start": 575, "char_end": 597, "chars": "        \"\"\"\n        )\n"}, {"char_start": 686, "char_end": 687, "chars": "<"}, {"char_start": 689, "char_end": 715, "chars": ":\n            return False"}, {"char_start": 731, "char_end": 735, "chars": "True"}], "added": [{"char_start": 29, "char_end": 29, "chars": ""}, {"char_start": 182, "char_end": 190, "chars": ", exists"}, {"char_start": 224, "char_end": 231, "chars": ", False"}, {"char_start": 243, "char_end": 258, "chars": ", queryset_list"}, {"char_start": 302, "char_end": 308, "chars": ", None"}, {"char_start": 317, "char_end": 321, "chars": "try:"}, {"char_start": 334, "char_end": 343, "chars": "query = \""}, {"char_start": 392, "char_end": 478, "chars": "question_id=%s AND user_id=%s\"\n            cur.execute(query, (self.question_id, self."}, {"char_start": 539, "char_end": 543, "chars": "    "}, {"char_start": 563, "char_end": 581, "chars": "    exists = True "}, {"char_start": 603, "char_end": 604, "chars": ">"}, {"char_start": 606, "char_end": 669, "chars": " else False\n        except Exception as e:\n            print(e)"}, {"char_start": 685, "char_end": 691, "chars": "exists"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/questions/models.py", "vul_type": "cwe-089"}
{"func_name": "delete", "func_src_before": "    def delete(self, instance_id):\n        \"\"\"\n        Delete a table records\n        :param instance_id: string: question id\n        :return: bool\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        try:\n            exist = self.filter_by(instance_id)['question']\n            if not len(exist) > 0:\n                return 404\n            if not self.record_exists(instance_id):\n                return 401\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            cur.execute(\"DELETE from {} WHERE {}= '{}'\".format(self.table, 'question_id', instance_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        con.close()\n        return True", "func_src_after": "    def delete(self):\n        \"\"\" Delete a table records\n        :return: bool\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            exist = self.filter_by()['question']\n            if not len(exist) > 0:\n                return 404\n            if not self.record_exists():\n                return 401\n            cur.execute(\"DELETE from {} WHERE {}= '{}'\".format(self.table, 'question_id', self.question_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        con.close()\n        return True", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 35, "line": "    def delete(self, instance_id):\n"}, {"line_no": 9, "char_start": 219, "char_end": 279, "line": "            exist = self.filter_by(instance_id)['question']\n"}, {"line_no": 12, "char_start": 341, "char_end": 393, "line": "            if not self.record_exists(instance_id):\n"}, {"line_no": 14, "char_start": 420, "char_end": 480, "line": "            cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 15, "char_start": 480, "char_end": 584, "line": "            cur.execute(\"DELETE from {} WHERE {}= '{}'\".format(self.table, 'question_id', instance_id))\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 22, "line": "    def delete(self):\n"}, {"line_no": 2, "char_start": 22, "char_end": 57, "line": "        \"\"\" Delete a table records\n"}, {"line_no": 6, "char_start": 137, "char_end": 193, "line": "        cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"line_no": 8, "char_start": 206, "char_end": 255, "line": "            exist = self.filter_by()['question']\n"}, {"line_no": 11, "char_start": 317, "char_end": 358, "line": "            if not self.record_exists():\n"}, {"line_no": 13, "char_start": 385, "char_end": 494, "line": "            cur.execute(\"DELETE from {} WHERE {}= '{}'\".format(self.table, 'question_id', self.question_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 19, "char_end": 32, "chars": ", instance_id"}, {"char_start": 46, "char_end": 54, "chars": "\n       "}, {"char_start": 78, "char_end": 126, "chars": "        :param instance_id: string: question id\n"}, {"char_start": 254, "char_end": 265, "chars": "instance_id"}, {"char_start": 379, "char_end": 390, "chars": "instance_id"}, {"char_start": 420, "char_end": 480, "chars": "            cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"char_start": 570, "char_end": 578, "chars": "instance"}], "added": [{"char_start": 137, "char_end": 193, "chars": "        cur = con.cursor(cursor_factory=RealDictCursor)\n"}, {"char_start": 475, "char_end": 488, "chars": "self.question"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/questions/models.py", "vul_type": "cwe-089"}
{"func_name": "vote_exists", "func_src_before": "    def vote_exists(self, answer_id=None):\n        \"\"\"\n        Checks if vote for a particular answer\n        is voted by current user\n        :param answer_id: Answer foreign key\n        :return: True if vote exist else False\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\n                \"\"\" SELECT user_id, vote_id FROM votes WHERE \n                    answer_id=\"\"\" + answer_id + \"\"\"\n                AND \n                    user_id=\"\"\" + str(session.get('user_id')) + \"\"\"\n                \"\"\"\n            )\n            queryset_list = cur.fetchall()\n            con.close()\n            if len(queryset_list) < 1:\n                return False\n            return True\n        except:\n            con.close()\n            return False", "func_src_after": "    def vote_exists(self):\n        \"\"\"\n        Checks if vote for a particular answer\n        is voted by current user\n        :return: True if vote exist else False\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"SELECT user_id, vote_id FROM votes WHERE answer_id=%s AND user_id=%s\"\n            cur.execute(query, (self.answer_id, self.user_id))\n            queryset_list = cur.fetchall()\n            con.close()\n            if len(queryset_list) < 1:\n                return False\n            return True\n        except Exception as e:\n            print(e)\n            con.close()\n            return False", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 43, "line": "    def vote_exists(self, answer_id=None):\n"}, {"line_no": 5, "char_start": 135, "char_end": 180, "line": "        :param answer_id: Answer foreign key\n"}, {"line_no": 11, "char_start": 354, "char_end": 379, "line": "            cur.execute(\n"}, {"line_no": 12, "char_start": 379, "char_end": 441, "line": "                \"\"\" SELECT user_id, vote_id FROM votes WHERE \n"}, {"line_no": 13, "char_start": 441, "char_end": 493, "line": "                    answer_id=\"\"\" + answer_id + \"\"\"\n"}, {"line_no": 14, "char_start": 493, "char_end": 514, "line": "                AND \n"}, {"line_no": 15, "char_start": 514, "char_end": 582, "line": "                    user_id=\"\"\" + str(session.get('user_id')) + \"\"\"\n"}, {"line_no": 16, "char_start": 582, "char_end": 602, "line": "                \"\"\"\n"}, {"line_no": 17, "char_start": 602, "char_end": 616, "line": "            )\n"}, {"line_no": 23, "char_start": 775, "char_end": 791, "line": "        except:\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 27, "line": "    def vote_exists(self):\n"}, {"line_no": 10, "char_start": 293, "char_end": 384, "line": "            query = \"SELECT user_id, vote_id FROM votes WHERE answer_id=%s AND user_id=%s\"\n"}, {"line_no": 11, "char_start": 384, "char_end": 447, "line": "            cur.execute(query, (self.answer_id, self.user_id))\n"}, {"line_no": 17, "char_start": 606, "char_end": 637, "line": "        except Exception as e:\n"}, {"line_no": 18, "char_start": 637, "char_end": 658, "line": "            print(e)\n"}]}, "char_changes": {"deleted": [{"char_start": 24, "char_end": 40, "chars": ", answer_id=None"}, {"char_start": 135, "char_end": 180, "chars": "        :param answer_id: Answer foreign key\n"}, {"char_start": 366, "char_end": 399, "chars": "cur.execute(\n                \"\"\" "}, {"char_start": 440, "char_end": 614, "chars": "\n                    answer_id=\"\"\" + answer_id + \"\"\"\n                AND \n                    user_id=\"\"\" + str(session.get('user_id')) + \"\"\"\n                \"\"\"\n            "}, {"char_start": 789, "char_end": 790, "chars": ":"}], "added": [{"char_start": 27, "char_end": 27, "chars": ""}, {"char_start": 305, "char_end": 314, "chars": "query = \""}, {"char_start": 355, "char_end": 445, "chars": "answer_id=%s AND user_id=%s\"\n            cur.execute(query, (self.answer_id, self.user_id)"}, {"char_start": 620, "char_end": 657, "chars": " Exception as e:\n            print(e)"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/votes/models.py", "vul_type": "cwe-089"}
{"func_name": "create_vote", "func_src_before": "    def create_vote(self, answer_id=None, data=None):\n        \"\"\"\n        Insert a vote in votes table\n        :param answer_id: string: answer id\n        :param data: dict: votes values\n        :return: True if record values are inserted successfully else false\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\n                \"\"\"\n                INSERT INTO \n                    votes(user_id, answer_id, vote)\n                values(\n                    \"\"\" + str(session.get('user_id')) + \"\"\",\n                    \"\"\" + str(answer_id) + \"\"\",\n                    \"\"\" + str(data.get('vote')) + \"\"\"\n                )\n                \"\"\"\n            )\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True", "func_src_after": "    def create_vote(self):\n        \"\"\"\n        Insert a vote in votes table\n        :return: True if record values are inserted successfully else false\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"INSERT INTO votes(user_id, answer_id, vote) VALUES(%s, %s, %s)\"\n            cur.execute(query, (self.user_id, self.answer_id, self.vote_value))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 54, "line": "    def create_vote(self, answer_id=None, data=None):\n"}, {"line_no": 4, "char_start": 103, "char_end": 147, "line": "        :param answer_id: string: answer id\n"}, {"line_no": 5, "char_start": 147, "char_end": 187, "line": "        :param data: dict: votes values\n"}, {"line_no": 11, "char_start": 390, "char_end": 415, "line": "            cur.execute(\n"}, {"line_no": 12, "char_start": 415, "char_end": 435, "line": "                \"\"\"\n"}, {"line_no": 13, "char_start": 435, "char_end": 464, "line": "                INSERT INTO \n"}, {"line_no": 14, "char_start": 464, "char_end": 516, "line": "                    votes(user_id, answer_id, vote)\n"}, {"line_no": 15, "char_start": 516, "char_end": 540, "line": "                values(\n"}, {"line_no": 16, "char_start": 540, "char_end": 601, "line": "                    \"\"\" + str(session.get('user_id')) + \"\"\",\n"}, {"line_no": 17, "char_start": 601, "char_end": 649, "line": "                    \"\"\" + str(answer_id) + \"\"\",\n"}, {"line_no": 18, "char_start": 649, "char_end": 703, "line": "                    \"\"\" + str(data.get('vote')) + \"\"\"\n"}, {"line_no": 19, "char_start": 703, "char_end": 721, "line": "                )\n"}, {"line_no": 20, "char_start": 721, "char_end": 741, "line": "                \"\"\"\n"}, {"line_no": 21, "char_start": 741, "char_end": 755, "line": "            )\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 27, "line": "    def create_vote(self):\n"}, {"line_no": 9, "char_start": 279, "char_end": 364, "line": "            query = \"INSERT INTO votes(user_id, answer_id, vote) VALUES(%s, %s, %s)\"\n"}, {"line_no": 10, "char_start": 364, "char_end": 444, "line": "            cur.execute(query, (self.user_id, self.answer_id, self.vote_value))\n"}]}, "char_changes": {"deleted": [{"char_start": 24, "char_end": 51, "chars": ", answer_id=None, data=None"}, {"char_start": 103, "char_end": 187, "chars": "        :param answer_id: string: answer id\n        :param data: dict: votes values\n"}, {"char_start": 402, "char_end": 753, "chars": "cur.execute(\n                \"\"\"\n                INSERT INTO \n                    votes(user_id, answer_id, vote)\n                values(\n                    \"\"\" + str(session.get('user_id')) + \"\"\",\n                    \"\"\" + str(answer_id) + \"\"\",\n                    \"\"\" + str(data.get('vote')) + \"\"\"\n                )\n                \"\"\"\n            "}], "added": [{"char_start": 27, "char_end": 27, "chars": ""}, {"char_start": 291, "char_end": 442, "chars": "query = \"INSERT INTO votes(user_id, answer_id, vote) VALUES(%s, %s, %s)\"\n            cur.execute(query, (self.user_id, self.answer_id, self.vote_value)"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/votes/models.py", "vul_type": "cwe-089"}
{"func_name": "update_vote", "func_src_before": "    def update_vote(self, answer_id=None, data=None):\n        \"\"\"\n        Modify record from votes table\n        :param answer_id: string: answer id\n        :param data: raw data value to for updating column values\n        :return:\n        \"\"\"\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            cur.execute(\n                \"\"\"\n                UPDATE votes SET \n                    vote='\"\"\" + data.get('vote') + \"\"\"'\n                WHERE \n                    answer_id=\"\"\" + answer_id + \"\"\"\n                AND \n                    user_id=\"\"\" + str(session.get('user_id')) + \"\"\"\n                \"\"\"\n            )\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True", "func_src_after": "    def update_vote(self):\n        \"\"\"\n        Modify record from votes table\n        :return:\n        \"\"\"\n        if not self.answer_id:\n            return False\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            query = \"UPDATE votes SET vote=%s WHERE answer_id=%s AND user_id=%s\"\n            cur.execute(query, (self.vote_value, self.answer_id, self.user_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 54, "line": "    def update_vote(self, answer_id=None, data=None):\n"}, {"line_no": 4, "char_start": 105, "char_end": 149, "line": "        :param answer_id: string: answer id\n"}, {"line_no": 5, "char_start": 149, "char_end": 215, "line": "        :param data: raw data value to for updating column values\n"}, {"line_no": 11, "char_start": 367, "char_end": 392, "line": "            cur.execute(\n"}, {"line_no": 12, "char_start": 392, "char_end": 412, "line": "                \"\"\"\n"}, {"line_no": 13, "char_start": 412, "char_end": 446, "line": "                UPDATE votes SET \n"}, {"line_no": 14, "char_start": 446, "char_end": 502, "line": "                    vote='\"\"\" + data.get('vote') + \"\"\"'\n"}, {"line_no": 15, "char_start": 502, "char_end": 525, "line": "                WHERE \n"}, {"line_no": 16, "char_start": 525, "char_end": 577, "line": "                    answer_id=\"\"\" + answer_id + \"\"\"\n"}, {"line_no": 17, "char_start": 577, "char_end": 598, "line": "                AND \n"}, {"line_no": 18, "char_start": 598, "char_end": 666, "line": "                    user_id=\"\"\" + str(session.get('user_id')) + \"\"\"\n"}, {"line_no": 19, "char_start": 666, "char_end": 686, "line": "                \"\"\"\n"}, {"line_no": 20, "char_start": 686, "char_end": 700, "line": "            )\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 27, "line": "    def update_vote(self):\n"}, {"line_no": 6, "char_start": 107, "char_end": 138, "line": "        if not self.answer_id:\n"}, {"line_no": 7, "char_start": 138, "char_end": 163, "line": "            return False\n"}, {"line_no": 11, "char_start": 286, "char_end": 367, "line": "            query = \"UPDATE votes SET vote=%s WHERE answer_id=%s AND user_id=%s\"\n"}, {"line_no": 12, "char_start": 367, "char_end": 447, "line": "            cur.execute(query, (self.vote_value, self.answer_id, self.user_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 24, "char_end": 51, "chars": ", answer_id=None, data=None"}, {"char_start": 114, "char_end": 214, "chars": "param answer_id: string: answer id\n        :param data: raw data value to for updating column values"}, {"char_start": 223, "char_end": 224, "chars": ":"}, {"char_start": 230, "char_end": 243, "chars": ":\n        \"\"\""}, {"char_start": 379, "char_end": 698, "chars": "cur.execute(\n                \"\"\"\n                UPDATE votes SET \n                    vote='\"\"\" + data.get('vote') + \"\"\"'\n                WHERE \n                    answer_id=\"\"\" + answer_id + \"\"\"\n                AND \n                    user_id=\"\"\" + str(session.get('user_id')) + \"\"\"\n                \"\"\"\n            "}], "added": [{"char_start": 87, "char_end": 142, "chars": "return:\n        \"\"\"\n        if not self.answer_id:\n    "}, {"char_start": 156, "char_end": 162, "chars": " False"}, {"char_start": 298, "char_end": 445, "chars": "query = \"UPDATE votes SET vote=%s WHERE answer_id=%s AND user_id=%s\"\n            cur.execute(query, (self.vote_value, self.answer_id, self.user_id)"}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/votes/models.py", "vul_type": "cwe-089"}
{"func_name": "vote", "func_src_before": "    def vote(self, answer_id=None, data=None):\n        \"\"\"\n        Switch bus for updating or creating a vote\n        :param answer_id: string: answer id\n        :param data: dict: raw vote values\n        :return: bool: True if transaction is\n                       completed successfully else false\n        \"\"\"\n        if self.vote_exists(answer_id):\n            return self.update_vote(answer_id, data)\n        return self.create_vote(answer_id, data)", "func_src_after": "    def vote(self):\n        \"\"\"\n        Switch bus for updating or creating a vote\n        :return: bool: True if transaction is\n                       completed successfully else false\n        \"\"\"\n        if self.vote_exists():\n            return self.update_vote()\n        return self.create_vote()", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 47, "line": "    def vote(self, answer_id=None, data=None):\n"}, {"line_no": 4, "char_start": 110, "char_end": 154, "line": "        :param answer_id: string: answer id\n"}, {"line_no": 5, "char_start": 154, "char_end": 197, "line": "        :param data: dict: raw vote values\n"}, {"line_no": 9, "char_start": 312, "char_end": 352, "line": "        if self.vote_exists(answer_id):\n"}, {"line_no": 10, "char_start": 352, "char_end": 405, "line": "            return self.update_vote(answer_id, data)\n"}, {"line_no": 11, "char_start": 405, "char_end": 453, "line": "        return self.create_vote(answer_id, data)\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 20, "line": "    def vote(self):\n"}, {"line_no": 7, "char_start": 198, "char_end": 229, "line": "        if self.vote_exists():\n"}, {"line_no": 8, "char_start": 229, "char_end": 267, "line": "            return self.update_vote()\n"}, {"line_no": 9, "char_start": 267, "char_end": 300, "line": "        return self.create_vote()\n"}]}, "char_changes": {"deleted": [{"char_start": 17, "char_end": 44, "chars": ", answer_id=None, data=None"}, {"char_start": 110, "char_end": 197, "chars": "        :param answer_id: string: answer id\n        :param data: dict: raw vote values\n"}, {"char_start": 340, "char_end": 349, "chars": "answer_id"}, {"char_start": 388, "char_end": 403, "chars": "answer_id, data"}, {"char_start": 437, "char_end": 452, "chars": "answer_id, data"}], "added": [{"char_start": 20, "char_end": 20, "chars": ""}]}, "commit_link": "github.com/p8ul/stackoverflow-lite/commit/ad02c932f85c0f4ed6c1e561efc5edc163347806", "file_name": "app/votes/models.py", "vul_type": "cwe-089"}
{"func_name": "fulltext_search_title", "func_src_before": "def fulltext_search_title(query):\n    query_string = \"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\".format(query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs", "func_src_after": "def fulltext_search_title(query):\n    query_statement = sql.text(\"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\")\n\n    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs", "line_changes": {"deleted": [{"line_no": 2, "char_start": 34, "char_end": 57, "line": "    query_string = \"\"\"\n"}, {"line_no": 4, "char_start": 173, "char_end": 292, "line": "        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n"}, {"line_no": 7, "char_start": 372, "char_end": 407, "line": "        LIMIT 50;\"\"\".format(query)\n"}, {"line_no": 9, "char_start": 408, "char_end": 472, "line": "    rows = db.engine.execute(sql.text(query_string)).fetchall()\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 69, "line": "    query_statement = sql.text(\"\"\"\n"}, {"line_no": 4, "char_start": 185, "char_end": 311, "line": "        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n"}, {"line_no": 7, "char_start": 391, "char_end": 413, "line": "        LIMIT 50;\"\"\")\n"}, {"line_no": 9, "char_start": 414, "char_end": 500, "line": "    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 46, "char_end": 53, "chars": "ring = "}, {"char_start": 223, "char_end": 227, "chars": "'{}'"}, {"char_start": 392, "char_end": 405, "chars": ".format(query"}, {"char_start": 437, "char_end": 458, "chars": "sql.text(query_string"}], "added": [{"char_start": 46, "char_end": 65, "chars": "atement = sql.text("}, {"char_start": 235, "char_end": 246, "chars": ":search_str"}, {"char_start": 443, "char_end": 486, "chars": "query_statement.bindparams(search_str=query"}]}, "commit_link": "github.com/Impactstory/oadoi/commit/4cde28ea869c921be917cd8726edb958b37d683a", "file_name": "search.py", "vul_type": "cwe-089"}
{"func_name": "autocomplete_phrases", "func_src_before": "def autocomplete_phrases(query):\n    query_string = ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, '({query}\\w*?\\M)', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{1}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{2}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{3}}|)\\M', 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\".format(query=query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases", "func_src_after": "def autocomplete_phrases(query):\n    query_statement = sql.text(ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\").bindparams(\n            p0='%{}%'.format(query),\n            p1=ur'({}\\w*?\\M)'.format(query),\n            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n        )\n\n    rows = db.engine.execute(query_statement).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases", "line_changes": {"deleted": [{"line_no": 2, "char_start": 33, "char_end": 58, "line": "    query_string = ur\"\"\"\n"}, {"line_no": 3, "char_start": 58, "char_end": 161, "line": "        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')\n"}, {"line_no": 5, "char_start": 208, "char_end": 295, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?\\M)', 'g') as match FROM s\n"}, {"line_no": 7, "char_start": 317, "char_end": 419, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{1}})\\M', 'g') as match FROM s\n"}, {"line_no": 9, "char_start": 441, "char_end": 543, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{2}})\\M', 'g') as match FROM s\n"}, {"line_no": 11, "char_start": 565, "char_end": 668, "line": "            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{3}}|)\\M', 'g') as match FROM s\n"}, {"line_no": 15, "char_start": 760, "char_end": 801, "line": "        LIMIT 50;\"\"\".format(query=query)\n"}, {"line_no": 17, "char_start": 802, "char_end": 866, "line": "    rows = db.engine.execute(sql.text(query_string)).fetchall()\n"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 70, "line": "    query_statement = sql.text(ur\"\"\"\n"}, {"line_no": 3, "char_start": 70, "char_end": 165, "line": "        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)\n"}, {"line_no": 5, "char_start": 212, "char_end": 285, "line": "            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s\n"}, {"line_no": 7, "char_start": 307, "char_end": 380, "line": "            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s\n"}, {"line_no": 9, "char_start": 402, "char_end": 475, "line": "            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s\n"}, {"line_no": 11, "char_start": 497, "char_end": 570, "line": "            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s\n"}, {"line_no": 15, "char_start": 662, "char_end": 696, "line": "        LIMIT 50;\"\"\").bindparams(\n"}, {"line_no": 16, "char_start": 696, "char_end": 733, "line": "            p0='%{}%'.format(query),\n"}, {"line_no": 17, "char_start": 733, "char_end": 778, "line": "            p1=ur'({}\\w*?\\M)'.format(query),\n"}, {"line_no": 18, "char_start": 778, "char_end": 838, "line": "            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n"}, {"line_no": 19, "char_start": 838, "char_end": 898, "line": "            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n"}, {"line_no": 20, "char_start": 898, "char_end": 958, "line": "            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n"}, {"line_no": 21, "char_start": 958, "char_end": 968, "line": "        )\n"}, {"line_no": 23, "char_start": 969, "char_end": 1026, "line": "    rows = db.engine.execute(query_statement).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 45, "char_end": 52, "chars": "ring = "}, {"char_start": 148, "char_end": 159, "chars": "'%{query}%'"}, {"char_start": 255, "char_end": 272, "chars": "'({query}\\w*?\\M)'"}, {"char_start": 364, "char_end": 396, "chars": "'({query}\\w*?(?:\\s+\\w+){{1}})\\M'"}, {"char_start": 488, "char_end": 520, "chars": "'({query}\\w*?(?:\\s+\\w+){{2}})\\M'"}, {"char_start": 612, "char_end": 645, "chars": "'({query}\\w*?(?:\\s+\\w+){{3}}|)\\M'"}, {"char_start": 780, "char_end": 799, "chars": ".format(query=query"}, {"char_start": 831, "char_end": 840, "chars": "sql.text("}, {"char_start": 848, "char_end": 853, "chars": "ring)"}], "added": [{"char_start": 45, "char_end": 64, "chars": "atement = sql.text("}, {"char_start": 160, "char_end": 163, "chars": ":p0"}, {"char_start": 259, "char_end": 262, "chars": ":p1"}, {"char_start": 354, "char_end": 357, "chars": ":p2"}, {"char_start": 449, "char_end": 452, "chars": ":p3"}, {"char_start": 544, "char_end": 547, "chars": ":p4"}, {"char_start": 682, "char_end": 966, "chars": ").bindparams(\n            p0='%{}%'.format(query),\n            p1=ur'({}\\w*?\\M)'.format(query),\n            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n        "}, {"char_start": 1006, "char_end": 1013, "chars": "atement"}]}, "commit_link": "github.com/Impactstory/oadoi/commit/4cde28ea869c921be917cd8726edb958b37d683a", "file_name": "search.py", "vul_type": "cwe-089"}
{"func_name": "send_message", "func_src_before": "@frappe.whitelist(allow_guest=True)\ndef send_message(subject=\"Website Query\", message=\"\", sender=\"\", status=\"Open\"):\n\tfrom frappe.www.contact import send_message as website_send_message\n\tlead = customer = None\n\n\twebsite_send_message(subject, message, sender)\n\n\tcustomer = frappe.db.sql(\"\"\"select distinct dl.link_name from `tabDynamic Link` dl\n\t\tleft join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'\n\t\tand c.email_id='{email_id}'\"\"\".format(email_id=sender))\n\n\tif not customer:\n\t\tlead = frappe.db.get_value('Lead', dict(email_id=sender))\n\t\tif not lead:\n\t\t\tnew_lead = frappe.get_doc(dict(\n\t\t\t\tdoctype='Lead',\n\t\t\t\temail_id = sender,\n\t\t\t\tlead_name = sender.split('@')[0].title()\n\t\t\t)).insert(ignore_permissions=True)\n\n\topportunity = frappe.get_doc(dict(\n\t\tdoctype ='Opportunity',\n\t\tenquiry_from = 'Customer' if customer else 'Lead',\n\t\tstatus = 'Open',\n\t\ttitle = subject,\n\t\tcontact_email = sender,\n\t\tto_discuss = message\n\t))\n\n\tif customer:\n\t\topportunity.customer = customer[0][0]\n\telif lead:\n\t\topportunity.lead = lead\n\telse:\n\t\topportunity.lead = new_lead.name\n\n\topportunity.insert(ignore_permissions=True)\n\n\tcomm = frappe.get_doc({\n\t\t\"doctype\":\"Communication\",\n\t\t\"subject\": subject,\n\t\t\"content\": message,\n\t\t\"sender\": sender,\n\t\t\"sent_or_received\": \"Received\",\n\t\t'reference_doctype': 'Opportunity',\n\t\t'reference_name': opportunity.name\n\t})\n\tcomm.insert(ignore_permissions=True)\n\n\treturn \"okay\"", "func_src_after": "@frappe.whitelist(allow_guest=True)\ndef send_message(subject=\"Website Query\", message=\"\", sender=\"\", status=\"Open\"):\n\tfrom frappe.www.contact import send_message as website_send_message\n\tlead = customer = None\n\n\twebsite_send_message(subject, message, sender)\n\n\tcustomer = frappe.db.sql(\"\"\"select distinct dl.link_name from `tabDynamic Link` dl\n\t\tleft join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'\n\t\tand c.email_id = %s\"\"\", sender)\n\n\tif not customer:\n\t\tlead = frappe.db.get_value('Lead', dict(email_id=sender))\n\t\tif not lead:\n\t\t\tnew_lead = frappe.get_doc(dict(\n\t\t\t\tdoctype='Lead',\n\t\t\t\temail_id = sender,\n\t\t\t\tlead_name = sender.split('@')[0].title()\n\t\t\t)).insert(ignore_permissions=True)\n\n\topportunity = frappe.get_doc(dict(\n\t\tdoctype ='Opportunity',\n\t\tenquiry_from = 'Customer' if customer else 'Lead',\n\t\tstatus = 'Open',\n\t\ttitle = subject,\n\t\tcontact_email = sender,\n\t\tto_discuss = message\n\t))\n\n\tif customer:\n\t\topportunity.customer = customer[0][0]\n\telif lead:\n\t\topportunity.lead = lead\n\telse:\n\t\topportunity.lead = new_lead.name\n\n\topportunity.insert(ignore_permissions=True)\n\n\tcomm = frappe.get_doc({\n\t\t\"doctype\":\"Communication\",\n\t\t\"subject\": subject,\n\t\t\"content\": message,\n\t\t\"sender\": sender,\n\t\t\"sent_or_received\": \"Received\",\n\t\t'reference_doctype': 'Opportunity',\n\t\t'reference_name': opportunity.name\n\t})\n\tcomm.insert(ignore_permissions=True)\n\n\treturn \"okay\"", "line_changes": {"deleted": [{"line_no": 10, "char_start": 424, "char_end": 482, "line": "\t\tand c.email_id='{email_id}'\"\"\".format(email_id=sender))\n"}], "added": [{"line_no": 10, "char_start": 424, "char_end": 458, "line": "\t\tand c.email_id = %s\"\"\", sender)\n"}]}, "char_changes": {"deleted": [{"char_start": 440, "char_end": 473, "chars": "='{email_id}'\"\"\".format(email_id="}, {"char_start": 480, "char_end": 481, "chars": ")"}], "added": [{"char_start": 440, "char_end": 450, "chars": " = %s\"\"\", "}]}, "commit_link": "github.com/libracore/erpnext/commit/9acb885e60f77cd4e9ea8c98bdc39c18abcac731", "file_name": "erpnext/templates/utils.py", "vul_type": "cwe-089"}
{"func_name": "load_user", "func_src_before": "@login_manager.user_loader\ndef load_user(s_id):\n    email = str(s_id)\n    query = '''select * from usr where email like\\'''' + email + '\\''\n    cursor = g.conn.execute(query)\n    user = User()\n    for row in cursor:\n        user.name = str(row.name)\n        user.email = str(row.email)\n        break\n    return user", "func_src_after": "@login_manager.user_loader\ndef load_user(s_id):\n    email = str(s_id)\n    query = 'select * from usr where email like %s'\n    cursor = g.conn.execute(query, (email, ))\n    user = User()\n    for row in cursor:\n        user.name = str(row.name)\n        user.email = str(row.email)\n        break\n    return user", "line_changes": {"deleted": [{"line_no": 4, "char_start": 70, "char_end": 140, "line": "    query = '''select * from usr where email like\\'''' + email + '\\''\n"}, {"line_no": 5, "char_start": 140, "char_end": 175, "line": "    cursor = g.conn.execute(query)\n"}], "added": [{"line_no": 4, "char_start": 70, "char_end": 122, "line": "    query = 'select * from usr where email like %s'\n"}, {"line_no": 5, "char_start": 122, "char_end": 168, "line": "    cursor = g.conn.execute(query, (email, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 82, "char_end": 84, "chars": "''"}, {"char_start": 119, "char_end": 138, "chars": "\\'''' + email + '\\'"}], "added": [{"char_start": 117, "char_end": 120, "chars": " %s"}, {"char_start": 155, "char_end": 166, "chars": ", (email, )"}]}, "commit_link": "github.com/Daniel-Bu/w4111-project1/commit/fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "file_name": "Web-app/Server.py", "vul_type": "cwe-089"}
{"func_name": "user_home_page", "func_src_before": "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n@login_required\ndef user_home_page():\n    message = \"Welcome back! \" + current_user.name\n    if request.method == 'GET':\n        query = '''\n        select tmp.jid as id, tmp.name as name, tmp.type as type,\n               tmp.sal_from as sfrom, tmp.sal_to as sto, \n               tmp.sal_freq as sfreq, tmp.posting_time as ptime\n        from (vacancy v natural join job j) as tmp, application ap\n        where ap.uemail = \\'''' + session[\"user_id\"] + '\\' and ap.jid = tmp.jid and ap.vtype = tmp.type'\n        cursor = g.conn.execute(text(query))\n        data = cursor.fetchall()\n        return render_template(\"user_home_page.html\", message = message, data = data)\n    return render_template(\"user_home_page.html\", message = message)", "func_src_after": "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n@login_required\ndef user_home_page():\n    message = \"Welcome back! \" + current_user.name\n    if request.method == 'GET':\n        query = '''\n        select tmp.jid as id, tmp.name as name, tmp.type as type,\n               tmp.sal_from as sfrom, tmp.sal_to as sto, \n               tmp.sal_freq as sfreq, tmp.posting_time as ptime\n        from (vacancy v natural join job j) as tmp, application ap\n        where ap.uemail = %s and ap.jid = tmp.jid and ap.vtype = tmp.type'''\n        cursor = g.conn.execute(query, (session[\"user_id\"], ))\n        data = cursor.fetchall()\n        return render_template(\"user_home_page.html\", message = message, data = data)\n    return render_template(\"user_home_page.html\", message = message)", "line_changes": {"deleted": [{"line_no": 11, "char_start": 437, "char_end": 542, "line": "        where ap.uemail = \\'''' + session[\"user_id\"] + '\\' and ap.jid = tmp.jid and ap.vtype = tmp.type'\n"}, {"line_no": 12, "char_start": 542, "char_end": 587, "line": "        cursor = g.conn.execute(text(query))\n"}], "added": [{"line_no": 11, "char_start": 437, "char_end": 514, "line": "        where ap.uemail = %s and ap.jid = tmp.jid and ap.vtype = tmp.type'''\n"}, {"line_no": 12, "char_start": 514, "char_end": 577, "line": "        cursor = g.conn.execute(query, (session[\"user_id\"], ))\n"}]}, "char_changes": {"deleted": [{"char_start": 463, "char_end": 495, "chars": "\\'''' + session[\"user_id\"] + '\\'"}, {"char_start": 574, "char_end": 579, "chars": "text("}], "added": [{"char_start": 463, "char_end": 465, "chars": "%s"}, {"char_start": 511, "char_end": 513, "chars": "''"}, {"char_start": 551, "char_end": 574, "chars": ", (session[\"user_id\"], "}]}, "commit_link": "github.com/Daniel-Bu/w4111-project1/commit/fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "file_name": "Web-app/Server.py", "vul_type": "cwe-089"}
{"func_name": "user_verify", "func_src_before": "    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = '''select * from usr where email like\\''''+eid+'\\''\n        cursor = g.conn.execute(query)\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break", "func_src_after": "    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = 'select * from usr where email like %s'\n        cursor = g.conn.execute(query, (eid, ))\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break", "line_changes": {"deleted": [{"line_no": 8, "char_start": 180, "char_end": 248, "line": "        query = '''select * from usr where email like\\''''+eid+'\\''\n"}, {"line_no": 9, "char_start": 248, "char_end": 287, "line": "        cursor = g.conn.execute(query)\n"}], "added": [{"line_no": 8, "char_start": 180, "char_end": 236, "line": "        query = 'select * from usr where email like %s'\n"}, {"line_no": 9, "char_start": 236, "char_end": 284, "line": "        cursor = g.conn.execute(query, (eid, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 196, "char_end": 198, "chars": "''"}, {"char_start": 233, "char_end": 246, "chars": "\\''''+eid+'\\'"}], "added": [{"char_start": 231, "char_end": 234, "chars": " %s"}, {"char_start": 273, "char_end": 282, "chars": ", (eid, )"}]}, "commit_link": "github.com/Daniel-Bu/w4111-project1/commit/fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "file_name": "Web-app/User.py", "vul_type": "cwe-089"}
{"func_name": "mysqlSelect", "func_src_before": "    def mysqlSelect(self):\n        if self.db is not None:\n            try:\n                cursor = self.db.cursor()\n                cursor.execute(\"SELECT * FROM tasks\")\n                row = cursor.fetchone()\n                while row is not None:\n                    print(row)\n                    #r = row[0]\n                    row = cursor.fetchone()\n            except:\n                print (\"The data was successfully read\")\n                self.db.rollback()", "func_src_after": "    def mysqlSelect(self):\n        if self.db is not None:\n            try:\n                cursor = self.db.cursor()\n                cursor.execute(\"SELECT * FROM tasks\")\n\n                row = cursor.fetchone()\n                while row is not None:\n                    for r in row:\n                        print (r , end = \"  \")\n                    row = cursor.fetchone()\n                    print(\"\\n\")\n            except:\n                print (\"The data was successfully read\")\n                self.db.rollback()", "line_changes": {"deleted": [{"line_no": 8, "char_start": 251, "char_end": 282, "line": "                    print(row)\n"}], "added": [{"line_no": 6, "char_start": 172, "char_end": 173, "line": "\n"}, {"line_no": 9, "char_start": 252, "char_end": 286, "line": "                    for r in row:\n"}, {"line_no": 10, "char_start": 286, "char_end": 333, "line": "                        print (r , end = \"  \")\n"}, {"line_no": 12, "char_start": 377, "char_end": 409, "line": "                    print(\"\\n\")\n"}]}, "char_changes": {"deleted": [{"char_start": 271, "char_end": 277, "chars": "print("}, {"char_start": 280, "char_end": 281, "chars": ")"}, {"char_start": 302, "char_end": 313, "chars": "#r = row[0]"}], "added": [{"char_start": 172, "char_end": 173, "chars": "\n"}, {"char_start": 272, "char_end": 281, "chars": "for r in "}, {"char_start": 284, "char_end": 285, "chars": ":"}, {"char_start": 306, "char_end": 332, "chars": "    print (r , end = \"  \")"}, {"char_start": 377, "char_end": 409, "chars": "                    print(\"\\n\")\n"}]}, "commit_link": "github.com/EugChesn/uselessScript/commit/5e6c2176af78cd815d6c7e5da68410f973bc5e97", "file_name": "RedmineProject/Mysql.py", "vul_type": "cwe-089"}
{"func_name": "closest_invoice_line", "func_src_before": "    def closest_invoice_line(self, prod, date_invoice):\n        \"\"\" Encuentra la linea de factura mas cercana a la fecha de ingreso del\n            ultimo quant del producto. Si no hay stock busca la mas cercana\n            a date_invoice\n        \"\"\"\n        in_date = self.oldest_quant(prod).in_date\n        if not in_date:\n            in_date = date_invoice\n\n        # busca el la linea de factura con prod_id mas cercano a in_date\n        # TODO quitar ai.date_invoice para retornar solo los ids\n\n        query = \"\"\"\n            SELECT ail.id, ai.date_invoice\n            FROM account_invoice_line ail\n            INNER JOIN account_invoice ai\n              ON ail.invoice_id = ai.id\n            INNER JOIN product_product pp\n              on ail.product_id = pp.id\n            INNER JOIN product_template pt\n              on pp.product_tmpl_id = pt.id\n            WHERE pt.id = %d AND\n                  ai.discount_processed = true\n            ORDER BY abs(ai.date_invoice - date '%s')\n            LIMIT 1;\n        \"\"\" % (prod.id, in_date)\n\n        self._cr.execute(query)\n        # TODO Renombrar a invoice_line_ids\n        invoice_lines = self._cr.fetchall()\n\n        if invoice_lines:\n            invoice_lines_obj = self.env['account.invoice.line']\n            for invoice_line in invoice_lines:\n                return invoice_lines_obj.browse(invoice_line[0])\n        else:\n            return False", "func_src_after": "    def closest_invoice_line(self, prod, date_invoice):\n        \"\"\" Encuentra la linea de factura mas cercana a la fecha de ingreso del\n            ultimo quant del producto. Si no hay stock busca la mas cercana\n            a date_invoice\n        \"\"\"\n        in_date = self.oldest_quant(prod).in_date\n        if not in_date:\n            in_date = date_invoice\n\n        # busca el la linea de factura con prod_id mas cercano a in_date\n        query = \"\"\"\n            SELECT ail.id\n            FROM account_invoice_line ail\n            INNER JOIN account_invoice ai\n              ON ail.invoice_id = ai.id\n            INNER JOIN product_product pp\n              on ail.product_id = pp.id\n            INNER JOIN product_template pt\n              on pp.product_tmpl_id = pt.id\n            WHERE pt.id = %s AND\n                  ai.discount_processed = true\n            ORDER BY abs(ai.date_invoice - date %s)\n            LIMIT 1;\n        \"\"\"\n        self._cr.execute(query, (prod.id, in_date,))\n        invoice_line_ids = self._cr.fetchall()\n\n        if invoice_line_ids:\n            invoice_lines_obj = self.env['account.invoice.line']\n            for invoice_line in invoice_line_ids:\n                return invoice_lines_obj.browse(invoice_line[0])\n        else:\n            return False", "line_changes": {"deleted": [{"line_no": 12, "char_start": 499, "char_end": 500, "line": "\n"}, {"line_no": 14, "char_start": 520, "char_end": 563, "line": "            SELECT ail.id, ai.date_invoice\n"}, {"line_no": 22, "char_start": 856, "char_end": 889, "line": "            WHERE pt.id = %d AND\n"}, {"line_no": 24, "char_start": 936, "char_end": 990, "line": "            ORDER BY abs(ai.date_invoice - date '%s')\n"}, {"line_no": 26, "char_start": 1011, "char_end": 1044, "line": "        \"\"\" % (prod.id, in_date)\n"}, {"line_no": 27, "char_start": 1044, "char_end": 1045, "line": "\n"}, {"line_no": 28, "char_start": 1045, "char_end": 1077, "line": "        self._cr.execute(query)\n"}, {"line_no": 30, "char_start": 1121, "char_end": 1165, "line": "        invoice_lines = self._cr.fetchall()\n"}, {"line_no": 32, "char_start": 1166, "char_end": 1192, "line": "        if invoice_lines:\n"}, {"line_no": 34, "char_start": 1257, "char_end": 1304, "line": "            for invoice_line in invoice_lines:\n"}], "added": [{"line_no": 12, "char_start": 454, "char_end": 480, "line": "            SELECT ail.id\n"}, {"line_no": 20, "char_start": 773, "char_end": 806, "line": "            WHERE pt.id = %s AND\n"}, {"line_no": 22, "char_start": 853, "char_end": 905, "line": "            ORDER BY abs(ai.date_invoice - date %s)\n"}, {"line_no": 24, "char_start": 926, "char_end": 938, "line": "        \"\"\"\n"}, {"line_no": 25, "char_start": 938, "char_end": 991, "line": "        self._cr.execute(query, (prod.id, in_date,))\n"}, {"line_no": 26, "char_start": 991, "char_end": 1038, "line": "        invoice_line_ids = self._cr.fetchall()\n"}, {"line_no": 28, "char_start": 1039, "char_end": 1068, "line": "        if invoice_line_ids:\n"}, {"line_no": 30, "char_start": 1133, "char_end": 1183, "line": "            for invoice_line in invoice_line_ids:\n"}]}, "char_changes": {"deleted": [{"char_start": 434, "char_end": 500, "chars": "        # TODO quitar ai.date_invoice para retornar solo los ids\n\n"}, {"char_start": 545, "char_end": 562, "chars": ", ai.date_invoice"}, {"char_start": 883, "char_end": 884, "chars": "d"}, {"char_start": 984, "char_end": 985, "chars": "'"}, {"char_start": 987, "char_end": 988, "chars": "'"}, {"char_start": 1022, "char_end": 1044, "chars": " % (prod.id, in_date)\n"}, {"char_start": 1075, "char_end": 1120, "chars": ")\n        # TODO Renombrar a invoice_line_ids"}], "added": [{"char_start": 800, "char_end": 801, "chars": "s"}, {"char_start": 968, "char_end": 990, "chars": ", (prod.id, in_date,))"}, {"char_start": 1011, "char_end": 1014, "chars": "_id"}, {"char_start": 1062, "char_end": 1065, "chars": "_id"}, {"char_start": 1177, "char_end": 1180, "chars": "_id"}]}, "commit_link": "github.com/jobiols/cl-iomaq/commit/96fc30b6bb1608e329a6c452e85a3509ec471640", "file_name": "product_autoload/models/product.py", "vul_type": "cwe-089"}
{"func_name": "init", "func_src_before": "    @api.model_cr\n    def init(self):\n\n        tools.drop_view_if_exists(self._cr, self._table)\n        self._cr.execute(\"\"\"\n            create or replace view %s as (\n                %s\n                %s\n            )\"\"\" % (self._table, self._select(), self._from()))", "func_src_after": "    @api.model_cr\n    def init(self):\n\n        tools.drop_view_if_exists(self._cr, self._table)\n        self._cr.execute(\n            \"\"\"\n            create or replace view %s as (\n                %s\n                %s\n            )\"\"\", (\n                AsIs(self._table), AsIs(self._select()), AsIs(self._from()))\n            )", "line_changes": {"deleted": [{"line_no": 5, "char_start": 96, "char_end": 125, "line": "        self._cr.execute(\"\"\"\n"}, {"line_no": 9, "char_start": 206, "char_end": 269, "line": "            )\"\"\" % (self._table, self._select(), self._from()))\n"}], "added": [{"line_no": 5, "char_start": 96, "char_end": 122, "line": "        self._cr.execute(\n"}, {"line_no": 6, "char_start": 122, "char_end": 138, "line": "            \"\"\"\n"}, {"line_no": 10, "char_start": 219, "char_end": 239, "line": "            )\"\"\", (\n"}, {"line_no": 11, "char_start": 239, "char_end": 316, "line": "                AsIs(self._table), AsIs(self._select()), AsIs(self._from()))\n"}, {"line_no": 12, "char_start": 316, "char_end": 329, "line": "            )"}]}, "char_changes": {"deleted": [{"char_start": 125, "char_end": 125, "chars": ""}, {"char_start": 222, "char_end": 225, "chars": " % "}], "added": [{"char_start": 121, "char_end": 134, "chars": "\n            "}, {"char_start": 235, "char_end": 259, "chars": ", (\n                AsIs"}, {"char_start": 271, "char_end": 272, "chars": ")"}, {"char_start": 274, "char_end": 279, "chars": "AsIs("}, {"char_start": 293, "char_end": 294, "chars": ")"}, {"char_start": 296, "char_end": 301, "chars": "AsIs("}, {"char_start": 315, "char_end": 329, "chars": "\n            )"}]}, "commit_link": "github.com/OCA/crm/commit/3e4550f6dd019a97f62fb10937af5b7788c68c58", "file_name": "crm_phonecall/report/crm_phonecall_report.py", "vul_type": "cwe-089"}
{"func_name": "query_signed_intromember", "func_src_before": "def query_signed_intromember(member):\n    \"\"\"\n    Query the database and return the list of packets signed by the given intro member\n    :param member: the user making the query\n    :return: list of results matching the query\n    \"\"\"\n    try:\n        return db.engine.execute(\"\"\"\n            SELECT DISTINCT packet.freshman_username AS username, signature_fresh.signed AS signed FROM packet \n            INNER JOIN signature_fresh ON packet.id = signature_fresh.packet_id \n            WHERE signature_fresh.freshman_username = '\"\"\" + member + \"';\")\n\n    except exc.SQLAlchemyError:\n        raise exc.SQLAlchemyError(\"Error: Failed to get intromember's signatures from database\")", "func_src_after": "def query_signed_intromember(member):\n    \"\"\"\n    Query the database and return the list of packets signed by the given intro member\n    :param member: the user making the query\n    :return: list of results matching the query\n    \"\"\"\n\n    s = \"\"\"\n            SELECT DISTINCT packet.freshman_username AS username, signature_fresh.signed AS signed FROM packet \n            INNER JOIN signature_fresh ON packet.id = signature_fresh.packet_id \n            WHERE signature_fresh.freshman_username = ':member';\"\"\"\n    try:\n        return db.engine.execute(s, member=member)\n\n    except exc.SQLAlchemyError:\n        raise exc.SQLAlchemyError(\"Error: Failed to get intromember's signatures from database\")", "line_changes": {"deleted": [{"line_no": 7, "char_start": 234, "char_end": 243, "line": "    try:\n"}, {"line_no": 8, "char_start": 243, "char_end": 280, "line": "        return db.engine.execute(\"\"\"\n"}, {"line_no": 11, "char_start": 473, "char_end": 549, "line": "            WHERE signature_fresh.freshman_username = '\"\"\" + member + \"';\")\n"}], "added": [{"line_no": 7, "char_start": 234, "char_end": 235, "line": "\n"}, {"line_no": 8, "char_start": 235, "char_end": 247, "line": "    s = \"\"\"\n"}, {"line_no": 11, "char_start": 440, "char_end": 508, "line": "            WHERE signature_fresh.freshman_username = ':member';\"\"\"\n"}, {"line_no": 12, "char_start": 508, "char_end": 517, "line": "    try:\n"}, {"line_no": 13, "char_start": 517, "char_end": 568, "line": "        return db.engine.execute(s, member=member)\n"}]}, "char_changes": {"deleted": [{"char_start": 234, "char_end": 276, "chars": "    try:\n        return db.engine.execute("}, {"char_start": 528, "char_end": 547, "chars": "\"\"\" + member + \"';\""}], "added": [{"char_start": 234, "char_end": 243, "chars": "\n    s = "}, {"char_start": 495, "char_end": 566, "chars": ":member';\"\"\"\n    try:\n        return db.engine.execute(s, member=member"}]}, "commit_link": "github.com/ComputerScienceHouse/packet/commit/97938ef591ea783e02c8935ea66cbd3ca4360851", "file_name": "packet/member.py", "vul_type": "cwe-089"}
{"func_name": "query_signed_upperclassman", "func_src_before": "def query_signed_upperclassman(member):\n    \"\"\"\n    Query the database and return the list of packets signed by the given upperclassman\n    :param member: the user making the query\n    :return: list of results matching the query\n    \"\"\"\n    try:\n        return db.engine.execute(\"\"\"\n            SELECT DISTINCT packet.freshman_username AS username, signature_upper.signed AS signed FROM packet \n            INNER JOIN signature_upper ON packet.id = signature_upper.packet_id \n            WHERE signature_upper.member = '\"\"\" + member + \"';\")\n\n    except exc.SQLAlchemyError:\n        raise exc.SQLAlchemyError(\"Error: Failed to get upperclassman's signatures from database\")", "func_src_after": "def query_signed_upperclassman(member):\n    \"\"\"\n    Query the database and return the list of packets signed by the given upperclassman\n    :param member: the user making the query\n    :return: list of results matching the query\n    \"\"\"\n\n    s = \"\"\"\n            SELECT DISTINCT packet.freshman_username AS username, signature_upper.signed AS signed FROM packet \n            INNER JOIN signature_upper ON packet.id = signature_upper.packet_id \n            WHERE signature_upper.member = ':member';\"\"\"\n\n    try:\n        return db.engine.execute(s, member=member)\n\n    except exc.SQLAlchemyError:\n        raise exc.SQLAlchemyError(\"Error: Failed to get upperclassman's signatures from database\")", "line_changes": {"deleted": [{"line_no": 7, "char_start": 237, "char_end": 246, "line": "    try:\n"}, {"line_no": 8, "char_start": 246, "char_end": 283, "line": "        return db.engine.execute(\"\"\"\n"}, {"line_no": 11, "char_start": 476, "char_end": 541, "line": "            WHERE signature_upper.member = '\"\"\" + member + \"';\")\n"}], "added": [{"line_no": 7, "char_start": 237, "char_end": 238, "line": "\n"}, {"line_no": 8, "char_start": 238, "char_end": 250, "line": "    s = \"\"\"\n"}, {"line_no": 11, "char_start": 443, "char_end": 500, "line": "            WHERE signature_upper.member = ':member';\"\"\"\n"}, {"line_no": 12, "char_start": 500, "char_end": 501, "line": "\n"}, {"line_no": 13, "char_start": 501, "char_end": 510, "line": "    try:\n"}, {"line_no": 14, "char_start": 510, "char_end": 561, "line": "        return db.engine.execute(s, member=member)\n"}]}, "char_changes": {"deleted": [{"char_start": 237, "char_end": 279, "chars": "    try:\n        return db.engine.execute("}, {"char_start": 520, "char_end": 539, "chars": "\"\"\" + member + \"';\""}], "added": [{"char_start": 237, "char_end": 246, "chars": "\n    s = "}, {"char_start": 487, "char_end": 559, "chars": ":member';\"\"\"\n\n    try:\n        return db.engine.execute(s, member=member"}]}, "commit_link": "github.com/ComputerScienceHouse/packet/commit/97938ef591ea783e02c8935ea66cbd3ca4360851", "file_name": "packet/member.py", "vul_type": "cwe-089"}
{"func_name": "query_signed_alumni", "func_src_before": "def query_signed_alumni(member):\n    \"\"\"\n    Query the database and return the list of packets signed by the given alumni/off-floor\n    :param member: the user making the query\n    :return: list of results matching the query\n    \"\"\"\n    try:\n        return db.engine.execute(\"\"\"\n            SELECT DISTINCT packet.freshman_username AS username, signature_misc.member AS signed \n            FROM packet LEFT OUTER JOIN signature_misc ON packet.id = signature_misc.packet_id \n            WHERE signature_misc.member = '\"\"\" + member + \"' OR signature_misc.member ISNULL;\")\n\n    except exc.SQLAlchemyError:\n        raise exc.SQLAlchemyError(\"Error: Failed to get alumni's signatures from database\")", "func_src_after": "def query_signed_alumni(member):\n    \"\"\"\n    Query the database and return the list of packets signed by the given alumni/off-floor\n    :param member: the user making the query\n    :return: list of results matching the query\n    \"\"\"\n\n    s = \"\"\"\n            SELECT DISTINCT packet.freshman_username AS username, signature_misc.member AS signed \n            FROM packet LEFT OUTER JOIN signature_misc ON packet.id = signature_misc.packet_id \n            WHERE signature_misc.member = ':member' OR signature_misc.member ISNULL;\"\"\"\n\n    try:\n        return db.engine.execute(s, member=member)\n\n    except exc.SQLAlchemyError:\n        raise exc.SQLAlchemyError(\"Error: Failed to get alumni's signatures from database\")", "line_changes": {"deleted": [{"line_no": 7, "char_start": 233, "char_end": 242, "line": "    try:\n"}, {"line_no": 8, "char_start": 242, "char_end": 279, "line": "        return db.engine.execute(\"\"\"\n"}, {"line_no": 11, "char_start": 474, "char_end": 570, "line": "            WHERE signature_misc.member = '\"\"\" + member + \"' OR signature_misc.member ISNULL;\")\n"}], "added": [{"line_no": 7, "char_start": 233, "char_end": 234, "line": "\n"}, {"line_no": 8, "char_start": 234, "char_end": 246, "line": "    s = \"\"\"\n"}, {"line_no": 11, "char_start": 441, "char_end": 529, "line": "            WHERE signature_misc.member = ':member' OR signature_misc.member ISNULL;\"\"\"\n"}, {"line_no": 12, "char_start": 529, "char_end": 530, "line": "\n"}, {"line_no": 13, "char_start": 530, "char_end": 539, "line": "    try:\n"}, {"line_no": 14, "char_start": 539, "char_end": 590, "line": "        return db.engine.execute(s, member=member)\n"}]}, "char_changes": {"deleted": [{"char_start": 233, "char_end": 275, "chars": "    try:\n        return db.engine.execute("}, {"char_start": 517, "char_end": 523, "chars": "\"\"\" + "}, {"char_start": 529, "char_end": 533, "chars": " + \""}], "added": [{"char_start": 233, "char_end": 242, "chars": "\n    s = "}, {"char_start": 484, "char_end": 485, "chars": ":"}, {"char_start": 526, "char_end": 588, "chars": "\"\"\n\n    try:\n        return db.engine.execute(s, member=member"}]}, "commit_link": "github.com/ComputerScienceHouse/packet/commit/97938ef591ea783e02c8935ea66cbd3ca4360851", "file_name": "packet/member.py", "vul_type": "cwe-089"}
{"func_name": "petitions_write", "func_src_before": "@app.route('/peti/write/', methods=['GET', 'POST'])\ndef petitions_write():\n    BODY_CONTENT = ''\n    if request.method == 'POST':\n        form_display_name = request.form['form_display_name']\n        form_author_name = request.form['form_author_name']\n        form_body_content = request.form['form_body_content']\n        form_body_content = form_body_content.replace('\"', '\\\\\"')\n        form_enabled = 1\n        form_author = form_author_name\n        form_publish_date = datetime.today()\n        curs.execute('insert into PETITION_DATA_TB (form_display_name, form_publish_date, form_enabled, form_author, form_body_content) values(\"{}\", \"{}\", {}, \"{}\", \"{}\")'.format(\n            form_display_name, \n            form_publish_date, \n            form_enabled, \n            form_author, \n            form_body_content)\n            )\n        conn.commit()\n        return redirect('/peti')\n    else:\n        BODY_CONTENT += open('templates/petitions.html', encoding='utf-8').read()\n        return render_template('index.html', OFORM_APPNAME = LocalSettings.OFORM_APPNAME, OFORM_CONTENT = BODY_CONTENT)", "func_src_after": "@app.route('/peti/write/', methods=['GET', 'POST'])\ndef petitions_write():\n    BODY_CONTENT = ''\n    if request.method == 'POST':\n        form_display_name = request.form['form_display_name'].replace('\"', '\"\"')\n        form_author_name = request.form['form_author_name'].replace('\"', '\"\"')\n        form_body_content = request.form['form_body_content'].replace('\"', '\"\"')\n        form_enabled = 1\n        form_author = form_author_name\n        form_publish_date = datetime.today()\n        curs.execute('insert into PETITION_DATA_TB (form_display_name, form_publish_date, form_enabled, form_author, form_body_content) values(\"{}\", \"{}\", {}, \"{}\", \"{}\")'.format(\n            form_display_name, \n            form_publish_date, \n            form_enabled, \n            form_author, \n            form_body_content)\n            )\n        conn.commit()\n        return redirect('/peti')\n    else:\n        BODY_CONTENT += open('templates/petitions.html', encoding='utf-8').read()\n        return render_template('index.html', OFORM_APPNAME = LocalSettings.OFORM_APPNAME, OFORM_CONTENT = BODY_CONTENT)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 130, "char_end": 192, "line": "        form_display_name = request.form['form_display_name']\n"}, {"line_no": 6, "char_start": 192, "char_end": 252, "line": "        form_author_name = request.form['form_author_name']\n"}, {"line_no": 7, "char_start": 252, "char_end": 314, "line": "        form_body_content = request.form['form_body_content']\n"}, {"line_no": 8, "char_start": 314, "char_end": 380, "line": "        form_body_content = form_body_content.replace('\"', '\\\\\"')\n"}], "added": [{"line_no": 5, "char_start": 130, "char_end": 211, "line": "        form_display_name = request.form['form_display_name'].replace('\"', '\"\"')\n"}, {"line_no": 6, "char_start": 211, "char_end": 290, "line": "        form_author_name = request.form['form_author_name'].replace('\"', '\"\"')\n"}, {"line_no": 7, "char_start": 290, "char_end": 371, "line": "        form_body_content = request.form['form_body_content'].replace('\"', '\"\"')\n"}]}, "char_changes": {"deleted": [{"char_start": 313, "char_end": 359, "chars": "\n        form_body_content = form_body_content"}, {"char_start": 374, "char_end": 376, "chars": "\\\\"}], "added": [{"char_start": 191, "char_end": 210, "chars": ".replace('\"', '\"\"')"}, {"char_start": 270, "char_end": 289, "chars": ".replace('\"', '\"\"')"}, {"char_start": 366, "char_end": 367, "chars": "\""}]}, "commit_link": "github.com/kpjhg0124/PetitionApplication-py/commit/8156af9ccfa49bd7c4807819c3e0eee75b14a738", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "insertNPC", "func_src_before": "def insertNPC(name, race,classe,sex,level,image,legit):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO npc VALUES ('\"+date+\"','\"+str(name)+\"','\"+race+\"','\"+classe+\"','\"+sex+\"','\"+str(level)+\"','\"+image+\"','\"+str(legit)+\"')\")\n\tconn.commit()\n\tconn.close()", "func_src_after": "def insertNPC(name, race,classe,sex,level,image,legit):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO npc VALUES (?,?,?,?,?,?,?,?)\",(date,str(name),race,classe,sex,str(level),image,str(legit)))\n\tconn.commit()\n\tconn.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 97, "char_end": 243, "line": "\tc.execute(\"INSERT INTO npc VALUES ('\"+date+\"','\"+str(name)+\"','\"+race+\"','\"+classe+\"','\"+sex+\"','\"+str(level)+\"','\"+image+\"','\"+str(legit)+\"')\")\n"}], "added": [{"line_no": 4, "char_start": 97, "char_end": 213, "line": "\tc.execute(\"INSERT INTO npc VALUES (?,?,?,?,?,?,?,?)\",(date,str(name),race,classe,sex,str(level),image,str(legit)))\n"}]}, "char_changes": {"deleted": [{"char_start": 133, "char_end": 226, "chars": "'\"+date+\"','\"+str(name)+\"','\"+race+\"','\"+classe+\"','\"+sex+\"','\"+str(level)+\"','\"+image+\"','\"+"}, {"char_start": 236, "char_end": 241, "chars": "+\"')\""}], "added": [{"char_start": 133, "char_end": 200, "chars": "?,?,?,?,?,?,?,?)\",(date,str(name),race,classe,sex,str(level),image,"}, {"char_start": 210, "char_end": 211, "chars": ")"}]}, "commit_link": "github.com/DangerBlack/DungeonsAndDragonsMasterBot/commit/63f980c6dff746f5fcf3005d0646b6c24f81cdc0", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "findNPC", "func_src_before": "def findNPC(race, classe, sex,level):\n\tc, conn = getConnection()\n\tdate = now()\n\t#select image, SUM(legit) as l FROM npc WHERE race='Elf' AND class='Bard' AND sex='Male' GROUP BY image HAVING l>5 ORDER BY SUM(legit) DESC;\n\tc.execute(\"select image, avg(legit) as l FROM npc WHERE race='\"+race+\"' AND class='\"+classe+\"' AND sex='\"+sex+\"' GROUP BY image HAVING l > 5 ORDER BY SUM(legit) DESC;\")\n\tconn.commit()\n\tout = c.fetchmany(5)\n\tconn.close()\n\treturn out", "func_src_after": "def findNPC(race, classe, sex,level):\n\tc, conn = getConnection()\n\tdate = now()\n\t#select image, SUM(legit) as l FROM npc WHERE race='Elf' AND class='Bard' AND sex='Male' GROUP BY image HAVING l>5 ORDER BY SUM(legit) DESC;\n\tc.execute(\"select image, avg(legit) as l FROM npc WHERE race=(?) AND class=(?) AND sex=(?) GROUP BY image HAVING l > 5 ORDER BY SUM(legit) DESC\",(race,classe,sex))\n\tconn.commit()\n\tout = c.fetchmany(5)\n\tconn.close()\n\treturn out", "line_changes": {"deleted": [{"line_no": 5, "char_start": 221, "char_end": 391, "line": "\tc.execute(\"select image, avg(legit) as l FROM npc WHERE race='\"+race+\"' AND class='\"+classe+\"' AND sex='\"+sex+\"' GROUP BY image HAVING l > 5 ORDER BY SUM(legit) DESC;\")\n"}], "added": [{"line_no": 5, "char_start": 221, "char_end": 386, "line": "\tc.execute(\"select image, avg(legit) as l FROM npc WHERE race=(?) AND class=(?) AND sex=(?) GROUP BY image HAVING l > 5 ORDER BY SUM(legit) DESC\",(race,classe,sex))\n"}]}, "char_changes": {"deleted": [{"char_start": 283, "char_end": 293, "chars": "'\"+race+\"'"}, {"char_start": 304, "char_end": 334, "chars": "'\"+classe+\"' AND sex='\"+sex+\"'"}, {"char_start": 387, "char_end": 388, "chars": ";"}], "added": [{"char_start": 283, "char_end": 286, "chars": "(?)"}, {"char_start": 297, "char_end": 312, "chars": "(?) AND sex=(?)"}, {"char_start": 366, "char_end": 384, "chars": ",(race,classe,sex)"}]}, "commit_link": "github.com/DangerBlack/DungeonsAndDragonsMasterBot/commit/63f980c6dff746f5fcf3005d0646b6c24f81cdc0", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "insertUsage", "func_src_before": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES ('\"+date+\"','\"+str(user)+\"','\"+command+\"')\")\n\tconn.commit()\n\tconn.close()", "func_src_after": "def insertUsage(user, command):\n\tc, conn = getConnection()\n\tdate = now()\n\tc.execute(\"INSERT INTO usage (date,user,command) VALUES (?,?,?)\",(date,str(user),command))\n\tconn.commit()\n\tconn.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 73, "char_end": 175, "line": "\tc.execute(\"INSERT INTO usage (date,user,command) VALUES ('\"+date+\"','\"+str(user)+\"','\"+command+\"')\")\n"}], "added": [{"line_no": 4, "char_start": 73, "char_end": 165, "line": "\tc.execute(\"INSERT INTO usage (date,user,command) VALUES (?,?,?)\",(date,str(user),command))\n"}]}, "char_changes": {"deleted": [{"char_start": 131, "char_end": 145, "chars": "'\"+date+\"','\"+"}, {"char_start": 154, "char_end": 161, "chars": "+\"','\"+"}, {"char_start": 168, "char_end": 173, "chars": "+\"')\""}], "added": [{"char_start": 131, "char_end": 145, "chars": "?,?,?)\",(date,"}, {"char_start": 154, "char_end": 155, "chars": ","}, {"char_start": 162, "char_end": 163, "chars": ")"}]}, "commit_link": "github.com/DangerBlack/DungeonsAndDragonsMasterBot/commit/63f980c6dff746f5fcf3005d0646b6c24f81cdc0", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "get_asset_and_volume", "func_src_before": "@app.route('/get_asset_and_volume')\ndef get_asset_and_volume():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n    #print asset_id\n    ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"get_assets\",[[\"' + asset_id + '\"], 0]]}')\n    result = ws.recv()\n    j = json.loads(result)\n\n    dynamic_asset_data_id =  j[\"result\"][0][\"dynamic_asset_data_id\"]\n\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+dynamic_asset_data_id+'\"]]]}')\n    result2 = ws.recv()\n    j2 = json.loads(result2)\n    #print j2[\"result\"][0][\"current_supply\"]\n\n    j[\"result\"][0][\"current_supply\"] = j2[\"result\"][0][\"current_supply\"]\n    j[\"result\"][0][\"confidential_supply\"] = j2[\"result\"][0][\"confidential_supply\"]\n    #print j[\"result\"]\n\n    j[\"result\"][0][\"accumulated_fees\"] = j2[\"result\"][0][\"accumulated_fees\"]\n    j[\"result\"][0][\"fee_pool\"] = j2[\"result\"][0][\"fee_pool\"]\n\n    issuer = j[\"result\"][0][\"issuer\"]\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+issuer+'\"]]]}')\n    result3 = ws.recv()\n    j3 = json.loads(result3)\n    j[\"result\"][0][\"issuer_name\"] = j3[\"result\"][0][\"name\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT volume, mcap FROM assets WHERE aid='\"+asset_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    try:\n        j[\"result\"][0][\"volume\"] = results[0][0]\n        j[\"result\"][0][\"mcap\"] = results[0][1]\n    except:\n        j[\"result\"][0][\"volume\"] = 0\n        j[\"result\"][0][\"mcap\"] = 0\n\n    return jsonify(j[\"result\"])", "func_src_after": "@app.route('/get_asset_and_volume')\ndef get_asset_and_volume():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n    #print asset_id\n    ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"get_assets\",[[\"' + asset_id + '\"], 0]]}')\n    result = ws.recv()\n    j = json.loads(result)\n\n    dynamic_asset_data_id =  j[\"result\"][0][\"dynamic_asset_data_id\"]\n\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+dynamic_asset_data_id+'\"]]]}')\n    result2 = ws.recv()\n    j2 = json.loads(result2)\n    #print j2[\"result\"][0][\"current_supply\"]\n\n    j[\"result\"][0][\"current_supply\"] = j2[\"result\"][0][\"current_supply\"]\n    j[\"result\"][0][\"confidential_supply\"] = j2[\"result\"][0][\"confidential_supply\"]\n    #print j[\"result\"]\n\n    j[\"result\"][0][\"accumulated_fees\"] = j2[\"result\"][0][\"accumulated_fees\"]\n    j[\"result\"][0][\"fee_pool\"] = j2[\"result\"][0][\"fee_pool\"]\n\n    issuer = j[\"result\"][0][\"issuer\"]\n    ws.send('{\"id\": 1, \"method\": \"call\", \"params\": [0, \"get_objects\", [[\"'+issuer+'\"]]]}')\n    result3 = ws.recv()\n    j3 = json.loads(result3)\n    j[\"result\"][0][\"issuer_name\"] = j3[\"result\"][0][\"name\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT volume, mcap FROM assets WHERE aid=%s\"\n    cur.execute(query, (asset_id,))\n    results = cur.fetchall()\n    con.close()\n    try:\n        j[\"result\"][0][\"volume\"] = results[0][0]\n        j[\"result\"][0][\"mcap\"] = results[0][1]\n    except:\n        j[\"result\"][0][\"volume\"] = 0\n        j[\"result\"][0][\"mcap\"] = 0\n\n    return jsonify(j[\"result\"])", "line_changes": {"deleted": [{"line_no": 40, "char_start": 1428, "char_end": 1499, "line": "    query = \"SELECT volume, mcap FROM assets WHERE aid='\"+asset_id+\"'\"\n"}, {"line_no": 41, "char_start": 1499, "char_end": 1522, "line": "    cur.execute(query)\n"}], "added": [{"line_no": 40, "char_start": 1428, "char_end": 1487, "line": "    query = \"SELECT volume, mcap FROM assets WHERE aid=%s\"\n"}, {"line_no": 41, "char_start": 1487, "char_end": 1523, "line": "    cur.execute(query, (asset_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 1483, "char_end": 1497, "chars": "'\"+asset_id+\"'"}], "added": [{"char_start": 1483, "char_end": 1485, "chars": "%s"}, {"char_start": 1508, "char_end": 1521, "chars": ", (asset_id,)"}]}, "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089"}
{"func_name": "get_markets", "func_src_before": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid='\"+asset_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "func_src_after": "@app.route('/get_markets')\ndef get_markets():\n    asset_id = request.args.get('asset_id')\n\n    if not isObject(asset_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_asset_symbols\",[[\"' + asset_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n        asset_id = j_l[\"result\"][0][\"id\"]\n\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT * FROM markets WHERE aid=%s\"\n    cur.execute(query, (asset_id,))\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "line_changes": {"deleted": [{"line_no": 15, "char_start": 408, "char_end": 469, "line": "    query = \"SELECT * FROM markets WHERE aid='\"+asset_id+\"'\"\n"}, {"line_no": 16, "char_start": 469, "char_end": 492, "line": "    cur.execute(query)\n"}], "added": [{"line_no": 15, "char_start": 408, "char_end": 457, "line": "    query = \"SELECT * FROM markets WHERE aid=%s\"\n"}, {"line_no": 16, "char_start": 457, "char_end": 493, "line": "    cur.execute(query, (asset_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 453, "char_end": 467, "chars": "'\"+asset_id+\"'"}], "added": [{"char_start": 453, "char_end": 455, "chars": "%s"}, {"char_start": 478, "char_end": 491, "chars": ", (asset_id,)"}]}, "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089"}
{"func_name": "top_proxies", "func_src_before": "@app.route('/top_proxies')\ndef top_proxies():\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT sum(amount) FROM holders\"\n    cur.execute(query)\n    total = cur.fetchone()\n    total_votes = total[0]\n\n    query = \"SELECT voting_as FROM holders WHERE voting_as<>'1.2.5' group by voting_as\"\n    cur.execute(query)\n    results = cur.fetchall()\n    #con.close()\n\n    proxies = []\n\n    for p in range(0, len(results)):\n\n        proxy_line = [0] * 5\n\n        proxy_id = results[p][0]\n        proxy_line[0] = proxy_id\n\n        query = \"SELECT account_name, amount FROM holders WHERE account_id='\"+proxy_id+\"' LIMIT 1\"\n        cur.execute(query)\n        proxy = cur.fetchone()\n\n        try:\n            proxy_name = proxy[0]\n            proxy_amount = proxy[1]\n        except:\n            proxy_name = \"unknown\"\n            proxy_amount = 0\n\n\n        proxy_line[1] = proxy_name\n\n        query = \"SELECT amount, account_id FROM holders WHERE voting_as='\"+proxy_id+\"'\"\n        cur.execute(query)\n        results2 = cur.fetchall()\n\n        proxy_line[2] = int(proxy_amount)\n\n        for p2 in range(0, len(results2)):\n            amount = results2[p2][0]\n            account_id = results2[p2][1]\n            proxy_line[2] = proxy_line[2] + int(amount)  # total proxy votes\n            proxy_line[3] = proxy_line[3] + 1       # followers\n\n        if proxy_line[3] > 2:\n            percentage = float(float(proxy_line[2]) * 100.0/ float(total_votes))\n            proxy_line[4] = percentage\n            proxies.append(proxy_line)\n\n    con.close()\n\n    proxies = sorted(proxies, key=lambda k: int(k[2]))\n    r_proxies = proxies[::-1]\n\n    return jsonify(filter(None, r_proxies))", "func_src_after": "@app.route('/top_proxies')\ndef top_proxies():\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT sum(amount) FROM holders\"\n    cur.execute(query)\n    total = cur.fetchone()\n    total_votes = total[0]\n\n    query = \"SELECT voting_as FROM holders WHERE voting_as<>'1.2.5' group by voting_as\"\n    cur.execute(query)\n    results = cur.fetchall()\n    #con.close()\n\n    proxies = []\n\n    for p in range(0, len(results)):\n\n        proxy_line = [0] * 5\n\n        proxy_id = results[p][0]\n        proxy_line[0] = proxy_id\n\n        query = \"SELECT account_name, amount FROM holders WHERE account_id=%s LIMIT 1\"\n        cur.execute(query, (proxy_id,))\n        proxy = cur.fetchone()\n\n        try:\n            proxy_name = proxy[0]\n            proxy_amount = proxy[1]\n        except:\n            proxy_name = \"unknown\"\n            proxy_amount = 0\n\n\n        proxy_line[1] = proxy_name\n\n        query = \"SELECT amount, account_id FROM holders WHERE voting_as=%s\"\n        cur.execute(query, (proxy_id,))\n        results2 = cur.fetchall()\n\n        proxy_line[2] = int(proxy_amount)\n\n        for p2 in range(0, len(results2)):\n            amount = results2[p2][0]\n            account_id = results2[p2][1]\n            proxy_line[2] = proxy_line[2] + int(amount)  # total proxy votes\n            proxy_line[3] = proxy_line[3] + 1       # followers\n\n        if proxy_line[3] > 2:\n            percentage = float(float(proxy_line[2]) * 100.0/ float(total_votes))\n            proxy_line[4] = percentage\n            proxies.append(proxy_line)\n\n    con.close()\n\n    proxies = sorted(proxies, key=lambda k: int(k[2]))\n    r_proxies = proxies[::-1]\n\n    return jsonify(filter(None, r_proxies))", "line_changes": {"deleted": [{"line_no": 25, "char_start": 551, "char_end": 650, "line": "        query = \"SELECT account_name, amount FROM holders WHERE account_id='\"+proxy_id+\"' LIMIT 1\"\n"}, {"line_no": 26, "char_start": 650, "char_end": 677, "line": "        cur.execute(query)\n"}, {"line_no": 39, "char_start": 910, "char_end": 998, "line": "        query = \"SELECT amount, account_id FROM holders WHERE voting_as='\"+proxy_id+\"'\"\n"}, {"line_no": 40, "char_start": 998, "char_end": 1025, "line": "        cur.execute(query)\n"}], "added": [{"line_no": 25, "char_start": 551, "char_end": 638, "line": "        query = \"SELECT account_name, amount FROM holders WHERE account_id=%s LIMIT 1\"\n"}, {"line_no": 26, "char_start": 638, "char_end": 678, "line": "        cur.execute(query, (proxy_id,))\n"}, {"line_no": 39, "char_start": 911, "char_end": 987, "line": "        query = \"SELECT amount, account_id FROM holders WHERE voting_as=%s\"\n"}, {"line_no": 40, "char_start": 987, "char_end": 1027, "line": "        cur.execute(query, (proxy_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 626, "char_end": 640, "chars": "'\"+proxy_id+\"'"}, {"char_start": 982, "char_end": 996, "chars": "'\"+proxy_id+\"'"}], "added": [{"char_start": 626, "char_end": 628, "chars": "%s"}, {"char_start": 663, "char_end": 676, "chars": ", (proxy_id,)"}, {"char_start": 983, "char_end": 985, "chars": "%s"}, {"char_start": 1012, "char_end": 1025, "chars": ", (proxy_id,)"}]}, "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089"}
{"func_name": "lookup_assets", "func_src_before": "@app.route('/lookup_assets')\ndef lookup_assets():\n    start = request.args.get('start')\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT aname FROM assets WHERE aname LIKE '\"+start+\"%'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "func_src_after": "@app.route('/lookup_assets')\ndef lookup_assets():\n    start = request.args.get('start')\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT aname FROM assets WHERE aname LIKE %s\"\n    cur.execute(query, (start+'%',))\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "line_changes": {"deleted": [{"line_no": 8, "char_start": 159, "char_end": 228, "line": "    query = \"SELECT aname FROM assets WHERE aname LIKE '\"+start+\"%'\"\n"}, {"line_no": 9, "char_start": 228, "char_end": 251, "line": "    cur.execute(query)\n"}], "added": [{"line_no": 8, "char_start": 159, "char_end": 218, "line": "    query = \"SELECT aname FROM assets WHERE aname LIKE %s\"\n"}, {"line_no": 9, "char_start": 218, "char_end": 255, "line": "    cur.execute(query, (start+'%',))\n"}]}, "char_changes": {"deleted": [{"char_start": 214, "char_end": 226, "chars": "'\"+start+\"%'"}], "added": [{"char_start": 214, "char_end": 216, "chars": "%s"}, {"char_start": 239, "char_end": 253, "chars": ", (start+'%',)"}]}, "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089"}
{"func_name": "referrer_count", "func_src_before": "@app.route('/referrer_count')\ndef referrer_count():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select count(*) from referrers where referrer='\"+account_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchone()\n\n    return jsonify(results)", "func_src_after": "@app.route('/referrer_count')\ndef referrer_count():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select count(*) from referrers where referrer=%s\"\n    cur.execute(query, (account_id,))\n    results = cur.fetchone()\n\n    return jsonify(results)", "line_changes": {"deleted": [{"line_no": 15, "char_start": 424, "char_end": 501, "line": "    query = \"select count(*) from referrers where referrer='\"+account_id+\"'\"\n"}, {"line_no": 16, "char_start": 501, "char_end": 524, "line": "    cur.execute(query)\n"}], "added": [{"line_no": 15, "char_start": 424, "char_end": 487, "line": "    query = \"select count(*) from referrers where referrer=%s\"\n"}, {"line_no": 16, "char_start": 487, "char_end": 525, "line": "    cur.execute(query, (account_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 483, "char_end": 499, "chars": "'\"+account_id+\"'"}], "added": [{"char_start": 483, "char_end": 485, "chars": "%s"}, {"char_start": 508, "char_end": 523, "chars": ", (account_id,)"}]}, "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089"}
{"func_name": "get_all_referrers", "func_src_before": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer='\"+account_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n\n    return jsonify(results)", "func_src_after": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer=%s\"\n    cur.execute(query, (account_id,))\n    results = cur.fetchall()\n\n    return jsonify(results)", "line_changes": {"deleted": [{"line_no": 15, "char_start": 430, "char_end": 500, "line": "    query = \"select * from referrers where referrer='\"+account_id+\"'\"\n"}, {"line_no": 16, "char_start": 500, "char_end": 523, "line": "    cur.execute(query)\n"}], "added": [{"line_no": 15, "char_start": 430, "char_end": 486, "line": "    query = \"select * from referrers where referrer=%s\"\n"}, {"line_no": 16, "char_start": 486, "char_end": 524, "line": "    cur.execute(query, (account_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 482, "char_end": 498, "chars": "'\"+account_id+\"'"}], "added": [{"char_start": 482, "char_end": 484, "chars": "%s"}, {"char_start": 507, "char_end": 522, "chars": ", (account_id,)"}]}, "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089"}
{"func_name": "main", "func_src_before": "def main():\n    global NUM_IMAGES_TO_GET\n\n    # parse commandline arguments\n    if len(sys.argv) > 1:\n        NUM_IMAGES_TO_GET = int(sys.argv[1])\n\n    # assert python version is 3\n    if sys.version_info.major < 3:\n        print(\"This script only runs in python3\")\n        return\n\n    # create data directory\n    data_dir = \"./data\"\n    if not os.path.isdir(data_dir):\n        os.makedirs(data_dir)\n        if not os.path.isdir(data_dir):\n            print(\"Failed to create data path '{}'\".format(data_dir))\n            return\n    image_dir = os.path.join(data_dir, \"{}_{}\".format(resolution_width, resolution_height))\n    if not os.path.isdir(image_dir):\n        os.makedirs(image_dir)\n        if not os.path.isdir(image_dir):\n            print(\"Failed to create image path '{}'\".format(image_dir))\n            return\n\n    # open db\n    conn = sqlite3.connect(\"./data/data.db\")\n\n    # get cursor\n    c = conn.cursor()\n\n    # create table\n    c.execute('''\n        select name from sqlite_master\n        where type='table' and name='wallpapers'\n        ''')\n    if c.fetchone() == None:\n        c.execute('''\n            create table wallpapers (\n                id integer primary key autoincrement not null,\n                image_date text not null,\n                url_base text not null,\n                copyright text not null)\n            ''')\n\n    idx = 0\n    while idx <= NUM_IMAGES_TO_GET:\n        list_url = \"https://www.bing.com/HPImageArchive.aspx?format=js&idx={}&n=1&mkt=en-US\".format(idx)\n        print(\"Getting iamge list from '{}'\".format(list_url))\n        r = requests.get(list_url)\n        if r.status_code != requests.codes.ok:\n            print(\"Failed to get url '{}'\".format(list_url))\n            break\n\n        j = r.json()\n        image_date = j['images'][0]['startdate']\n        url_base = j['images'][0]['urlbase']\n        url = j['images'][0]['url']\n        copyright = j['images'][0]['copyright']\n\n        c.execute('''\n            select * from wallpapers\n            where image_date='{}'\n            '''.format(image_date))\n        if c.fetchone() == None:\n            c.execute('''\n                insert into wallpapers (image_date, url_base, copyright)\n                values ('{}', '{}', '{}')\n                '''.format(image_date, url_base, copyright))\n            print(\"## Inserted image {} to database ##\".format(image_date))\n\n        image_path = os.path.join(image_dir, \"{}.jpg\".format(image_date))\n        if not os.path.isfile(image_path):\n            image_url = \"https://www.bing.com{}_{}x{}.jpg\".format(url_base, resolution_width, resolution_height)\n            print(\"## Downloading image from '{}'\".format(image_url))\n            r_image = requests.get(image_url)\n            if r_image.status_code != requests.codes.ok:\n                print(\"Failed to get url '{}'\".format(image_url))\n                break\n            image = Image.open(BytesIO(r_image.content))\n            image.save(image_path)\n            print(\"## Downloaded image {} ##\".format(image_path))\n\n        idx += 1\n\n    # insert record\n    #c.execute('''\n    #    insert into wallpapers (image_date, url_base, copyright)\n    #    values ('aa', 'bb', 'cc')\n    #    ''')\n\n    # query records\n    ##c.execute(\"select * from wallpapers order by id desc limit 0,10\")\n    ##print(c.fetchall())\n\n    # commit connection changes\n    conn.commit()\n\n    # close cursor and db\n    c.close()\n    conn.close()", "func_src_after": "def main():\n    global NUM_IMAGES_TO_GET\n\n    # parse commandline arguments\n    if len(sys.argv) > 1:\n        NUM_IMAGES_TO_GET = int(sys.argv[1])\n\n    # assert python version is 3\n    if sys.version_info.major < 3:\n        print(\"This script only runs in python3\")\n        return\n\n    # create data directory\n    data_dir = \"./data\"\n    if not os.path.isdir(data_dir):\n        os.makedirs(data_dir)\n        if not os.path.isdir(data_dir):\n            print(\"Failed to create data path '{}'\".format(data_dir))\n            return\n    image_dir = os.path.join(data_dir, \"{}_{}\".format(resolution_width, resolution_height))\n    if not os.path.isdir(image_dir):\n        os.makedirs(image_dir)\n        if not os.path.isdir(image_dir):\n            print(\"Failed to create image path '{}'\".format(image_dir))\n            return\n\n    # open db\n    conn = sqlite3.connect(\"./data/data.db\")\n\n    # get cursor\n    c = conn.cursor()\n\n    # create table\n    c.execute(\"select name from sqlite_master where type='table' and name='wallpapers'\")\n    if c.fetchone() == None:\n        c.execute('''\n            create table wallpapers (\n                id integer primary key autoincrement not null,\n                image_date text not null,\n                url_base text not null,\n                copyright text not null)\n            ''')\n\n    idx = 0\n    while idx <= NUM_IMAGES_TO_GET:\n        list_url = \"https://www.bing.com/HPImageArchive.aspx?format=js&idx={}&n=1&mkt=en-US\".format(idx)\n        print(\"Getting iamge list from '{}'\".format(list_url))\n        r = requests.get(list_url)\n        if r.status_code != requests.codes.ok:\n            print(\"Failed to get url '{}'\".format(list_url))\n            break\n\n        j = r.json()\n        image_date = j['images'][0]['startdate']\n        url_base = j['images'][0]['urlbase']\n        url = j['images'][0]['url']\n        copyright = j['images'][0]['copyright']\n\n        c.execute(\"select * from wallpapers where image_date=?\", (image_date,))\n        if c.fetchone() == None:\n            c.execute(\"insert into wallpapers (image_date, url_base, copyright) values (?, ?, ?)\", (image_date, url_base, copyright))\n            print(\"## Inserted image {} to database ##\".format(image_date))\n\n        image_path = os.path.join(image_dir, \"{}.jpg\".format(image_date))\n        if not os.path.isfile(image_path):\n            image_url = \"https://www.bing.com{}_{}x{}.jpg\".format(url_base, resolution_width, resolution_height)\n            print(\"## Downloading image from '{}'\".format(image_url))\n            r_image = requests.get(image_url)\n            if r_image.status_code != requests.codes.ok:\n                print(\"Failed to get url '{}'\".format(image_url))\n                break\n            image = Image.open(BytesIO(r_image.content))\n            image.save(image_path)\n            print(\"## Downloaded image {} ##\".format(image_path))\n\n        idx += 1\n\n    # commit connection changes\n    conn.commit()\n\n    # close cursor and db\n    c.close()\n    conn.close()", "line_changes": {"deleted": [{"line_no": 34, "char_start": 941, "char_end": 959, "line": "    c.execute('''\n"}, {"line_no": 35, "char_start": 959, "char_end": 998, "line": "        select name from sqlite_master\n"}, {"line_no": 36, "char_start": 998, "char_end": 1047, "line": "        where type='table' and name='wallpapers'\n"}, {"line_no": 37, "char_start": 1047, "char_end": 1060, "line": "        ''')\n"}, {"line_no": 62, "char_start": 1931, "char_end": 1953, "line": "        c.execute('''\n"}, {"line_no": 63, "char_start": 1953, "char_end": 1990, "line": "            select * from wallpapers\n"}, {"line_no": 64, "char_start": 1990, "char_end": 2024, "line": "            where image_date='{}'\n"}, {"line_no": 65, "char_start": 2024, "char_end": 2060, "line": "            '''.format(image_date))\n"}, {"line_no": 67, "char_start": 2093, "char_end": 2119, "line": "            c.execute('''\n"}, {"line_no": 68, "char_start": 2119, "char_end": 2192, "line": "                insert into wallpapers (image_date, url_base, copyright)\n"}, {"line_no": 69, "char_start": 2192, "char_end": 2234, "line": "                values ('{}', '{}', '{}')\n"}, {"line_no": 70, "char_start": 2234, "char_end": 2295, "line": "                '''.format(image_date, url_base, copyright))\n"}, {"line_no": 92, "char_start": 3194, "char_end": 3195, "line": "\n"}, {"line_no": 96, "char_start": 3313, "char_end": 3314, "line": "\n"}], "added": [{"line_no": 34, "char_start": 941, "char_end": 1030, "line": "    c.execute(\"select name from sqlite_master where type='table' and name='wallpapers'\")\n"}, {"line_no": 59, "char_start": 1901, "char_end": 1981, "line": "        c.execute(\"select * from wallpapers where image_date=?\", (image_date,))\n"}, {"line_no": 61, "char_start": 2014, "char_end": 2148, "line": "            c.execute(\"insert into wallpapers (image_date, url_base, copyright) values (?, ?, ?)\", (image_date, url_base, copyright))\n"}]}, "char_changes": {"deleted": [{"char_start": 955, "char_end": 967, "chars": "'''\n        "}, {"char_start": 997, "char_end": 1005, "chars": "\n       "}, {"char_start": 1046, "char_end": 1058, "chars": "\n        '''"}, {"char_start": 1949, "char_end": 1965, "chars": "'''\n            "}, {"char_start": 1989, "char_end": 2001, "chars": "\n           "}, {"char_start": 2019, "char_end": 2046, "chars": "'{}'\n            '''.format"}, {"char_start": 2115, "char_end": 2135, "chars": "'''\n                "}, {"char_start": 2191, "char_end": 2260, "chars": "\n                values ('{}', '{}', '{}')\n                '''.format"}, {"char_start": 3040, "char_end": 3314, "chars": "    # insert record\n    #c.execute('''\n    #    insert into wallpapers (image_date, url_base, copyright)\n    #    values ('aa', 'bb', 'cc')\n    #    ''')\n\n    # query records\n    ##c.execute(\"select * from wallpapers order by id desc limit 0,10\")\n    ##print(c.fetchall())\n\n"}], "added": [{"char_start": 955, "char_end": 956, "chars": "\""}, {"char_start": 1027, "char_end": 1028, "chars": "\""}, {"char_start": 1919, "char_end": 1920, "chars": "\""}, {"char_start": 1962, "char_end": 1966, "chars": "?\", "}, {"char_start": 1977, "char_end": 1978, "chars": ","}, {"char_start": 2036, "char_end": 2037, "chars": "\""}, {"char_start": 2093, "char_end": 2113, "chars": " values (?, ?, ?)\", "}]}, "commit_link": "github.com/haozhigh/py_utilities/commit/15f2706fa8a05d86b1cbfcd7ddff7b16ce93bccb", "file_name": "bing_desktop/update.py", "vul_type": "cwe-089"}
{"func_name": "select", "func_src_before": "\tdef select(self, table):\n\t\t\"\"\"\n        \tselect function:\n           \t\tRetorna todos os dados da tabela em formato JSON\n    \t\"\"\"\n\t\taux_dict = dict()\n\t\tself.cursor.execute(\"SELECT * FROM {0}\".format( table))\n\t\tjson_data = {}\n\t\tfor user in self.cursor:\n\t\t\tjson_data[str(user[3])] = {}\n\t\t\tjson_data[str(user[3])]['nome'] = user[0]\n\t\t\tjson_data[str(user[3])]['sobrenome'] = user[1]\n\t\t\tjson_data[str(user[3])]['endereco'] = user[2]\n\t\treturn json.dumps(json_data)", "func_src_after": "\tdef select(self):\n\t\t\"\"\"\n        \tselect function:\n           \t\tRetorna todos os dados da tabela em formato JSON\n    \t\"\"\"\n\t\tusers = \"users\"\n\t\taux_dict = dict()\n\t\tselect = \"\"\"SELECT * FROM users\"\"\"\n\t\tself.cursor.execute(select)\n\t\tjson_data = {}\n\t\tfor user in self.cursor:\n\t\t\tjson_data[str(user[3])] = {}\n\t\t\tjson_data[str(user[3])]['nome'] = user[0]\n\t\t\tjson_data[str(user[3])]['sobrenome'] = user[1]\n\t\t\tjson_data[str(user[3])]['endereco'] = user[2]\n\t\treturn json.dumps(json_data)", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 26, "line": "\tdef select(self, table):\n"}, {"line_no": 7, "char_start": 149, "char_end": 207, "line": "\t\tself.cursor.execute(\"SELECT * FROM {0}\".format( table))\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 19, "line": "\tdef select(self):\n"}, {"line_no": 6, "char_start": 122, "char_end": 140, "line": "\t\tusers = \"users\"\n"}, {"line_no": 8, "char_start": 160, "char_end": 197, "line": "\t\tselect = \"\"\"SELECT * FROM users\"\"\"\n"}, {"line_no": 9, "char_start": 197, "char_end": 227, "line": "\t\tself.cursor.execute(select)\n"}]}, "char_changes": {"deleted": [{"char_start": 16, "char_end": 23, "chars": ", table"}, {"char_start": 154, "char_end": 205, "chars": "f.cursor.execute(\"SELECT * FROM {0}\".format( table)"}], "added": [{"char_start": 122, "char_end": 140, "chars": "\t\tusers = \"users\"\n"}, {"char_start": 165, "char_end": 225, "chars": "ect = \"\"\"SELECT * FROM users\"\"\"\n\t\tself.cursor.execute(select"}]}, "commit_link": "github.com/arturgoms/Teste-Tecnico/commit/c0dee37a2719986a18835893c9632d84bc984d14", "file_name": "src/models/mysql.py", "vul_type": "cwe-089"}
{"func_name": "insert", "func_src_before": "\tdef insert(self, table, content):\n\t\t\"\"\"\n        \tinsert function:\n           \t\tRecebe em JSON os dados e grava na tabela\n    \t\"\"\"\n\t\tnome = content[\"nome\"]\n\t\tsobrenome = content[\"sobrenome\"]\n\t\tendereco = content[\"endereco\"]\n\t\tadd_user = \"\"\"INSERT INTO users (nome, sobrenome, endereco) VALUES (%s,%s,%s)\"\"\"\n\n\t\tdata_user = (nome, sobrenome, endereco)\n\t\ttry:\n\t\t    self.cursor.execute(add_user,data_user)\n\t\texcept mysql.Error as error:\n\t\t    print(\"Error: {}\".format(error))\n\t\tself.__connection.commit()\n\t\tself.cursor.lastrowid", "func_src_after": "\tdef insert(self,  content):\n\t\t\"\"\"\n        \tinsert function:\n           \t\tRecebe em JSON os dados e grava na tabela\n    \t\"\"\"\n\t\tnome = content[\"nome\"]\n\t\tsobrenome = content[\"sobrenome\"]\n\t\tendereco = content[\"endereco\"]\n\t\tadd_user = \"\"\"INSERT INTO users (nome, sobrenome, endereco) VALUES (%s,%s,%s)\"\"\"\n\n\t\tdata_user = (nome, sobrenome, endereco,)\n\t\ttry:\n\t\t    self.cursor.execute(add_user,data_user)\n\t\texcept mysql.Error as error:\n\t\t    print(\"Error: {}\".format(error))\n\t\tself.__connection.commit()\n\t\tself.cursor.lastrowid", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 35, "line": "\tdef insert(self, table, content):\n"}, {"line_no": 11, "char_start": 308, "char_end": 350, "line": "\t\tdata_user = (nome, sobrenome, endereco)\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 29, "line": "\tdef insert(self,  content):\n"}, {"line_no": 11, "char_start": 302, "char_end": 345, "line": "\t\tdata_user = (nome, sobrenome, endereco,)\n"}]}, "char_changes": {"deleted": [{"char_start": 18, "char_end": 24, "chars": "table,"}], "added": [{"char_start": 342, "char_end": 343, "chars": ","}]}, "commit_link": "github.com/arturgoms/Teste-Tecnico/commit/c0dee37a2719986a18835893c9632d84bc984d14", "file_name": "src/models/mysql.py", "vul_type": "cwe-089"}
{"func_name": "delete_where", "func_src_before": "\tdef delete_where(self, table, where):\n\t\t\"\"\"\n        \tdelete_where function:\n           \t\tDeleta um campo especifico da tabela\n    \t\"\"\"\n\t\ttry:\n\t\t    self.cursor.execute(\"DELETE FROM {0} WHERE {1}\".format(table, where))\n\t\texcept mysql.Error as error:\n\t\t    print(\"Erro: {}\".format(error))\n\t\tself.__connection.commit()\n\t\treturn self.cursor", "func_src_after": "\tdef delete_where(self, where):\n\t\t\"\"\"\n        \tdelete_where function:\n           \t\tDeleta um campo especifico da tabela\n    \t\"\"\"\n\t\ttry:\n\t\t\tdelete_query = \"\"\"DELETE FROM users WHERE id=(%s)\"\"\"\n\t\t\tself.cursor.execute(delete_query,(where,))\n\t\texcept mysql.Error as error:\n\t\t    print(\"Erro: {}\".format(error))\n\t\tself.__connection.commit()\n\t\treturn self.cursor", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 39, "line": "\tdef delete_where(self, table, where):\n"}, {"line_no": 7, "char_start": 143, "char_end": 219, "line": "\t\t    self.cursor.execute(\"DELETE FROM {0} WHERE {1}\".format(table, where))\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 32, "line": "\tdef delete_where(self, where):\n"}, {"line_no": 7, "char_start": 136, "char_end": 192, "line": "\t\t\tdelete_query = \"\"\"DELETE FROM users WHERE id=(%s)\"\"\"\n"}, {"line_no": 8, "char_start": 192, "char_end": 238, "line": "\t\t\tself.cursor.execute(delete_query,(where,))\n"}]}, "char_changes": {"deleted": [{"char_start": 23, "char_end": 30, "chars": " table,"}, {"char_start": 145, "char_end": 169, "chars": "    self.cursor.execute("}, {"char_start": 182, "char_end": 185, "chars": "{0}"}, {"char_start": 192, "char_end": 211, "chars": "{1}\".format(table, "}], "added": [{"char_start": 138, "char_end": 156, "chars": "\tdelete_query = \"\""}, {"char_start": 169, "char_end": 174, "chars": "users"}, {"char_start": 181, "char_end": 229, "chars": "id=(%s)\"\"\"\n\t\t\tself.cursor.execute(delete_query,("}, {"char_start": 234, "char_end": 235, "chars": ","}]}, "commit_link": "github.com/arturgoms/Teste-Tecnico/commit/c0dee37a2719986a18835893c9632d84bc984d14", "file_name": "src/models/mysql.py", "vul_type": "cwe-089"}
{"func_name": "update_where", "func_src_before": "\tdef update_where(self, table, info, where):\n\t\t\"\"\"\n        \tupdate_where function:\n           \t\tAtualiza um campo espec\u00edfico da tabela\n    \t\"\"\"\n\t\ttry:\n\t\t    self.cursor.execute(\"UPDATE {0} SET {1} WHERE {2}\".format(table, info, where))\n\t\texcept mysql.Error as error:\n\t\t    print(\"Erro: {}\".format(error))\n\t\tself.__connection.commit()\n\t\treturn self.cursor", "func_src_after": "\tdef update_where(self, info, where):\n\t\t\"\"\"\n        \tupdate_where function:\n           \t\tAtualiza um campo espec\u00edfico da tabela\n    \t\"\"\"\n\t\ttry:\n\t\t\tupdate_query = \"\"\"UPDATE users SET nome=%s, sobrenome=%s, endereco=%s WHERE id=%s\"\"\"\n\t\t\tself.cursor.execute(update_query,(info[0],info[1], info[2], where,))\n\t\texcept mysql.Error as error:\n\t\t    print(\"Erro: {}\".format(error))\n\t\tself.__connection.commit()\n\t\treturn self.cursor", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 45, "line": "\tdef update_where(self, table, info, where):\n"}, {"line_no": 7, "char_start": 151, "char_end": 236, "line": "\t\t    self.cursor.execute(\"UPDATE {0} SET {1} WHERE {2}\".format(table, info, where))\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 38, "line": "\tdef update_where(self, info, where):\n"}, {"line_no": 7, "char_start": 144, "char_end": 232, "line": "\t\t\tupdate_query = \"\"\"UPDATE users SET nome=%s, sobrenome=%s, endereco=%s WHERE id=%s\"\"\"\n"}, {"line_no": 8, "char_start": 232, "char_end": 304, "line": "\t\t\tself.cursor.execute(update_query,(info[0],info[1], info[2], where,))\n"}]}, "char_changes": {"deleted": [{"char_start": 23, "char_end": 30, "chars": " table,"}, {"char_start": 153, "char_end": 220, "chars": "    self.cursor.execute(\"UPDATE {0} SET {1} WHERE {2}\".format(table"}], "added": [{"char_start": 38, "char_end": 38, "chars": ""}, {"char_start": 146, "char_end": 284, "chars": "\tupdate_query = \"\"\"UPDATE users SET nome=%s, sobrenome=%s, endereco=%s WHERE id=%s\"\"\"\n\t\t\tself.cursor.execute(update_query,(info[0],info[1]"}, {"char_start": 290, "char_end": 293, "chars": "[2]"}, {"char_start": 300, "char_end": 301, "chars": ","}]}, "commit_link": "github.com/arturgoms/Teste-Tecnico/commit/c0dee37a2719986a18835893c9632d84bc984d14", "file_name": "src/models/mysql.py", "vul_type": "cwe-089"}
{"func_name": "get_plugin_version", "func_src_before": "    def get_plugin_version(self, base, plugin):\n        plugin_readme_url = urljoin(base, 'wp-content/plugins/%s/readme.txt' % plugin)\n        get_result = self.get(plugin_readme_url)\n        if get_result:\n            self.logger.debug(\"Plugin %s exists, getting version from readme.txt\" % plugin)\n            text = get_result.text\n            get_version = re.search('(?s)changelog.+?(\\d+\\.\\d+(?:\\.\\d+)?)', text, re.IGNORECASE)\n            if get_version:\n                return get_version.group(1)\n        return None", "func_src_after": "    def get_plugin_version(self, base, plugin):\n        plugin_readme_url = urljoin(base, 'wp-content/plugins/%s/readme.txt' % plugin)\n        get_result = self.get(plugin_readme_url)\n        if get_result and get_result.status_code == 200:\n            self.logger.debug(\"Plugin %s exists, getting version from readme.txt\" % plugin)\n            text = get_result.text\n            get_version = re.search('(?s)changelog.+?(\\d+\\.\\d+(?:\\.\\d+)?)', text, re.IGNORECASE)\n            if get_version:\n                return get_version.group(1)\n        return None", "line_changes": {"deleted": [{"line_no": 4, "char_start": 184, "char_end": 207, "line": "        if get_result:\n"}], "added": [{"line_no": 4, "char_start": 184, "char_end": 241, "line": "        if get_result and get_result.status_code == 200:\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 205, "char_end": 239, "chars": " and get_result.status_code == 200"}]}, "commit_link": "github.com/stefan2200/Helios/commit/8dbc65d9c4542b0b36fe8dca164338ab7716e295", "file_name": "libcms/scanners/wordpress.py", "vul_type": "cwe-089"}
{"func_name": "update", "func_src_before": "    def update(self):\n        try:\n            self.logger.info(\"Updating plugin files\")\n            data1 = self.get(self.plugin_update_url)\n            with open(self.cache_file(self.plugin_cache_file), 'w') as f:\n                x = data1.text.encode('ascii', 'ignore')\n                f.write(x)\n            self.logger.info(\"Updating version files\")\n            data2 = self.get(self.version_update_url)\n            with open(self.cache_file(self.version_cache_file), 'w') as f:\n                x = data2.text.encode('ascii', 'ignore')\n                f.write(x)\n            self.logger.info(\"Update complete\")\n        except Exception as e:\n            self.logger.error(\"Error updating databases\" % str(e))\n        return", "func_src_after": "    def update(self):\n        try:\n            self.logger.info(\"Updating plugin files\")\n            data1 = self.get(self.plugin_update_url)\n            with open(self.cache_file(self.plugin_cache_file), 'wb') as f:\n                x = data1.content\n                f.write(x)\n            self.logger.info(\"Updating version files\")\n            data2 = self.get(self.version_update_url)\n            with open(self.cache_file(self.version_cache_file), 'wb') as f:\n                x = data2.content\n                f.write(x)\n            self.logger.info(\"Update complete\")\n        except Exception as e:\n            self.logger.error(\"Error updating databases: %s\" % str(e))\n        return", "line_changes": {"deleted": [{"line_no": 5, "char_start": 142, "char_end": 216, "line": "            with open(self.cache_file(self.plugin_cache_file), 'w') as f:\n"}, {"line_no": 6, "char_start": 216, "char_end": 273, "line": "                x = data1.text.encode('ascii', 'ignore')\n"}, {"line_no": 10, "char_start": 409, "char_end": 484, "line": "            with open(self.cache_file(self.version_cache_file), 'w') as f:\n"}, {"line_no": 11, "char_start": 484, "char_end": 541, "line": "                x = data2.text.encode('ascii', 'ignore')\n"}, {"line_no": 15, "char_start": 647, "char_end": 714, "line": "            self.logger.error(\"Error updating databases\" % str(e))\n"}], "added": [{"line_no": 5, "char_start": 142, "char_end": 217, "line": "            with open(self.cache_file(self.plugin_cache_file), 'wb') as f:\n"}, {"line_no": 6, "char_start": 217, "char_end": 251, "line": "                x = data1.content\n"}, {"line_no": 10, "char_start": 387, "char_end": 463, "line": "            with open(self.cache_file(self.version_cache_file), 'wb') as f:\n"}, {"line_no": 11, "char_start": 463, "char_end": 497, "line": "                x = data2.content\n"}, {"line_no": 15, "char_start": 603, "char_end": 674, "line": "            self.logger.error(\"Error updating databases: %s\" % str(e))\n"}]}, "char_changes": {"deleted": [{"char_start": 242, "char_end": 272, "chars": "text.encode('ascii', 'ignore')"}, {"char_start": 510, "char_end": 540, "chars": "text.encode('ascii', 'ignore')"}, {"char_start": 647, "char_end": 647, "chars": ""}], "added": [{"char_start": 207, "char_end": 208, "chars": "b"}, {"char_start": 243, "char_end": 250, "chars": "content"}, {"char_start": 453, "char_end": 454, "chars": "b"}, {"char_start": 489, "char_end": 496, "chars": "content"}, {"char_start": 658, "char_end": 662, "chars": ": %s"}]}, "commit_link": "github.com/stefan2200/Helios/commit/8dbc65d9c4542b0b36fe8dca164338ab7716e295", "file_name": "libcms/scanners/wordpress.py", "vul_type": "cwe-089"}
{"func_name": "get_records_by_time", "func_src_before": "def get_records_by_time(\n    start_time,\n    end_time,\n    jurisdiction,\n    limit,\n    offset,\n    order_column,\n    order,\n    set_status\n):\n    matched_hmis_table = generate_matched_table_name(jurisdiction, 'hmis_service_stays')\n    matched_bookings_table = generate_matched_table_name(jurisdiction, 'jail_bookings')\n    hmis_exists = table_exists(matched_hmis_table, db.engine)\n    bookings_exists = table_exists(matched_bookings_table, db.engine)\n    if not hmis_exists:\n        raise ValueError('HMIS matched table {} does not exist. Please try again later.'.format(matched_hmis_table))\n    if not bookings_exists:\n        raise ValueError('Bookings matched table {} does not exist. Please try again later.'.format(matched_bookings_table))\n    columns = [\n        (\"matched_id\", 'matched_id'),\n        (\"coalesce(hmis_summary.first_name, jail_summary.first_name)\", 'first_name'),\n        (\"coalesce(hmis_summary.last_name, jail_summary.last_name)\", 'last_name'),\n        (\"hmis_summary.hmis_id\", 'hmis_id'),\n        (\"hmis_summary.hmis_contact\", 'hmis_contact'),\n        (\"hmis_summary.last_hmis_contact\", 'last_hmis_contact'),\n        (\"hmis_summary.cumu_hmis_days\", 'cumu_hmis_days'),\n        (\"jail_summary.jail_id\", 'jail_id'),\n        (\"jail_summary.jail_contact\", 'jail_contact'),\n        (\"jail_summary.last_jail_contact\", 'last_jail_contact'),\n        (\"jail_summary.cumu_jail_days\", 'cumu_jail_days'),\n        (\"coalesce(hmis_summary.hmis_contact, 0) + coalesce(jail_summary.jail_contact, 0)\", 'total_contact'),\n    ]\n    if not any(order_column for expression, alias in columns):\n        raise ValueError('Given order column expression does not match any alias in query. Exiting to avoid SQL injection attacks')\n    base_query = \"\"\"WITH hmis_summary AS (\n        SELECT\n            matched_id,\n            string_agg(distinct internal_person_id::text, ',') as hmis_id,\n            sum(\n                case when client_location_end_date is not null \n                    then date_part('day', client_location_end_date::timestamp - client_location_start_date::timestamp) \\\n                    else date_part('day', updated_ts::timestamp - client_location_start_date::timestamp) \n                end\n            )::int as cumu_hmis_days,\n            count(*) AS hmis_contact,\n            to_char(max(client_location_start_date::timestamp), 'YYYY-MM-DD') as last_hmis_contact,\n            max(first_name) as first_name,\n            max(last_name) as last_name\n        FROM (\n            SELECT\n               *\n            FROM {hmis_table}\n            WHERE\n                not (client_location_start_date < %(start_date)s AND client_location_end_date < %(start_date)s) and\n                not (client_location_start_date > %(end_date)s AND client_location_end_date > %(end_date)s)\n        ) AS hmis\n        GROUP BY matched_id\n    ), jail_summary AS (\n        SELECT\n            matched_id,\n            string_agg(distinct coalesce(internal_person_id, inmate_number)::text, ',') as jail_id,\n            sum(\n                case when jail_exit_date is not null \n                    then date_part('day', jail_exit_date::timestamp - jail_entry_date::timestamp) \\\n                    else date_part('day', updated_ts::timestamp - jail_entry_date::timestamp) \n                end\n            )::int as cumu_jail_days,\n            count(*) AS jail_contact,\n            to_char(max(jail_entry_date::timestamp), 'YYYY-MM-DD') as last_jail_contact,\n            max(first_name) as first_name,\n            max(last_name) as last_name\n        FROM (\n            SELECT\n               *\n            FROM {booking_table}\n            WHERE\n                not (jail_entry_date < %(start_date)s AND jail_exit_date < %(start_date)s) and\n                not (jail_entry_date > %(end_date)s AND jail_exit_date > %(end_date)s)\n        ) AS jail\n        GROUP BY matched_id\n    )\n    SELECT\n    {columns}\n    FROM hmis_summary\n    FULL OUTER JOIN jail_summary USING(matched_id)\n    \"\"\".format(\n        hmis_table=matched_hmis_table,\n        booking_table=matched_bookings_table,\n        columns=\",\\n\".join(\"{} as {}\".format(expression, alias) for expression, alias in columns),\n    )\n\n\n    logging.info('Querying table records')\n    if order not in {'asc', 'desc'}:\n        raise ValueError('Given order direction is not valid. Exiting to avoid SQL injection attacks')\n    if not isinstance(limit, int) and not limit.isdigit() and limit != 'ALL':\n        raise ValueError('Given limit is not valid. Existing to avoid SQL injection attacks')\n    filter_by_status = {\n        'Jail': 'jail_summary.matched_id is not null',\n        'HMIS': 'hmis_summary.matched_id is not null',\n        'Intersection': 'hmis_summary.matched_id = jail_summary.matched_id'\n    }\n    status_filter = filter_by_status.get(set_status, 'true')\n    rows_to_show = [dict(row) for row in db.engine.execute(\"\"\"\n        {}\n        where {}\n        order by {} {}\n        limit {} offset %(offset)s\"\"\".format(\n            base_query,\n            status_filter,\n            order_column,\n            order,\n            limit\n        ),\n        start_date=start_time,\n        end_date=end_time,\n        offset=offset,\n    )]\n    query = \"\"\"\n    SELECT\n    *,\n    DATE_PART('day', {exit}::timestamp - {start}::timestamp) as days\n    FROM {table_name}\n    WHERE\n        not ({start} < %(start_time)s AND {exit} < %(start_time)s) and\n        not ({start} > %(end_time)s AND {exit} > %(end_time)s)\n    \"\"\"\n    hmis_query = query.format(\n        table_name=matched_hmis_table,\n        start=\"client_location_start_date\",\n        exit=\"client_location_end_date\"\n    )\n    bookings_query = query.format(\n        table_name=matched_bookings_table,\n        start=\"jail_entry_date\",\n        exit=\"jail_exit_date\"\n    )\n    logging.info('Done querying table records')\n    logging.info('Querying venn diagram stats')\n    venn_diagram_stats = next(db.engine.execute('''select\n        count(distinct(hmis.matched_id)) as hmis_size,\n        count(distinct(bookings.matched_id)) as bookings_size,\n        count(distinct(case when hmis.matched_id = bookings.matched_id then hmis.matched_id else null end)) as shared_size,\n        count(distinct(matched_id))\n        from ({}) hmis\n        full outer join ({}) bookings using (matched_id)\n    '''.format(hmis_query, bookings_query),\n                                start_time=start_time,\n                                end_time=end_time))\n    counts_by_status = {\n        'HMIS': venn_diagram_stats[0],\n        'Jail': venn_diagram_stats[1],\n        'Intersection': venn_diagram_stats[2]\n    }\n\n    logging.info('Done querying venn diagram stats')\n\n    venn_diagram_data = [\n        {\n            \"sets\": [\n                \"Jail\"\n            ],\n            \"size\": venn_diagram_stats[1]\n        },\n        {\n            \"sets\": [\n                \"Homeless\"\n            ],\n            \"size\": venn_diagram_stats[0]\n        },\n        {\n            \"sets\": [\n                \"Jail\",\n                \"Homeless\"\n            ],\n            \"size\": venn_diagram_stats[2]\n        }\n    ]\n    logging.info('Retrieving bar data from database')\n    filtered_data = retrieve_bar_data(matched_hmis_table, matched_bookings_table, start_time, end_time)\n    logging.info('Done retrieving bar data from database')\n    filtered_data['tableData'] = rows_to_show\n    return {\n        \"vennDiagramData\": venn_diagram_data,\n        \"totalTableRows\": counts_by_status.get(set_status, venn_diagram_stats[3]),\n        \"filteredData\": filtered_data\n    }", "func_src_after": "def get_records_by_time(\n    start_time,\n    end_time,\n    jurisdiction,\n    limit,\n    offset,\n    order_column,\n    order,\n    set_status\n):\n    matched_hmis_table = generate_matched_table_name(jurisdiction, 'hmis_service_stays')\n    matched_bookings_table = generate_matched_table_name(jurisdiction, 'jail_bookings')\n    hmis_exists = table_exists(matched_hmis_table, db.engine)\n    bookings_exists = table_exists(matched_bookings_table, db.engine)\n    if not hmis_exists:\n        raise ValueError('HMIS matched table {} does not exist. Please try again later.'.format(matched_hmis_table))\n    if not bookings_exists:\n        raise ValueError('Bookings matched table {} does not exist. Please try again later.'.format(matched_bookings_table))\n    columns = [\n        (\"regexp_replace(matched_id, '[^\\w]', '', 'g')\", 'matched_id'),\n        (\"coalesce(hmis_summary.first_name, jail_summary.first_name)\", 'first_name'),\n        (\"coalesce(hmis_summary.last_name, jail_summary.last_name)\", 'last_name'),\n        (\"hmis_summary.hmis_id\", 'hmis_id'),\n        (\"hmis_summary.hmis_contact\", 'hmis_contact'),\n        (\"hmis_summary.last_hmis_contact\", 'last_hmis_contact'),\n        (\"hmis_summary.cumu_hmis_days\", 'cumu_hmis_days'),\n        (\"jail_summary.jail_id\", 'jail_id'),\n        (\"jail_summary.jail_contact\", 'jail_contact'),\n        (\"jail_summary.last_jail_contact\", 'last_jail_contact'),\n        (\"jail_summary.cumu_jail_days\", 'cumu_jail_days'),\n        (\"coalesce(hmis_summary.hmis_contact, 0) + coalesce(jail_summary.jail_contact, 0)\", 'total_contact'),\n    ]\n    if not any(alias == order_column for expression, alias in columns):\n        raise ValueError('Given order column expression does not match any alias in query. Exiting to avoid SQL injection attacks')\n    base_query = \"\"\"WITH hmis_summary AS (\n        SELECT\n            matched_id,\n            string_agg(distinct internal_person_id::text, ',') as hmis_id,\n            sum(\n                case when client_location_end_date is not null \n                    then date_part('day', client_location_end_date::timestamp - client_location_start_date::timestamp) \\\n                    else date_part('day', updated_ts::timestamp - client_location_start_date::timestamp) \n                end\n            )::int as cumu_hmis_days,\n            count(*) AS hmis_contact,\n            to_char(max(client_location_start_date::timestamp), 'YYYY-MM-DD') as last_hmis_contact,\n            max(first_name) as first_name,\n            max(last_name) as last_name\n        FROM (\n            SELECT\n               *\n            FROM {hmis_table}\n            WHERE\n                not (client_location_start_date < %(start_date)s AND client_location_end_date < %(start_date)s) and\n                not (client_location_start_date > %(end_date)s AND client_location_end_date > %(end_date)s)\n        ) AS hmis\n        GROUP BY matched_id\n    ), jail_summary AS (\n        SELECT\n            matched_id,\n            string_agg(distinct coalesce(internal_person_id, inmate_number)::text, ',') as jail_id,\n            sum(\n                case when jail_exit_date is not null \n                    then date_part('day', jail_exit_date::timestamp - jail_entry_date::timestamp) \\\n                    else date_part('day', updated_ts::timestamp - jail_entry_date::timestamp) \n                end\n            )::int as cumu_jail_days,\n            count(*) AS jail_contact,\n            to_char(max(jail_entry_date::timestamp), 'YYYY-MM-DD') as last_jail_contact,\n            max(first_name) as first_name,\n            max(last_name) as last_name\n        FROM (\n            SELECT\n               *\n            FROM {booking_table}\n            WHERE\n                not (jail_entry_date < %(start_date)s AND jail_exit_date < %(start_date)s) and\n                not (jail_entry_date > %(end_date)s AND jail_exit_date > %(end_date)s)\n        ) AS jail\n        GROUP BY matched_id\n    )\n    SELECT\n    {columns}\n    FROM hmis_summary\n    FULL OUTER JOIN jail_summary USING(matched_id)\n    \"\"\".format(\n        hmis_table=matched_hmis_table,\n        booking_table=matched_bookings_table,\n        columns=\",\\n\".join(\"{} as {}\".format(expression, alias) for expression, alias in columns),\n    )\n\n\n    logging.info('Querying table records')\n    if order not in {'asc', 'desc'}:\n        raise ValueError('Given order direction is not valid. Exiting to avoid SQL injection attacks')\n    if not isinstance(limit, int) and not limit.isdigit() and limit != 'ALL':\n        raise ValueError('Given limit is not valid. Existing to avoid SQL injection attacks')\n    filter_by_status = {\n        'Jail': 'jail_summary.matched_id is not null',\n        'HMIS': 'hmis_summary.matched_id is not null',\n        'Intersection': 'hmis_summary.matched_id = jail_summary.matched_id'\n    }\n    status_filter = filter_by_status.get(set_status, 'true')\n    rows_to_show = [dict(row) for row in db.engine.execute(\"\"\"\n        {}\n        where {}\n        order by {} {}\n        limit {} offset %(offset)s\"\"\".format(\n            base_query,\n            status_filter,\n            order_column,\n            order,\n            limit\n        ),\n        start_date=start_time,\n        end_date=end_time,\n        offset=offset,\n    )]\n    query = \"\"\"\n    SELECT\n    *,\n    DATE_PART('day', {exit}::timestamp - {start}::timestamp) as days\n    FROM {table_name}\n    WHERE\n        not ({start} < %(start_time)s AND {exit} < %(start_time)s) and\n        not ({start} > %(end_time)s AND {exit} > %(end_time)s)\n    \"\"\"\n    hmis_query = query.format(\n        table_name=matched_hmis_table,\n        start=\"client_location_start_date\",\n        exit=\"client_location_end_date\"\n    )\n    bookings_query = query.format(\n        table_name=matched_bookings_table,\n        start=\"jail_entry_date\",\n        exit=\"jail_exit_date\"\n    )\n    logging.info('Done querying table records')\n    logging.info('Querying venn diagram stats')\n    venn_diagram_stats = next(db.engine.execute('''select\n        count(distinct(hmis.matched_id)) as hmis_size,\n        count(distinct(bookings.matched_id)) as bookings_size,\n        count(distinct(case when hmis.matched_id = bookings.matched_id then hmis.matched_id else null end)) as shared_size,\n        count(distinct(matched_id))\n        from ({}) hmis\n        full outer join ({}) bookings using (matched_id)\n    '''.format(hmis_query, bookings_query),\n                                start_time=start_time,\n                                end_time=end_time))\n    counts_by_status = {\n        'HMIS': venn_diagram_stats[0],\n        'Jail': venn_diagram_stats[1],\n        'Intersection': venn_diagram_stats[2]\n    }\n\n    logging.info('Done querying venn diagram stats')\n\n    venn_diagram_data = [\n        {\n            \"sets\": [\n                \"Jail\"\n            ],\n            \"size\": venn_diagram_stats[1]\n        },\n        {\n            \"sets\": [\n                \"Homeless\"\n            ],\n            \"size\": venn_diagram_stats[0]\n        },\n        {\n            \"sets\": [\n                \"Jail\",\n                \"Homeless\"\n            ],\n            \"size\": venn_diagram_stats[2]\n        }\n    ]\n    logging.info('Retrieving bar data from database')\n    filtered_data = retrieve_bar_data(matched_hmis_table, matched_bookings_table, start_time, end_time)\n    logging.info('Done retrieving bar data from database')\n    filtered_data['tableData'] = rows_to_show\n    return {\n        \"vennDiagramData\": venn_diagram_data,\n        \"totalTableRows\": counts_by_status.get(set_status, venn_diagram_stats[3]),\n        \"filteredData\": filtered_data\n    }", "line_changes": {"deleted": [{"line_no": 20, "char_start": 762, "char_end": 800, "line": "        (\"matched_id\", 'matched_id'),\n"}, {"line_no": 33, "char_start": 1533, "char_end": 1596, "line": "    if not any(order_column for expression, alias in columns):\n"}], "added": [{"line_no": 20, "char_start": 762, "char_end": 834, "line": "        (\"regexp_replace(matched_id, '[^\\w]', '', 'g')\", 'matched_id'),\n"}, {"line_no": 33, "char_start": 1567, "char_end": 1639, "line": "    if not any(alias == order_column for expression, alias in columns):\n"}]}, "char_changes": {"deleted": [{"char_start": 772, "char_end": 782, "chars": "matched_id"}], "added": [{"char_start": 772, "char_end": 816, "chars": "regexp_replace(matched_id, '[^\\w]', '', 'g')"}, {"char_start": 1582, "char_end": 1591, "chars": "alias == "}]}, "commit_link": "github.com/dssg/matching-tool/commit/ff6de91a060c1f585887e29381183e619627bbc5", "file_name": "webapp/webapp/apis/query.py", "vul_type": "cwe-089"}
{"func_name": "all_deposits", "func_src_before": "    def all_deposits(self,coin):\n        sql = \"SELECT * FROM deposits WHERE coin='%s'\" % coin\n        self.cursor.execute(sql)\n        return self.cursor.fetchall()", "func_src_after": "    def all_deposits(self,coin):\n        sql = \"SELECT * FROM deposits WHERE coin='%s'\"\n        self.cursor.execute(sql, (coin,))\n        return self.cursor.fetchall()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 33, "char_end": 95, "line": "        sql = \"SELECT * FROM deposits WHERE coin='%s'\" % coin\n"}, {"line_no": 3, "char_start": 95, "char_end": 128, "line": "        self.cursor.execute(sql)\n"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 88, "line": "        sql = \"SELECT * FROM deposits WHERE coin='%s'\"\n"}, {"line_no": 3, "char_start": 88, "char_end": 130, "line": "        self.cursor.execute(sql, (coin,))\n"}]}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 94, "chars": " % coin"}], "added": [{"char_start": 119, "char_end": 128, "chars": ", (coin,)"}]}, "commit_link": "github.com/ktechmidas/garlictipsbot/commit/7c262255f933cb721109ac4be752b5b7599275aa", "file_name": "deposit.py", "vul_type": "cwe-089"}
{"func_name": "generate_insert", "func_src_before": "    def generate_insert(self, query):\n\n        keys = \",\".join([x.encode(\"utf-8\") for x in query.values.keys()])\n        values = \",\".join([x.encode(\"utf-8\") for x in query.values.values()])\n\n        str_query = (\"INSERT INTO {0} ({1}) VALUES ({2})\"\n                    .format(query.model_class._meta.table_name, keys, values))\n\n        if query.on_conflict:\n            str_query += (\" ON CONFLICT ({0}) DO UPDATE SET ({1}) = ({2})\"\n                         .format(\",\".join(query.on_conflict), keys, values))\n\n        if query.return_id:\n            str_query += \" RETURNING id\"\n\n        str_query += \";\"\n        return str_query", "func_src_after": "    def generate_insert(self, query):\n\n        keys = \",\".join([x.encode(\"utf-8\") for x in query.values.keys()])\n        inputs = \",\".join([ \"%s\" for x in query.values.values()])\n        values = query.values.values()\n\n        str_query = (\"INSERT INTO {0} ({1}) VALUES ({2})\"\n                    .format(query.model_class._meta.table_name, keys, inputs))\n\n        if query.on_conflict:\n            str_query += (\" ON CONFLICT ({0}) DO UPDATE SET ({1}) = ({2})\"\n                         .format(\",\".join(query.on_conflict), keys, inputs))\n            values += values\n\n        if query.return_id:\n            str_query += \" RETURNING id\"\n\n        str_query += \";\"\n        return str_query, values", "line_changes": {"deleted": [{"line_no": 4, "char_start": 113, "char_end": 191, "line": "        values = \",\".join([x.encode(\"utf-8\") for x in query.values.values()])\n"}, {"line_no": 7, "char_start": 250, "char_end": 329, "line": "                    .format(query.model_class._meta.table_name, keys, values))\n"}, {"line_no": 11, "char_start": 435, "char_end": 512, "line": "                         .format(\",\".join(query.on_conflict), keys, values))\n"}, {"line_no": 17, "char_start": 608, "char_end": 632, "line": "        return str_query\n"}], "added": [{"line_no": 4, "char_start": 113, "char_end": 179, "line": "        inputs = \",\".join([ \"%s\" for x in query.values.values()])\n"}, {"line_no": 5, "char_start": 179, "char_end": 218, "line": "        values = query.values.values()\n"}, {"line_no": 8, "char_start": 277, "char_end": 356, "line": "                    .format(query.model_class._meta.table_name, keys, inputs))\n"}, {"line_no": 12, "char_start": 462, "char_end": 539, "line": "                         .format(\",\".join(query.on_conflict), keys, inputs))\n"}, {"line_no": 13, "char_start": 539, "char_end": 568, "line": "            values += values\n"}, {"line_no": 19, "char_start": 664, "char_end": 696, "line": "        return str_query, values\n"}]}, "char_changes": {"deleted": [{"char_start": 121, "char_end": 126, "chars": "value"}, {"char_start": 140, "char_end": 157, "chars": "x.encode(\"utf-8\")"}, {"char_start": 320, "char_end": 325, "chars": "value"}, {"char_start": 509, "char_end": 511, "chars": "))"}], "added": [{"char_start": 121, "char_end": 126, "chars": "input"}, {"char_start": 140, "char_end": 145, "chars": " \"%s\""}, {"char_start": 178, "char_end": 217, "chars": "\n        values = query.values.values()"}, {"char_start": 347, "char_end": 352, "chars": "input"}, {"char_start": 530, "char_end": 561, "chars": "inputs))\n            values += "}, {"char_start": 688, "char_end": 696, "chars": ", values"}]}, "commit_link": "github.com/ThinkEE/Kameleon/commit/a474a6be7af8378db583ef160475c38a0d6809e2", "file_name": "kameleon/databases/postgresql.py", "vul_type": "cwe-089"}
{"func_name": "generate_update", "func_src_before": "    def generate_update(self, query):\n\n        if query.model_class._meta.primary_key:\n            _id = query.values[\"id\"]\n            del query.values[\"id\"]\n\n        keys = \",\".join([x.encode(\"utf-8\") for x in query.values.keys()])\n        values = \",\".join([x.encode(\"utf-8\") for x in query.values.values()])\n\n        if query.model_class._meta.primary_key:\n            str_query = (\"UPDATE {0} SET ({1})=({2}) WHERE id = {3}\"\n                        .format(query.model_class._meta.table_name, keys, values, _id))\n        else:\n            # XXX To Do: If not id -> check if one of the field is Unique. If one is unique use it to update\n            print(\"ERROR: Not primary key cannot update row. Need to be implemented\")\n            raise Exception(\"ERROR: Not primary key cannot update row. Need to be implemented\")\n\n        if query.return_id:\n            str_query += \" RETURNING id\"\n\n        str_query += \";\"\n        return str_query", "func_src_after": "    def generate_update(self, query):\n\n        if query.model_class._meta.primary_key:\n            _id = query.values[\"id\"]\n            del query.values[\"id\"]\n\n        keys = \",\".join([x.encode(\"utf-8\") for x in query.values.keys()])\n        inputs = \",\".join([ \"%s\" for x in query.values.values()])\n\n        if query.model_class._meta.primary_key:\n            str_query = (\"UPDATE {0} SET ({1})=({2}) WHERE id = {3}\"\n                        .format(query.model_class._meta.table_name, keys, inputs, _id))\n        else:\n            # XXX To Do: If not id -> check if one of the field is Unique. If one is unique use it to update\n            print(\"ERROR: Not primary key cannot update row. Need to be implemented\")\n            raise Exception(\"ERROR: Not primary key cannot update row. Need to be implemented\")\n\n        if query.return_id:\n            str_query += \" RETURNING id\"\n\n        str_query += \";\"\n        return str_query, query.values.values()", "line_changes": {"deleted": [{"line_no": 8, "char_start": 234, "char_end": 312, "line": "        values = \",\".join([x.encode(\"utf-8\") for x in query.values.values()])\n"}, {"line_no": 12, "char_start": 430, "char_end": 518, "line": "                        .format(query.model_class._meta.table_name, keys, values, _id))\n"}, {"line_no": 22, "char_start": 919, "char_end": 943, "line": "        return str_query\n"}], "added": [{"line_no": 8, "char_start": 234, "char_end": 300, "line": "        inputs = \",\".join([ \"%s\" for x in query.values.values()])\n"}, {"line_no": 12, "char_start": 418, "char_end": 506, "line": "                        .format(query.model_class._meta.table_name, keys, inputs, _id))\n"}, {"line_no": 22, "char_start": 907, "char_end": 954, "line": "        return str_query, query.values.values()\n"}]}, "char_changes": {"deleted": [{"char_start": 242, "char_end": 247, "chars": "value"}, {"char_start": 261, "char_end": 278, "chars": "x.encode(\"utf-8\")"}, {"char_start": 504, "char_end": 509, "chars": "value"}], "added": [{"char_start": 242, "char_end": 247, "chars": "input"}, {"char_start": 261, "char_end": 266, "chars": " \"%s\""}, {"char_start": 492, "char_end": 497, "chars": "input"}, {"char_start": 931, "char_end": 954, "chars": ", query.values.values()"}]}, "commit_link": "github.com/ThinkEE/Kameleon/commit/a474a6be7af8378db583ef160475c38a0d6809e2", "file_name": "kameleon/databases/postgresql.py", "vul_type": "cwe-089"}
{"func_name": "check_tables", "func_src_before": "def check_tables():\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT 1 FROM people LIMIT 1;\n            ''')\n        cursor.fetchone()\n        logger.debug('people table exists')\n    except:\n        raise\n    try:\n        cursor.execute('''\n            SELECT 1 FROM people LIMIT 1;\n            ''')\n        cursor.fetchone()\n        logger.debug('people table exists')\n    except:\n        raise", "func_src_after": "def check_tables():\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT 1 FROM people LIMIT 1;\n            ''')\n        cursor.fetchone()\n        logger.debug('people table exists')\n    except Exception as e:\n        logger.exception(e)\n        raise\n    try:\n        cursor.execute('''\n            SELECT 1 FROM people LIMIT 1;\n            ''')\n        cursor.fetchone()\n        logger.debug('people table exists')\n    except Exception as e:\n        logger.exception(e)\n        raise", "line_changes": {"deleted": [{"line_no": 10, "char_start": 232, "char_end": 244, "line": "    except:\n"}, {"line_no": 18, "char_start": 423, "char_end": 435, "line": "    except:\n"}], "added": [{"line_no": 10, "char_start": 232, "char_end": 259, "line": "    except Exception as e:\n"}, {"line_no": 11, "char_start": 259, "char_end": 287, "line": "        logger.exception(e)\n"}, {"line_no": 19, "char_start": 466, "char_end": 493, "line": "    except Exception as e:\n"}, {"line_no": 20, "char_start": 493, "char_end": 521, "line": "        logger.exception(e)\n"}]}, "char_changes": {"deleted": [{"char_start": 242, "char_end": 243, "chars": ":"}, {"char_start": 433, "char_end": 434, "chars": ":"}], "added": [{"char_start": 242, "char_end": 286, "chars": " Exception as e:\n        logger.exception(e)"}, {"char_start": 476, "char_end": 520, "chars": " Exception as e:\n        logger.exception(e)"}]}, "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089"}
{"func_name": "karma_ask", "func_src_before": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(\n            ''' SELECT karma FROM people WHERE name='{}' '''.format(name))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(''' SELECT karma FROM people WHERE name=%(name)s ''',\n                       (name, ))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "line_changes": {"deleted": [{"line_no": 5, "char_start": 77, "char_end": 101, "line": "        cursor.execute(\n"}, {"line_no": 6, "char_start": 101, "char_end": 176, "line": "            ''' SELECT karma FROM people WHERE name='{}' '''.format(name))\n"}], "added": [{"line_no": 5, "char_start": 77, "char_end": 154, "line": "        cursor.execute(''' SELECT karma FROM people WHERE name=%(name)s ''',\n"}, {"line_no": 6, "char_start": 154, "char_end": 187, "line": "                       (name, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 100, "char_end": 113, "chars": "\n            "}, {"char_start": 153, "char_end": 168, "chars": "'{}' '''.format"}], "added": [{"char_start": 140, "char_end": 177, "chars": "%(name)s ''',\n                       "}, {"char_start": 182, "char_end": 184, "chars": ", "}]}, "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089"}
{"func_name": "karma_rank", "func_src_before": "def karma_rank(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT (SELECT COUNT(*) FROM people AS t2 WHERE t2.karma > t1.karma)\n            AS row_Num FROM people AS t1 WHERE name='{}'\n        '''.format(name))\n        rank = cursor.fetchone()[0] + 1\n        logger.debug('Rank of {} found for name {}'.format(rank, name))\n        db.close()\n        return rank\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def karma_rank(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT (SELECT COUNT(*) FROM people AS t2 WHERE t2.karma > t1.karma)\n            AS row_Num FROM people AS t1 WHERE name=%(name)s\n        ''', (name, ))\n        rank = cursor.fetchone()[0] + 1\n        logger.debug('Rank of {} found for name {}'.format(rank, name))\n        db.close()\n        return rank\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "line_changes": {"deleted": [{"line_no": 7, "char_start": 186, "char_end": 243, "line": "            AS row_Num FROM people AS t1 WHERE name='{}'\n"}, {"line_no": 8, "char_start": 243, "char_end": 269, "line": "        '''.format(name))\n"}], "added": [{"line_no": 7, "char_start": 186, "char_end": 247, "line": "            AS row_Num FROM people AS t1 WHERE name=%(name)s\n"}, {"line_no": 8, "char_start": 247, "char_end": 270, "line": "        ''', (name, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 238, "char_end": 242, "chars": "'{}'"}, {"char_start": 254, "char_end": 261, "chars": ".format"}], "added": [{"char_start": 238, "char_end": 246, "chars": "%(name)s"}, {"char_start": 258, "char_end": 260, "chars": ", "}, {"char_start": 265, "char_end": 267, "chars": ", "}]}, "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089"}
{"func_name": "karma_add", "func_src_before": "def karma_add(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES('{}',1,0)\n                '''.format(name))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 karma for {}'.format(name))\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = {0} WHERE name = '{1}'\n                '''.format(karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} karma for {}'.format(\n                karma, name))\n            return karma\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    db.close()", "func_src_after": "def karma_add(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES(%(name)s,1,0)\n                ''', name)\n            db.commit()\n            logger.debug('Inserted into karmadb 1 karma for {}'.format(name))\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = %(karma)s WHERE name = %(name)s\n                ''', (karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} karma for {}'.format(\n                karma,\n                name,\n            ))\n            return karma\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    db.close()", "line_changes": {"deleted": [{"line_no": 8, "char_start": 162, "char_end": 232, "line": "                INSERT INTO people(name,karma,shame) VALUES('{}',1,0)\n"}, {"line_no": 9, "char_start": 232, "char_end": 266, "line": "                '''.format(name))\n"}, {"line_no": 20, "char_start": 588, "char_end": 653, "line": "                UPDATE people SET karma = {0} WHERE name = '{1}'\n"}, {"line_no": 21, "char_start": 653, "char_end": 694, "line": "                '''.format(karma, name))\n"}, {"line_no": 24, "char_start": 791, "char_end": 821, "line": "                karma, name))\n"}], "added": [{"line_no": 8, "char_start": 162, "char_end": 236, "line": "                INSERT INTO people(name,karma,shame) VALUES(%(name)s,1,0)\n"}, {"line_no": 9, "char_start": 236, "char_end": 263, "line": "                ''', name)\n"}, {"line_no": 20, "char_start": 585, "char_end": 659, "line": "                UPDATE people SET karma = %(karma)s WHERE name = %(name)s\n"}, {"line_no": 21, "char_start": 659, "char_end": 695, "line": "                ''', (karma, name))\n"}, {"line_no": 24, "char_start": 792, "char_end": 815, "line": "                karma,\n"}, {"line_no": 25, "char_start": 815, "char_end": 837, "line": "                name,\n"}, {"line_no": 26, "char_start": 837, "char_end": 852, "line": "            ))\n"}]}, "char_changes": {"deleted": [{"char_start": 222, "char_end": 226, "chars": "'{}'"}, {"char_start": 251, "char_end": 259, "chars": ".format("}, {"char_start": 264, "char_end": 265, "chars": ")"}, {"char_start": 630, "char_end": 633, "chars": "{0}"}, {"char_start": 647, "char_end": 652, "chars": "'{1}'"}, {"char_start": 672, "char_end": 679, "chars": ".format"}, {"char_start": 813, "char_end": 818, "chars": " name"}], "added": [{"char_start": 222, "char_end": 230, "chars": "%(name)s"}, {"char_start": 255, "char_end": 257, "chars": ", "}, {"char_start": 627, "char_end": 636, "chars": "%(karma)s"}, {"char_start": 650, "char_end": 658, "chars": "%(name)s"}, {"char_start": 678, "char_end": 680, "chars": ", "}, {"char_start": 814, "char_end": 849, "chars": "\n                name,\n            "}]}, "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089"}
{"func_name": "karma_sub", "func_src_before": "def karma_sub(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES('{}',-1,0)\n                '''.format(name))\n            db.commit()\n            logger.debug('Inserted into karmadb -1 karma for {}'.format(name))\n            db.close()\n            return -1\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma - 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = {0} WHERE name = '{1}'\n                '''.format(karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb -1 karma for {}'.format(name))\n            db.close()\n            return karma\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "func_src_after": "def karma_sub(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES(%(name)s,-1,0)\n                ''', (name, ))\n            db.commit()\n            logger.debug('Inserted into karmadb -1 karma for {}'.format(name))\n            db.close()\n            return -1\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma - 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = %(karma)s WHERE name = %(name)s\n                ''', (\n                karma,\n                name,\n            ))\n            db.commit()\n            logger.debug('Inserted into karmadb -1 karma for {}'.format(name))\n            db.close()\n            return karma\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "line_changes": {"deleted": [{"line_no": 8, "char_start": 162, "char_end": 233, "line": "                INSERT INTO people(name,karma,shame) VALUES('{}',-1,0)\n"}, {"line_no": 9, "char_start": 233, "char_end": 267, "line": "                '''.format(name))\n"}, {"line_no": 22, "char_start": 615, "char_end": 680, "line": "                UPDATE people SET karma = {0} WHERE name = '{1}'\n"}, {"line_no": 23, "char_start": 680, "char_end": 721, "line": "                '''.format(karma, name))\n"}], "added": [{"line_no": 8, "char_start": 162, "char_end": 237, "line": "                INSERT INTO people(name,karma,shame) VALUES(%(name)s,-1,0)\n"}, {"line_no": 9, "char_start": 237, "char_end": 268, "line": "                ''', (name, ))\n"}, {"line_no": 22, "char_start": 616, "char_end": 690, "line": "                UPDATE people SET karma = %(karma)s WHERE name = %(name)s\n"}, {"line_no": 23, "char_start": 690, "char_end": 713, "line": "                ''', (\n"}, {"line_no": 24, "char_start": 713, "char_end": 736, "line": "                karma,\n"}, {"line_no": 25, "char_start": 736, "char_end": 758, "line": "                name,\n"}, {"line_no": 26, "char_start": 758, "char_end": 773, "line": "            ))\n"}]}, "char_changes": {"deleted": [{"char_start": 222, "char_end": 226, "chars": "'{}'"}, {"char_start": 252, "char_end": 259, "chars": ".format"}, {"char_start": 657, "char_end": 660, "chars": "{0}"}, {"char_start": 674, "char_end": 679, "chars": "'{1}'"}, {"char_start": 699, "char_end": 718, "chars": ".format(karma, name"}], "added": [{"char_start": 222, "char_end": 230, "chars": "%(name)s"}, {"char_start": 256, "char_end": 258, "chars": ", "}, {"char_start": 263, "char_end": 265, "chars": ", "}, {"char_start": 658, "char_end": 667, "chars": "%(karma)s"}, {"char_start": 681, "char_end": 689, "chars": "%(name)s"}, {"char_start": 709, "char_end": 770, "chars": ", (\n                karma,\n                name,\n            "}]}, "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089"}
{"func_name": "shame_ask", "func_src_before": "def shame_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT shame FROM people WHERE name='{}'\n            '''.format(name))\n        shame = cursor.fetchone()\n        db.close()\n        if shame is None:\n            logger.debug('No shame found for name {}'.format(name))\n            return shame\n        else:\n            shame = shame[0]\n            logger.debug('shame of {} found for name {}'.format(shame, name))\n            return shame\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def shame_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT shame FROM people WHERE name=%(name)s\n            ''', (name, ))\n        shame = cursor.fetchone()\n        db.close()\n        if shame is None:\n            logger.debug('No shame found for name {}'.format(name))\n            return shame\n        else:\n            shame = shame[0]\n            logger.debug('shame of {} found for name {}'.format(shame, name))\n            return shame\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "line_changes": {"deleted": [{"line_no": 6, "char_start": 104, "char_end": 157, "line": "            SELECT shame FROM people WHERE name='{}'\n"}, {"line_no": 7, "char_start": 157, "char_end": 187, "line": "            '''.format(name))\n"}], "added": [{"line_no": 6, "char_start": 104, "char_end": 161, "line": "            SELECT shame FROM people WHERE name=%(name)s\n"}, {"line_no": 7, "char_start": 161, "char_end": 188, "line": "            ''', (name, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 152, "char_end": 156, "chars": "'{}'"}, {"char_start": 172, "char_end": 179, "chars": ".format"}], "added": [{"char_start": 152, "char_end": 160, "chars": "%(name)s"}, {"char_start": 176, "char_end": 178, "chars": ", "}, {"char_start": 183, "char_end": 185, "chars": ", "}]}, "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089"}
{"func_name": "shame_add", "func_src_before": "def shame_add(name):\n    shame = shame_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if shame is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES('{}',0,1)\n                '''.format(name))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 shame for {}'.format(name))\n            db.close()\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n\n    else:\n        shame = shame + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET shame = {0} WHERE name = '{1}'\n                '''.format(shame, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} shame for {}'.format(\n                shame, name))\n            db.close()\n            return shame\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "func_src_after": "def shame_add(name):\n    shame = shame_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if shame is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES(%(name)s,0,1)\n                ''', (name, ))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 shame for {}'.format(name))\n            db.close()\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n\n    else:\n        shame = shame + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET shame = %(karma)s WHERE name = %(name)s\n                ''' (\n                shame,\n                name,\n            ))\n            db.commit()\n            logger.debug('Inserted into karmadb {} shame for {}'.format(\n                shame, name))\n            db.close()\n            return shame\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "line_changes": {"deleted": [{"line_no": 8, "char_start": 162, "char_end": 232, "line": "                INSERT INTO people(name,karma,shame) VALUES('{}',0,1)\n"}, {"line_no": 9, "char_start": 232, "char_end": 266, "line": "                '''.format(name))\n"}, {"line_no": 22, "char_start": 612, "char_end": 677, "line": "                UPDATE people SET shame = {0} WHERE name = '{1}'\n"}, {"line_no": 23, "char_start": 677, "char_end": 718, "line": "                '''.format(shame, name))\n"}], "added": [{"line_no": 8, "char_start": 162, "char_end": 236, "line": "                INSERT INTO people(name,karma,shame) VALUES(%(name)s,0,1)\n"}, {"line_no": 9, "char_start": 236, "char_end": 267, "line": "                ''', (name, ))\n"}, {"line_no": 22, "char_start": 613, "char_end": 687, "line": "                UPDATE people SET shame = %(karma)s WHERE name = %(name)s\n"}, {"line_no": 23, "char_start": 687, "char_end": 709, "line": "                ''' (\n"}, {"line_no": 24, "char_start": 709, "char_end": 732, "line": "                shame,\n"}, {"line_no": 25, "char_start": 732, "char_end": 754, "line": "                name,\n"}, {"line_no": 26, "char_start": 754, "char_end": 769, "line": "            ))\n"}]}, "char_changes": {"deleted": [{"char_start": 222, "char_end": 226, "chars": "'{}'"}, {"char_start": 251, "char_end": 258, "chars": ".format"}, {"char_start": 654, "char_end": 657, "chars": "{0}"}, {"char_start": 671, "char_end": 676, "chars": "'{1}'"}, {"char_start": 696, "char_end": 715, "chars": ".format(shame, name"}], "added": [{"char_start": 222, "char_end": 230, "chars": "%(name)s"}, {"char_start": 255, "char_end": 257, "chars": ", "}, {"char_start": 262, "char_end": 264, "chars": ", "}, {"char_start": 655, "char_end": 664, "chars": "%(karma)s"}, {"char_start": 678, "char_end": 686, "chars": "%(name)s"}, {"char_start": 706, "char_end": 766, "chars": " (\n                shame,\n                name,\n            "}]}, "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089"}
{"func_name": "also_add", "func_src_before": "def also_add(name, also):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            INSERT INTO isalso(name,also) VALUES('{}','{}')\n            '''.format(name, also))\n        db.commit()\n        logger.debug('added to isalso name {} with value {}'.format(\n            name, also))\n        db.close()\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def also_add(name, also):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            INSERT INTO isalso(name,also) VALUES(%(name)s,%(also)s)\n            ''', (\n            name,\n            also,\n        ))\n        db.commit()\n        logger.debug('added to isalso name {} with value {}'.format(\n            name, also))\n        db.close()\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "line_changes": {"deleted": [{"line_no": 6, "char_start": 109, "char_end": 169, "line": "            INSERT INTO isalso(name,also) VALUES('{}','{}')\n"}, {"line_no": 7, "char_start": 169, "char_end": 205, "line": "            '''.format(name, also))\n"}], "added": [{"line_no": 6, "char_start": 109, "char_end": 177, "line": "            INSERT INTO isalso(name,also) VALUES(%(name)s,%(also)s)\n"}, {"line_no": 7, "char_start": 177, "char_end": 196, "line": "            ''', (\n"}, {"line_no": 8, "char_start": 196, "char_end": 214, "line": "            name,\n"}, {"line_no": 9, "char_start": 214, "char_end": 232, "line": "            also,\n"}, {"line_no": 10, "char_start": 232, "char_end": 243, "line": "        ))\n"}]}, "char_changes": {"deleted": [{"char_start": 158, "char_end": 202, "chars": "'{}','{}')\n            '''.format(name, also"}], "added": [{"char_start": 158, "char_end": 240, "chars": "%(name)s,%(also)s)\n            ''', (\n            name,\n            also,\n        "}]}, "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089"}
{"func_name": "also_ask", "func_src_before": "def also_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    if env.name == None:\n        r = 'RANDOM()'\n    else:\n        r = 'RANDOM()'\n    try:\n        cursor.execute('''\n            SELECT also FROM isalso WHERE name='{0}' ORDER BY {1} LIMIT 1\n            '''.format(name, r))\n        also = cursor.fetchone()\n        db.close()\n        if also is None:\n            logger.debug('could not find is_also for name {}'.format(name))\n            return also\n        else:\n            also = also[0]\n            logger.debug('found is_also {} for name {}'.format(also, name))\n            return also\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def also_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    if env.name is None:\n        r = 'RANDOM()'\n    else:\n        r = 'RANDOM()'\n    try:\n        cursor.execute('''\n            SELECT also FROM isalso WHERE name= %(name)r ORDER BY {} LIMIT 1\n            '''.format(r), (name, ))\n        also = cursor.fetchone()\n        db.close()\n        if also is None:\n            logger.debug('could not find is_also for name {}'.format(name))\n            return also\n        else:\n            also = also[0]\n            logger.debug('found is_also {} for name {}'.format(also, name))\n            return also\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "line_changes": {"deleted": [{"line_no": 4, "char_start": 67, "char_end": 92, "line": "    if env.name == None:\n"}, {"line_no": 10, "char_start": 184, "char_end": 258, "line": "            SELECT also FROM isalso WHERE name='{0}' ORDER BY {1} LIMIT 1\n"}, {"line_no": 11, "char_start": 258, "char_end": 291, "line": "            '''.format(name, r))\n"}], "added": [{"line_no": 4, "char_start": 67, "char_end": 92, "line": "    if env.name is None:\n"}, {"line_no": 10, "char_start": 184, "char_end": 261, "line": "            SELECT also FROM isalso WHERE name= %(name)r ORDER BY {} LIMIT 1\n"}, {"line_no": 11, "char_start": 261, "char_end": 298, "line": "            '''.format(r), (name, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 83, "char_end": 85, "chars": "=="}, {"char_start": 231, "char_end": 236, "chars": "'{0}'"}, {"char_start": 247, "char_end": 248, "chars": "1"}, {"char_start": 287, "char_end": 288, "chars": "r"}], "added": [{"char_start": 83, "char_end": 85, "chars": "is"}, {"char_start": 231, "char_end": 240, "chars": " %(name)r"}, {"char_start": 283, "char_end": 288, "chars": "(r), "}]}, "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw. \n            # See section on SQL injection below\n            query = \"INSERT INTO crimes (description) VALUES('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw. \n            # See section on SQL injection below\n            query = \"INSERT INTO crimes (description) VALUES(%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 6, "char_start": 197, "char_end": 279, "line": "            query = \"INSERT INTO crimes (description) VALUES('{}');\".format(data)\n"}, {"line_no": 8, "char_start": 327, "char_end": 365, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 6, "char_start": 197, "char_end": 264, "line": "            query = \"INSERT INTO crimes (description) VALUES(%s);\"\n"}, {"line_no": 8, "char_start": 312, "char_end": 356, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 258, "char_end": 278, "chars": "'{}');\".format(data)"}], "added": [{"char_start": 258, "char_end": 263, "chars": "%s);\""}, {"char_start": 348, "char_end": 354, "chars": ", data"}]}, "commit_link": "github.com/mudspringhiker/crimemap/commit/35e78962e7288c643cdde0f886ff7aa5ac77cb8c", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "recv", "func_src_before": "def recv(code, *args):\n    # check if this track is done\n    # No result in database would return none, so do a query and insert\n\n    # TODO: SQL Injection\n    try:\n        db_res = db.select(\"SELECT * FROM job WHERE track_id='%s'\" % code)[0]\n    except IndexError:\n        db_res = db.select(\"SELECT * FROM job WHERE track_id='%s'\" % code)\n\n    if len(db_res) == 0:\n        com_code = auto_detect(code)\n        if not com_code:\n            return 'My dear, I think you have entered a wrong number.'\n        res = query_express_status(com_code, code)\n\n        done = 1 if (res.get('state') == '3' or res.get('state') == '4') else 0\n        try:\n            sql_cmd = \"INSERT INTO job VALUES (%s,'%s','%s','%s','%s','%s','%s','%s','%s')\" % \\\n                      ('null', args[0], args[1], com_code, code, res.get('data')[0].get('context'),\n                       state.get(res.get('state')), res.get('data')[0].get('time'), done)\n\n            db.upsert(sql_cmd)\n            return code + '\\n' + res.get('data')[0].get('time') + ' ' + res.get('data')[0].get('context')\n        except IndexError:\n            return res.get('message')\n    elif db_res[8] == 0:\n        com_code = auto_detect(code)\n        if not com_code:\n            return 'My dear, I think you have entered a wrong number.'\n        res = query_express_status(com_code, code)\n        done = 1 if (res.get('state') == '3' or res.get('state') == '4') else 0\n        try:\n            sql_cmd = \"UPDATE job set content='%s',status='%s',date='%s',done='%s' WHERE track_id='%s'\" % \\\n                      (res.get('data')[0].get('context'),\n                       state.get(res.get('state')),\n                       res.get('data')[0].get('time'),\n                       done,\n                       code)\n            db.upsert(sql_cmd)\n            return code + '\\n' + res.get('data')[0].get('time') + ' ' + res.get('data')[0].get('context')\n        except IndexError:\n            return res.get('message')\n    else:\n        return db_res[4] + '\\n' + db_res[7] + ' ' + db_res[5]", "func_src_after": "def recv(code, *args):\n    # check if this track is done\n    # No result in database would return none, so do a query and insert\n\n    # TODO: SQL Injection\n    try:\n        db_res = db.select(\"SELECT * FROM job WHERE track_id='%s'\" % code)[0]\n    except IndexError:\n        db_res = db.select(\"SELECT * FROM job WHERE track_id='%s'\" % code)\n\n    if len(db_res) == 0:\n        com_code = auto_detect(code)\n\n        if not com_code:\n            return 'My dear, I think you have entered a wrong number.'\n        res = query_express_status(com_code, code)\n        done = 1 if (res.get('state') == '3' or res.get('state') == '4') else 0\n\n        try:\n            sql_cmd = \"INSERT INTO job VALUES (%s,'%s','%s','%s','%s','%s','%s','%s','%s')\" % \\\n                      ('null', args[0], args[1], com_code, code, res.get('data')[0].get('context'),\n                       state.get(res.get('state')), res.get('data')[0].get('time'), done)\n\n            db.upsert(sql_cmd)\n            return code + '\\n' + res.get('data')[0].get('time') + ' ' + res.get('data')[0].get('context')\n        except IndexError:\n            return res.get('message')\n    elif db_res[8] == 0:\n        com_code = auto_detect(code)\n        if not com_code:\n            return 'My dear, I think you have entered a wrong number.'\n        res = query_express_status(com_code, code)\n        done = 1 if (res.get('state') == '3' or res.get('state') == '4') else 0\n\n        try:\n            sql_cmd = \"UPDATE job set content='%s',status='%s',date='%s',done='%s' WHERE track_id='%s'\" % \\\n                      (res.get('data')[0].get('context'),\n                       state.get(res.get('state')),\n                       res.get('data')[0].get('time'),\n                       done,\n                       code)\n            db.upsert(sql_cmd)\n            return code + '\\n' + res.get('data')[0].get('time') + ' ' + res.get('data')[0].get('context')\n        except IndexError:\n            return res.get('message')\n    else:\n        return db_res[4] + '\\n' + db_res[7] + ' ' + db_res[5]", "line_changes": {"deleted": [{"line_no": 16, "char_start": 551, "char_end": 552, "line": "\n"}], "added": [{"line_no": 13, "char_start": 404, "char_end": 405, "line": "\n"}, {"line_no": 18, "char_start": 632, "char_end": 633, "line": "\n"}, {"line_no": 34, "char_start": 1424, "char_end": 1425, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 551, "char_end": 552, "chars": "\n"}], "added": [{"char_start": 404, "char_end": 405, "chars": "\n"}, {"char_start": 632, "char_end": 633, "chars": "\n"}, {"char_start": 1424, "char_end": 1425, "chars": "\n"}]}, "commit_link": "github.com/BennyThink/ExpressBot/commit/3bccb53178e1e04b54873b4a9c62984af0fc5b2a", "file_name": "kuaidi100.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # WARNING SECURITY FLAW\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 116, "char_end": 199, "line": "            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n"}, {"line_no": 7, "char_start": 247, "char_end": 285, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 4, "char_start": 80, "char_end": 148, "line": "            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 6, "char_start": 196, "char_end": 240, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 80, "char_end": 116, "chars": "            # WARNING SECURITY FLAW\n"}, {"char_start": 178, "char_end": 198, "chars": "'{}');\".format(data)"}, {"char_start": 247, "char_end": 247, "chars": ""}], "added": [{"char_start": 142, "char_end": 147, "chars": "%s);\""}, {"char_start": 232, "char_end": 238, "chars": ", data"}]}, "commit_link": "github.com/LordLizard/crimemap/commit/09f55805199f4bbe1d31334963ce4ef00595aae9", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "fetch_issue", "func_src_before": "def fetch_issue(cursor, id):\n    \"\"\"\n    Fetch an issue by id along with its tags. Returns None if no issue\n    with the specified id exists in the database.\n    \"\"\"\n    cursor.execute(f\"\"\"\n        SELECT\n            issue.id,\n            issue.title,\n            issue.description,\n            tag.namespace,\n            tag.predicate,\n            tag.value\n        FROM\n            issue LEFT JOIN tag\n            ON issue.id = tag.issue_id\n        WHERE\n            issue.id = {id}\n    \"\"\")\n\n    issue = None\n    for row in cursor:\n        if issue is None:\n            issue = {\n                \"id\": row[\"id\"],\n                \"title\": row[\"title\"],\n                \"description\": row[\"description\"],\n                \"tags\": [],\n            }\n        # If tag exists in row, add to issue.\n        if row[\"value\"]:\n            issue[\"tags\"].append({\n                \"namespace\": row[\"namespace\"],\n                \"predicate\": row[\"predicate\"],\n                \"value\": row[\"value\"],\n            })\n\n    return issue", "func_src_after": "def fetch_issue(cursor, id):\n    \"\"\"\n    Fetch an issue by id along with its tags. Returns None if no issue\n    with the specified id exists in the database.\n    \"\"\"\n    cursor.execute(\"\"\"\n        SELECT\n            issue.id,\n            issue.title,\n            issue.description,\n            tag.namespace,\n            tag.predicate,\n            tag.value\n        FROM\n            issue LEFT JOIN tag\n            ON issue.id = tag.issue_id\n        WHERE\n            issue.id = ?\n    \"\"\", (id,))\n\n    issue = None\n    for row in cursor:\n        if issue is None:\n            issue = {\n                \"id\": row[\"id\"],\n                \"title\": row[\"title\"],\n                \"description\": row[\"description\"],\n                \"tags\": [],\n            }\n        # If tag exists in row, add to issue.\n        if row[\"value\"]:\n            issue[\"tags\"].append({\n                \"namespace\": row[\"namespace\"],\n                \"predicate\": row[\"predicate\"],\n                \"value\": row[\"value\"],\n            })\n\n    return issue", "line_changes": {"deleted": [{"line_no": 6, "char_start": 166, "char_end": 190, "line": "    cursor.execute(f\"\"\"\n"}, {"line_no": 18, "char_start": 457, "char_end": 485, "line": "            issue.id = {id}\n"}, {"line_no": 19, "char_start": 485, "char_end": 494, "line": "    \"\"\")\n"}], "added": [{"line_no": 6, "char_start": 166, "char_end": 189, "line": "    cursor.execute(\"\"\"\n"}, {"line_no": 18, "char_start": 456, "char_end": 481, "line": "            issue.id = ?\n"}, {"line_no": 19, "char_start": 481, "char_end": 497, "line": "    \"\"\", (id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 185, "char_end": 186, "chars": "f"}, {"char_start": 480, "char_end": 484, "chars": "{id}"}], "added": [{"char_start": 479, "char_end": 480, "chars": "?"}, {"char_start": 488, "char_end": 495, "chars": ", (id,)"}]}, "commit_link": "github.com/nutty7t/tissue/commit/306dd094749bb39cbd5c74a6ded3d3b191033061", "file_name": "server/server.py", "vul_type": "cwe-089"}
{"func_name": "create_issue", "func_src_before": "def create_issue(cursor, issue):\n    \"\"\"\n    Create an issue with tags.\n    \"\"\"\n    cursor.execute(f\"\"\"\n        INSERT INTO issue (\n            title,\n            description\n        )\n        VALUES (\n            \"{issue[\"title\"]}\",\n            \"{issue.get(\"description\", \"\")}\"\n        )\n    \"\"\")\n\n    issue_id = cursor.lastrowid\n    for tag in issue.get(\"tags\", []):\n        cursor.execute(f\"\"\"\n            INSERT INTO tag (\n                namespace,\n                predicate,\n                value,\n                issue_id\n            )\n            VALUES (\n                \"{tag.get(\"namespace\", \"\")}\",\n                \"{tag.get(\"predicate\", \"\")}\",\n                \"{tag.get(\"value\", \"\")}\",\n                \"{issue_id}\"\n            )\n        \"\"\")\n\n    return issue_id", "func_src_after": "def create_issue(cursor, issue):\n    \"\"\"\n    Create an issue with tags.\n    \"\"\"\n    cursor.execute(\"\"\"\n        INSERT INTO issue (title, description)\n        VALUES (?, ?)\n    \"\"\", (\n        issue[\"title\"],\n        issue.get(\"description\", \"\")\n    ))\n\n    issue_id = cursor.lastrowid\n    for tag in issue.get(\"tags\", []):\n        cursor.execute(f\"\"\"\n            INSERT INTO tag (namespace, predicate, value, issue_id)\n            VALUES (?, ?, ?, ?)\n        \"\"\", (\n            tag.get(\"namespace\", \"\"),\n            tag.get(\"predicate\", \"\"),\n            tag.get(\"value\", \"\"),\n            issue_id,\n        ))\n\n    return issue_id", "line_changes": {"deleted": [{"line_no": 5, "char_start": 80, "char_end": 104, "line": "    cursor.execute(f\"\"\"\n"}, {"line_no": 6, "char_start": 104, "char_end": 132, "line": "        INSERT INTO issue (\n"}, {"line_no": 7, "char_start": 132, "char_end": 151, "line": "            title,\n"}, {"line_no": 8, "char_start": 151, "char_end": 175, "line": "            description\n"}, {"line_no": 9, "char_start": 175, "char_end": 185, "line": "        )\n"}, {"line_no": 10, "char_start": 185, "char_end": 202, "line": "        VALUES (\n"}, {"line_no": 11, "char_start": 202, "char_end": 234, "line": "            \"{issue[\"title\"]}\",\n"}, {"line_no": 12, "char_start": 234, "char_end": 279, "line": "            \"{issue.get(\"description\", \"\")}\"\n"}, {"line_no": 13, "char_start": 279, "char_end": 289, "line": "        )\n"}, {"line_no": 14, "char_start": 289, "char_end": 298, "line": "    \"\"\")\n"}, {"line_no": 19, "char_start": 397, "char_end": 427, "line": "            INSERT INTO tag (\n"}, {"line_no": 20, "char_start": 427, "char_end": 454, "line": "                namespace,\n"}, {"line_no": 21, "char_start": 454, "char_end": 481, "line": "                predicate,\n"}, {"line_no": 22, "char_start": 481, "char_end": 504, "line": "                value,\n"}, {"line_no": 23, "char_start": 504, "char_end": 529, "line": "                issue_id\n"}, {"line_no": 24, "char_start": 529, "char_end": 543, "line": "            )\n"}, {"line_no": 25, "char_start": 543, "char_end": 564, "line": "            VALUES (\n"}, {"line_no": 26, "char_start": 564, "char_end": 610, "line": "                \"{tag.get(\"namespace\", \"\")}\",\n"}, {"line_no": 27, "char_start": 610, "char_end": 656, "line": "                \"{tag.get(\"predicate\", \"\")}\",\n"}, {"line_no": 28, "char_start": 656, "char_end": 698, "line": "                \"{tag.get(\"value\", \"\")}\",\n"}, {"line_no": 29, "char_start": 698, "char_end": 727, "line": "                \"{issue_id}\"\n"}, {"line_no": 30, "char_start": 727, "char_end": 741, "line": "            )\n"}, {"line_no": 31, "char_start": 741, "char_end": 754, "line": "        \"\"\")\n"}], "added": [{"line_no": 5, "char_start": 80, "char_end": 103, "line": "    cursor.execute(\"\"\"\n"}, {"line_no": 6, "char_start": 103, "char_end": 150, "line": "        INSERT INTO issue (title, description)\n"}, {"line_no": 7, "char_start": 150, "char_end": 172, "line": "        VALUES (?, ?)\n"}, {"line_no": 8, "char_start": 172, "char_end": 183, "line": "    \"\"\", (\n"}, {"line_no": 9, "char_start": 183, "char_end": 207, "line": "        issue[\"title\"],\n"}, {"line_no": 10, "char_start": 207, "char_end": 244, "line": "        issue.get(\"description\", \"\")\n"}, {"line_no": 11, "char_start": 244, "char_end": 251, "line": "    ))\n"}, {"line_no": 16, "char_start": 350, "char_end": 418, "line": "            INSERT INTO tag (namespace, predicate, value, issue_id)\n"}, {"line_no": 17, "char_start": 418, "char_end": 450, "line": "            VALUES (?, ?, ?, ?)\n"}, {"line_no": 18, "char_start": 450, "char_end": 465, "line": "        \"\"\", (\n"}, {"line_no": 19, "char_start": 465, "char_end": 503, "line": "            tag.get(\"namespace\", \"\"),\n"}, {"line_no": 20, "char_start": 503, "char_end": 541, "line": "            tag.get(\"predicate\", \"\"),\n"}, {"line_no": 21, "char_start": 541, "char_end": 575, "line": "            tag.get(\"value\", \"\"),\n"}, {"line_no": 22, "char_start": 575, "char_end": 597, "line": "            issue_id,\n"}, {"line_no": 23, "char_start": 597, "char_end": 608, "line": "        ))\n"}]}, "char_changes": {"deleted": [{"char_start": 99, "char_end": 100, "chars": "f"}, {"char_start": 131, "char_end": 162, "chars": "\n            title,\n           "}, {"char_start": 174, "char_end": 183, "chars": "\n        "}, {"char_start": 201, "char_end": 206, "chars": "\n    "}, {"char_start": 214, "char_end": 216, "chars": "\"{"}, {"char_start": 230, "char_end": 237, "chars": "}\",\n   "}, {"char_start": 245, "char_end": 248, "chars": " \"{"}, {"char_start": 276, "char_end": 296, "chars": "}\"\n        )\n    \"\"\""}, {"char_start": 426, "char_end": 519, "chars": "\n                namespace,\n                predicate,\n                value,\n               "}, {"char_start": 541, "char_end": 567, "chars": ")\n            VALUES (\n   "}, {"char_start": 579, "char_end": 582, "chars": " \"{"}, {"char_start": 606, "char_end": 612, "chars": "}\",\n  "}, {"char_start": 624, "char_end": 628, "chars": "  \"{"}, {"char_start": 652, "char_end": 654, "chars": "}\""}, {"char_start": 668, "char_end": 669, "chars": " "}, {"char_start": 669, "char_end": 674, "chars": "   \"{"}, {"char_start": 694, "char_end": 696, "chars": "}\""}, {"char_start": 710, "char_end": 716, "chars": "    \"{"}, {"char_start": 724, "char_end": 730, "chars": "}\"\n   "}, {"char_start": 738, "char_end": 752, "chars": " )\n        \"\"\""}], "added": [{"char_start": 130, "char_end": 136, "chars": "title,"}, {"char_start": 166, "char_end": 183, "chars": "?, ?)\n    \"\"\", (\n"}, {"char_start": 205, "char_end": 207, "chars": ",\n"}, {"char_start": 243, "char_end": 249, "chars": "\n    )"}, {"char_start": 379, "char_end": 407, "chars": "namespace, predicate, value,"}, {"char_start": 416, "char_end": 417, "chars": ")"}, {"char_start": 430, "char_end": 465, "chars": "VALUES (?, ?, ?, ?)\n        \"\"\", (\n"}, {"char_start": 501, "char_end": 503, "chars": ",\n"}, {"char_start": 595, "char_end": 597, "chars": ",\n"}, {"char_start": 605, "char_end": 606, "chars": ")"}]}, "commit_link": "github.com/nutty7t/tissue/commit/306dd094749bb39cbd5c74a6ded3d3b191033061", "file_name": "server/server.py", "vul_type": "cwe-089"}
{"func_name": "update_issue", "func_src_before": "def update_issue(cursor, id, fields):\n    \"\"\"\n    Update the issue specified by the id field.\n    \"\"\"\n    updated_fields = {}\n    if \"title\" in fields:\n        updated_fields[\"title\"] = fields[\"title\"]\n    if \"description\" in fields:\n        updated_fields[\"description\"] = fields[\"description\"]\n\n    set_clause_args = \", \".join(map(\n        lambda kv: f\"{kv[0]} = \\\"{kv[1]}\\\"\",\n        updated_fields.items(),\n    ))\n\n    if len(updated_fields) != 0:\n        cursor.execute(f\"\"\"\n            UPDATE issue\n            SET {set_clause_args}\n            WHERE id = {id}\n        \"\"\")\n\n    cursor.execute(f\"\"\"\n        DELETE FROM tag\n        WHERE issue_id = {id}\n    \"\"\")\n\n    for tag in fields.get(\"tags\", []):\n        cursor.execute(f\"\"\"\n            INSERT INTO tag (\n                namespace,\n                predicate,\n                value,\n                issue_id\n            )\n            VALUES (\n                \"{tag[\"namespace\"]}\",\n                \"{tag[\"predicate\"]}\",\n                \"{tag[\"value\"]}\",\n                \"{id}\"\n            )\n        \"\"\")", "func_src_after": "def update_issue(cursor, id, fields):\n    \"\"\"\n    Update the issue specified by the id field.\n    \"\"\"\n    updated_fields = {}\n    if \"title\" in fields:\n        updated_fields[\"title\"] = fields[\"title\"]\n    if \"description\" in fields:\n        updated_fields[\"description\"] = fields[\"description\"]\n\n    if len(updated_fields) != 0:\n        # Construct a variadic SQL query (in terms of DB-API's parameter\n        # substitution) based on the number of fields that will get updated.\n        set_clause_args = \", \".join(map(\n            lambda key: f\"{key} = ?\",\n            updated_fields.keys()\n        ))\n        cursor.execute(\n            f\"UPDATE issue SET {set_clause_args} WHERE id = ?\",\n            (*updated_fields.values(), str(id)),\n        )\n\n    cursor.execute(\"DELETE FROM tag WHERE issue_id = ?\", str(id))\n    for tag in fields.get(\"tags\", []):\n        cursor.execute(\"\"\"\n            INSERT INTO tag (\n                namespace,\n                predicate,\n                value,\n                issue_id\n            )\n            VALUES (?, ?, ?, ?)\n        \"\"\", (\n            tag[\"namespace\"],\n            tag[\"predicate\"],\n            tag[\"value\"],\n            str(id),\n        ))", "line_changes": {"deleted": [{"line_no": 11, "char_start": 297, "char_end": 334, "line": "    set_clause_args = \", \".join(map(\n"}, {"line_no": 12, "char_start": 334, "char_end": 379, "line": "        lambda kv: f\"{kv[0]} = \\\"{kv[1]}\\\"\",\n"}, {"line_no": 13, "char_start": 379, "char_end": 411, "line": "        updated_fields.items(),\n"}, {"line_no": 14, "char_start": 411, "char_end": 418, "line": "    ))\n"}, {"line_no": 15, "char_start": 418, "char_end": 419, "line": "\n"}, {"line_no": 17, "char_start": 452, "char_end": 480, "line": "        cursor.execute(f\"\"\"\n"}, {"line_no": 18, "char_start": 480, "char_end": 505, "line": "            UPDATE issue\n"}, {"line_no": 19, "char_start": 505, "char_end": 539, "line": "            SET {set_clause_args}\n"}, {"line_no": 20, "char_start": 539, "char_end": 567, "line": "            WHERE id = {id}\n"}, {"line_no": 21, "char_start": 567, "char_end": 580, "line": "        \"\"\")\n"}, {"line_no": 22, "char_start": 580, "char_end": 581, "line": "\n"}, {"line_no": 23, "char_start": 581, "char_end": 605, "line": "    cursor.execute(f\"\"\"\n"}, {"line_no": 24, "char_start": 605, "char_end": 629, "line": "        DELETE FROM tag\n"}, {"line_no": 25, "char_start": 629, "char_end": 659, "line": "        WHERE issue_id = {id}\n"}, {"line_no": 26, "char_start": 659, "char_end": 668, "line": "    \"\"\")\n"}, {"line_no": 29, "char_start": 708, "char_end": 736, "line": "        cursor.execute(f\"\"\"\n"}, {"line_no": 36, "char_start": 882, "char_end": 903, "line": "            VALUES (\n"}, {"line_no": 37, "char_start": 903, "char_end": 941, "line": "                \"{tag[\"namespace\"]}\",\n"}, {"line_no": 38, "char_start": 941, "char_end": 979, "line": "                \"{tag[\"predicate\"]}\",\n"}, {"line_no": 39, "char_start": 979, "char_end": 1013, "line": "                \"{tag[\"value\"]}\",\n"}, {"line_no": 40, "char_start": 1013, "char_end": 1036, "line": "                \"{id}\"\n"}, {"line_no": 41, "char_start": 1036, "char_end": 1050, "line": "            )\n"}, {"line_no": 42, "char_start": 1050, "char_end": 1062, "line": "        \"\"\")\n"}], "added": [{"line_no": 14, "char_start": 480, "char_end": 521, "line": "        set_clause_args = \", \".join(map(\n"}, {"line_no": 15, "char_start": 521, "char_end": 559, "line": "            lambda key: f\"{key} = ?\",\n"}, {"line_no": 16, "char_start": 559, "char_end": 593, "line": "            updated_fields.keys()\n"}, {"line_no": 17, "char_start": 593, "char_end": 604, "line": "        ))\n"}, {"line_no": 18, "char_start": 604, "char_end": 628, "line": "        cursor.execute(\n"}, {"line_no": 19, "char_start": 628, "char_end": 692, "line": "            f\"UPDATE issue SET {set_clause_args} WHERE id = ?\",\n"}, {"line_no": 20, "char_start": 692, "char_end": 741, "line": "            (*updated_fields.values(), str(id)),\n"}, {"line_no": 21, "char_start": 741, "char_end": 751, "line": "        )\n"}, {"line_no": 23, "char_start": 752, "char_end": 818, "line": "    cursor.execute(\"DELETE FROM tag WHERE issue_id = ?\", str(id))\n"}, {"line_no": 25, "char_start": 857, "char_end": 884, "line": "        cursor.execute(\"\"\"\n"}, {"line_no": 32, "char_start": 1030, "char_end": 1062, "line": "            VALUES (?, ?, ?, ?)\n"}, {"line_no": 33, "char_start": 1062, "char_end": 1077, "line": "        \"\"\", (\n"}, {"line_no": 34, "char_start": 1077, "char_end": 1107, "line": "            tag[\"namespace\"],\n"}, {"line_no": 35, "char_start": 1107, "char_end": 1137, "line": "            tag[\"predicate\"],\n"}, {"line_no": 36, "char_start": 1137, "char_end": 1163, "line": "            tag[\"value\"],\n"}, {"line_no": 37, "char_start": 1163, "char_end": 1184, "line": "            str(id),\n"}, {"line_no": 38, "char_start": 1184, "char_end": 1194, "line": "        ))\n"}]}, "char_changes": {"deleted": [{"char_start": 350, "char_end": 351, "chars": "v"}, {"char_start": 357, "char_end": 379, "chars": "v[0]} = \\\"{kv[1]}\\\"\",\n"}, {"char_start": 402, "char_end": 406, "chars": "item"}, {"char_start": 409, "char_end": 410, "chars": ","}, {"char_start": 415, "char_end": 451, "chars": "))\n\n    if len(updated_fields) != 0:"}, {"char_start": 475, "char_end": 479, "chars": "f\"\"\""}, {"char_start": 504, "char_end": 516, "chars": "\n           "}, {"char_start": 538, "char_end": 566, "chars": "\n            WHERE id = {id}"}, {"char_start": 575, "char_end": 578, "chars": "\"\"\""}, {"char_start": 600, "char_end": 613, "chars": "f\"\"\"\n        "}, {"char_start": 628, "char_end": 636, "chars": "\n       "}, {"char_start": 654, "char_end": 668, "chars": "{id}\n    \"\"\")\n"}, {"char_start": 731, "char_end": 732, "chars": "f"}, {"char_start": 919, "char_end": 921, "chars": "\"{"}, {"char_start": 937, "char_end": 939, "chars": "}\""}, {"char_start": 953, "char_end": 954, "chars": " "}, {"char_start": 954, "char_end": 959, "chars": "   \"{"}, {"char_start": 975, "char_end": 981, "chars": "}\",\n  "}, {"char_start": 993, "char_end": 997, "chars": "  \"{"}, {"char_start": 1009, "char_end": 1016, "chars": "}\",\n   "}, {"char_start": 1028, "char_end": 1049, "chars": " \"{id}\"\n            )"}, {"char_start": 1058, "char_end": 1061, "chars": "\"\"\""}], "added": [{"char_start": 297, "char_end": 484, "chars": "    if len(updated_fields) != 0:\n        # Construct a variadic SQL query (in terms of DB-API's parameter\n        # substitution) based on the number of fields that will get updated.\n    "}, {"char_start": 529, "char_end": 533, "chars": "    "}, {"char_start": 541, "char_end": 543, "chars": "ey"}, {"char_start": 549, "char_end": 563, "chars": "ey} = ?\",\n    "}, {"char_start": 586, "char_end": 589, "chars": "key"}, {"char_start": 597, "char_end": 603, "chars": "    ))"}, {"char_start": 640, "char_end": 642, "chars": "f\""}, {"char_start": 676, "char_end": 740, "chars": " WHERE id = ?\",\n            (*updated_fields.values(), str(id)),"}, {"char_start": 771, "char_end": 772, "chars": "\""}, {"char_start": 805, "char_end": 817, "chars": "?\", str(id))"}, {"char_start": 1050, "char_end": 1061, "chars": "?, ?, ?, ?)"}, {"char_start": 1070, "char_end": 1077, "chars": "\"\"\", (\n"}, {"char_start": 1085, "char_end": 1089, "chars": "    "}, {"char_start": 1135, "char_end": 1137, "chars": ",\n"}, {"char_start": 1175, "char_end": 1193, "chars": "str(id),\n        )"}]}, "commit_link": "github.com/nutty7t/tissue/commit/306dd094749bb39cbd5c74a6ded3d3b191033061", "file_name": "server/server.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\t# The following introduces a deliberate security flaw.See section on SQL injection below\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES('{}');\".format(data)\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "func_src_after": "\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\t# The following introduces a deliberate security flaw.See section on SQL injection below\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES (%s);\"\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query, data)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 157, "char_end": 230, "line": "\t\t\tquery = \"INSERT INTO crimes (description) VALUES('{}');\".format(data)\n"}, {"line_no": 7, "char_start": 269, "char_end": 295, "line": "\t\t\t\tcursor.execute(query)\n"}], "added": [{"line_no": 5, "char_start": 157, "char_end": 216, "line": "\t\t\tquery = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 7, "char_start": 255, "char_end": 287, "line": "\t\t\t\tcursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 208, "char_end": 229, "chars": "('{}');\".format(data)"}], "added": [{"char_start": 208, "char_end": 215, "chars": " (%s);\""}, {"char_start": 279, "char_end": 285, "chars": ", data"}]}, "commit_link": "github.com/fangyansun/crimemap/commit/a3ab652c214f801c2910e2f96e4de18848de58ae", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "authenticate", "func_src_before": "    @gen.coroutine\n    def authenticate(self, handler, data):\n        args = {}\n        args[\"host\"] = self.dbhost\n        args[\"user\"] = self.dbuser\n        args[\"password\"] = self.dbpassword\n        args[\"db\"] = self.dbname\n        args[\"charset\"] = \"utf8mb4\"\n        args[\"cursorclass\"] = pymysql.cursors.Cursor\n\n        with pymysql.connect(**args) as cursor:\n            sql =   \"SELECT \" \\\n                            \"user_pass \" \\\n                    \"FROM \" \\\n                            \"{0}users \" \\\n                    \"WHERE \" \\\n                            \"user_login = \\\"{1}\\\"\" \\\n                    .format(self.table_prefix, data[\"username\"])\n            if cursor.execute(sql) == 0:\n                return None\n            if phpass.verify(data[\"password\"],cursor.fetchone()[0]) == True:\n                return data[\"username\"]\n        return None", "func_src_after": "    @gen.coroutine\n    def authenticate(self, handler, data):\n        args = {}\n        args[\"host\"] = self.dbhost\n        args[\"user\"] = self.dbuser\n        args[\"password\"] = self.dbpassword\n        args[\"db\"] = self.dbname\n        args[\"charset\"] = \"utf8mb4\"\n        args[\"cursorclass\"] = pymysql.cursors.Cursor\n\n        with pymysql.connect(**args) as cursor:\n            sql =   \"SELECT \" \\\n                        \"`user_pass` \" \\\n                    \"FROM \" \\\n                        \"`{0}users` \" \\\n                    \"WHERE \" \\\n                        \"`user_login` = %s\" \\\n                    .format(self.table_prefix)\n            if cursor.execute(sql, (data[\"username\"], )) == 0:\n                return None\n            if phpass.verify(data[\"password\"],cursor.fetchone()[0]) == True:\n                return data[\"username\"]\n        return None", "line_changes": {"deleted": [{"line_no": 13, "char_start": 396, "char_end": 439, "line": "                            \"user_pass \" \\\n"}, {"line_no": 15, "char_start": 469, "char_end": 511, "line": "                            \"{0}users \" \\\n"}, {"line_no": 17, "char_start": 542, "char_end": 595, "line": "                            \"user_login = \\\"{1}\\\"\" \\\n"}, {"line_no": 18, "char_start": 595, "char_end": 660, "line": "                    .format(self.table_prefix, data[\"username\"])\n"}, {"line_no": 19, "char_start": 660, "char_end": 701, "line": "            if cursor.execute(sql) == 0:\n"}], "added": [{"line_no": 13, "char_start": 396, "char_end": 437, "line": "                        \"`user_pass` \" \\\n"}, {"line_no": 15, "char_start": 467, "char_end": 507, "line": "                        \"`{0}users` \" \\\n"}, {"line_no": 17, "char_start": 538, "char_end": 584, "line": "                        \"`user_login` = %s\" \\\n"}, {"line_no": 18, "char_start": 584, "char_end": 631, "line": "                    .format(self.table_prefix)\n"}, {"line_no": 19, "char_start": 631, "char_end": 694, "line": "            if cursor.execute(sql, (data[\"username\"], )) == 0:\n"}]}, "char_changes": {"deleted": [{"char_start": 420, "char_end": 424, "chars": "    "}, {"char_start": 493, "char_end": 497, "chars": "    "}, {"char_start": 566, "char_end": 570, "chars": "    "}, {"char_start": 584, "char_end": 591, "chars": "\\\"{1}\\\""}, {"char_start": 640, "char_end": 658, "chars": ", data[\"username\"]"}], "added": [{"char_start": 421, "char_end": 422, "chars": "`"}, {"char_start": 431, "char_end": 432, "chars": "`"}, {"char_start": 492, "char_end": 493, "chars": "`"}, {"char_start": 501, "char_end": 502, "chars": "`"}, {"char_start": 563, "char_end": 564, "chars": "`"}, {"char_start": 574, "char_end": 575, "chars": "`"}, {"char_start": 578, "char_end": 580, "chars": "%s"}, {"char_start": 664, "char_end": 686, "chars": ", (data[\"username\"], )"}]}, "commit_link": "github.com/harapekoaomushi/jupyterhub-wordpressauthenticator/commit/8b7bd49f1e1ccc9b806e247a829e322e06148c3e", "file_name": "wordpressauthenticator/wordpressauthenticator.py", "vul_type": "cwe-089"}
{"func_name": "run_platform_query", "func_src_before": "@app.route(\"/data/platform/\")\n@json_response\ndef run_platform_query():\n    platform = request.args.get(\"platform\")\n    build_system_type = request.args.get(\"build_system_type\")\n    start_date, end_date = clean_date_params(request.args)\n\n    log_message = 'platform: %s startDate: %s endDate: %s' % (platform,\n                                                              start_date.strftime('%Y-%m-%d'),\n                                                              end_date.strftime('%Y-%m-%d'))\n    app.logger.debug(log_message)\n\n    db = create_db_connnection()\n    cursor = db.cursor()\n\n    query = \"\"\"select distinct revision from testjobs\n                      where platform = '%s'\n                      and branch = 'mozilla-central'\n                      and date between '%s' and '%s'\n                      and build_system_type='%s'\n                      order by date desc;\"\"\" % (platform, start_date, end_date, build_system_type)\n\n    cursor.execute(query)\n\n    csets = cursor.fetchall()\n\n    cset_summaries = []\n    test_summaries = {}\n    dates = []\n\n    labels = 'green orange blue red'.split()\n    summary = {result: 0 for result in labels}\n\n    for cset in csets:\n        cset_id = cset[0]\n        cset_summary = CSetSummary(cset_id)\n\n        query = \"\"\"select result, testtype, date from testjobs\n                   where platform='%s' and buildtype='opt' and revision='%s' and\n                   build_system_type='%s' order by testtype\"\"\" % (\n            platform, cset_id, build_system_type)\n\n        cursor.execute(query)\n        test_results = cursor.fetchall()\n\n        for res, testtype, date in test_results:\n            test_summary = test_summaries.setdefault(testtype, summary.copy())\n\n            if res == 'success':\n                cset_summary.green[testtype] += 1\n                test_summary['green'] += 1\n            elif res == 'testfailed':\n                cset_summary.orange[testtype] += 1\n                test_summary['orange'] += 1\n            elif res == 'retry':\n                cset_summary.blue[testtype] += 1\n                test_summary['blue'] += 1\n            elif res == 'exception' or res == 'busted':\n                cset_summary.red[testtype] += 1\n                test_summary['red'] += 1\n            elif res == 'usercancel':\n                app.logger.debug('usercancel')\n            else:\n                app.logger.debug('UNRECOGNIZED RESULT: %s' % res)\n            dates.append(date)\n\n        cset_summaries.append(cset_summary)\n\n    cursor.close()\n    db.close()\n\n    # sort tests alphabetically and append total & percentage to end of the list\n    test_types = sorted(test_summaries.keys())\n    test_types += ['total', 'percentage']\n\n    # calculate total stats and percentage\n    total = Counter()\n    percentage = {}\n\n    for test in test_summaries:\n        total.update(test_summaries[test])\n    test_count = sum(total.values())\n\n    for key in total:\n        percentage[key] = round((100.0 * total[key] / test_count), 2)\n\n    fail_rates = calculate_fail_rate(passes=total['green'],\n                                     retries=total['blue'],\n                                     totals=test_count)\n\n    test_summaries['total'] = total\n    test_summaries['percentage'] = percentage\n\n    return {'testTypes': test_types,\n            'byRevision': cset_summaries,\n            'byTest': test_summaries,\n            'failRates': fail_rates,\n            'dates': get_date_range(dates)}", "func_src_after": "@app.route(\"/data/platform/\")\n@json_response\ndef run_platform_query():\n    platform = sanitize_string(request.args.get(\"platform\"))\n    build_system_type = sanitize_string(request.args.get(\"build_system_type\"))\n    start_date, end_date = clean_date_params(request.args)\n\n    log_message = 'platform: %s startDate: %s endDate: %s' % (platform,\n                                                              start_date.strftime('%Y-%m-%d'),\n                                                              end_date.strftime('%Y-%m-%d'))\n    app.logger.debug(log_message)\n\n    db = create_db_connnection()\n    cursor = db.cursor()\n\n    query = \"\"\"select distinct revision from testjobs\n                      where platform = '%s'\n                      and branch = 'mozilla-central'\n                      and date between '%s' and '%s'\n                      and build_system_type='%s'\n                      order by date desc;\"\"\" % (platform, start_date, end_date, build_system_type)\n\n    cursor.execute(query)\n\n    csets = cursor.fetchall()\n\n    cset_summaries = []\n    test_summaries = {}\n    dates = []\n\n    labels = 'green orange blue red'.split()\n    summary = {result: 0 for result in labels}\n\n    for cset in csets:\n        cset_id = cset[0]\n        cset_summary = CSetSummary(cset_id)\n\n        query = \"\"\"select result, testtype, date from testjobs\n                   where platform='%s' and buildtype='opt' and revision='%s' and\n                   build_system_type='%s' order by testtype\"\"\" % (\n            platform, cset_id, build_system_type)\n\n        cursor.execute(query)\n        test_results = cursor.fetchall()\n\n        for res, testtype, date in test_results:\n            test_summary = test_summaries.setdefault(testtype, summary.copy())\n\n            if res == 'success':\n                cset_summary.green[testtype] += 1\n                test_summary['green'] += 1\n            elif res == 'testfailed':\n                cset_summary.orange[testtype] += 1\n                test_summary['orange'] += 1\n            elif res == 'retry':\n                cset_summary.blue[testtype] += 1\n                test_summary['blue'] += 1\n            elif res == 'exception' or res == 'busted':\n                cset_summary.red[testtype] += 1\n                test_summary['red'] += 1\n            elif res == 'usercancel':\n                app.logger.debug('usercancel')\n            else:\n                app.logger.debug('UNRECOGNIZED RESULT: %s' % res)\n            dates.append(date)\n\n        cset_summaries.append(cset_summary)\n\n    cursor.close()\n    db.close()\n\n    # sort tests alphabetically and append total & percentage to end of the list\n    test_types = sorted(test_summaries.keys())\n    test_types += ['total', 'percentage']\n\n    # calculate total stats and percentage\n    total = Counter()\n    percentage = {}\n\n    for test in test_summaries:\n        total.update(test_summaries[test])\n    test_count = sum(total.values())\n\n    for key in total:\n        percentage[key] = round((100.0 * total[key] / test_count), 2)\n\n    fail_rates = calculate_fail_rate(passes=total['green'],\n                                     retries=total['blue'],\n                                     totals=test_count)\n\n    test_summaries['total'] = total\n    test_summaries['percentage'] = percentage\n\n    return {'testTypes': test_types,\n            'byRevision': cset_summaries,\n            'byTest': test_summaries,\n            'failRates': fail_rates,\n            'dates': get_date_range(dates)}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 71, "char_end": 115, "line": "    platform = request.args.get(\"platform\")\n"}, {"line_no": 5, "char_start": 115, "char_end": 177, "line": "    build_system_type = request.args.get(\"build_system_type\")\n"}], "added": [{"line_no": 4, "char_start": 71, "char_end": 132, "line": "    platform = sanitize_string(request.args.get(\"platform\"))\n"}, {"line_no": 5, "char_start": 132, "char_end": 211, "line": "    build_system_type = sanitize_string(request.args.get(\"build_system_type\"))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 86, "char_end": 102, "chars": "sanitize_string("}, {"char_start": 130, "char_end": 131, "chars": ")"}, {"char_start": 156, "char_end": 172, "chars": "sanitize_string("}, {"char_start": 209, "char_end": 210, "chars": ")"}]}, "commit_link": "github.com/mozilla/ouija/commit/8ab444e1c80e603758759c1c71417b0a53ede131", "file_name": "src/server.py", "vul_type": "cwe-089"}
{"func_name": "run_seta_details_query", "func_src_before": "@app.route(\"/data/setadetails/\")\n@json_response\ndef run_seta_details_query():\n    date = request.args.get(\"date\", \"\")\n    active = request.args.get(\"active\", 0)\n    buildbot = request.args.get(\"buildbot\", 0)\n    branch = request.args.get(\"branch\", '')\n    taskcluster = request.args.get(\"taskcluster\", 0)\n    priority = request.args.get(\"priority\", \"low\")\n    jobnames = JOBSDATA.jobnames_query()\n    if date == \"\" or date == \"latest\":\n        today = datetime.now()\n        date = today.strftime(\"%Y-%m-%d\")\n\n    db = create_db_connnection()\n    cursor = db.cursor()\n    query = \"select jobtype from seta where date='%s 00:00:00'\" % date\n    cursor.execute(query)\n    retVal = {}\n    retVal[date] = []\n    jobtype = []\n\n    # we only support fx-team and mozilla-inbound branch in seta\n    if (str(branch) in ['fx-team', 'mozilla-inbound', 'autoland']) is not True \\\n            and str(branch) != '':\n        abort(404)\n    for d in cursor.fetchall():\n        parts = d[0].split(\"'\")\n        jobtype.append([parts[1], parts[3], parts[5]])\n\n    alljobs = JOBSDATA.jobtype_query()\n\n    # Because we store high value jobs in seta table as default,\n    # so we return low value jobs(default) when the priority is 'low',\n    # otherwise we return high value jobs.\n    if priority == 'low':\n        low_value_jobs = [low_value_job for low_value_job in alljobs if\n                          low_value_job not in jobtype]\n        jobtype = low_value_jobs\n\n    if active:\n        active_jobs = []\n        for job in alljobs:\n            found = False\n            for j in jobtype:\n                if j[0] == job[0] and j[1] == job[1] and j[2] == job[2]:\n                    found = True\n                    break\n            if not found:\n                active_jobs.append(job)\n        jobtype = active_jobs\n\n    if buildbot:\n        active_jobs = []\n        # pick up buildbot jobs from job list to faster the filter process\n        buildbot_jobs = [job for job in jobnames if job['buildplatform'] == 'buildbot']\n        # find out the correspond job detail information\n        for job in jobtype:\n            for j in buildbot_jobs:\n                if j['name'] == job[2] and j['platform'] == job[0] and j['buildtype'] == job[1]:\n                    active_jobs.append(j['ref_data_name'] if branch is 'mozilla-inbound'\n                                       else j['ref_data_name'].replace('mozilla-inbound', branch))\n\n        jobtype = active_jobs\n\n    if taskcluster:\n        active_jobs = []\n        taskcluster_jobs = [job for job in jobnames if job['buildplatform'] == 'taskcluster']\n        for job in jobtype:\n            for j in taskcluster_jobs:\n                if j['name'] == job[2] and j['platform'] == job[0] and j['buildtype'] == job[1]:\n                    active_jobs.append(j['ref_data_name'])\n        jobtype = active_jobs\n\n    retVal[date] = jobtype\n    return {'jobtypes': retVal}", "func_src_after": "@app.route(\"/data/setadetails/\")\n@json_response\ndef run_seta_details_query():\n    startDate, date = clean_date_params(request.args)\n    active = sanitize_bool(request.args.get(\"active\", 0))\n    buildbot = sanitize_bool(request.args.get(\"buildbot\", 0))\n    branch = sanitize_string(request.args.get(\"branch\", ''))\n    taskcluster = sanitize_bool(request.args.get(\"taskcluster\", 0))\n    priority = sanitize_string(request.args.get(\"priority\", \"low\"))\n    jobnames = JOBSDATA.jobnames_query()\n    if date == \"\" or date == \"latest\":\n        today = datetime.now()\n        date = today.strftime(\"%Y-%m-%d\")\n    date = \"%s\" % date\n\n    db = create_db_connnection()\n    cursor = db.cursor()\n    query = \"select jobtype from seta where date='%s 00:00:00'\" % date\n    cursor.execute(query)\n    retVal = {}\n    retVal[date] = []\n    jobtype = []\n\n    # we only support fx-team and mozilla-inbound branch in seta\n    if (str(branch) in ['fx-team', 'mozilla-inbound', 'autoland']) is not True \\\n            and str(branch) != '':\n        abort(404)\n    for d in cursor.fetchall():\n        parts = d[0].split(\"'\")\n        jobtype.append([parts[1], parts[3], parts[5]])\n\n    alljobs = JOBSDATA.jobtype_query()\n\n    # Because we store high value jobs in seta table as default,\n    # so we return low value jobs(default) when the priority is 'low',\n    # otherwise we return high value jobs.\n    if priority == 'low':\n        low_value_jobs = [low_value_job for low_value_job in alljobs if\n                          low_value_job not in jobtype]\n        jobtype = low_value_jobs\n\n    if active:\n        active_jobs = []\n        for job in alljobs:\n            found = False\n            for j in jobtype:\n                if j[0] == job[0] and j[1] == job[1] and j[2] == job[2]:\n                    found = True\n                    break\n            if not found:\n                active_jobs.append(job)\n        jobtype = active_jobs\n\n    if buildbot:\n        active_jobs = []\n        # pick up buildbot jobs from job list to faster the filter process\n        buildbot_jobs = [job for job in jobnames if job['buildplatform'] == 'buildbot']\n        # find out the correspond job detail information\n        for job in jobtype:\n            for j in buildbot_jobs:\n                if j['name'] == job[2] and j['platform'] == job[0] and j['buildtype'] == job[1]:\n                    active_jobs.append(j['ref_data_name'] if branch is 'mozilla-inbound'\n                                       else j['ref_data_name'].replace('mozilla-inbound', branch))\n\n        jobtype = active_jobs\n\n    if taskcluster:\n        active_jobs = []\n        taskcluster_jobs = [job for job in jobnames if job['buildplatform'] == 'taskcluster']\n        for job in jobtype:\n            for j in taskcluster_jobs:\n                if j['name'] == job[2] and j['platform'] == job[0] and j['buildtype'] == job[1]:\n                    active_jobs.append(j['ref_data_name'])\n        jobtype = active_jobs\n\n    retVal[date] = jobtype\n    return {\"jobtypes\": retVal}", "line_changes": {"deleted": [{"line_no": 4, "char_start": 78, "char_end": 118, "line": "    date = request.args.get(\"date\", \"\")\n"}, {"line_no": 5, "char_start": 118, "char_end": 161, "line": "    active = request.args.get(\"active\", 0)\n"}, {"line_no": 6, "char_start": 161, "char_end": 208, "line": "    buildbot = request.args.get(\"buildbot\", 0)\n"}, {"line_no": 7, "char_start": 208, "char_end": 252, "line": "    branch = request.args.get(\"branch\", '')\n"}, {"line_no": 8, "char_start": 252, "char_end": 305, "line": "    taskcluster = request.args.get(\"taskcluster\", 0)\n"}, {"line_no": 9, "char_start": 305, "char_end": 356, "line": "    priority = request.args.get(\"priority\", \"low\")\n"}, {"line_no": 76, "char_start": 2864, "char_end": 2895, "line": "    return {'jobtypes': retVal}\n"}], "added": [{"line_no": 4, "char_start": 78, "char_end": 132, "line": "    startDate, date = clean_date_params(request.args)\n"}, {"line_no": 5, "char_start": 132, "char_end": 190, "line": "    active = sanitize_bool(request.args.get(\"active\", 0))\n"}, {"line_no": 6, "char_start": 190, "char_end": 252, "line": "    buildbot = sanitize_bool(request.args.get(\"buildbot\", 0))\n"}, {"line_no": 7, "char_start": 252, "char_end": 313, "line": "    branch = sanitize_string(request.args.get(\"branch\", ''))\n"}, {"line_no": 8, "char_start": 313, "char_end": 381, "line": "    taskcluster = sanitize_bool(request.args.get(\"taskcluster\", 0))\n"}, {"line_no": 9, "char_start": 381, "char_end": 449, "line": "    priority = sanitize_string(request.args.get(\"priority\", \"low\"))\n"}, {"line_no": 14, "char_start": 602, "char_end": 625, "line": "    date = \"%s\" % date\n"}, {"line_no": 77, "char_start": 2980, "char_end": 3011, "line": "    return {\"jobtypes\": retVal}\n"}]}, "char_changes": {"deleted": [{"char_start": 82, "char_end": 116, "chars": "date = request.args.get(\"date\", \"\""}, {"char_start": 467, "char_end": 467, "chars": ""}, {"char_start": 2876, "char_end": 2877, "chars": "'"}, {"char_start": 2885, "char_end": 2886, "chars": "'"}], "added": [{"char_start": 82, "char_end": 130, "chars": "startDate, date = clean_date_params(request.args"}, {"char_start": 145, "char_end": 159, "chars": "sanitize_bool("}, {"char_start": 188, "char_end": 189, "chars": ")"}, {"char_start": 205, "char_end": 219, "chars": "sanitize_bool("}, {"char_start": 250, "char_end": 251, "chars": ")"}, {"char_start": 265, "char_end": 281, "chars": "sanitize_string("}, {"char_start": 311, "char_end": 312, "chars": ")"}, {"char_start": 331, "char_end": 345, "chars": "sanitize_bool("}, {"char_start": 379, "char_end": 380, "chars": ")"}, {"char_start": 396, "char_end": 412, "chars": "sanitize_string("}, {"char_start": 447, "char_end": 448, "chars": ")"}, {"char_start": 601, "char_end": 624, "chars": "\n    date = \"%s\" % date"}, {"char_start": 2992, "char_end": 2993, "chars": "\""}, {"char_start": 3001, "char_end": 3002, "chars": "\""}]}, "commit_link": "github.com/mozilla/ouija/commit/8ab444e1c80e603758759c1c71417b0a53ede131", "file_name": "src/server.py", "vul_type": "cwe-089"}
{"func_name": "new_expense", "func_src_before": "def new_expense(person, expense_date, amount, category, description):\n    try:\n        conn = check_heroku_db()\n        cur = conn.cursor()\n        cur.execute('''INSERT INTO ledger (person_id, txn_date, amount, category_id, description)\n                        SELECT (SELECT id FROM persons WHERE person_name='%s'), '%s', %d,\n                        (SELECT id FROM categories WHERE cat_name='%s'), '%s' ;'''\n                        % (person, expense_date, amount, category, description))\n        conn.commit()\n        conn.close()\n\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "func_src_after": "def new_expense(person, expense_date, amount, category, description):\n    try:\n        conn = check_heroku_db()\n        cur = conn.cursor()\n\n        query = '''INSERT INTO ledger (person_id, txn_date, amount, category_id, description)\n                        SELECT (SELECT id FROM persons WHERE person_name=%s), %s, %s,\n                        (SELECT id FROM categories WHERE cat_name=%s), %s ;'''\n        data = (person, expense_date, amount, category, description, )\n        cur.execute(query, data)\n\n        conn.commit()\n        conn.close()\n\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 140, "char_end": 238, "line": "        cur.execute('''INSERT INTO ledger (person_id, txn_date, amount, category_id, description)\n"}, {"line_no": 6, "char_start": 238, "char_end": 328, "line": "                        SELECT (SELECT id FROM persons WHERE person_name='%s'), '%s', %d,\n"}, {"line_no": 7, "char_start": 328, "char_end": 411, "line": "                        (SELECT id FROM categories WHERE cat_name='%s'), '%s' ;'''\n"}, {"line_no": 8, "char_start": 411, "char_end": 492, "line": "                        % (person, expense_date, amount, category, description))\n"}], "added": [{"line_no": 5, "char_start": 140, "char_end": 141, "line": "\n"}, {"line_no": 6, "char_start": 141, "char_end": 235, "line": "        query = '''INSERT INTO ledger (person_id, txn_date, amount, category_id, description)\n"}, {"line_no": 7, "char_start": 235, "char_end": 321, "line": "                        SELECT (SELECT id FROM persons WHERE person_name=%s), %s, %s,\n"}, {"line_no": 8, "char_start": 321, "char_end": 400, "line": "                        (SELECT id FROM categories WHERE cat_name=%s), %s ;'''\n"}, {"line_no": 9, "char_start": 400, "char_end": 471, "line": "        data = (person, expense_date, amount, category, description, )\n"}, {"line_no": 10, "char_start": 471, "char_end": 504, "line": "        cur.execute(query, data)\n"}, {"line_no": 11, "char_start": 504, "char_end": 505, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 148, "char_end": 160, "chars": "cur.execute("}, {"char_start": 311, "char_end": 312, "chars": "'"}, {"char_start": 314, "char_end": 315, "chars": "'"}, {"char_start": 318, "char_end": 319, "chars": "'"}, {"char_start": 321, "char_end": 322, "chars": "'"}, {"char_start": 325, "char_end": 326, "chars": "d"}, {"char_start": 394, "char_end": 395, "chars": "'"}, {"char_start": 397, "char_end": 398, "chars": "'"}, {"char_start": 401, "char_end": 402, "chars": "'"}, {"char_start": 404, "char_end": 405, "chars": "'"}, {"char_start": 419, "char_end": 436, "chars": "                %"}, {"char_start": 489, "char_end": 491, "chars": "))"}], "added": [{"char_start": 140, "char_end": 141, "chars": "\n"}, {"char_start": 149, "char_end": 157, "chars": "query = "}, {"char_start": 318, "char_end": 319, "chars": "s"}, {"char_start": 408, "char_end": 414, "chars": "data ="}, {"char_start": 467, "char_end": 504, "chars": ", )\n        cur.execute(query, data)\n"}]}, "commit_link": "github.com/leeorb321/expenses/commit/f93c0fa4d30787ef16420bfefc52565b98bc7fcf", "file_name": "db.py", "vul_type": "cwe-089"}
{"func_name": "new_category", "func_src_before": "def new_category(category_name):\n    try:\n        conn = check_heroku_db()\n        cur = conn.cursor()\n        cur.execute('''INSERT INTO categories (cat_name) VALUES (%s)''', (category_name,))\n        conn.commit()\n        conn.close()\n\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "func_src_after": "def new_category(category_name):\n    try:\n        conn = check_heroku_db()\n        cur = conn.cursor()\n\n        query = \"INSERT INTO categories (cat_name) VALUES (%s);\"\n        data = (category_name,)\n        cur.execute(query, data)\n\n        conn.commit()\n        conn.close()\n\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 103, "char_end": 194, "line": "        cur.execute('''INSERT INTO categories (cat_name) VALUES (%s)''', (category_name,))\n"}], "added": [{"line_no": 5, "char_start": 103, "char_end": 104, "line": "\n"}, {"line_no": 6, "char_start": 104, "char_end": 169, "line": "        query = \"INSERT INTO categories (cat_name) VALUES (%s);\"\n"}, {"line_no": 7, "char_start": 169, "char_end": 201, "line": "        data = (category_name,)\n"}, {"line_no": 8, "char_start": 201, "char_end": 234, "line": "        cur.execute(query, data)\n"}, {"line_no": 9, "char_start": 234, "char_end": 235, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 111, "char_end": 126, "chars": "cur.execute('''"}, {"char_start": 171, "char_end": 193, "chars": "''', (category_name,))"}], "added": [{"char_start": 103, "char_end": 104, "chars": "\n"}, {"char_start": 112, "char_end": 121, "chars": "query = \""}, {"char_start": 166, "char_end": 234, "chars": ";\"\n        data = (category_name,)\n        cur.execute(query, data)\n"}]}, "commit_link": "github.com/leeorb321/expenses/commit/f93c0fa4d30787ef16420bfefc52565b98bc7fcf", "file_name": "db.py", "vul_type": "cwe-089"}
{"func_name": "update_expense", "func_src_before": "def update_expense(new_person, new_date, new_amount, new_category, new_description, txn_id):\n    try:\n        conn = psycopg2.connect(database=\"expenses\")\n        cur = conn.cursor()\n        cur.execute('''UPDATE ledger SET\n                        person_id = (SELECT id FROM persons WHERE person_name = '%s'),\n                        txn_date = '%s',\n                        amount = '%s',\n                        category_id = (SELECT id FROM categories WHERE cat_name = '%s'),\n                        description = '%s'\n                        WHERE id = '%s';\n                    ''' % (new_person, new_date, new_amount, new_category, new_description, txn_id))\n        conn.commit()\n        conn.close()\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "func_src_after": "def update_expense(new_person, new_date, new_amount, new_category, new_description, txn_id):\n    try:\n        conn = psycopg2.connect(database=\"expenses\")\n        cur = conn.cursor()\n\n        query = '''UPDATE ledger SET\n                        person_id = (SELECT id FROM persons WHERE person_name = %s),\n                        txn_date = %s,\n                        amount = %s,\n                        category_id = (SELECT id FROM categories WHERE cat_name = %s),\n                        description = %s\n                        WHERE id = %s;\n                    '''\n        data = (new_person, new_date, new_amount, new_category, new_description, txn_id, )\n        cur.execute(query, data)\n\n        conn.commit()\n        conn.close()\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 183, "char_end": 224, "line": "        cur.execute('''UPDATE ledger SET\n"}, {"line_no": 6, "char_start": 224, "char_end": 311, "line": "                        person_id = (SELECT id FROM persons WHERE person_name = '%s'),\n"}, {"line_no": 7, "char_start": 311, "char_end": 352, "line": "                        txn_date = '%s',\n"}, {"line_no": 8, "char_start": 352, "char_end": 391, "line": "                        amount = '%s',\n"}, {"line_no": 9, "char_start": 391, "char_end": 480, "line": "                        category_id = (SELECT id FROM categories WHERE cat_name = '%s'),\n"}, {"line_no": 10, "char_start": 480, "char_end": 523, "line": "                        description = '%s'\n"}, {"line_no": 11, "char_start": 523, "char_end": 564, "line": "                        WHERE id = '%s';\n"}, {"line_no": 12, "char_start": 564, "char_end": 665, "line": "                    ''' % (new_person, new_date, new_amount, new_category, new_description, txn_id))\n"}], "added": [{"line_no": 5, "char_start": 183, "char_end": 184, "line": "\n"}, {"line_no": 6, "char_start": 184, "char_end": 221, "line": "        query = '''UPDATE ledger SET\n"}, {"line_no": 7, "char_start": 221, "char_end": 306, "line": "                        person_id = (SELECT id FROM persons WHERE person_name = %s),\n"}, {"line_no": 8, "char_start": 306, "char_end": 345, "line": "                        txn_date = %s,\n"}, {"line_no": 9, "char_start": 345, "char_end": 382, "line": "                        amount = %s,\n"}, {"line_no": 10, "char_start": 382, "char_end": 469, "line": "                        category_id = (SELECT id FROM categories WHERE cat_name = %s),\n"}, {"line_no": 11, "char_start": 469, "char_end": 510, "line": "                        description = %s\n"}, {"line_no": 12, "char_start": 510, "char_end": 549, "line": "                        WHERE id = %s;\n"}, {"line_no": 13, "char_start": 549, "char_end": 573, "line": "                    '''\n"}, {"line_no": 14, "char_start": 573, "char_end": 664, "line": "        data = (new_person, new_date, new_amount, new_category, new_description, txn_id, )\n"}, {"line_no": 15, "char_start": 664, "char_end": 697, "line": "        cur.execute(query, data)\n"}, {"line_no": 16, "char_start": 697, "char_end": 698, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 191, "char_end": 203, "chars": "cur.execute("}, {"char_start": 304, "char_end": 305, "chars": "'"}, {"char_start": 307, "char_end": 308, "chars": "'"}, {"char_start": 346, "char_end": 347, "chars": "'"}, {"char_start": 349, "char_end": 350, "chars": "'"}, {"char_start": 385, "char_end": 386, "chars": "'"}, {"char_start": 388, "char_end": 389, "chars": "'"}, {"char_start": 473, "char_end": 474, "chars": "'"}, {"char_start": 476, "char_end": 477, "chars": "'"}, {"char_start": 518, "char_end": 519, "chars": "'"}, {"char_start": 521, "char_end": 522, "chars": "'"}, {"char_start": 558, "char_end": 559, "chars": "'"}, {"char_start": 561, "char_end": 562, "chars": "'"}, {"char_start": 587, "char_end": 589, "chars": " %"}, {"char_start": 662, "char_end": 664, "chars": "))"}], "added": [{"char_start": 183, "char_end": 184, "chars": "\n"}, {"char_start": 192, "char_end": 200, "chars": "query = "}, {"char_start": 572, "char_end": 587, "chars": "\n        data ="}, {"char_start": 660, "char_end": 697, "chars": ", )\n        cur.execute(query, data)\n"}]}, "commit_link": "github.com/leeorb321/expenses/commit/f93c0fa4d30787ef16420bfefc52565b98bc7fcf", "file_name": "db.py", "vul_type": "cwe-089"}
{"func_name": "delete_expense", "func_src_before": "def delete_expense(txn_id):\n    try:\n        conn = psycopg2.connect(database=\"expenses\")\n        cur = conn.cursor()\n        cur.execute('''DELETE FROM ledger WHERE id = '%s';''' % txn_id)\n\n        conn.commit()\n        conn.close()\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "func_src_after": "def delete_expense(txn_id):\n    try:\n        conn = psycopg2.connect(database=\"expenses\")\n        cur = conn.cursor()\n\n        query = \"DELETE FROM ledger WHERE id = %s;\"\n        data = (txn_id, )\n        cur.execute(query, data)\n\n        conn.commit()\n        conn.close()\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 118, "char_end": 190, "line": "        cur.execute('''DELETE FROM ledger WHERE id = '%s';''' % txn_id)\n"}], "added": [{"line_no": 5, "char_start": 118, "char_end": 119, "line": "\n"}, {"line_no": 6, "char_start": 119, "char_end": 171, "line": "        query = \"DELETE FROM ledger WHERE id = %s;\"\n"}, {"line_no": 7, "char_start": 171, "char_end": 197, "line": "        data = (txn_id, )\n"}, {"line_no": 8, "char_start": 197, "char_end": 230, "line": "        cur.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 126, "char_end": 141, "chars": "cur.execute('''"}, {"char_start": 171, "char_end": 172, "chars": "'"}, {"char_start": 174, "char_end": 188, "chars": "';''' % txn_id"}], "added": [{"char_start": 118, "char_end": 119, "chars": "\n"}, {"char_start": 127, "char_end": 136, "chars": "query = \""}, {"char_start": 168, "char_end": 228, "chars": ";\"\n        data = (txn_id, )\n        cur.execute(query, data"}]}, "commit_link": "github.com/leeorb321/expenses/commit/f93c0fa4d30787ef16420bfefc52565b98bc7fcf", "file_name": "db.py", "vul_type": "cwe-089"}
{"func_name": "current_metric", "func_src_before": "@app.route(\"/metric/api/v1.0/metric/current\")\n@crossdomain(origin=\"*\")\ndef current_metric():\n    res = getMetric(request.args.get(\"fromtime\", None), request.args.get(\"totime\", None),\n                    request.args.get(\"origin\", None), request.args.get(\"key\", None), 1,\n                    (\"Time\", True))\n    return jsonify({\"results\": res, \"resultcount\": len(res)})", "func_src_after": "@app.route(\"/metric/api/v1.0/metric/current\")\n@crossdomain(origin=\"*\")\ndef current_metric():\n    res = getMetric(request.args.get(\"fromtime\", None), request.args.get(\"totime\", None),\n                    request.args.get(\"origin\", None), request.args.get(\"key\", None), 1,\n                    (\"time\", True))\n    return jsonify({\"results\": res, \"resultcount\": len(res)})", "line_changes": {"deleted": [{"line_no": 6, "char_start": 271, "char_end": 307, "line": "                    (\"Time\", True))\n"}], "added": [{"line_no": 6, "char_start": 271, "char_end": 307, "line": "                    (\"time\", True))\n"}]}, "char_changes": {"deleted": [{"char_start": 293, "char_end": 294, "chars": "T"}], "added": [{"char_start": 293, "char_end": 294, "chars": "t"}]}, "commit_link": "github.com/laubed/pyMetric/commit/eed42eb5078b6e1a03ddd2611026e11d7f7e7c0a", "file_name": "pyMetricServer/handler/metric.py", "vul_type": "cwe-089"}
{"func_name": "getMetric", "func_src_before": "def getMetric(timefrom = None, timeto = None, origin = None, key = None, count = None, order = None):\n    results = []\n    cursor = database.cursor()\n\n    params = []\n    query = \"SELECT Id, Time, Origin, Key, Value FROM log_metric \"\n    if(timefrom != None or timeto != None or origin != None or key != None):\n        query += \"WHERE \"\n\n    if timefrom != None:\n        query += \"Time >= %s AND \"\n        params.append(timefrom)\n\n    if timeto != None:\n        query += \"Time <= %s AND \"\n        params.append(timeto)\n\n    if origin != None:\n        query += \"Origin = %s AND \"\n        params.append(origin)\n\n    if key != None:\n        query += \"Key = %s AND \"\n        params.append(key)\n\n    query = query.strip(\"AND \")\n    query += \" \"\n\n\n    if order != None and order[0] != None:\n        if(order[1]):\n            query += \"ORDER BY %s DESC \" % order[0]\n        else:\n            query += \"ORDER BY %s ASC \" % order[0]\n\n    if count != None:\n        query += \"LIMIT %s \"\n        params.append(count)\n\n    cursor.execute(query, tuple(params))\n    for row in cursor:\n        results.append({\n            \"Id\": str(row[0]),\n            \"Time\": str(row[1]),\n            \"Origin\": str(row[2]),\n            \"Key\": str(row[3]),\n            \"Value\": str(row[4]),\n        })\n\n    return results", "func_src_after": "def getMetric(timefrom = None, timeto = None, origin = None, key = None, count = None, order = None):\n    results = []\n    cursor = database.cursor()\n\n    params = []\n    query = \"SELECT Id, Time, Origin, Key, Value FROM log_metric \"\n    if(timefrom != None or timeto != None or origin != None or key != None):\n        query += \"WHERE \"\n\n    if timefrom != None:\n        query += \"Time >= %s AND \"\n        params.append(timefrom)\n\n    if timeto != None:\n        query += \"Time <= %s AND \"\n        params.append(timeto)\n\n    if origin != None:\n        query += \"Origin = %s AND \"\n        params.append(origin)\n\n    if key != None:\n        query += \"Key = %s AND \"\n        params.append(key)\n\n    query = query.strip(\"AND \")\n    query += \" \"\n\n\n    if order != None and order[0] != None:\n        if order[1]:\n            desc = \"DESC\"\n        else:\n            desc = \"ASC\"\n            \n        if order[0] == \"time\":\n            query += \"ORDER BY Time \" + desc\n        elif order[0] == \"value\":\n            query += \"ORDER BY Value \" + desc\n        elif order[0] == \"key\":\n            query += \"ORDER BY Key \" + desc\n        elif order[0] == \"origin\":\n            query += \"ORDER BY Origin \" + desc\n        elif order[0] == \"id\":\n            query += \"ORDER BY Id\" + desc\n\n    if count != None:\n        query += \"LIMIT %s \"\n        params.append(count)\n\n    cursor.execute(query, tuple(params))\n    for row in cursor:\n        results.append({\n            \"Id\": str(row[0]),\n            \"Time\": str(row[1]),\n            \"Origin\": str(row[2]),\n            \"Key\": str(row[3]),\n            \"Value\": str(row[4]),\n        })\n\n    return results", "line_changes": {"deleted": [{"line_no": 31, "char_start": 785, "char_end": 807, "line": "        if(order[1]):\n"}, {"line_no": 32, "char_start": 807, "char_end": 859, "line": "            query += \"ORDER BY %s DESC \" % order[0]\n"}, {"line_no": 34, "char_start": 873, "char_end": 924, "line": "            query += \"ORDER BY %s ASC \" % order[0]\n"}], "added": [{"line_no": 31, "char_start": 785, "char_end": 806, "line": "        if order[1]:\n"}, {"line_no": 32, "char_start": 806, "char_end": 832, "line": "            desc = \"DESC\"\n"}, {"line_no": 34, "char_start": 846, "char_end": 871, "line": "            desc = \"ASC\"\n"}, {"line_no": 35, "char_start": 871, "char_end": 884, "line": "            \n"}, {"line_no": 36, "char_start": 884, "char_end": 915, "line": "        if order[0] == \"time\":\n"}, {"line_no": 37, "char_start": 915, "char_end": 960, "line": "            query += \"ORDER BY Time \" + desc\n"}, {"line_no": 38, "char_start": 960, "char_end": 994, "line": "        elif order[0] == \"value\":\n"}, {"line_no": 39, "char_start": 994, "char_end": 1040, "line": "            query += \"ORDER BY Value \" + desc\n"}, {"line_no": 40, "char_start": 1040, "char_end": 1072, "line": "        elif order[0] == \"key\":\n"}, {"line_no": 41, "char_start": 1072, "char_end": 1116, "line": "            query += \"ORDER BY Key \" + desc\n"}, {"line_no": 42, "char_start": 1116, "char_end": 1151, "line": "        elif order[0] == \"origin\":\n"}, {"line_no": 43, "char_start": 1151, "char_end": 1198, "line": "            query += \"ORDER BY Origin \" + desc\n"}, {"line_no": 44, "char_start": 1198, "char_end": 1229, "line": "        elif order[0] == \"id\":\n"}, {"line_no": 45, "char_start": 1229, "char_end": 1271, "line": "            query += \"ORDER BY Id\" + desc\n"}]}, "char_changes": {"deleted": [{"char_start": 795, "char_end": 796, "chars": "("}, {"char_start": 804, "char_end": 923, "chars": "):\n            query += \"ORDER BY %s DESC \" % order[0]\n        else:\n            query += \"ORDER BY %s ASC \" % order[0]"}], "added": [{"char_start": 795, "char_end": 796, "chars": " "}, {"char_start": 804, "char_end": 1270, "chars": ":\n            desc = \"DESC\"\n        else:\n            desc = \"ASC\"\n            \n        if order[0] == \"time\":\n            query += \"ORDER BY Time \" + desc\n        elif order[0] == \"value\":\n            query += \"ORDER BY Value \" + desc\n        elif order[0] == \"key\":\n            query += \"ORDER BY Key \" + desc\n        elif order[0] == \"origin\":\n            query += \"ORDER BY Origin \" + desc\n        elif order[0] == \"id\":\n            query += \"ORDER BY Id\" + desc"}]}, "commit_link": "github.com/laubed/pyMetric/commit/eed42eb5078b6e1a03ddd2611026e11d7f7e7c0a", "file_name": "pyMetricServer/system/database.py", "vul_type": "cwe-089"}
{"func_name": "add_post", "func_src_before": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(\"dbname=forum\")\n  c = db.cursor()\n  c.execute(\"INSERT INTO posts (content) VALUES ('%s')\" % content)\n  db.commit()\n  db.close()", "func_src_after": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(\"dbname=forum\")\n  c = db.cursor()\n  # IMPORTANT: When using Insert, use query paramaters instead of String substituition \n  c.execute(\"INSERT INTO posts (content) VALUES (%s)\",\n            (content, ))\n  db.commit()\n  db.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 146, "char_end": 213, "line": "  c.execute(\"INSERT INTO posts (content) VALUES ('%s')\" % content)\n"}], "added": [{"line_no": 6, "char_start": 234, "char_end": 289, "line": "  c.execute(\"INSERT INTO posts (content) VALUES (%s)\",\n"}, {"line_no": 7, "char_start": 289, "char_end": 314, "line": "            (content, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 195, "char_end": 196, "chars": "'"}, {"char_start": 198, "char_end": 199, "chars": "'"}, {"char_start": 201, "char_end": 204, "chars": " % "}], "added": [{"char_start": 146, "char_end": 234, "chars": "  # IMPORTANT: When using Insert, use query paramaters instead of String substituition \n"}, {"char_start": 287, "char_end": 302, "chars": ",\n            ("}, {"char_start": 309, "char_end": 312, "chars": ", )"}]}, "commit_link": "github.com/Christianq010/vagrant-box-Intro-to-relational-DB/commit/5582a2267a0897ce5e64ba1594bef86ad941b45c", "file_name": "forum/forumdb.py", "vul_type": "cwe-089"}
{"func_name": "process_vote", "func_src_before": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target)).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target))\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "func_src_after": "def process_vote(target,action,chan,mask,db,notice,conn):\n    if ' ' in target: \n        notice('Invalid nick')\n        return\n\n    try: votes2kick = database.get(db,'channels','votekick','chan',chan)\n    except: votes2kick = 10\n    try: votes2ban = database.get(db,'channels','voteban','chan',chan)\n    except: votes2ban = 10\n\n    if len(target) is 0:\n        if action is 'kick': notice('Votes required to kick: {}'.format(votes2kick))\n        elif action is 'ban': notice('Votes required to ban: {}'.format(votes2ban))\n        return\n\n    votefinished = False\n    global db_ready\n    if not db_ready: db_init(db)\n    chan = chan.lower()\n    target = target.lower()\n    voter = user.format_hostmask(mask)\n    voters = db.execute(\"SELECT voters FROM votes where chan=? and action=? and target like ?\", chan, action, target).fetchone()\n\n    if conn.nick.lower() in target: return \"I dont think so Tim.\"\n\n    if voters: \n        voters = voters[0]\n        if voter in voters: \n            notice(\"You have already voted.\")\n            return\n        else:\n            voters = '{} {}'.format(voters,voter).strip()\n            notice(\"Thank you for your vote!\")\n    else: \n        voters = voter\n\n    votecount = len(voters.split(' '))\n\n    if 'kick' in action: \n        votemax = int(votes2kick)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"KICK {} {} :{}\".format(chan, target, \"You have been voted off the island.\"))\n    if 'ban' in action:\n        votemax = int(votes2ban)\n        if votecount >= votemax:\n            votefinished = True\n            conn.send(\"MODE {} +b {}\".format(chan, user.get_hostmask(target,db)))\n            conn.send(\"KICK {} {} :\".format(chan, target, \"You have been voted off the island.\"))\n    \n    if votefinished: db.execute(\"DELETE FROM votes where chan=? and action=? and target like ?\", chan, action, target)\n    else: db.execute(\"insert or replace into votes(chan, action, target, voters, time) values(?,?,?,?,?)\", (chan, action, target, voters, time.time()))\n        \n    db.commit()\n    return (\"Votes to {} {}: {}/{}\".format(action, target, votecount,votemax))", "line_changes": {"deleted": [{"line_no": 22, "char_start": 707, "char_end": 850, "line": "    voters = db.execute(\"SELECT voters FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target)).fetchone()\n"}, {"line_no": 51, "char_start": 1781, "char_end": 1914, "line": "    if votefinished: db.execute(\"DELETE FROM votes where chan='{}' and action='{}' and target like '{}'\".format(chan,action,target))\n"}], "added": [{"line_no": 22, "char_start": 707, "char_end": 836, "line": "    voters = db.execute(\"SELECT voters FROM votes where chan=? and action=? and target like ?\", chan, action, target).fetchone()\n"}, {"line_no": 51, "char_start": 1767, "char_end": 1886, "line": "    if votefinished: db.execute(\"DELETE FROM votes where chan=? and action=? and target like ?\", chan, action, target)\n"}]}, "char_changes": {"deleted": [{"char_start": 768, "char_end": 772, "chars": "'{}'"}, {"char_start": 784, "char_end": 788, "chars": "'{}'"}, {"char_start": 805, "char_end": 818, "chars": "'{}'\".format("}, {"char_start": 837, "char_end": 838, "chars": ")"}, {"char_start": 1843, "char_end": 1847, "chars": "'{}'"}, {"char_start": 1859, "char_end": 1863, "chars": "'{}'"}, {"char_start": 1880, "char_end": 1893, "chars": "'{}'\".format("}, {"char_start": 1912, "char_end": 1913, "chars": ")"}], "added": [{"char_start": 768, "char_end": 769, "chars": "?"}, {"char_start": 781, "char_end": 782, "chars": "?"}, {"char_start": 799, "char_end": 803, "chars": "?\", "}, {"char_start": 808, "char_end": 809, "chars": " "}, {"char_start": 816, "char_end": 817, "chars": " "}, {"char_start": 1829, "char_end": 1830, "chars": "?"}, {"char_start": 1842, "char_end": 1843, "chars": "?"}, {"char_start": 1860, "char_end": 1864, "chars": "?\", "}, {"char_start": 1869, "char_end": 1870, "chars": " "}, {"char_start": 1877, "char_end": 1878, "chars": " "}]}, "commit_link": "github.com/gstack/uguubot/commit/700ff40be84be88964e61f8ae780564e5862460d", "file_name": "plugins/vote.py", "vul_type": "cwe-089"}
{"func_name": "registerPlayer", "func_src_before": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    cursor.execute(\"INSERT INTO players (name) VALUES ('%s')\" % (name,));\n    conn.commit()\n    conn.close()", "func_src_after": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    query = \"INSERT INTO players (name) VALUES (%s);\"\n    cursor.execute(query, (name,))\n    conn.commit()\n    conn.close()", "line_changes": {"deleted": [{"line_no": 12, "char_start": 351, "char_end": 425, "line": "    cursor.execute(\"INSERT INTO players (name) VALUES ('%s')\" % (name,));\n"}], "added": [{"line_no": 12, "char_start": 351, "char_end": 405, "line": "    query = \"INSERT INTO players (name) VALUES (%s);\"\n"}, {"line_no": 13, "char_start": 405, "char_end": 440, "line": "    cursor.execute(query, (name,))\n"}]}, "char_changes": {"deleted": [{"char_start": 355, "char_end": 370, "chars": "cursor.execute("}, {"char_start": 406, "char_end": 407, "chars": "'"}, {"char_start": 409, "char_end": 414, "chars": "')\" %"}, {"char_start": 423, "char_end": 424, "chars": ";"}], "added": [{"char_start": 355, "char_end": 363, "chars": "query = "}, {"char_start": 401, "char_end": 430, "chars": ");\"\n    cursor.execute(query,"}]}, "commit_link": "github.com/sarahkcaplan/tournament/commit/40aba5686059f5f398f6323b1483412c56140cc0", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    cursor.execute(\"INSERT INTO playsRecord (winner, loser) VALUES ('%s', '%s')\" % (winner, loser));\n    conn.commit()\n    conn.close()", "func_src_after": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    conn = connect()\n    cursor = conn.cursor()\n    query = \"INSERT INTO playsRecord (winner, loser) VALUES (%s, %s);\"\n    cursor.execute(query, (winner, loser));\n    conn.commit()\n    conn.close()", "line_changes": {"deleted": [{"line_no": 10, "char_start": 267, "char_end": 368, "line": "    cursor.execute(\"INSERT INTO playsRecord (winner, loser) VALUES ('%s', '%s')\" % (winner, loser));\n"}], "added": [{"line_no": 10, "char_start": 267, "char_end": 338, "line": "    query = \"INSERT INTO playsRecord (winner, loser) VALUES (%s, %s);\"\n"}, {"line_no": 11, "char_start": 338, "char_end": 382, "line": "    cursor.execute(query, (winner, loser));\n"}]}, "char_changes": {"deleted": [{"char_start": 271, "char_end": 286, "chars": "cursor.execute("}, {"char_start": 335, "char_end": 336, "chars": "'"}, {"char_start": 338, "char_end": 339, "chars": "'"}, {"char_start": 341, "char_end": 342, "chars": "'"}, {"char_start": 344, "char_end": 349, "chars": "')\" %"}], "added": [{"char_start": 271, "char_end": 279, "chars": "query = "}, {"char_start": 334, "char_end": 363, "chars": ");\"\n    cursor.execute(query,"}]}, "commit_link": "github.com/sarahkcaplan/tournament/commit/40aba5686059f5f398f6323b1483412c56140cc0", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "openPoll", "func_src_before": "@hook.command(adminonly=True)\ndef openPoll(question, reply=None, db=None):\n    \"\"\"Creates a new poll.\"\"\"\n    if not db_ready: db_init(db)\n    try:\n        active = db.execute(\"SELECT pollID FROM polls WHERE active = 1\").fetchone()[0]\n        if active: \n            reply(\"There already is an open poll.\")\n            return\n    except:\n        db.execute(\"INSERT INTO polls (question, active) VALUES ('{}', 1)\".format(question))\n        reply(\"Opened new poll: {}\".format(question))\n        #reply(\"Poll opened!\")\n    return", "func_src_after": "@hook.command(adminonly=True)\ndef openPoll(question, reply=None, db=None):\n    \"\"\"Creates a new poll.\"\"\"\n    if not db_ready: db_init(db)\n    try:\n        active = db.execute(\"SELECT pollID FROM polls WHERE active = 1\").fetchone()[0]\n        if active: \n            reply(\"There already is an open poll.\")\n            return\n    except:\n        db.execute(\"INSERT INTO polls (question, active) VALUES (?, 1)\", (question,))\n        reply(\"Opened new poll: {}\".format(question))\n        #reply(\"Poll opened!\")\n    return", "line_changes": {"deleted": [{"line_no": 11, "char_start": 337, "char_end": 430, "line": "        db.execute(\"INSERT INTO polls (question, active) VALUES ('{}', 1)\".format(question))\n"}], "added": [{"line_no": 11, "char_start": 337, "char_end": 423, "line": "        db.execute(\"INSERT INTO polls (question, active) VALUES (?, 1)\", (question,))\n"}]}, "char_changes": {"deleted": [{"char_start": 402, "char_end": 406, "chars": "'{}'"}, {"char_start": 411, "char_end": 418, "chars": ".format"}], "added": [{"char_start": 402, "char_end": 403, "chars": "?"}, {"char_start": 408, "char_end": 410, "chars": ", "}, {"char_start": 419, "char_end": 420, "chars": ","}]}, "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089"}
{"func_name": "showPoll", "func_src_before": "@hook.command(autohelp=False)\ndef showPoll(pollID, db=None):\n    \"\"\"Shows the answers for a given poll.\"\"\"\n    if not db_ready: db_init(db)\n    if pollID == None:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE active = 1\")\n        if len(poll) == 0:\n            reply(\"There's no poll open.\")\n            return\n    else:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE pollID = '{}'\".format(pollID))\n        if len(poll) == 0:\n            reply(\"No such poll found.\")\n            return\n    pollID = poll[0][0]\n    question = poll[0][1]\n    reply(question)\n    for (index, answer, votes) in db.execute(\"SELECT 'index', answer, count(voteID) FROM answers LEFT JOIN votes ON votes.answerID = answers.answerID WHERE pollID = {} GROUP BY answers.answerID, 'index', answer ORDER BY 'index' ASC\".format(pollID, )):\n        reply(\"%s. %s (%s)\" % (index, answer, votes))", "func_src_after": "@hook.command(autohelp=False)\ndef showPoll(pollID, db=None):\n    \"\"\"Shows the answers for a given poll.\"\"\"\n    if not db_ready: db_init(db)\n    if pollID == None:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE active = 1\")\n        if len(poll) == 0:\n            reply(\"There's no poll open.\")\n            return\n    else:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE pollID = ?\", (pollID,))\n        if len(poll) == 0:\n            reply(\"No such poll found.\")\n            return\n    pollID = poll[0][0]\n    question = poll[0][1]\n    reply(question)\n    for (index, answer, votes) in db.execute(\"SELECT 'index', answer, count(voteID) FROM answers LEFT JOIN votes ON votes.answerID = answers.answerID WHERE pollID = ? GROUP BY answers.answerID, 'index', answer ORDER BY 'index' ASC\", (pollID, )):\n        reply(\"%s. %s (%s)\" % (index, answer, votes))", "line_changes": {"deleted": [{"line_no": 11, "char_start": 343, "char_end": 442, "line": "        poll = db.execute(\"SELECT pollID, question FROM polls WHERE pollID = '{}'\".format(pollID))\n"}, {"line_no": 18, "char_start": 599, "char_end": 851, "line": "    for (index, answer, votes) in db.execute(\"SELECT 'index', answer, count(voteID) FROM answers LEFT JOIN votes ON votes.answerID = answers.answerID WHERE pollID = {} GROUP BY answers.answerID, 'index', answer ORDER BY 'index' ASC\".format(pollID, )):\n"}], "added": [{"line_no": 11, "char_start": 343, "char_end": 435, "line": "        poll = db.execute(\"SELECT pollID, question FROM polls WHERE pollID = ?\", (pollID,))\n"}, {"line_no": 18, "char_start": 592, "char_end": 838, "line": "    for (index, answer, votes) in db.execute(\"SELECT 'index', answer, count(voteID) FROM answers LEFT JOIN votes ON votes.answerID = answers.answerID WHERE pollID = ? GROUP BY answers.answerID, 'index', answer ORDER BY 'index' ASC\", (pollID, )):\n"}]}, "char_changes": {"deleted": [{"char_start": 420, "char_end": 432, "chars": "'{}'\".format"}, {"char_start": 764, "char_end": 766, "chars": "{}"}, {"char_start": 831, "char_end": 838, "chars": ".format"}], "added": [{"char_start": 420, "char_end": 424, "chars": "?\", "}, {"char_start": 431, "char_end": 432, "chars": ","}, {"char_start": 757, "char_end": 758, "chars": "?"}, {"char_start": 823, "char_end": 825, "chars": ", "}]}, "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089"}
{"func_name": "voteFor", "func_src_before": "@hook.command\ndef voteFor(answerIndex, reply=None, db=None):\n    \"\"\"Casts a vote for the current poll.\"\"\"\n    if not db_ready: db_init(db)\n    polls = db.execute(\"SELECT pollID FROM polls WHERE active = 1\")\n    if len(polls) == 0:\n        reply(\"No poll is open at the moment.\")\n        return\n    pollID = polls[0][0]\n    answers = db.execute(\"SELECT answerID FROM answers WHERE pollID = %s AND 'index' = %s\" % (pollID, answerIndex))\n    if len(answers) == 0:\n        reply(\"No item #%s found.\" % answerIndex)\n        return\n    answerID = answers[0][0]\n    db.execute(\"DELETE FROM votes WHERE nick = %s AND answerID IN (SELECT answerID FROM answers WHERE pollID = %s)\", (sender, pollID))\n    db.execute(\"INSERT INTO votes (answerID, nick) VALUES (%s, %s)\", (answerID, sender))\n    reply(\"Vote registered.\")", "func_src_after": "@hook.command\ndef voteFor(answerIndex, reply=None, db=None):\n    \"\"\"Casts a vote for the current poll.\"\"\"\n    if not db_ready: db_init(db)\n    polls = db.execute(\"SELECT pollID FROM polls WHERE active = 1\")\n    if len(polls) == 0:\n        reply(\"No poll is open at the moment.\")\n        return\n    pollID = polls[0][0]\n    answers = db.execute(\"SELECT answerID FROM answers WHERE pollID = ? AND 'index' = ?\", (pollID, answerIndex))\n    if len(answers) == 0:\n        reply(\"No item #%s found.\" % answerIndex)\n        return\n    answerID = answers[0][0]\n    db.execute(\"DELETE FROM votes WHERE nick = ? AND answerID IN (SELECT answerID FROM answers WHERE pollID = ?)\", (sender, pollID))\n    db.execute(\"INSERT INTO votes (answerID, nick) VALUES (?, ?)\", (answerID, sender))\n    reply(\"Vote registered.\")", "line_changes": {"deleted": [{"line_no": 10, "char_start": 319, "char_end": 435, "line": "    answers = db.execute(\"SELECT answerID FROM answers WHERE pollID = %s AND 'index' = %s\" % (pollID, answerIndex))\n"}, {"line_no": 15, "char_start": 555, "char_end": 690, "line": "    db.execute(\"DELETE FROM votes WHERE nick = %s AND answerID IN (SELECT answerID FROM answers WHERE pollID = %s)\", (sender, pollID))\n"}, {"line_no": 16, "char_start": 690, "char_end": 779, "line": "    db.execute(\"INSERT INTO votes (answerID, nick) VALUES (%s, %s)\", (answerID, sender))\n"}], "added": [{"line_no": 10, "char_start": 319, "char_end": 432, "line": "    answers = db.execute(\"SELECT answerID FROM answers WHERE pollID = ? AND 'index' = ?\", (pollID, answerIndex))\n"}, {"line_no": 15, "char_start": 552, "char_end": 685, "line": "    db.execute(\"DELETE FROM votes WHERE nick = ? AND answerID IN (SELECT answerID FROM answers WHERE pollID = ?)\", (sender, pollID))\n"}, {"line_no": 16, "char_start": 685, "char_end": 772, "line": "    db.execute(\"INSERT INTO votes (answerID, nick) VALUES (?, ?)\", (answerID, sender))\n"}]}, "char_changes": {"deleted": [{"char_start": 389, "char_end": 391, "chars": "%s"}, {"char_start": 406, "char_end": 411, "chars": "%s\" %"}, {"char_start": 602, "char_end": 604, "chars": "%s"}, {"char_start": 666, "char_end": 668, "chars": "%s"}, {"char_start": 749, "char_end": 755, "chars": "%s, %s"}], "added": [{"char_start": 389, "char_end": 390, "chars": "?"}, {"char_start": 405, "char_end": 408, "chars": "?\","}, {"char_start": 599, "char_end": 600, "chars": "?"}, {"char_start": 662, "char_end": 663, "chars": "?"}, {"char_start": 744, "char_end": 748, "chars": "?, ?"}]}, "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089"}
{"func_name": "voteNew", "func_src_before": "@hook.command\ndef voteNew(answer, reply=None, db=None):\n    \"\"\"Creates a new possible answer for the current poll and votes for it.\"\"\"\n    if not db_ready: db_init(db)\n    polls = db.execute(\"SELECT pollID FROM polls WHERE active = 1\")\n    if len(polls) == 0:\n        reply(\"No poll is open at the moment.\")\n        return\n    pollID = polls[0][0]\n    maxIndex = db.execute(\"SELECT MAX('index') FROM answers WHERE answers.pollID = %s\", pollID)[0][0]\n    if maxIndex == None:\n        index = 1\n    else:\n        index = maxIndex + 1\n    db.execute(\"INSERT INTO answers (pollID, 'index', answer) VALUES (%s, %s, %s)\", (pollID, index, answer))\n    answerID = db.execute(\"SELECT answerID FROM answers WHERE pollID = %s AND 'index' = %s\", (pollID, index))[0][0]\n    db.execute(\"DELETE FROM votes WHERE nick = %s AND answerID IN (SELECT answerID FROM answers WHERE pollID = %s)\", (sender, pollID))\n    db.execute(\"INSERT INTO votes (answerID, nick) VALUES (%s, %s)\", (answerID, sender))\n    reply(\"Vote added.\")", "func_src_after": "@hook.command\ndef voteNew(answer, reply=None, db=None):\n    \"\"\"Creates a new possible answer for the current poll and votes for it.\"\"\"\n    if not db_ready: db_init(db)\n    polls = db.execute(\"SELECT pollID FROM polls WHERE active = 1\")\n    if len(polls) == 0:\n        reply(\"No poll is open at the moment.\")\n        return\n    pollID = polls[0][0]\n    maxIndex = db.execute(\"SELECT MAX('index') FROM answers WHERE answers.pollID = ?\", (pollID,))[0][0]\n    if maxIndex == None:\n        index = 1\n    else:\n        index = maxIndex + 1\n    db.execute(\"INSERT INTO answers (pollID, 'index', answer) VALUES (?, ?, ?)\", (pollID, index, answer))\n    answerID = db.execute(\"SELECT answerID FROM answers WHERE pollID = ? AND 'index' = ?\", (pollID, index))[0][0]\n    db.execute(\"DELETE FROM votes WHERE nick = ? AND answerID IN (SELECT answerID FROM answers WHERE pollID = ?)\", (sender, pollID))\n    db.execute(\"INSERT INTO votes (answerID, nick) VALUES (?, ?)\", (answerID, sender))\n    reply(\"Vote added.\")", "line_changes": {"deleted": [{"line_no": 10, "char_start": 348, "char_end": 450, "line": "    maxIndex = db.execute(\"SELECT MAX('index') FROM answers WHERE answers.pollID = %s\", pollID)[0][0]\n"}, {"line_no": 15, "char_start": 532, "char_end": 641, "line": "    db.execute(\"INSERT INTO answers (pollID, 'index', answer) VALUES (%s, %s, %s)\", (pollID, index, answer))\n"}, {"line_no": 16, "char_start": 641, "char_end": 757, "line": "    answerID = db.execute(\"SELECT answerID FROM answers WHERE pollID = %s AND 'index' = %s\", (pollID, index))[0][0]\n"}, {"line_no": 17, "char_start": 757, "char_end": 892, "line": "    db.execute(\"DELETE FROM votes WHERE nick = %s AND answerID IN (SELECT answerID FROM answers WHERE pollID = %s)\", (sender, pollID))\n"}, {"line_no": 18, "char_start": 892, "char_end": 981, "line": "    db.execute(\"INSERT INTO votes (answerID, nick) VALUES (%s, %s)\", (answerID, sender))\n"}], "added": [{"line_no": 10, "char_start": 348, "char_end": 452, "line": "    maxIndex = db.execute(\"SELECT MAX('index') FROM answers WHERE answers.pollID = ?\", (pollID,))[0][0]\n"}, {"line_no": 15, "char_start": 534, "char_end": 640, "line": "    db.execute(\"INSERT INTO answers (pollID, 'index', answer) VALUES (?, ?, ?)\", (pollID, index, answer))\n"}, {"line_no": 16, "char_start": 640, "char_end": 754, "line": "    answerID = db.execute(\"SELECT answerID FROM answers WHERE pollID = ? AND 'index' = ?\", (pollID, index))[0][0]\n"}, {"line_no": 17, "char_start": 754, "char_end": 887, "line": "    db.execute(\"DELETE FROM votes WHERE nick = ? AND answerID IN (SELECT answerID FROM answers WHERE pollID = ?)\", (sender, pollID))\n"}, {"line_no": 18, "char_start": 887, "char_end": 974, "line": "    db.execute(\"INSERT INTO votes (answerID, nick) VALUES (?, ?)\", (answerID, sender))\n"}]}, "char_changes": {"deleted": [{"char_start": 431, "char_end": 433, "chars": "%s"}, {"char_start": 602, "char_end": 612, "chars": "%s, %s, %s"}, {"char_start": 712, "char_end": 714, "chars": "%s"}, {"char_start": 729, "char_end": 731, "chars": "%s"}, {"char_start": 804, "char_end": 806, "chars": "%s"}, {"char_start": 868, "char_end": 870, "chars": "%s"}, {"char_start": 951, "char_end": 957, "chars": "%s, %s"}], "added": [{"char_start": 431, "char_end": 432, "chars": "?"}, {"char_start": 435, "char_end": 436, "chars": "("}, {"char_start": 442, "char_end": 444, "chars": ",)"}, {"char_start": 604, "char_end": 611, "chars": "?, ?, ?"}, {"char_start": 711, "char_end": 712, "chars": "?"}, {"char_start": 727, "char_end": 728, "chars": "?"}, {"char_start": 801, "char_end": 802, "chars": "?"}, {"char_start": 864, "char_end": 865, "chars": "?"}, {"char_start": 946, "char_end": 950, "chars": "?, ?"}]}, "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089"}
{"func_name": "searchPoll", "func_src_before": "@hook.command\ndef searchPoll(searchTerm, reply=None, db=None):\n    \"\"\"Search polls matching a given search term.\"\"\"\n    if not db_ready: db_init(db)\n    polls = db.execute(\"SELECT pollID, question FROM polls WHERE question LIKE %s\", ('%' + searchTerm + '%',))\n    if len(polls) == 0:\n        reply(\"No polls found.\")\n        return\n    if len(polls) > 3:\n        reply(\"%s entries found, refine your search\" % len(polls))\n        return\n    for (pollID, question) in polls:\n        winners = db.execute(\"SELECT answer, count(voteID) FROM answers INNER JOIN votes ON votes.answerID = answers.answerID WHERE pollID = %s GROUP BY answers.answerID, answer ORDER BY count(voteID) DESC LIMIT 1\", (pollID, ))\n        if len(winners) == 0:\n            reply(\"%s. %s\" % (pollID, question))\n        else:\n            reply(\"%s. %s -- Winner: %s (%s)\" % (pollID, question, winners[0][0], winners[0][1]))", "func_src_after": "@hook.command\ndef searchPoll(searchTerm, reply=None, db=None):\n    \"\"\"Search polls matching a given search term.\"\"\"\n    if not db_ready: db_init(db)\n    polls = db.execute(\"SELECT pollID, question FROM polls WHERE question LIKE ?\", ('%' + searchTerm + '%',))\n    if len(polls) == 0:\n        reply(\"No polls found.\")\n        return\n    if len(polls) > 3:\n        reply(\"%s entries found, refine your search\" % len(polls))\n        return\n    for (pollID, question) in polls:\n        winners = db.execute(\"SELECT answer, count(voteID) FROM answers INNER JOIN votes ON votes.answerID = answers.answerID WHERE pollID = ? GROUP BY answers.answerID, answer ORDER BY count(voteID) DESC LIMIT 1\", (pollID, ))\n        if len(winners) == 0:\n            reply(\"%s. %s\" % (pollID, question))\n        else:\n            reply(\"%s. %s -- Winner: %s (%s)\" % (pollID, question, winners[0][0], winners[0][1]))", "line_changes": {"deleted": [{"line_no": 5, "char_start": 149, "char_end": 260, "line": "    polls = db.execute(\"SELECT pollID, question FROM polls WHERE question LIKE %s\", ('%' + searchTerm + '%',))\n"}, {"line_no": 13, "char_start": 474, "char_end": 702, "line": "        winners = db.execute(\"SELECT answer, count(voteID) FROM answers INNER JOIN votes ON votes.answerID = answers.answerID WHERE pollID = %s GROUP BY answers.answerID, answer ORDER BY count(voteID) DESC LIMIT 1\", (pollID, ))\n"}], "added": [{"line_no": 5, "char_start": 149, "char_end": 259, "line": "    polls = db.execute(\"SELECT pollID, question FROM polls WHERE question LIKE ?\", ('%' + searchTerm + '%',))\n"}, {"line_no": 13, "char_start": 473, "char_end": 700, "line": "        winners = db.execute(\"SELECT answer, count(voteID) FROM answers INNER JOIN votes ON votes.answerID = answers.answerID WHERE pollID = ? GROUP BY answers.answerID, answer ORDER BY count(voteID) DESC LIMIT 1\", (pollID, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 228, "char_end": 230, "chars": "%s"}, {"char_start": 615, "char_end": 617, "chars": "%s"}], "added": [{"char_start": 228, "char_end": 229, "chars": "?"}, {"char_start": 614, "char_end": 615, "chars": "?"}]}, "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089"}
{"func_name": "deletePoll", "func_src_before": "@hook.command(adminonly=True)\ndef deletePoll(pollID, reply=None, db=None):\n    \"\"\"Deletes a poll from the archives.\"\"\"\n    if not db_ready: db_init(db)\n    if len(db.execute(\"SELECT pollID FROM polls WHERE pollID = %s\", (pollID, ))) == 0:\n        reply(\"No such poll found\")\n    db.execute(\"DELETE FROM votes WHERE answerID IN (SELECT answerID FROM answers WHERE pollID = %s)\", (pollID, ))\n    db.execute(\"DELETE FROM answers WHERE pollID = %s\", (pollID, ))\n    db.execute(\"DELETE FROM polls WHERE pollID = %s\", (pollID, ))\n    reply(\"Poll deleted.\")", "func_src_after": "@hook.command(adminonly=True)\ndef deletePoll(pollID, reply=None, db=None):\n    \"\"\"Deletes a poll from the archives.\"\"\"\n    if not db_ready: db_init(db)\n    if len(db.execute(\"SELECT pollID FROM polls WHERE pollID = ?\", (pollID, ))) == 0:\n        reply(\"No such poll found\")\n    db.execute(\"DELETE FROM votes WHERE answerID IN (SELECT answerID FROM answers WHERE pollID = ?)\", (pollID, ))\n    db.execute(\"DELETE FROM answers WHERE pollID = ?\", (pollID, ))\n    db.execute(\"DELETE FROM polls WHERE pollID = ?\", (pollID, ))\n    reply(\"Poll deleted.\")", "line_changes": {"deleted": [{"line_no": 5, "char_start": 152, "char_end": 239, "line": "    if len(db.execute(\"SELECT pollID FROM polls WHERE pollID = %s\", (pollID, ))) == 0:\n"}, {"line_no": 7, "char_start": 275, "char_end": 390, "line": "    db.execute(\"DELETE FROM votes WHERE answerID IN (SELECT answerID FROM answers WHERE pollID = %s)\", (pollID, ))\n"}, {"line_no": 8, "char_start": 390, "char_end": 458, "line": "    db.execute(\"DELETE FROM answers WHERE pollID = %s\", (pollID, ))\n"}, {"line_no": 9, "char_start": 458, "char_end": 524, "line": "    db.execute(\"DELETE FROM polls WHERE pollID = %s\", (pollID, ))\n"}], "added": [{"line_no": 5, "char_start": 152, "char_end": 238, "line": "    if len(db.execute(\"SELECT pollID FROM polls WHERE pollID = ?\", (pollID, ))) == 0:\n"}, {"line_no": 7, "char_start": 274, "char_end": 388, "line": "    db.execute(\"DELETE FROM votes WHERE answerID IN (SELECT answerID FROM answers WHERE pollID = ?)\", (pollID, ))\n"}, {"line_no": 8, "char_start": 388, "char_end": 455, "line": "    db.execute(\"DELETE FROM answers WHERE pollID = ?\", (pollID, ))\n"}, {"line_no": 9, "char_start": 455, "char_end": 520, "line": "    db.execute(\"DELETE FROM polls WHERE pollID = ?\", (pollID, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 215, "char_end": 217, "chars": "%s"}, {"char_start": 372, "char_end": 374, "chars": "%s"}, {"char_start": 441, "char_end": 443, "chars": "%s"}, {"char_start": 507, "char_end": 509, "chars": "%s"}], "added": [{"char_start": 215, "char_end": 216, "chars": "?"}, {"char_start": 371, "char_end": 372, "chars": "?"}, {"char_start": 439, "char_end": 440, "chars": "?"}, {"char_start": 504, "char_end": 505, "chars": "?"}]}, "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089"}
{"func_name": "SaveDocumentCollection", "func_src_before": "def SaveDocumentCollection(dc, filenameedges, filenamedata):\n    try:\n        os.remove(filenameedges)\n    except:\n        pass\n    c = sqlite3.connect(filenameedges)\n    # Create table\n    c.execute('''CREATE TABLE IF NOT EXISTS edge (\n                    documentid text, \n                    documentclassname text, \n                    edgeclassname text, \n                    edgeid text PRIMARY KEY, \n                    startnode1id text, \n                    startnode2id text, \n                    endnodeid text, \n                    propertyownerid text, \n                    propertyname text, \n                    propertyvalue text, \n                    propertytype text\n                )''')\n    c.execute(\"DELETE FROM edge\")\n    for documentid in dc.objects:\n        documentlist = dc.objects[documentid]\n        for document in documentlist:\n            history = document.history\n            edge = history.edges[edgeid]\n            startnodes = list(edge.startnodes)\n            if len(edge.startnodes) == 1:\n                startnode1id = startnodes[0]\n                startnode2id = \"\"\n            elif len(edge.startnodes) == 2:\n                startnode1id = startnodes[0]\n                startnode2id = startnodes[1]\n            else:\n                assert False\n            \n            if edge.propertytype is None:\n                propertytypename = \"\"\n            else:\n                propertytypename = edge.propertytype.__name__\n            c.execute(\"INSERT INTO edge VALUES ('\" + document.id + \"', '\" + document.__class__.__name__ + \"', '\" + edge.__class__.__name__ + \"', '\" + edge.edgeid + \"', \" +\n                \"'\" + startnode1id + \"', '\" + startnode2id + \"', '\" + edge.endnode + \"', '\" + edge.propertyownerid + \"', '\" + edge.propertyname + \"', '\" + str(edge.propertyvalue) + \"', \"\n                \"'\" + propertytypename + \"')\")\n\n    c.commit()\n    c.close()\n\n    try:\n        os.remove(filenamedata)\n    except:\n        pass\n    database = sqlite3.connect(filenamedata)\n    foreignkeydict = defaultdict(list)\n    for classname in dc.classes:\n        theclass = dc.classes[classname]\n        variables = [a for a in dir(theclass) if not a.startswith('__') and not callable(getattr(theclass,a))]\n        for a in variables:\n            if isinstance(getattr(theclass, a), FieldList):\n                foreignkeydict[getattr(theclass, a).theclass.__name__].append((classname, a))\n    columndict = defaultdict(list)\n    for classname in dc.classes:\n        theclass = dc.classes[classname]\n        variables = [a for a in dir(theclass) if not a.startswith('__') and not callable(getattr(theclass,a))]\n        for a in variables:\n            if isinstance(getattr(theclass, a), FieldList) == False:\n                columndict[classname].append((a, \"int\" if isinstance(getattr(theclass, a), FieldInt) else \"text\"))\n    for k in foreignkeydict:\n        for (classname, a) in foreignkeydict[k]:\n            columndict[k].append((classname + \"id\", \"text\"))\n    for classname in columndict:\n        columnlist = columndict[classname]\n        sql = \"CREATE TABLE \" + classname + \" (id text \"\n        for (a, thetype) in columnlist:\n            sql += \",\"\n            sql += a + \" \" + thetype\n        sql += \")\"\n\n        database.execute(sql)\n    \n    for documentid in dc.objects:\n        SaveDocumentObject(database, dc.objects[documentid][0], None, foreignkeydict, columndict)\n\n    database.commit()", "func_src_after": "def SaveDocumentCollection(dc, filenameedges, filenamedata):\n    try:\n        os.remove(filenameedges)\n    except:\n        pass\n    c = sqlite3.connect(filenameedges)\n    # Create table\n    c.execute('''CREATE TABLE IF NOT EXISTS edge (\n                    documentid text, \n                    documentclassname text, \n                    edgeclassname text, \n                    edgeid text PRIMARY KEY, \n                    startnode1id text, \n                    startnode2id text, \n                    endnodeid text, \n                    propertyownerid text, \n                    propertyname text, \n                    propertyvalue text, \n                    propertytype text\n                )''')\n    c.execute(\"DELETE FROM edge\")\n    for documentid in dc.objects:\n        documentlist = dc.objects[documentid]\n        for document in documentlist:\n            history = document.history\n            edge = history.edges[edgeid]\n            startnodes = list(edge.startnodes)\n            if len(edge.startnodes) == 1:\n                startnode1id = startnodes[0]\n                startnode2id = \"\"\n            elif len(edge.startnodes) == 2:\n                startnode1id = startnodes[0]\n                startnode2id = startnodes[1]\n            else:\n                assert False\n            \n            if edge.propertytype is None:\n                propertytypename = \"\"\n            else:\n                propertytypename = edge.propertytype.__name__\n            c.execute(\"INSERT INTO edge VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", (document.id, document.__class__.__name__, \n                edge.__class__.__name__, edge.edgeid, startnode1id, startnode2id, edge.endnode, edge.propertyownerid, edge.propertyname,\n                edge.propertyvalue, propertytypename))\n            #c.execute(\"INSERT INTO edge VALUES ('\" + document.id + \"', '\" + document.__class__.__name__ + \"', '\" + edge.__class__.__name__ + \"', '\" + edge.edgeid + \"', \" +\n            #    \"'\" + startnode1id + \"', '\" + startnode2id + \"', '\" + edge.endnode + \"', '\" + edge.propertyownerid + \"', '\" + edge.propertyname + \"', '\" + str(edge.propertyvalue) + \"', \"\n            #    \"'\" + propertytypename + \"')\")\n\n    c.commit()\n    c.close()\n\n    try:\n        os.remove(filenamedata)\n    except:\n        pass\n    database = sqlite3.connect(filenamedata)\n    foreignkeydict = defaultdict(list)\n    for classname in dc.classes:\n        theclass = dc.classes[classname]\n        variables = [a for a in dir(theclass) if not a.startswith('__') and not callable(getattr(theclass,a))]\n        for a in variables:\n            if isinstance(getattr(theclass, a), FieldList):\n                foreignkeydict[getattr(theclass, a).theclass.__name__].append((classname, a))\n    columndict = defaultdict(list)\n    for classname in dc.classes:\n        theclass = dc.classes[classname]\n        variables = [a for a in dir(theclass) if not a.startswith('__') and not callable(getattr(theclass,a))]\n        for a in variables:\n            if isinstance(getattr(theclass, a), FieldList) == False:\n                columndict[classname].append((a, \"int\" if isinstance(getattr(theclass, a), FieldInt) else \"text\"))\n    for k in foreignkeydict:\n        for (classname, a) in foreignkeydict[k]:\n            columndict[k].append((classname + \"id\", \"text\"))\n    for classname in columndict:\n        columnlist = columndict[classname]\n        sql = \"CREATE TABLE \" + classname + \" (id text \"\n        for (a, thetype) in columnlist:\n            sql += \",\"\n            sql += a + \" \" + thetype\n        sql += \")\"\n\n        database.execute(sql)\n    \n    for documentid in dc.objects:\n        SaveDocumentObject(database, dc.objects[documentid][0], None, foreignkeydict, columndict)\n\n    database.commit()", "line_changes": {"deleted": [{"line_no": 41, "char_start": 1462, "char_end": 1634, "line": "            c.execute(\"INSERT INTO edge VALUES ('\" + document.id + \"', '\" + document.__class__.__name__ + \"', '\" + edge.__class__.__name__ + \"', '\" + edge.edgeid + \"', \" +\n"}, {"line_no": 42, "char_start": 1634, "char_end": 1821, "line": "                \"'\" + startnode1id + \"', '\" + startnode2id + \"', '\" + edge.endnode + \"', '\" + edge.propertyownerid + \"', '\" + edge.propertyname + \"', '\" + str(edge.propertyvalue) + \"', \"\n"}, {"line_no": 43, "char_start": 1821, "char_end": 1868, "line": "                \"'\" + propertytypename + \"')\")\n"}], "added": [{"line_no": 41, "char_start": 1462, "char_end": 1589, "line": "            c.execute(\"INSERT INTO edge VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", (document.id, document.__class__.__name__, \n"}, {"line_no": 42, "char_start": 1589, "char_end": 1726, "line": "                edge.__class__.__name__, edge.edgeid, startnode1id, startnode2id, edge.endnode, edge.propertyownerid, edge.propertyname,\n"}, {"line_no": 43, "char_start": 1726, "char_end": 1781, "line": "                edge.propertyvalue, propertytypename))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 1509, "char_end": 1829, "chars": "(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", (document.id, document.__class__.__name__, \n                edge.__class__.__name__, edge.edgeid, startnode1id, startnode2id, edge.endnode, edge.propertyownerid, edge.propertyname,\n                edge.propertyvalue, propertytypename))\n            #c.execute(\"INSERT INTO edge VALUES "}, {"char_start": 1966, "char_end": 1967, "chars": "#"}, {"char_start": 2154, "char_end": 2155, "chars": "#"}]}, "commit_link": "github.com/mlockett42/pypddemo/commit/dcd99aabcf811b3bc0e3bc12f214b04ab4d7fe4a", "file_name": "doop/DocumentCollectionHelper.py", "vul_type": "cwe-089"}
{"func_name": "SaveDocumentObject", "func_src_before": "def SaveDocumentObject(self, documentobject, parentobject, foreignkeydict, columndict):\n    variables = [a for a in dir(documentobject.__class__) if not a.startswith('__') and not callable(getattr(documentobject.__class__,a))]\n    for a in variables:\n        if isinstance(getattr(documentobject.__class__, a), FieldList):\n            for childobj in getattr(documentobject, a):\n                self.SaveDocumentObject(childobj, documentobject, foreignkeydict, columndict)\n    foreignkeyclassname = \"\"\n    if documentobject.__class__.__name__ in foreignkeydict:\n        if len(foreignkeydict[documentobject.__class__.__name__]) == 0:\n            pass #No foreign keys to worry about\n        elif len(foreignkeydict[documentobject.__class__.__name__]) == 1:\n            (foreignkeyclassname, a) = foreignkeydict[documentobject.__class__.__name__][0]\n        else:\n            assert False #Only one foreign key allowed\n    sql = \"INSERT INTO \" + documentobject.__class__.__name__ + \" VALUES ('\" + documentobject.id + \"'\"\n    for (columnname, columntype) in columndict[documentobject.__class__.__name__]:\n        if columntype == \"int\":\n            quote = \"\"\n        elif columntype == \"text\":\n            quote = \"'\"\n        else:\n            assert False\n            quote = \"\"\n        sql += \",\"\n        if foreignkeyclassname != \"\" and foreignkeyclassname + \"id\" == columnname:\n            sql += quote + parentobject.id + quote\n        else:\n            sql += quote + str(getattr(documentobject, columnname)) + quote\n    sql += \")\"\n    self.database.execute(sql)", "func_src_after": "def SaveDocumentObject(self, documentobject, parentobject, foreignkeydict, columndict):\n    variables = [a for a in dir(documentobject.__class__) if not a.startswith('__') and not callable(getattr(documentobject.__class__,a))]\n    for a in variables:\n        if isinstance(getattr(documentobject.__class__, a), FieldList):\n            for childobj in getattr(documentobject, a):\n                self.SaveDocumentObject(childobj, documentobject, foreignkeydict, columndict)\n    foreignkeyclassname = \"\"\n    if documentobject.__class__.__name__ in foreignkeydict:\n        if len(foreignkeydict[documentobject.__class__.__name__]) == 0:\n            pass #No foreign keys to worry about\n        elif len(foreignkeydict[documentobject.__class__.__name__]) == 1:\n            (foreignkeyclassname, a) = foreignkeydict[documentobject.__class__.__name__][0]\n        else:\n            assert False #Only one foreign key allowed\n    sql = \"INSERT INTO \" + documentobject.__class__.__name__ + \" VALUES (?\"\n    values = list()\n    for (columnname, columntype) in columndict[documentobject.__class__.__name__]:\n        sql += \",?\"\n        \n        if foreignkeyclassname != \"\" and foreignkeyclassname + \"id\" == columnname:\n            values.append(parentobject.id)\n        else:\n            values.append(getattr(documentobject, columnname))\n    sql += \")\"\n    self.database.execute(sql, tuple(values))", "line_changes": {"deleted": [{"line_no": 15, "char_start": 918, "char_end": 1020, "line": "    sql = \"INSERT INTO \" + documentobject.__class__.__name__ + \" VALUES ('\" + documentobject.id + \"'\"\n"}, {"line_no": 17, "char_start": 1103, "char_end": 1135, "line": "        if columntype == \"int\":\n"}, {"line_no": 18, "char_start": 1135, "char_end": 1158, "line": "            quote = \"\"\n"}, {"line_no": 19, "char_start": 1158, "char_end": 1193, "line": "        elif columntype == \"text\":\n"}, {"line_no": 20, "char_start": 1193, "char_end": 1217, "line": "            quote = \"'\"\n"}, {"line_no": 21, "char_start": 1217, "char_end": 1231, "line": "        else:\n"}, {"line_no": 22, "char_start": 1231, "char_end": 1256, "line": "            assert False\n"}, {"line_no": 23, "char_start": 1256, "char_end": 1279, "line": "            quote = \"\"\n"}, {"line_no": 24, "char_start": 1279, "char_end": 1298, "line": "        sql += \",\"\n"}, {"line_no": 26, "char_start": 1381, "char_end": 1432, "line": "            sql += quote + parentobject.id + quote\n"}, {"line_no": 28, "char_start": 1446, "char_end": 1522, "line": "            sql += quote + str(getattr(documentobject, columnname)) + quote\n"}, {"line_no": 30, "char_start": 1537, "char_end": 1567, "line": "    self.database.execute(sql)\n"}], "added": [{"line_no": 15, "char_start": 918, "char_end": 994, "line": "    sql = \"INSERT INTO \" + documentobject.__class__.__name__ + \" VALUES (?\"\n"}, {"line_no": 16, "char_start": 994, "char_end": 1014, "line": "    values = list()\n"}, {"line_no": 18, "char_start": 1097, "char_end": 1117, "line": "        sql += \",?\"\n"}, {"line_no": 19, "char_start": 1117, "char_end": 1126, "line": "        \n"}, {"line_no": 21, "char_start": 1209, "char_end": 1252, "line": "            values.append(parentobject.id)\n"}, {"line_no": 23, "char_start": 1266, "char_end": 1329, "line": "            values.append(getattr(documentobject, columnname))\n"}, {"line_no": 25, "char_start": 1344, "char_end": 1389, "line": "    self.database.execute(sql, tuple(values))\n"}]}, "char_changes": {"deleted": [{"char_start": 991, "char_end": 1019, "chars": "'\" + documentobject.id + \"'\""}, {"char_start": 1111, "char_end": 1274, "chars": "if columntype == \"int\":\n            quote = \"\"\n        elif columntype == \"text\":\n            quote = \"'\"\n        else:\n            assert False\n            quote "}, {"char_start": 1287, "char_end": 1297, "chars": "sql += \",\""}, {"char_start": 1393, "char_end": 1408, "chars": "sql += quote + "}, {"char_start": 1423, "char_end": 1431, "chars": " + quote"}, {"char_start": 1458, "char_end": 1476, "chars": "sql += quote + str"}, {"char_start": 1513, "char_end": 1521, "chars": " + quote"}], "added": [{"char_start": 991, "char_end": 1013, "chars": "?\"\n    values = list()"}, {"char_start": 1105, "char_end": 1125, "chars": "sql += \",?\"\n        "}, {"char_start": 1221, "char_end": 1235, "chars": "values.append("}, {"char_start": 1250, "char_end": 1251, "chars": ")"}, {"char_start": 1278, "char_end": 1291, "chars": "values.append"}, {"char_start": 1373, "char_end": 1388, "chars": ", tuple(values)"}]}, "commit_link": "github.com/mlockett42/pypddemo/commit/dcd99aabcf811b3bc0e3bc12f214b04ab4d7fe4a", "file_name": "doop/DocumentCollectionHelper.py", "vul_type": "cwe-089"}
{"func_name": "SaveEdges", "func_src_before": "def SaveEdges(dc, filenameedges, edges):\n    c = sqlite3.connect(filenameedges)\n    # Create table\n    for edge in edges:\n        startnodes = list(edge.startnodes)\n        if len(edge.startnodes) == 1:\n            startnode1id = startnodes[0]\n            startnode2id = \"\"\n        elif len(edge.startnodes) == 2:\n            startnode1id = startnodes[0]\n            startnode2id = startnodes[1]\n        else:\n            assert False\n        \n        if edge.propertytype is None:\n            propertytypename = \"\"\n        else:\n            propertytypename = edge.propertytype\n        #try:\n        if startnode1id == \"\":\n            global firstsavededgeid\n            if firstsavededgeid == \"\":\n                firstsavededgeid = edge.edgeid\n            global firstsaved\n            assert firstsaved == False or firstsavededgeid == edge.edgeid\n            firstsaved = True\n        c.execute(\"INSERT OR IGNORE INTO edge VALUES ('\" + edge.documentid + \"', '\" + edge.documentclassname + \"', '\" + edge.__class__.__name__ + \"', '\" + edge.edgeid + \"', \" +\n                \"'\" + startnode1id + \"', '\" + startnode2id + \"', '\" + edge.endnode + \"', '\" + edge.propertyownerid + \"', '\" + edge.propertyname + \"', '\" + str(edge.propertyvalue) + \"', \"\n                \"'\" + propertytypename + \"')\")\n    c.commit()\n    c.close()", "func_src_after": "def SaveEdges(dc, filenameedges, edges):\n    c = sqlite3.connect(filenameedges)\n    # Create table\n    for edge in edges:\n        startnodes = list(edge.startnodes)\n        if len(edge.startnodes) == 1:\n            startnode1id = startnodes[0]\n            startnode2id = \"\"\n        elif len(edge.startnodes) == 2:\n            startnode1id = startnodes[0]\n            startnode2id = startnodes[1]\n        else:\n            assert False\n        \n        if edge.propertytype is None:\n            propertytypename = \"\"\n        else:\n            propertytypename = edge.propertytype\n        #try:\n        if startnode1id == \"\":\n            global firstsavededgeid\n            if firstsavededgeid == \"\":\n                firstsavededgeid = edge.edgeid\n            global firstsaved\n            assert firstsaved == False or firstsavededgeid == edge.edgeid\n            firstsaved = True\n        c.execute(\"INSERT INTO edge VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", (edge.documentid , edge.documentclassname, \n            edge.__class__.__name__, edge.edgeid, startnode1id, startnode2id, edge.endnode, edge.propertyownerid, edge.propertyname,\n            edge.propertyvalue, propertytypename))\n        #c.execute(\"INSERT OR IGNORE INTO edge VALUES ('\" + edge.documentid + \"', '\" + edge.documentclassname + \"', '\" + edge.__class__.__name__ + \"', '\" + edge.edgeid + \"', \" +\n        #        \"'\" + startnode1id + \"', '\" + startnode2id + \"', '\" + edge.endnode + \"', '\" + edge.propertyownerid + \"', '\" + edge.propertyname + \"', '\" + str(edge.propertyvalue) + \"', \"\n        #        \"'\" + propertytypename + \"')\")\n    c.commit()\n    c.close()", "line_changes": {"deleted": [{"line_no": 27, "char_start": 880, "char_end": 1057, "line": "        c.execute(\"INSERT OR IGNORE INTO edge VALUES ('\" + edge.documentid + \"', '\" + edge.documentclassname + \"', '\" + edge.__class__.__name__ + \"', '\" + edge.edgeid + \"', \" +\n"}, {"line_no": 28, "char_start": 1057, "char_end": 1244, "line": "                \"'\" + startnode1id + \"', '\" + startnode2id + \"', '\" + edge.endnode + \"', '\" + edge.propertyownerid + \"', '\" + edge.propertyname + \"', '\" + str(edge.propertyvalue) + \"', \"\n"}, {"line_no": 29, "char_start": 1244, "char_end": 1291, "line": "                \"'\" + propertytypename + \"')\")\n"}], "added": [{"line_no": 27, "char_start": 880, "char_end": 1003, "line": "        c.execute(\"INSERT INTO edge VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", (edge.documentid , edge.documentclassname, \n"}, {"line_no": 28, "char_start": 1003, "char_end": 1136, "line": "            edge.__class__.__name__, edge.edgeid, startnode1id, startnode2id, edge.endnode, edge.propertyownerid, edge.propertyname,\n"}, {"line_no": 29, "char_start": 1136, "char_end": 1187, "line": "            edge.propertyvalue, propertytypename))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 906, "char_end": 1214, "chars": "INTO edge VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\", (edge.documentid , edge.documentclassname, \n            edge.__class__.__name__, edge.edgeid, startnode1id, startnode2id, edge.endnode, edge.propertyownerid, edge.propertyname,\n            edge.propertyvalue, propertytypename))\n        #c.execute(\"INSERT "}, {"char_start": 1373, "char_end": 1374, "chars": "#"}, {"char_start": 1561, "char_end": 1562, "chars": "#"}]}, "commit_link": "github.com/mlockett42/pypddemo/commit/dcd99aabcf811b3bc0e3bc12f214b04ab4d7fe4a", "file_name": "doop/DocumentCollectionHelper.py", "vul_type": "cwe-089"}
{"func_name": "SaveDocumentObject", "func_src_before": "def SaveDocumentObject(database, documentobject, parentobject, foreignkeydict, columndict):\n    variables = [a for a in dir(documentobject.__class__) if not a.startswith('__') and not callable(getattr(documentobject.__class__,a))]\n    for a in variables:\n        if isinstance(getattr(documentobject.__class__, a), FieldList):\n            for childobj in getattr(documentobject, a):\n                SaveDocumentObject(database, childobj, documentobject, foreignkeydict, columndict)\n    foreignkeyclassname = \"\"\n    if documentobject.__class__.__name__ in foreignkeydict:\n        if len(foreignkeydict[documentobject.__class__.__name__]) == 0:\n            pass #No foreign keys to worry about\n        elif len(foreignkeydict[documentobject.__class__.__name__]) == 1:\n            (foreignkeyclassname, a) = foreignkeydict[documentobject.__class__.__name__][0]\n        else:\n            assert False #Only one foreign key allowed\n    sql = \"INSERT INTO \" + documentobject.__class__.__name__ + \" VALUES ('\" + documentobject.id + \"'\"\n    for (columnname, columntype) in columndict[documentobject.__class__.__name__]:\n        if columntype == \"int\":\n            quote = \"\"\n        elif columntype == \"text\":\n            quote = \"'\"\n        else:\n            assert False\n            quote = \"\"\n        sql += \",\"\n        if foreignkeyclassname != \"\" and foreignkeyclassname + \"id\" == columnname:\n            sql += quote + parentobject.id + quote\n        else:\n            sql += quote + str(getattr(documentobject, columnname)) + quote\n    sql += \")\"\n    database.execute(sql)", "func_src_after": "def SaveDocumentObject(database, documentobject, parentobject, foreignkeydict, columndict):\n    variables = [a for a in dir(documentobject.__class__) if not a.startswith('__') and not callable(getattr(documentobject.__class__,a))]\n    for a in variables:\n        if isinstance(getattr(documentobject.__class__, a), FieldList):\n            for childobj in getattr(documentobject, a):\n                SaveDocumentObject(database, childobj, documentobject, foreignkeydict, columndict)\n    foreignkeyclassname = \"\"\n    if documentobject.__class__.__name__ in foreignkeydict:\n        if len(foreignkeydict[documentobject.__class__.__name__]) == 0:\n            pass #No foreign keys to worry about\n        elif len(foreignkeydict[documentobject.__class__.__name__]) == 1:\n            (foreignkeyclassname, a) = foreignkeydict[documentobject.__class__.__name__][0]\n        else:\n            assert False #Only one foreign key allowed\n    sql = \"INSERT INTO \" + documentobject.__class__.__name__ + \" VALUES ('\" + documentobject.id + \"'\"\n    sql = \"INSERT INTO \" + documentobject.__class__.__name__ + \" VALUES (?\"\n    values = list()\n    for (columnname, columntype) in columndict[documentobject.__class__.__name__]:\n        sql += \",?\"\n        \n        if foreignkeyclassname != \"\" and foreignkeyclassname + \"id\" == columnname:\n            values.append(parentobject.id)\n        else:\n            values.append(getattr(documentobject, columnname))\n    sql += \")\"\n    self.database.execute(sql, tuple(values))", "line_changes": {"deleted": [{"line_no": 17, "char_start": 1112, "char_end": 1144, "line": "        if columntype == \"int\":\n"}, {"line_no": 18, "char_start": 1144, "char_end": 1167, "line": "            quote = \"\"\n"}, {"line_no": 19, "char_start": 1167, "char_end": 1202, "line": "        elif columntype == \"text\":\n"}, {"line_no": 20, "char_start": 1202, "char_end": 1226, "line": "            quote = \"'\"\n"}, {"line_no": 21, "char_start": 1226, "char_end": 1240, "line": "        else:\n"}, {"line_no": 22, "char_start": 1240, "char_end": 1265, "line": "            assert False\n"}, {"line_no": 23, "char_start": 1265, "char_end": 1288, "line": "            quote = \"\"\n"}, {"line_no": 24, "char_start": 1288, "char_end": 1307, "line": "        sql += \",\"\n"}, {"line_no": 26, "char_start": 1390, "char_end": 1441, "line": "            sql += quote + parentobject.id + quote\n"}, {"line_no": 28, "char_start": 1455, "char_end": 1531, "line": "            sql += quote + str(getattr(documentobject, columnname)) + quote\n"}, {"line_no": 30, "char_start": 1546, "char_end": 1571, "line": "    database.execute(sql)\n"}], "added": [{"line_no": 16, "char_start": 1029, "char_end": 1105, "line": "    sql = \"INSERT INTO \" + documentobject.__class__.__name__ + \" VALUES (?\"\n"}, {"line_no": 17, "char_start": 1105, "char_end": 1125, "line": "    values = list()\n"}, {"line_no": 19, "char_start": 1208, "char_end": 1228, "line": "        sql += \",?\"\n"}, {"line_no": 20, "char_start": 1228, "char_end": 1237, "line": "        \n"}, {"line_no": 22, "char_start": 1320, "char_end": 1363, "line": "            values.append(parentobject.id)\n"}, {"line_no": 24, "char_start": 1377, "char_end": 1440, "line": "            values.append(getattr(documentobject, columnname))\n"}, {"line_no": 26, "char_start": 1455, "char_end": 1500, "line": "    self.database.execute(sql, tuple(values))\n"}]}, "char_changes": {"deleted": [{"char_start": 1033, "char_end": 1283, "chars": "for (columnname, columntype) in columndict[documentobject.__class__.__name__]:\n        if columntype == \"int\":\n            quote = \"\"\n        elif columntype == \"text\":\n            quote = \"'\"\n        else:\n            assert False\n            quote "}, {"char_start": 1296, "char_end": 1306, "chars": "sql += \",\""}, {"char_start": 1402, "char_end": 1417, "chars": "sql += quote + "}, {"char_start": 1432, "char_end": 1440, "chars": " + quote"}, {"char_start": 1467, "char_end": 1485, "chars": "sql += quote + str"}, {"char_start": 1522, "char_end": 1530, "chars": " + quote"}], "added": [{"char_start": 1033, "char_end": 1221, "chars": "sql = \"INSERT INTO \" + documentobject.__class__.__name__ + \" VALUES (?\"\n    values = list()\n    for (columnname, columntype) in columndict[documentobject.__class__.__name__]:\n        sql +"}, {"char_start": 1224, "char_end": 1226, "chars": ",?"}, {"char_start": 1332, "char_end": 1346, "chars": "values.append("}, {"char_start": 1361, "char_end": 1362, "chars": ")"}, {"char_start": 1389, "char_end": 1402, "chars": "values.append"}, {"char_start": 1459, "char_end": 1464, "chars": "self."}, {"char_start": 1484, "char_end": 1499, "chars": ", tuple(values)"}]}, "commit_link": "github.com/mlockett42/pypddemo/commit/dcd99aabcf811b3bc0e3bc12f214b04ab4d7fe4a", "file_name": "doop/DocumentCollectionHelper.py", "vul_type": "cwe-089"}
{"func_name": "get_player", "func_src_before": "def get_player(username):\n\tdb = MySQLdb.connect(HOST_NAME, USER_NAME, USER_PASS, TABL_NAME)\n\tc = db.cursor()\n\tc.execute(\"SELECT * FROM Player WHERE Username = \\\"\" + username + \"\\\"\")\n\tresult = c.fetchone()\n\tdb.close()\n\treturn result", "func_src_after": "def get_player(username):\n\tdb = db_connect()\n\tc = db.cursor()\n\tc.execute(\"SELECT * FROM Player WHERE Username=?\", username)\n\tresult = c.fetchone()\n\tdb.close()\n\treturn result", "line_changes": {"deleted": [{"line_no": 2, "char_start": 26, "char_end": 92, "line": "\tdb = MySQLdb.connect(HOST_NAME, USER_NAME, USER_PASS, TABL_NAME)\n"}, {"line_no": 4, "char_start": 109, "char_end": 182, "line": "\tc.execute(\"SELECT * FROM Player WHERE Username = \\\"\" + username + \"\\\"\")\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 45, "line": "\tdb = db_connect()\n"}, {"line_no": 4, "char_start": 62, "char_end": 124, "line": "\tc.execute(\"SELECT * FROM Player WHERE Username=?\", username)\n"}]}, "char_changes": {"deleted": [{"char_start": 32, "char_end": 37, "chars": "MySQL"}, {"char_start": 39, "char_end": 40, "chars": "."}, {"char_start": 48, "char_end": 90, "chars": "HOST_NAME, USER_NAME, USER_PASS, TABL_NAME"}, {"char_start": 156, "char_end": 164, "chars": " = \\\"\" +"}, {"char_start": 173, "char_end": 180, "chars": " + \"\\\"\""}], "added": [{"char_start": 34, "char_end": 35, "chars": "_"}, {"char_start": 109, "char_end": 113, "chars": "=?\","}]}, "commit_link": "github.com/steve2/COMP4350/commit/8f1596ec03bd7442a6bfaef69374e1538d6d9b1d", "file_name": "Server/backend/database.py", "vul_type": "cwe-089"}
{"func_name": "check", "func_src_before": "def check(current_num):\n    try:\n        cursor.execute('SELECT * FROM comics WHERE num=\"%s\"' % current_num)\n    except sqlite3.OperationalError:\n        cursor.execute('CREATE TABLE comics (num text)')\n        return False\n    else:\n        return False if cursor.fetchone() is None else True", "func_src_after": "def check(current_num):\n    try:\n        cursor.execute('SELECT * FROM comics WHERE num=?', (current_num,))\n    except sqlite3.OperationalError:\n        cursor.execute('CREATE TABLE comics (num text)')\n        return False\n    else:\n        return False if cursor.fetchone() is None else True", "line_changes": {"deleted": [{"line_no": 3, "char_start": 33, "char_end": 109, "line": "        cursor.execute('SELECT * FROM comics WHERE num=\"%s\"' % current_num)\n"}], "added": [{"line_no": 3, "char_start": 33, "char_end": 108, "line": "        cursor.execute('SELECT * FROM comics WHERE num=?', (current_num,))\n"}]}, "char_changes": {"deleted": [{"char_start": 88, "char_end": 96, "chars": "\"%s\"' % "}], "added": [{"char_start": 88, "char_end": 93, "chars": "?', ("}, {"char_start": 104, "char_end": 106, "chars": ",)"}]}, "commit_link": "github.com/lord63/a_bunch_of_code/commit/c0d67a1312306fd1257c354bfb5d6cac7643aa29", "file_name": "comics/check_comics.py", "vul_type": "cwe-089"}
{"func_name": "fetch_data", "func_src_before": "    def fetch_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            data = res.dictresult()[0]['data']\n        except IndexError:\n            raise ObjectDoesNotExistException(id)\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000\\\\001', nonTextToken)\n        ndata = ndata.replace('\\\\012', '\\n')\n        return ndata", "func_src_after": "    def fetch_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            data = res.dictresult()[0]['data']\n        except IndexError:\n            raise ObjectDoesNotExistException(id)\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000\\\\001', nonTextToken)\n        ndata = ndata.replace('\\\\012', '\\n')\n        return ndata", "line_changes": {"deleted": [{"line_no": 6, "char_start": 207, "char_end": 273, "line": "        query = (\"SELECT data FROM %s WHERE identifier = '%s';\" %\n"}, {"line_no": 7, "char_start": 273, "char_end": 308, "line": "                 (self.table, sid)\n"}, {"line_no": 9, "char_start": 327, "char_end": 360, "line": "        res = self._query(query)\n"}], "added": [{"line_no": 6, "char_start": 207, "char_end": 271, "line": "        query = (\"SELECT data FROM %s WHERE identifier = $1;\" %\n"}, {"line_no": 7, "char_start": 271, "char_end": 301, "line": "                 (self.table)\n"}, {"line_no": 9, "char_start": 320, "char_end": 358, "line": "        res = self._query(query, sid)\n"}]}, "char_changes": {"deleted": [{"char_start": 264, "char_end": 268, "chars": "'%s'"}, {"char_start": 301, "char_end": 306, "chars": ", sid"}], "added": [{"char_start": 264, "char_end": 266, "chars": "$1"}, {"char_start": 351, "char_end": 356, "chars": ", sid"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089"}
{"func_name": "delete_data", "func_src_before": "    def delete_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, str(id))\n        query = \"DELETE FROM %s WHERE identifier = '%s';\" % (self.table, sid)\n        self._query(query)\n        return None", "func_src_after": "    def delete_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, str(id))\n        query = \"DELETE FROM %s WHERE identifier = $1;\" % (self.table)\n        self._query(query, sid)\n        return None", "line_changes": {"deleted": [{"line_no": 6, "char_start": 212, "char_end": 290, "line": "        query = \"DELETE FROM %s WHERE identifier = '%s';\" % (self.table, sid)\n"}, {"line_no": 7, "char_start": 290, "char_end": 317, "line": "        self._query(query)\n"}], "added": [{"line_no": 6, "char_start": 212, "char_end": 283, "line": "        query = \"DELETE FROM %s WHERE identifier = $1;\" % (self.table)\n"}, {"line_no": 7, "char_start": 283, "char_end": 315, "line": "        self._query(query, sid)\n"}]}, "char_changes": {"deleted": [{"char_start": 263, "char_end": 267, "chars": "'%s'"}, {"char_start": 283, "char_end": 288, "chars": ", sid"}], "added": [{"char_start": 263, "char_end": 265, "chars": "$1"}, {"char_start": 308, "char_end": 313, "chars": ", sid"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089"}
{"func_name": "fetch_metadata", "func_src_before": "    def fetch_metadata(self, session, id, mType):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"SELECT %s FROM %s WHERE identifier = '%s';\" %\n                 (mType, self.table, id)\n                 )\n        res = self._query(query)\n        try:\n            data = res.dictresult()[0][mtype]\n        except:\n            if mtype.endswith((\"Count\", \"Position\", \"Amount\", \"Offset\")):\n                return 0\n            return None\n        return data", "func_src_after": "    def fetch_metadata(self, session, id, mType):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"SELECT %s FROM %s WHERE identifier = $1;\" %\n                 (mType, self.table)\n                 )\n        res = self._query(query, id)\n        try:\n            data = res.dictresult()[0][mType]\n        except:\n            if mType.endswith((\"Count\", \"Position\", \"Amount\", \"Offset\")):\n                return 0\n            return None\n        return data", "line_changes": {"deleted": [{"line_no": 9, "char_start": 303, "char_end": 367, "line": "        query = (\"SELECT %s FROM %s WHERE identifier = '%s';\" %\n"}, {"line_no": 10, "char_start": 367, "char_end": 408, "line": "                 (mType, self.table, id)\n"}, {"line_no": 12, "char_start": 427, "char_end": 460, "line": "        res = self._query(query)\n"}, {"line_no": 14, "char_start": 473, "char_end": 519, "line": "            data = res.dictresult()[0][mtype]\n"}, {"line_no": 16, "char_start": 535, "char_end": 609, "line": "            if mtype.endswith((\"Count\", \"Position\", \"Amount\", \"Offset\")):\n"}], "added": [{"line_no": 9, "char_start": 303, "char_end": 365, "line": "        query = (\"SELECT %s FROM %s WHERE identifier = $1;\" %\n"}, {"line_no": 10, "char_start": 365, "char_end": 402, "line": "                 (mType, self.table)\n"}, {"line_no": 12, "char_start": 421, "char_end": 458, "line": "        res = self._query(query, id)\n"}, {"line_no": 14, "char_start": 471, "char_end": 517, "line": "            data = res.dictresult()[0][mType]\n"}, {"line_no": 16, "char_start": 533, "char_end": 607, "line": "            if mType.endswith((\"Count\", \"Position\", \"Amount\", \"Offset\")):\n"}]}, "char_changes": {"deleted": [{"char_start": 358, "char_end": 362, "chars": "'%s'"}, {"char_start": 402, "char_end": 406, "chars": ", id"}, {"char_start": 513, "char_end": 514, "chars": "t"}, {"char_start": 551, "char_end": 552, "chars": "t"}], "added": [{"char_start": 358, "char_end": 360, "chars": "$1"}, {"char_start": 452, "char_end": 456, "chars": ", id"}, {"char_start": 511, "char_end": 512, "chars": "T"}, {"char_start": 549, "char_end": 550, "chars": "T"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089"}
{"func_name": "store_metadata", "func_src_before": "    def store_metadata(self, session, key, mType, value):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"UPDATE %s SET %s = %r WHERE identifier = '%s';\" %\n                 (self.table, mType, value, id)\n                 )\n        try:\n            self._query(query)\n        except:\n            return None\n        return value", "func_src_after": "    def store_metadata(self, session, key, mType, value):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"UPDATE %s SET %s = $1 WHERE identifier = $2;\" %\n                 (self.table, mType)\n                 )\n        args = (value, id)\n        try:\n            self._query(query, *args)\n        except:\n            return None\n        return value", "line_changes": {"deleted": [{"line_no": 9, "char_start": 311, "char_end": 379, "line": "        query = (\"UPDATE %s SET %s = %r WHERE identifier = '%s';\" %\n"}, {"line_no": 10, "char_start": 379, "char_end": 427, "line": "                 (self.table, mType, value, id)\n"}, {"line_no": 13, "char_start": 459, "char_end": 490, "line": "            self._query(query)\n"}], "added": [{"line_no": 9, "char_start": 311, "char_end": 377, "line": "        query = (\"UPDATE %s SET %s = $1 WHERE identifier = $2;\" %\n"}, {"line_no": 10, "char_start": 377, "char_end": 414, "line": "                 (self.table, mType)\n"}, {"line_no": 12, "char_start": 433, "char_end": 460, "line": "        args = (value, id)\n"}, {"line_no": 14, "char_start": 473, "char_end": 511, "line": "            self._query(query, *args)\n"}]}, "char_changes": {"deleted": [{"char_start": 348, "char_end": 350, "chars": "%r"}, {"char_start": 370, "char_end": 374, "chars": "'%s'"}, {"char_start": 414, "char_end": 425, "chars": ", value, id"}], "added": [{"char_start": 348, "char_end": 350, "chars": "$1"}, {"char_start": 370, "char_end": 372, "chars": "$2"}, {"char_start": 433, "char_end": 460, "chars": "        args = (value, id)\n"}, {"char_start": 502, "char_end": 509, "chars": ", *args"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089"}
{"func_name": "clean", "func_src_before": "    def clean(self, session):\n        # here is where sql is nice...\n        self._openContainer(session)\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(time.time()))\n        query = \"DELETE FROM %s WHERE expires < '%s';\" % (self.table, nowStr)\n        self._query(query)", "func_src_after": "    def clean(self, session):\n        # here is where sql is nice...\n        self._openContainer(session)\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(time.time()))\n        query = \"DELETE FROM %s WHERE expires < $1;\" % (self.table)\n        self._query(query, nowStr)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 184, "char_end": 262, "line": "        query = \"DELETE FROM %s WHERE expires < '%s';\" % (self.table, nowStr)\n"}, {"line_no": 6, "char_start": 262, "char_end": 288, "line": "        self._query(query)\n"}], "added": [{"line_no": 5, "char_start": 184, "char_end": 252, "line": "        query = \"DELETE FROM %s WHERE expires < $1;\" % (self.table)\n"}, {"line_no": 6, "char_start": 252, "char_end": 286, "line": "        self._query(query, nowStr)\n"}]}, "char_changes": {"deleted": [{"char_start": 232, "char_end": 236, "chars": "'%s'"}, {"char_start": 252, "char_end": 260, "chars": ", nowStr"}], "added": [{"char_start": 232, "char_end": 234, "chars": "$1"}, {"char_start": 277, "char_end": 285, "chars": ", nowStr"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089"}
{"func_name": "link", "func_src_before": "    def link(self, session, relation, *args, **kw):\n        \"\"\"Create a new row in the named relation.\n\n        NOT API\n        \"\"\"\n        fields = []\n        values = []\n        for obj in args:\n            #fields.append(obj.recordStore)\n            # Allows to link for objects other than Records\n            fields.append(self.table)\n            oid = obj.id\n            if (self.idNormalizer):\n                oid = self.idNormalizer.process_string(session, oid)\n            values.append(repr(oid))\n        for (name, value) in kw.iteritems():\n            fields.append(name)\n            if isinstance(value, basestring) and value.find(\"'\") > -1:\n                values.append(\"'{0}'\".format(value.replace(\"'\", r\"\\'\")))\n            else:\n                values.append(repr(value))\n\n        query = (\"INSERT INTO %s_%s (%s) VALUES (%s);\" %\n                 (self.table, relation, ', '.join(fields), ', '.join(values))\n                 )\n        self._query(query)", "func_src_after": "    def link(self, session, relation, *args, **kw):\n        \"\"\"Create a new row in the named relation.\n\n        NOT API\n        \"\"\"\n        fields = []\n        values = []\n        for obj in args:\n            #fields.append(obj.recordStore)\n            # Allows to link for objects other than Records\n            fields.append(self.table)\n            oid = obj.id\n            if (self.idNormalizer):\n                oid = self.idNormalizer.process_string(session, oid)\n            values.append(oid)\n        for (name, value) in kw.iteritems():\n            fields.append(name)\n            values.append(value)\n\n        valuemarkers = [\"${0}\".format(i + 1) for i in range(len(values))]\n        query = (\"INSERT INTO %s_%s (%s) VALUES (%s);\" %\n                 (self.table,\n                  relation,\n                  ', '.join(fields),\n                  ', '.join(valuemarkers)\n                  )\n                 )\n        self._query(query, *values)", "line_changes": {"deleted": [{"line_no": 15, "char_start": 469, "char_end": 506, "line": "            values.append(repr(oid))\n"}, {"line_no": 18, "char_start": 583, "char_end": 654, "line": "            if isinstance(value, basestring) and value.find(\"'\") > -1:\n"}, {"line_no": 19, "char_start": 654, "char_end": 727, "line": "                values.append(\"'{0}'\".format(value.replace(\"'\", r\"\\'\")))\n"}, {"line_no": 20, "char_start": 727, "char_end": 745, "line": "            else:\n"}, {"line_no": 21, "char_start": 745, "char_end": 788, "line": "                values.append(repr(value))\n"}, {"line_no": 24, "char_start": 846, "char_end": 924, "line": "                 (self.table, relation, ', '.join(fields), ', '.join(values))\n"}, {"line_no": 26, "char_start": 943, "char_end": 969, "line": "        self._query(query)\n"}], "added": [{"line_no": 15, "char_start": 469, "char_end": 500, "line": "            values.append(oid)\n"}, {"line_no": 18, "char_start": 577, "char_end": 610, "line": "            values.append(value)\n"}, {"line_no": 20, "char_start": 611, "char_end": 685, "line": "        valuemarkers = [\"${0}\".format(i + 1) for i in range(len(values))]\n"}, {"line_no": 22, "char_start": 742, "char_end": 772, "line": "                 (self.table,\n"}, {"line_no": 23, "char_start": 772, "char_end": 800, "line": "                  relation,\n"}, {"line_no": 24, "char_start": 800, "char_end": 837, "line": "                  ', '.join(fields),\n"}, {"line_no": 25, "char_start": 837, "char_end": 879, "line": "                  ', '.join(valuemarkers)\n"}, {"line_no": 26, "char_start": 879, "char_end": 899, "line": "                  )\n"}, {"line_no": 28, "char_start": 918, "char_end": 953, "line": "        self._query(query, *values)\n"}]}, "char_changes": {"deleted": [{"char_start": 495, "char_end": 500, "chars": "repr("}, {"char_start": 504, "char_end": 505, "chars": ")"}, {"char_start": 595, "char_end": 629, "chars": "if isinstance(value, basestring) a"}, {"char_start": 631, "char_end": 632, "chars": " "}, {"char_start": 637, "char_end": 661, "chars": ".find(\"'\") > -1:\n       "}, {"char_start": 669, "char_end": 670, "chars": " "}, {"char_start": 675, "char_end": 686, "chars": "s.append(\"'"}, {"char_start": 689, "char_end": 690, "chars": "'"}, {"char_start": 699, "char_end": 779, "chars": "value.replace(\"'\", r\"\\'\")))\n            else:\n                values.append(repr"}, {"char_start": 787, "char_end": 788, "chars": "\n"}, {"char_start": 875, "char_end": 922, "chars": " relation, ', '.join(fields), ', '.join(values)"}], "added": [{"char_start": 589, "char_end": 600, "chars": "values.appe"}, {"char_start": 602, "char_end": 603, "chars": "("}, {"char_start": 608, "char_end": 637, "chars": ")\n\n        valuemarkers = [\"$"}, {"char_start": 649, "char_end": 674, "chars": "i + 1) for i in range(len"}, {"char_start": 680, "char_end": 681, "chars": "s"}, {"char_start": 683, "char_end": 684, "chars": "]"}, {"char_start": 771, "char_end": 897, "chars": "\n                  relation,\n                  ', '.join(fields),\n                  ', '.join(valuemarkers)\n                  "}, {"char_start": 943, "char_end": 952, "chars": ", *values"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089"}
{"func_name": "unlink", "func_src_before": "    def unlink(self, session, relation, *args, **kw):\n        \"\"\"Remove a row in the named relation.\n\n        NOT API\n        \"\"\"\n        conds = []\n        for obj in args:\n            oid = obj.id\n            if (self.idNormalizer):\n                oid = self.idNormalizer.process_string(session, oid)\n            #cond += (\"%s = %r, \" % (obj.recordStore, oid))\n            # Allows to unlink for objects other than Records\n            conds.append(\"%s = %r\" % (self.table, oid))\n        for (name, value) in kw.iteritems():\n            conds.append(\"%s = %r\" % (name, value))\n        query = (\"DELETE FROM %s_%s WHERE %s;\" %\n                 (self.table, relation, ' AND '.join(conds))\n                 )\n        self._query(query)", "func_src_after": "    def unlink(self, session, relation, *args, **kw):\n        \"\"\"Remove a row in the named relation.\n\n        NOT API\n        \"\"\"\n        condvals = []\n        conds = []\n        for obj in args:\n            oid = obj.id\n            if (self.idNormalizer):\n                oid = self.idNormalizer.process_string(session, oid)\n            #cond += (\"%s = %r, \" % (obj.recordStore, oid))\n            # Allows to unlink for objects other than Records\n            condvals.append(oid)\n            conds.append(\"%s = $%d\" % (self.table, len(condvals)))\n\n        for (name, value) in kw.iteritems():\n            condvals.append(value)\n            conds.append(\"%s = $%d\" % (name, len(condvals)))\n        query = (\"DELETE FROM %s_%s WHERE %s;\" %\n                 (self.table, relation, ' AND '.join(conds))\n                 )\n        self._query(query, *condvals)", "line_changes": {"deleted": [{"line_no": 13, "char_start": 426, "char_end": 482, "line": "            conds.append(\"%s = %r\" % (self.table, oid))\n"}, {"line_no": 15, "char_start": 527, "char_end": 579, "line": "            conds.append(\"%s = %r\" % (name, value))\n"}, {"line_no": 19, "char_start": 708, "char_end": 734, "line": "        self._query(query)\n"}], "added": [{"line_no": 6, "char_start": 130, "char_end": 152, "line": "        condvals = []\n"}, {"line_no": 14, "char_start": 448, "char_end": 481, "line": "            condvals.append(oid)\n"}, {"line_no": 15, "char_start": 481, "char_end": 548, "line": "            conds.append(\"%s = $%d\" % (self.table, len(condvals)))\n"}, {"line_no": 16, "char_start": 548, "char_end": 549, "line": "\n"}, {"line_no": 18, "char_start": 594, "char_end": 629, "line": "            condvals.append(value)\n"}, {"line_no": 19, "char_start": 629, "char_end": 690, "line": "            conds.append(\"%s = $%d\" % (name, len(condvals)))\n"}, {"line_no": 23, "char_start": 819, "char_end": 856, "line": "        self._query(query, *condvals)\n"}]}, "char_changes": {"deleted": [{"char_start": 457, "char_end": 459, "chars": "%r"}, {"char_start": 476, "char_end": 481, "chars": "oid))"}, {"char_start": 558, "char_end": 560, "chars": "%r"}, {"char_start": 574, "char_end": 576, "chars": "ue"}], "added": [{"char_start": 130, "char_end": 152, "chars": "        condvals = []\n"}, {"char_start": 448, "char_end": 481, "chars": "            condvals.append(oid)\n"}, {"char_start": 512, "char_end": 515, "chars": "$%d"}, {"char_start": 532, "char_end": 548, "chars": "len(condvals)))\n"}, {"char_start": 594, "char_end": 629, "chars": "            condvals.append(value)\n"}, {"char_start": 660, "char_end": 663, "chars": "$%d"}, {"char_start": 674, "char_end": 682, "chars": "len(cond"}, {"char_start": 685, "char_end": 687, "chars": "s)"}, {"char_start": 844, "char_end": 855, "chars": ", *condvals"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089"}
{"func_name": "get_links", "func_src_before": "    def get_links(self, session, relation, *args, **kw):\n        \"\"\"Get linked rows in the named relation.\n\n        NOT API\n        \"\"\"\n        conds = []\n        for obj in args:\n            oid = obj.id\n            if (self.idNormalizer):\n                oid = self.idNormalizer.process_string(session, oid)\n            #cond += (\"%s = %r, \" % (obj.recordStore, oid))\n            # Allows get_links for objects other than Records\n            conds.append(\"%s = %r\" % (self.table, oid))\n        for (name, value) in kw.iteritems():\n            conds.append(\"%s = %r\" % (name, value))\n        query = (\"SELECT * FROM %s_%s WHERE %s;\" %\n                 (self.table, relation, ', '.join(conds))\n                 )\n        res = self._query(query)\n\n        links = []\n        reln = self.relations[relation]\n        for row in res.getresult():\n            link = []\n            linkHash = {}\n            for i in range(len(row)):\n                name = reln[i - 1][0]\n                if (reln[i - 1][2]):\n                    link.append(SimpleResultSetItem(session, row[i], name))\n                else:\n                    linkHash[name] = row[i]\n\n            links.append((link, linkHash))\n        return links", "func_src_after": "    def get_links(self, session, relation, *args, **kw):\n        \"\"\"Get linked rows in the named relation.\n\n        NOT API\n        \"\"\"\n        condvals = []\n        conds = []\n        for obj in args:\n            oid = obj.id\n            if (self.idNormalizer):\n                oid = self.idNormalizer.process_string(session, oid)\n            #cond += (\"%s = %r, \" % (obj.recordStore, oid))\n            # Allows get_links for objects other than Records\n            condvals.append(oid)\n            conds.append(\"%s = $%d\" % (self.table, len(condvals)))\n\n        for (name, value) in kw.iteritems():\n            condvals.append(value)\n            conds.append(\"%s = $%d\" % (name, len(condvals)))\n        query = (\"SELECT * FROM %s_%s WHERE %s;\" %\n                 (self.table, relation, ', '.join(conds))\n                 )\n        res = self._query(query, *condvals)\n\n        links = []\n        reln = self.relations[relation]\n        for row in res.getresult():\n            link = []\n            linkHash = {}\n            for i in range(len(row)):\n                name = reln[i - 1][0]\n                if (reln[i - 1][2]):\n                    link.append(SimpleResultSetItem(session, row[i], name))\n                else:\n                    linkHash[name] = row[i]\n\n            links.append((link, linkHash))\n        return links", "line_changes": {"deleted": [{"line_no": 13, "char_start": 432, "char_end": 488, "line": "            conds.append(\"%s = %r\" % (self.table, oid))\n"}, {"line_no": 15, "char_start": 533, "char_end": 585, "line": "            conds.append(\"%s = %r\" % (name, value))\n"}, {"line_no": 19, "char_start": 713, "char_end": 746, "line": "        res = self._query(query)\n"}], "added": [{"line_no": 6, "char_start": 136, "char_end": 158, "line": "        condvals = []\n"}, {"line_no": 14, "char_start": 454, "char_end": 487, "line": "            condvals.append(oid)\n"}, {"line_no": 15, "char_start": 487, "char_end": 554, "line": "            conds.append(\"%s = $%d\" % (self.table, len(condvals)))\n"}, {"line_no": 16, "char_start": 554, "char_end": 555, "line": "\n"}, {"line_no": 18, "char_start": 600, "char_end": 635, "line": "            condvals.append(value)\n"}, {"line_no": 19, "char_start": 635, "char_end": 696, "line": "            conds.append(\"%s = $%d\" % (name, len(condvals)))\n"}, {"line_no": 23, "char_start": 824, "char_end": 868, "line": "        res = self._query(query, *condvals)\n"}]}, "char_changes": {"deleted": [{"char_start": 463, "char_end": 465, "chars": "%r"}, {"char_start": 482, "char_end": 487, "chars": "oid))"}, {"char_start": 564, "char_end": 566, "chars": "%r"}, {"char_start": 580, "char_end": 582, "chars": "ue"}], "added": [{"char_start": 136, "char_end": 158, "chars": "        condvals = []\n"}, {"char_start": 454, "char_end": 487, "chars": "            condvals.append(oid)\n"}, {"char_start": 518, "char_end": 521, "chars": "$%d"}, {"char_start": 538, "char_end": 554, "chars": "len(condvals)))\n"}, {"char_start": 600, "char_end": 635, "chars": "            condvals.append(value)\n"}, {"char_start": 666, "char_end": 669, "chars": "$%d"}, {"char_start": 680, "char_end": 688, "chars": "len(cond"}, {"char_start": 691, "char_end": 693, "chars": "s)"}, {"char_start": 855, "char_end": 866, "chars": ", *condvals"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089"}
{"func_name": "store_resultSet", "func_src_before": "    def store_resultSet(self, session, rset):\n        self._openContainer(session)\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        if (rset.expires):\n            expires = now + rset.expires\n        else:\n            expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n        id = rset.id\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n\n        # Serialise and store\n        srlz = rset.serialize(session)\n        cl = '.'.join((rset.__class__.__module__, rset.__class__.__name__))\n        data = srlz.replace('\\x00', '\\\\\\\\000')\n        try:\n            ndata = pg.escape_bytea(data)\n        except:\n            # insufficient PyGreSQL version - do the best we can\n            ndata = data.replace(\"'\", \"\\\\'\")\n\n        query = (\"INSERT INTO %s (identifier, data, size, class, \"\n                 \"timeCreated, timeAccessed, expires) VALUES \"\n                 \"('%s', '%s', %s, '%s', '%s', '%s', '%s')\" %\n                 (self.table,\n                  id,\n                  ndata,\n                  len(rset),\n                  cl,\n                  nowStr,\n                  nowStr,\n                  expiresStr\n                  )\n                 )\n        try:\n            self._query(query)\n        except pg.ProgrammingError as e:\n            # already exists, retry for overwrite, create\n            if self.get_setting(session, 'overwriteOkay', 0):\n                query = (\"UPDATE %s SET data = '%s', size = %s, \"\n                         \"class = '%s', timeAccessed = '%s', expires = '%s' \"\n                         \"WHERE identifier = '%s';\" %\n                         (self.table,\n                          ndata,\n                          len(rset),\n                          cl,\n                          nowStr,\n                          expiresStr,\n                          id\n                          )\n                         )\n                self._query(query)\n            elif hasattr(rset, 'retryOnFail'):\n                # generate new id, re-store\n                id = self.generate_id(session)\n                if (self.idNormalizer is not None):\n                    id = self.idNormalizer.process_string(session, id)\n                query = (\"INSERT INTO %s (identifier, data, size, class, \"\n                         \"timeCreated, timeAccessed, expires) VALUES \"\n                         \"('%s', '%s', %s, '%s', '%s', '%s', '%s')\" %\n                         (self.table,\n                          id,\n                          ndata,\n                          len(rset),\n                          cl,\n                          nowStr,\n                          nowStr,\n                          expiresStr\n                          )\n                         )\n                self._query(query)\n            else:\n                raise ObjectAlreadyExistsException(self.id + '/' + id)\n        return rset", "func_src_after": "    def store_resultSet(self, session, rset):\n        self._openContainer(session)\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        if (rset.expires):\n            expires = now + rset.expires\n        else:\n            expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n        id = rset.id\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n\n        # Serialise and store\n        srlz = rset.serialize(session)\n        cl = '.'.join((rset.__class__.__module__, rset.__class__.__name__))\n        data = srlz.replace('\\x00', '\\\\\\\\000')\n        try:\n            ndata = pg.escape_bytea(data)\n        except:\n            # insufficient PyGreSQL version - do the best we can\n            ndata = data.replace(\"'\", \"\\\\'\")\n\n        query = (\"INSERT INTO %s (identifier, data, size, class, \"\n                 \"timeCreated, timeAccessed, expires) VALUES \"\n                 \"($1, $2, $3, $4, $5, $6, $7)\" %\n                 (self.table)\n                 )\n        args = (id,\n                ndata,\n                len(rset),\n                cl,\n                nowStr,\n                nowStr,\n                expiresStr\n                )\n        try:\n            self._query(query, *args)\n        except pg.ProgrammingError as e:\n            # already exists, retry for overwrite, create\n            if self.get_setting(session, 'overwriteOkay', 0):\n                query = (\"UPDATE %s SET data = $1, size = $2, \"\n                         \"class = $3, timeAccessed = $4, expires = $5 \"\n                         \"WHERE identifier = $6;\" % (self.table)\n                         )\n                args = (ndata,\n                        len(rset),\n                        cl,\n                        nowStr,\n                        expiresStr,\n                        id\n                        )\n                self._query(query, *args)\n            elif hasattr(rset, 'retryOnFail'):\n                # generate new id, re-store\n                id = self.generate_id(session)\n                if (self.idNormalizer is not None):\n                    id = self.idNormalizer.process_string(session, id)\n                query = (\"INSERT INTO %s (identifier, data, size, class, \"\n                         \"timeCreated, timeAccessed, expires) VALUES \"\n                         \"($1, $2, $3, $4, $5, $6, $7)\" %\n                         (self.table)\n                         )\n                args = (id,\n                        ndata,\n                        len(rset),\n                        cl,\n                        nowStr,\n                        nowStr,\n                        expiresStr\n                        )\n                self._query(query, *args)\n            else:\n                raise ObjectAlreadyExistsException(self.id + '/' + id)\n        return rset", "line_changes": {"deleted": [{"line_no": 27, "char_start": 1077, "char_end": 1139, "line": "                 \"('%s', '%s', %s, '%s', '%s', '%s', '%s')\" %\n"}, {"line_no": 28, "char_start": 1139, "char_end": 1169, "line": "                 (self.table,\n"}, {"line_no": 29, "char_start": 1169, "char_end": 1191, "line": "                  id,\n"}, {"line_no": 30, "char_start": 1191, "char_end": 1216, "line": "                  ndata,\n"}, {"line_no": 31, "char_start": 1216, "char_end": 1245, "line": "                  len(rset),\n"}, {"line_no": 32, "char_start": 1245, "char_end": 1267, "line": "                  cl,\n"}, {"line_no": 33, "char_start": 1267, "char_end": 1293, "line": "                  nowStr,\n"}, {"line_no": 34, "char_start": 1293, "char_end": 1319, "line": "                  nowStr,\n"}, {"line_no": 35, "char_start": 1319, "char_end": 1348, "line": "                  expiresStr\n"}, {"line_no": 36, "char_start": 1348, "char_end": 1368, "line": "                  )\n"}, {"line_no": 39, "char_start": 1400, "char_end": 1431, "line": "            self._query(query)\n"}, {"line_no": 43, "char_start": 1592, "char_end": 1658, "line": "                query = (\"UPDATE %s SET data = '%s', size = %s, \"\n"}, {"line_no": 44, "char_start": 1658, "char_end": 1736, "line": "                         \"class = '%s', timeAccessed = '%s', expires = '%s' \"\n"}, {"line_no": 45, "char_start": 1736, "char_end": 1790, "line": "                         \"WHERE identifier = '%s';\" %\n"}, {"line_no": 46, "char_start": 1790, "char_end": 1828, "line": "                         (self.table,\n"}, {"line_no": 47, "char_start": 1828, "char_end": 1861, "line": "                          ndata,\n"}, {"line_no": 48, "char_start": 1861, "char_end": 1898, "line": "                          len(rset),\n"}, {"line_no": 49, "char_start": 1898, "char_end": 1928, "line": "                          cl,\n"}, {"line_no": 50, "char_start": 1928, "char_end": 1962, "line": "                          nowStr,\n"}, {"line_no": 51, "char_start": 1962, "char_end": 2000, "line": "                          expiresStr,\n"}, {"line_no": 52, "char_start": 2000, "char_end": 2029, "line": "                          id\n"}, {"line_no": 53, "char_start": 2029, "char_end": 2057, "line": "                          )\n"}, {"line_no": 55, "char_start": 2084, "char_end": 2119, "line": "                self._query(query)\n"}, {"line_no": 63, "char_start": 2526, "char_end": 2596, "line": "                         \"('%s', '%s', %s, '%s', '%s', '%s', '%s')\" %\n"}, {"line_no": 64, "char_start": 2596, "char_end": 2634, "line": "                         (self.table,\n"}, {"line_no": 65, "char_start": 2634, "char_end": 2664, "line": "                          id,\n"}, {"line_no": 66, "char_start": 2664, "char_end": 2697, "line": "                          ndata,\n"}, {"line_no": 67, "char_start": 2697, "char_end": 2734, "line": "                          len(rset),\n"}, {"line_no": 68, "char_start": 2734, "char_end": 2764, "line": "                          cl,\n"}, {"line_no": 69, "char_start": 2764, "char_end": 2798, "line": "                          nowStr,\n"}, {"line_no": 70, "char_start": 2798, "char_end": 2832, "line": "                          nowStr,\n"}, {"line_no": 71, "char_start": 2832, "char_end": 2869, "line": "                          expiresStr\n"}, {"line_no": 72, "char_start": 2869, "char_end": 2897, "line": "                          )\n"}, {"line_no": 74, "char_start": 2924, "char_end": 2959, "line": "                self._query(query)\n"}], "added": [{"line_no": 27, "char_start": 1077, "char_end": 1127, "line": "                 \"($1, $2, $3, $4, $5, $6, $7)\" %\n"}, {"line_no": 28, "char_start": 1127, "char_end": 1157, "line": "                 (self.table)\n"}, {"line_no": 30, "char_start": 1176, "char_end": 1196, "line": "        args = (id,\n"}, {"line_no": 31, "char_start": 1196, "char_end": 1219, "line": "                ndata,\n"}, {"line_no": 32, "char_start": 1219, "char_end": 1246, "line": "                len(rset),\n"}, {"line_no": 33, "char_start": 1246, "char_end": 1266, "line": "                cl,\n"}, {"line_no": 34, "char_start": 1266, "char_end": 1290, "line": "                nowStr,\n"}, {"line_no": 35, "char_start": 1290, "char_end": 1314, "line": "                nowStr,\n"}, {"line_no": 36, "char_start": 1314, "char_end": 1341, "line": "                expiresStr\n"}, {"line_no": 37, "char_start": 1341, "char_end": 1359, "line": "                )\n"}, {"line_no": 39, "char_start": 1372, "char_end": 1410, "line": "            self._query(query, *args)\n"}, {"line_no": 43, "char_start": 1571, "char_end": 1635, "line": "                query = (\"UPDATE %s SET data = $1, size = $2, \"\n"}, {"line_no": 44, "char_start": 1635, "char_end": 1707, "line": "                         \"class = $3, timeAccessed = $4, expires = $5 \"\n"}, {"line_no": 45, "char_start": 1707, "char_end": 1772, "line": "                         \"WHERE identifier = $6;\" % (self.table)\n"}, {"line_no": 47, "char_start": 1799, "char_end": 1830, "line": "                args = (ndata,\n"}, {"line_no": 48, "char_start": 1830, "char_end": 1865, "line": "                        len(rset),\n"}, {"line_no": 49, "char_start": 1865, "char_end": 1893, "line": "                        cl,\n"}, {"line_no": 50, "char_start": 1893, "char_end": 1925, "line": "                        nowStr,\n"}, {"line_no": 51, "char_start": 1925, "char_end": 1961, "line": "                        expiresStr,\n"}, {"line_no": 52, "char_start": 1961, "char_end": 1988, "line": "                        id\n"}, {"line_no": 53, "char_start": 1988, "char_end": 2014, "line": "                        )\n"}, {"line_no": 54, "char_start": 2014, "char_end": 2056, "line": "                self._query(query, *args)\n"}, {"line_no": 62, "char_start": 2463, "char_end": 2521, "line": "                         \"($1, $2, $3, $4, $5, $6, $7)\" %\n"}, {"line_no": 63, "char_start": 2521, "char_end": 2559, "line": "                         (self.table)\n"}, {"line_no": 65, "char_start": 2586, "char_end": 2614, "line": "                args = (id,\n"}, {"line_no": 66, "char_start": 2614, "char_end": 2645, "line": "                        ndata,\n"}, {"line_no": 67, "char_start": 2645, "char_end": 2680, "line": "                        len(rset),\n"}, {"line_no": 68, "char_start": 2680, "char_end": 2708, "line": "                        cl,\n"}, {"line_no": 69, "char_start": 2708, "char_end": 2740, "line": "                        nowStr,\n"}, {"line_no": 70, "char_start": 2740, "char_end": 2772, "line": "                        nowStr,\n"}, {"line_no": 71, "char_start": 2772, "char_end": 2807, "line": "                        expiresStr\n"}, {"line_no": 72, "char_start": 2807, "char_end": 2833, "line": "                        )\n"}, {"line_no": 73, "char_start": 2833, "char_end": 2875, "line": "                self._query(query, *args)\n"}]}, "char_changes": {"deleted": [{"char_start": 1096, "char_end": 1134, "chars": "'%s', '%s', %s, '%s', '%s', '%s', '%s'"}, {"char_start": 1167, "char_end": 1168, "chars": ","}, {"char_start": 1186, "char_end": 1187, "chars": " "}, {"char_start": 1191, "char_end": 1193, "chars": "  "}, {"char_start": 1216, "char_end": 1218, "chars": "  "}, {"char_start": 1261, "char_end": 1263, "chars": "  "}, {"char_start": 1267, "char_end": 1269, "chars": "  "}, {"char_start": 1293, "char_end": 1295, "chars": "  "}, {"char_start": 1335, "char_end": 1337, "chars": "  "}, {"char_start": 1348, "char_end": 1369, "chars": "                  )\n "}, {"char_start": 1639, "char_end": 1643, "chars": "'%s'"}, {"char_start": 1652, "char_end": 1654, "chars": "%s"}, {"char_start": 1692, "char_end": 1696, "chars": "'%s'"}, {"char_start": 1713, "char_end": 1717, "chars": "'%s'"}, {"char_start": 1729, "char_end": 1733, "chars": "'%s'"}, {"char_start": 1781, "char_end": 1789, "chars": "'%s';\" %"}, {"char_start": 1815, "char_end": 1836, "chars": "(self.table,\n        "}, {"char_start": 1852, "char_end": 1854, "chars": "  "}, {"char_start": 1861, "char_end": 1863, "chars": "  "}, {"char_start": 1922, "char_end": 1924, "chars": "  "}, {"char_start": 1928, "char_end": 1930, "chars": "  "}, {"char_start": 1986, "char_end": 1987, "chars": " "}, {"char_start": 1987, "char_end": 1988, "chars": " "}, {"char_start": 2000, "char_end": 2002, "chars": "  "}, {"char_start": 2029, "char_end": 2058, "chars": "                          )\n "}, {"char_start": 2553, "char_end": 2591, "chars": "'%s', '%s', %s, '%s', '%s', '%s', '%s'"}, {"char_start": 2632, "char_end": 2633, "chars": ","}, {"char_start": 2659, "char_end": 2660, "chars": " "}, {"char_start": 2664, "char_end": 2666, "chars": "  "}, {"char_start": 2697, "char_end": 2699, "chars": "  "}, {"char_start": 2758, "char_end": 2760, "chars": "  "}, {"char_start": 2788, "char_end": 2789, "chars": " "}, {"char_start": 2789, "char_end": 2790, "chars": " "}, {"char_start": 2798, "char_end": 2800, "chars": "  "}, {"char_start": 2832, "char_end": 2834, "chars": "  "}, {"char_start": 2869, "char_end": 2898, "chars": "                          )\n "}], "added": [{"char_start": 1096, "char_end": 1122, "chars": "$1, $2, $3, $4, $5, $6, $7"}, {"char_start": 1155, "char_end": 1156, "chars": ")"}, {"char_start": 1174, "char_end": 1192, "chars": ")\n        args = ("}, {"char_start": 1401, "char_end": 1408, "chars": ", *args"}, {"char_start": 1618, "char_end": 1620, "chars": "$1"}, {"char_start": 1629, "char_end": 1631, "chars": "$2"}, {"char_start": 1669, "char_end": 1671, "chars": "$3"}, {"char_start": 1688, "char_end": 1690, "chars": "$4"}, {"char_start": 1702, "char_end": 1704, "chars": "$5"}, {"char_start": 1752, "char_end": 1771, "chars": "$6;\" % (self.table)"}, {"char_start": 1797, "char_end": 1798, "chars": ")"}, {"char_start": 1815, "char_end": 1823, "chars": "args = ("}, {"char_start": 2047, "char_end": 2054, "chars": ", *args"}, {"char_start": 2490, "char_end": 2516, "chars": "$1, $2, $3, $4, $5, $6, $7"}, {"char_start": 2557, "char_end": 2558, "chars": ")"}, {"char_start": 2584, "char_end": 2610, "chars": ")\n                args = ("}, {"char_start": 2866, "char_end": 2873, "chars": ", *args"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089"}
{"func_name": "fetch_resultSet", "func_src_before": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = '%s', expires = '%s' \"\n                 \"WHERE identifier = '%s';\" %\n                 (self.table, nowStr, expiresStr, sid)\n                 )\n        self._query(query)\n        return rset", "func_src_after": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = $1, expires = $2 \"\n                 \"WHERE identifier = $3;\" % (self.table)\n                 )\n        self._query(query, nowStr, expiresStr, sid)\n        return rset", "line_changes": {"deleted": [{"line_no": 7, "char_start": 213, "char_end": 286, "line": "        query = (\"SELECT class, data FROM %s WHERE identifier = '%s';\" %\n"}, {"line_no": 8, "char_start": 286, "char_end": 321, "line": "                 (self.table, sid)\n"}, {"line_no": 10, "char_start": 340, "char_end": 373, "line": "        res = self._query(query)\n"}, {"line_no": 38, "char_start": 1291, "char_end": 1361, "line": "        query = (\"UPDATE %s SET timeAccessed = '%s', expires = '%s' \"\n"}, {"line_no": 39, "char_start": 1361, "char_end": 1407, "line": "                 \"WHERE identifier = '%s';\" %\n"}, {"line_no": 40, "char_start": 1407, "char_end": 1462, "line": "                 (self.table, nowStr, expiresStr, sid)\n"}, {"line_no": 42, "char_start": 1481, "char_end": 1508, "line": "        self._query(query)\n"}], "added": [{"line_no": 7, "char_start": 213, "char_end": 284, "line": "        query = (\"SELECT class, data FROM %s WHERE identifier = $1;\" %\n"}, {"line_no": 8, "char_start": 284, "char_end": 314, "line": "                 (self.table)\n"}, {"line_no": 10, "char_start": 333, "char_end": 371, "line": "        res = self._query(query, sid)\n"}, {"line_no": 38, "char_start": 1289, "char_end": 1355, "line": "        query = (\"UPDATE %s SET timeAccessed = $1, expires = $2 \"\n"}, {"line_no": 39, "char_start": 1355, "char_end": 1412, "line": "                 \"WHERE identifier = $3;\" % (self.table)\n"}, {"line_no": 41, "char_start": 1431, "char_end": 1483, "line": "        self._query(query, nowStr, expiresStr, sid)\n"}]}, "char_changes": {"deleted": [{"char_start": 277, "char_end": 281, "chars": "'%s'"}, {"char_start": 314, "char_end": 319, "chars": ", sid"}, {"char_start": 1338, "char_end": 1342, "chars": "'%s'"}, {"char_start": 1354, "char_end": 1358, "chars": "'%s'"}, {"char_start": 1398, "char_end": 1460, "chars": "'%s';\" %\n                 (self.table, nowStr, expiresStr, sid"}], "added": [{"char_start": 277, "char_end": 279, "chars": "$1"}, {"char_start": 364, "char_end": 369, "chars": ", sid"}, {"char_start": 1336, "char_end": 1338, "chars": "$1"}, {"char_start": 1350, "char_end": 1352, "chars": "$2"}, {"char_start": 1392, "char_end": 1410, "chars": "$3;\" % (self.table"}, {"char_start": 1456, "char_end": 1481, "chars": ", nowStr, expiresStr, sid"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089"}
{"func_name": "delete_resultSet", "func_src_before": "    def delete_resultSet(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = \"DELETE FROM %s WHERE identifier = '%s';\" % (self.table, sid)\n        self._query(query)", "func_src_after": "    def delete_resultSet(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = \"DELETE FROM %s WHERE identifier = $1;\" % (self.table)\n        self._query(query, sid)", "line_changes": {"deleted": [{"line_no": 6, "char_start": 213, "char_end": 291, "line": "        query = \"DELETE FROM %s WHERE identifier = '%s';\" % (self.table, sid)\n"}, {"line_no": 7, "char_start": 291, "char_end": 317, "line": "        self._query(query)\n"}], "added": [{"line_no": 6, "char_start": 213, "char_end": 284, "line": "        query = \"DELETE FROM %s WHERE identifier = $1;\" % (self.table)\n"}, {"line_no": 7, "char_start": 284, "char_end": 315, "line": "        self._query(query, sid)"}]}, "char_changes": {"deleted": [{"char_start": 264, "char_end": 268, "chars": "'%s'"}, {"char_start": 284, "char_end": 289, "chars": ", sid"}], "added": [{"char_start": 264, "char_end": 266, "chars": "$1"}, {"char_start": 309, "char_end": 314, "chars": ", sid"}]}, "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089"}
{"func_name": "update_fields", "func_src_before": "def update_fields(self, **kwargs):\n    \"\"\"\n    Update selected model fields in the database, but leave the other\n    fields alone. Use this rather than model.save() for performance\n    and data consistency.\n\n    You can use this as a function or add it as a method to your models:\n    import granular_update\n    class Example(models.Model):\n        name = models.CharField(max_length=20)\n        number = models.IntegerField()\n        update_fields = granular_update.update_fields\n    \"\"\"\n    sql = ['UPDATE', connection.ops.quote_name(self._meta.db_table), 'SET']\n    for field_name in kwargs:\n        setattr(self, field_name, kwargs[field_name])\n        field = self._meta.get_field(field_name)\n        value = field.get_db_prep_save(kwargs[field_name])\n        if isinstance(value, basestring):\n            value = \"'%s'\" % value.encode('utf-8').replace('\\\\', r'\\\\')\n        elif isinstance(value, models.Model):\n            value = str(value.id)\n        elif value is None:\n            value = 'NULL'\n        else:\n            value = str(value)\n        sql.extend((connection.ops.quote_name(field.column), '=', value, ','))\n    sql.pop(-1) # Remove the last comma\n    sql.extend(['WHERE', 'id', '=', str(self.id)])\n    sql = ' '.join(sql)\n    connection.cursor().execute(sql)\n    transaction.commit_unless_managed()", "func_src_after": "def update_fields(self, **kwargs):\n    \"\"\"\n    Update selected model fields in the database, but leave the other\n    fields alone. Use this rather than model.save() for performance\n    and data consistency.\n\n    You can use this as a function or add it as a method to your models:\n    import granular_update\n    class Example(models.Model):\n        name = models.CharField(max_length=20)\n        number = models.IntegerField()\n        update_fields = granular_update.update_fields\n    \"\"\"\n    sql = ['UPDATE', connection.ops.quote_name(self._meta.db_table), 'SET']\n    values = []\n    for field_name in kwargs:\n        setattr(self, field_name, kwargs[field_name])\n        field = self._meta.get_field(field_name)\n        value = field.get_db_prep_save(kwargs[field_name])\n        if isinstance(value, models.Model):\n            value = value.id\n        sql.extend((connection.ops.quote_name(field.column), '=', '%s', ','))\n        values.append(value)\n    sql.pop(-1) # Remove the last comma\n    sql.extend(['WHERE', 'id', '=', '%s'])\n    values.append(self.id)\n    sql = ' '.join(sql)\n    connection.cursor().execute(sql, values)\n    transaction.commit_unless_managed()", "line_changes": {"deleted": [{"line_no": 19, "char_start": 757, "char_end": 799, "line": "        if isinstance(value, basestring):\n"}, {"line_no": 20, "char_start": 799, "char_end": 871, "line": "            value = \"'%s'\" % value.encode('utf-8').replace('\\\\', r'\\\\')\n"}, {"line_no": 21, "char_start": 871, "char_end": 917, "line": "        elif isinstance(value, models.Model):\n"}, {"line_no": 22, "char_start": 917, "char_end": 951, "line": "            value = str(value.id)\n"}, {"line_no": 23, "char_start": 951, "char_end": 979, "line": "        elif value is None:\n"}, {"line_no": 24, "char_start": 979, "char_end": 1006, "line": "            value = 'NULL'\n"}, {"line_no": 25, "char_start": 1006, "char_end": 1020, "line": "        else:\n"}, {"line_no": 26, "char_start": 1020, "char_end": 1051, "line": "            value = str(value)\n"}, {"line_no": 27, "char_start": 1051, "char_end": 1130, "line": "        sql.extend((connection.ops.quote_name(field.column), '=', value, ','))\n"}, {"line_no": 29, "char_start": 1170, "char_end": 1221, "line": "    sql.extend(['WHERE', 'id', '=', str(self.id)])\n"}, {"line_no": 31, "char_start": 1245, "char_end": 1282, "line": "    connection.cursor().execute(sql)\n"}], "added": [{"line_no": 15, "char_start": 565, "char_end": 581, "line": "    values = []\n"}, {"line_no": 20, "char_start": 773, "char_end": 817, "line": "        if isinstance(value, models.Model):\n"}, {"line_no": 21, "char_start": 817, "char_end": 846, "line": "            value = value.id\n"}, {"line_no": 22, "char_start": 846, "char_end": 924, "line": "        sql.extend((connection.ops.quote_name(field.column), '=', '%s', ','))\n"}, {"line_no": 23, "char_start": 924, "char_end": 953, "line": "        values.append(value)\n"}, {"line_no": 25, "char_start": 993, "char_end": 1036, "line": "    sql.extend(['WHERE', 'id', '=', '%s'])\n"}, {"line_no": 26, "char_start": 1036, "char_end": 1063, "line": "    values.append(self.id)\n"}, {"line_no": 28, "char_start": 1087, "char_end": 1132, "line": "    connection.cursor().execute(sql, values)\n"}]}, "char_changes": {"deleted": [{"char_start": 785, "char_end": 901, "chars": " basestring):\n            value = \"'%s'\" % value.encode('utf-8').replace('\\\\', r'\\\\')\n        elif isinstance(value,"}, {"char_start": 937, "char_end": 941, "chars": "str("}, {"char_start": 949, "char_end": 1050, "chars": ")\n        elif value is None:\n            value = 'NULL'\n        else:\n            value = str(value)"}, {"char_start": 1117, "char_end": 1122, "chars": "value"}, {"char_start": 1206, "char_end": 1209, "chars": "str"}, {"char_start": 1218, "char_end": 1220, "chars": "])"}], "added": [{"char_start": 565, "char_end": 581, "chars": "    values = []\n"}, {"char_start": 912, "char_end": 916, "chars": "'%s'"}, {"char_start": 924, "char_end": 953, "chars": "        values.append(value)\n"}, {"char_start": 1029, "char_end": 1053, "chars": "'%s'])\n    values.append"}, {"char_start": 1122, "char_end": 1130, "chars": ", values"}]}, "commit_link": "github.com/nunkung3/browsershots/commit/9b5bddf6282c390549e319b8f203ad8555a9912e", "file_name": "shotserver/shotserver04/common/granular_update.py", "vul_type": "cwe-089"}
{"func_name": "add_post", "func_src_before": "def add_post(content):\n    data_base = psycopg2.connect(\"dbname=forum\")\n    cursor = data_base.cursor()\n    cursor.execute(\"insert into posts values (%s)\", (content,))\n    data_base.commit()\n    data_base.close()", "func_src_after": "def add_post(content):\n    data_base = psycopg2.connect(\"dbname=forum\")\n    cursor = data_base.cursor()\n    cursor.execute('insert into posts values (%s)', (content,)) #important to protect code from SQL injections!\n    data_base.commit()\n    data_base.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 104, "char_end": 168, "line": "    cursor.execute(\"insert into posts values (%s)\", (content,))\n"}], "added": [{"line_no": 4, "char_start": 104, "char_end": 216, "line": "    cursor.execute('insert into posts values (%s)', (content,)) #important to protect code from SQL injections!\n"}]}, "char_changes": {"deleted": [{"char_start": 123, "char_end": 124, "chars": "\""}, {"char_start": 153, "char_end": 154, "chars": "\""}], "added": [{"char_start": 123, "char_end": 124, "chars": "'"}, {"char_start": 153, "char_end": 154, "chars": "'"}, {"char_start": 167, "char_end": 215, "chars": " #important to protect code from SQL injections!"}]}, "commit_link": "github.com/astenstrasser/udacity_courses/commit/9d3476fc99d20734e313ef64a6e506f20e1d8a8c", "file_name": "relational-databases/forum_db.py", "vul_type": "cwe-089"}
{"func_name": "sendIndexReq", "func_src_before": "def sendIndexReq(nGram):\n\t\n\n\ttry:\n\t\tprint(nGram)\n\t\tsql = \"SELECT * FROM index WHERE ngram='\" + nGram + \"';\"\n\n\t\tcursor.execute(sql)\n\t\trecords = cursor.fetchall()\n\texcept Exception as ex:\n\t\tprint(ex)\n\n\t\treturn []\n\n\n\treturn records", "func_src_after": "def sendIndexReq(nGram):\n\t\n\n\ttry:\n\t\tprint(nGram)\n\t\tcursor.execute(\"SELECT * FROM index WHERE ngram=%(ngram)s;\", {\"ngram\": nGram})\n\t\trecords = cursor.fetchall()\n\texcept Exception as ex:\n\t\tprint(ex)\n\n\t\treturn []\n\n\n\treturn records", "line_changes": {"deleted": [{"line_no": 6, "char_start": 49, "char_end": 108, "line": "\t\tsql = \"SELECT * FROM index WHERE ngram='\" + nGram + \"';\"\n"}, {"line_no": 7, "char_start": 108, "char_end": 109, "line": "\n"}, {"line_no": 8, "char_start": 109, "char_end": 131, "line": "\t\tcursor.execute(sql)\n"}], "added": [{"line_no": 6, "char_start": 49, "char_end": 130, "line": "\t\tcursor.execute(\"SELECT * FROM index WHERE ngram=%(ngram)s;\", {\"ngram\": nGram})\n"}]}, "char_changes": {"deleted": [{"char_start": 51, "char_end": 57, "chars": "sql = "}, {"char_start": 90, "char_end": 129, "chars": "'\" + nGram + \"';\"\n\n\t\tcursor.execute(sql"}], "added": [{"char_start": 51, "char_end": 66, "chars": "cursor.execute("}, {"char_start": 99, "char_end": 128, "chars": "%(ngram)s;\", {\"ngram\": nGram}"}]}, "commit_link": "github.com/Angelyr/Ranking/commit/e10e3976ec3d65b9a9af3870eb02418c757615bb", "file_name": "MessageHandler.py", "vul_type": "cwe-089"}
{"func_name": "query_restaurants_by_ingredient", "func_src_before": "@app.route('/restaurants/<ingredient>/')\ndef query_restaurants_by_ingredient(ingredient):\n    \"\"\"\n    To query this method, use :\n    '/restaurants/<ingredient>/?key=value&key=value&...' where keys are optional\n    strings from ['loclat', 'loclng', 'price_category', 'online_delivery', 'min_review']\n    for example: '/restaurants/flour/?min_review=3.5&price_category=2'\n    \"\"\"\n    logger.info(\"GET query_restaurants_by_ingredient query\")\n    loclat, loclng = request.args.get('loclat'), request.args.get('loclng')\n    price_category = request.args.get('price_category')\n    online_delivery = request.args.get('online_delivery')\n    min_review = request.args.get('min_review')\n    base_query = sql_queries.restaurants_by_ingredient % ingredient\n    if loclat != None and loclng != None:\n        lat_range = [float(loclat) - geodist, float(loclat) + geodist]\n        lng_range = [float(loclng) - geodist, float(loclng) + geodist]\n    else:\n        lat_range = None\n        lng_range = None\n    filtered_query = database.restaurant_query_builder(base_query,\n                                                       lat_range, lng_range,\n                                                       price_category,\n                                                       min_review, online_delivery)\n    limited_query = database.order_by_and_limit_query(filtered_query,\n                                                    \"agg_review DESC\", 20)\n    query_res = database.run_sql_query(limited_query)\n    if query_res == -1:\n        return None\n    return query_res", "func_src_after": "@app.route('/restaurants/<ingredient>/')\ndef query_restaurants_by_ingredient(ingredient):\n    \"\"\"\n    To query this method, use :\n    '/restaurants/<ingredient>/?key=value&key=value&...' where keys are optional\n    strings from ['loclat', 'loclng', 'price_category', 'online_delivery', 'min_review']\n    for example: '/restaurants/flour/?min_review=3.5&price_category=2'\n    \"\"\"\n    logger.info(\"GET query_restaurants_by_ingredient query\")\n    loclat, loclng = request.args.get('loclat'), request.args.get('loclng')\n    price_category = request.args.get('price_category')\n    online_delivery = request.args.get('online_delivery')\n    min_review = request.args.get('min_review')\n    base_query = sql_queries.restaurants_by_ingredient % ingredient\n    if loclat != None and loclng != None:\n        try:\n            lat_range = [float(loclat) - geodist, float(loclat) + geodist]\n            lng_range = [float(loclng) - geodist, float(loclng) + geodist]\n        except:\n            logger.error(\"Error translating location to floats in \"\n                     \"query_restaurants_by_ingredient, passed values: \"\n                     \"%s, %s\" % (loclat, loclng))\n            return None\n    else:\n        lat_range = None\n        lng_range = None\n    filtered_query = database.restaurant_query_builder(base_query,\n                                                       lat_range, lng_range,\n                                                       price_category,\n                                                       min_review, online_delivery)\n    if filtered_query == -1:\n        logger.error(\"Restaurant query builder failed to process inputs for \"\n                     \"query_restaurants_by_ingredient: %s, %s, %s\" %\n                     (price_category,\n                     min, online_delivery))\n    limited_query = database.order_by_and_limit_query(filtered_query,\n                                                    \"agg_review DESC\", 20)\n    query_res = database.run_sql_query(limited_query)\n    if query_res == -1:\n        return None\n    return query_res", "line_changes": {"deleted": [{"line_no": 16, "char_start": 788, "char_end": 859, "line": "        lat_range = [float(loclat) - geodist, float(loclat) + geodist]\n"}, {"line_no": 17, "char_start": 859, "char_end": 930, "line": "        lng_range = [float(loclng) - geodist, float(loclng) + geodist]\n"}], "added": [{"line_no": 16, "char_start": 788, "char_end": 801, "line": "        try:\n"}, {"line_no": 17, "char_start": 801, "char_end": 876, "line": "            lat_range = [float(loclat) - geodist, float(loclat) + geodist]\n"}, {"line_no": 18, "char_start": 876, "char_end": 951, "line": "            lng_range = [float(loclng) - geodist, float(loclng) + geodist]\n"}, {"line_no": 19, "char_start": 951, "char_end": 967, "line": "        except:\n"}, {"line_no": 20, "char_start": 967, "char_end": 1035, "line": "            logger.error(\"Error translating location to floats in \"\n"}, {"line_no": 21, "char_start": 1035, "char_end": 1107, "line": "                     \"query_restaurants_by_ingredient, passed values: \"\n"}, {"line_no": 22, "char_start": 1107, "char_end": 1157, "line": "                     \"%s, %s\" % (loclat, loclng))\n"}, {"line_no": 23, "char_start": 1157, "char_end": 1181, "line": "            return None\n"}, {"line_no": 31, "char_start": 1540, "char_end": 1569, "line": "    if filtered_query == -1:\n"}, {"line_no": 32, "char_start": 1569, "char_end": 1647, "line": "        logger.error(\"Restaurant query builder failed to process inputs for \"\n"}, {"line_no": 33, "char_start": 1647, "char_end": 1716, "line": "                     \"query_restaurants_by_ingredient: %s, %s, %s\" %\n"}, {"line_no": 34, "char_start": 1716, "char_end": 1754, "line": "                     (price_category,\n"}, {"line_no": 35, "char_start": 1754, "char_end": 1798, "line": "                     min, online_delivery))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 788, "char_end": 805, "chars": "        try:\n    "}, {"char_start": 876, "char_end": 880, "chars": "    "}, {"char_start": 951, "char_end": 1181, "chars": "        except:\n            logger.error(\"Error translating location to floats in \"\n                     \"query_restaurants_by_ingredient, passed values: \"\n                     \"%s, %s\" % (loclat, loclng))\n            return None\n"}, {"char_start": 1540, "char_end": 1798, "chars": "    if filtered_query == -1:\n        logger.error(\"Restaurant query builder failed to process inputs for \"\n                     \"query_restaurants_by_ingredient: %s, %s, %s\" %\n                     (price_category,\n                     min, online_delivery))\n"}]}, "commit_link": "github.com/RamFlo/DBSystems/commit/1ba43609e1acee05ae2f821180765eb96b45bbd2", "file_name": "SRC/APPLICATION-SOURCE-CODE/server.py", "vul_type": "cwe-089"}
{"func_name": "query_restaurants_by_taste", "func_src_before": "@app.route('/restaurants/<saltiness>/<sweetness>/<sourness>/<bitterness>/')\ndef query_restaurants_by_taste(saltiness, sweetness, sourness, bitterness):\n    \"\"\"\n    To query this method, use :\n    '/restaurants/<saltiness>/<sweetness>/<sourness>/<bitterness>/?key=value&key=value&...'\n    where keys are optional strings from\n    ['loclat', 'loclng', 'price_category', 'online_delivery', 'min_review']\n    and tastes (e.g. 'saltiness') are either 0 or 1\n    for example: '/restaurants/0/1/0/1/?min_review=3.5&price_category=2'\n    \"\"\"\n    logger.info(\"GET query_restaurants_by_taste query\")\n    try:\n        saltiness, sweetness, sourness, bitterness = int(saltiness), \\\n                                                     int(sweetness), \\\n                                                     int(sourness), int(bitterness)\n    except:\n        return None\n\n    restaurant_query = sql_queries.restaurant_by_taste % (\n        get_taste_condition(saltiness),\n        get_taste_condition(sweetness),\n        get_taste_condition(sourness),\n        get_taste_condition(bitterness),\n        get_taste_condition(1 - saltiness),\n        get_taste_condition(1 - sweetness),\n        get_taste_condition(1 - sourness),\n        get_taste_condition(1 - bitterness),\n    )\n    loclat, loclng = request.args.get('loclat'), request.args.get('loclng')\n    price_category = request.args.get('price_category')\n    online_delivery = request.args.get('online_delivery')\n    min_review = request.args.get('min_review')\n    if loclat != None and loclng != None:\n        lat_range = [float(loclat) - geodist, float(loclat) + geodist]\n        lng_range = [float(loclng) - geodist, float(loclng) + geodist]\n    else:\n        lat_range = None\n        lng_range = None\n    filtered_query = database.restaurant_query_builder(restaurant_query,\n                                                       lat_range, lng_range,\n                                                       price_category,\n                                                       min_review, online_delivery)\n    limited_query = database.order_by_and_limit_query(filtered_query,\n                                                    \"agg_review DESC\", 20)\n    query_res = database.run_sql_query(limited_query)\n    if query_res == -1:\n        return None\n    return query_res", "func_src_after": "@app.route('/restaurants/<saltiness>/<sweetness>/<sourness>/<bitterness>/')\ndef query_restaurants_by_taste(saltiness, sweetness, sourness, bitterness):\n    \"\"\"\n    To query this method, use :\n    '/restaurants/<saltiness>/<sweetness>/<sourness>/<bitterness>/?key=value&key=value&...'\n    where keys are optional strings from\n    ['loclat', 'loclng', 'price_category', 'online_delivery', 'min_review']\n    and tastes (e.g. 'saltiness') are either 0 or 1\n    for example: '/restaurants/0/1/0/1/?min_review=3.5&price_category=2'\n    \"\"\"\n    logger.info(\"GET query_restaurants_by_taste query\")\n    try:\n        saltiness, sweetness, sourness, bitterness = int(saltiness), \\\n                                                     int(sweetness), \\\n                                                     int(sourness), int(bitterness)\n    except:\n        logger.error(\"Error translating flavors to int in \"\n                     \"query_restaurants_by_taste, passed values: \"\n                     \"%s/%s/%s/%s\" % (saltiness, sweetness, sourness, bitterness))\n        return None\n\n    restaurant_query = sql_queries.restaurant_by_taste % (\n        get_taste_condition(saltiness),\n        get_taste_condition(sweetness),\n        get_taste_condition(sourness),\n        get_taste_condition(bitterness),\n        get_taste_condition(1 - saltiness),\n        get_taste_condition(1 - sweetness),\n        get_taste_condition(1 - sourness),\n        get_taste_condition(1 - bitterness),\n    )\n    loclat, loclng = request.args.get('loclat'), request.args.get('loclng')\n    price_category = request.args.get('price_category')\n    online_delivery = request.args.get('online_delivery')\n    min_review = request.args.get('min_review')\n    if loclat != None and loclng != None:\n        try:\n            lat_range = [float(loclat) - geodist, float(loclat) + geodist]\n            lng_range = [float(loclng) - geodist, float(loclng) + geodist]\n        except:\n            logger.error(\"Error translating location to floats in \"\n                     \"query_restaurants_by_taste, passed values: \"\n                     \"%s, %s\" % (loclat, loclng))\n            return None\n    else:\n        lat_range = None\n        lng_range = None\n    filtered_query = database.restaurant_query_builder(restaurant_query,\n                                                       lat_range, lng_range,\n                                                       price_category,\n                                                       min_review, online_delivery)\n    if filtered_query == -1:\n        logger.error(\"Restaurant query builder failed to process inputs for \"\n                     \"query_restaurants_by_taste: %s, %s, %s\" %\n                     (price_category,\n                     min, online_delivery))\n    limited_query = database.order_by_and_limit_query(filtered_query,\n                                                    \"agg_review DESC\", 20)\n    query_res = database.run_sql_query(limited_query)\n    if query_res == -1:\n        return None\n    return query_res", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1539, "char_end": 1610, "line": "        lat_range = [float(loclat) - geodist, float(loclat) + geodist]\n"}, {"line_no": 35, "char_start": 1610, "char_end": 1681, "line": "        lng_range = [float(loclng) - geodist, float(loclng) + geodist]\n"}], "added": [{"line_no": 17, "char_start": 837, "char_end": 897, "line": "        logger.error(\"Error translating flavors to int in \"\n"}, {"line_no": 18, "char_start": 897, "char_end": 964, "line": "                     \"query_restaurants_by_taste, passed values: \"\n"}, {"line_no": 19, "char_start": 964, "char_end": 1047, "line": "                     \"%s/%s/%s/%s\" % (saltiness, sweetness, sourness, bitterness))\n"}, {"line_no": 37, "char_start": 1749, "char_end": 1762, "line": "        try:\n"}, {"line_no": 38, "char_start": 1762, "char_end": 1837, "line": "            lat_range = [float(loclat) - geodist, float(loclat) + geodist]\n"}, {"line_no": 39, "char_start": 1837, "char_end": 1912, "line": "            lng_range = [float(loclng) - geodist, float(loclng) + geodist]\n"}, {"line_no": 40, "char_start": 1912, "char_end": 1928, "line": "        except:\n"}, {"line_no": 41, "char_start": 1928, "char_end": 1996, "line": "            logger.error(\"Error translating location to floats in \"\n"}, {"line_no": 42, "char_start": 1996, "char_end": 2063, "line": "                     \"query_restaurants_by_taste, passed values: \"\n"}, {"line_no": 43, "char_start": 2063, "char_end": 2113, "line": "                     \"%s, %s\" % (loclat, loclng))\n"}, {"line_no": 44, "char_start": 2113, "char_end": 2137, "line": "            return None\n"}, {"line_no": 52, "char_start": 2502, "char_end": 2531, "line": "    if filtered_query == -1:\n"}, {"line_no": 53, "char_start": 2531, "char_end": 2609, "line": "        logger.error(\"Restaurant query builder failed to process inputs for \"\n"}, {"line_no": 54, "char_start": 2609, "char_end": 2673, "line": "                     \"query_restaurants_by_taste: %s, %s, %s\" %\n"}, {"line_no": 55, "char_start": 2673, "char_end": 2711, "line": "                     (price_category,\n"}, {"line_no": 56, "char_start": 2711, "char_end": 2755, "line": "                     min, online_delivery))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 837, "char_end": 1047, "chars": "        logger.error(\"Error translating flavors to int in \"\n                     \"query_restaurants_by_taste, passed values: \"\n                     \"%s/%s/%s/%s\" % (saltiness, sweetness, sourness, bitterness))\n"}, {"char_start": 1749, "char_end": 1766, "chars": "        try:\n    "}, {"char_start": 1837, "char_end": 1841, "chars": "    "}, {"char_start": 1912, "char_end": 2137, "chars": "        except:\n            logger.error(\"Error translating location to floats in \"\n                     \"query_restaurants_by_taste, passed values: \"\n                     \"%s, %s\" % (loclat, loclng))\n            return None\n"}, {"char_start": 2502, "char_end": 2755, "chars": "    if filtered_query == -1:\n        logger.error(\"Restaurant query builder failed to process inputs for \"\n                     \"query_restaurants_by_taste: %s, %s, %s\" %\n                     (price_category,\n                     min, online_delivery))\n"}]}, "commit_link": "github.com/RamFlo/DBSystems/commit/1ba43609e1acee05ae2f821180765eb96b45bbd2", "file_name": "SRC/APPLICATION-SOURCE-CODE/server.py", "vul_type": "cwe-089"}
{"func_name": "get_first_month", "func_src_before": "def get_first_month(db, scene):\n    sql = \"select date from matches where scene='{}' order by date limit 1;\".format(scene)\n    res = db.exec(sql)\n    date = res[0][0]\n    return date", "func_src_after": "def get_first_month(db, scene):\n    sql = \"select date from matches where scene='{scene}' order by date limit 1;\"\n    args = {'scene': scene}\n    res = db.exec(sql, args)\n    date = res[0][0]\n    return date", "line_changes": {"deleted": [{"line_no": 2, "char_start": 32, "char_end": 123, "line": "    sql = \"select date from matches where scene='{}' order by date limit 1;\".format(scene)\n"}, {"line_no": 3, "char_start": 123, "char_end": 146, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 2, "char_start": 32, "char_end": 114, "line": "    sql = \"select date from matches where scene='{scene}' order by date limit 1;\"\n"}, {"line_no": 3, "char_start": 114, "char_end": 142, "line": "    args = {'scene': scene}\n"}, {"line_no": 4, "char_start": 142, "char_end": 171, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 108, "char_end": 122, "chars": ".format(scene)"}], "added": [{"char_start": 82, "char_end": 87, "chars": "scene"}, {"char_start": 113, "char_end": 141, "chars": "\n    args = {'scene': scene}"}, {"char_start": 163, "char_end": 169, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_last_month", "func_src_before": "def get_last_month(db, scene):\n    sql = \"select date from matches where scene='{}' order by date desc limit 1;\".format(scene)\n    res = db.exec(sql)\n    date = res[0][0]\n\n    # If it has been more than 1 month since this last tournament,\n    # go ahead and round this date up by a 1 month\n    # eg, if the last tournament was 2015-01-15 (a long time ago)\n    # we can assume the scene won't have more tournaments\n    # So just round to 2015-02-01\n    today = datetime.datetime.today().strftime('%Y-%m-%d')\n    y, m, d = today.split('-')\n    cy, cm, cd = date.split('-')\n    if y > cy or m > cm:\n        # Add 1 to the month before we return\n        # eg 2018-03-01 -> 2018-04-01\n        date = get_next_month(date)\n\n    return date", "func_src_after": "def get_last_month(db, scene):\n    sql = \"select date from matches where scene='{scene}' order by date desc limit 1;\"\n    args = {'scene': scene}\n    res = db.exec(sql, args)\n    date = res[0][0]\n\n    # If it has been more than 1 month since this last tournament,\n    # go ahead and round this date up by a 1 month\n    # eg, if the last tournament was 2015-01-15 (a long time ago)\n    # we can assume the scene won't have more tournaments\n    # So just round to 2015-02-01\n    today = datetime.datetime.today().strftime('%Y-%m-%d')\n    y, m, d = today.split('-')\n    cy, cm, cd = date.split('-')\n    if y > cy or m > cm:\n        # Add 1 to the month before we return\n        # eg 2018-03-01 -> 2018-04-01\n        date = get_next_month(date)\n\n    return date", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 127, "line": "    sql = \"select date from matches where scene='{}' order by date desc limit 1;\".format(scene)\n"}, {"line_no": 3, "char_start": 127, "char_end": 150, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 118, "line": "    sql = \"select date from matches where scene='{scene}' order by date desc limit 1;\"\n"}, {"line_no": 3, "char_start": 118, "char_end": 146, "line": "    args = {'scene': scene}\n"}, {"line_no": 4, "char_start": 146, "char_end": 175, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 112, "char_end": 126, "chars": ".format(scene)"}], "added": [{"char_start": 81, "char_end": 86, "chars": "scene"}, {"char_start": 117, "char_end": 145, "chars": "\n    args = {'scene': scene}"}, {"char_start": 167, "char_end": 173, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_first_ranked_month", "func_src_before": "def get_first_ranked_month(db, scene, player):\n    sql = \"select date from ranks where scene='{}' and player='{}' order by date limit 1;\".format(scene, player)\n    res = db.exec(sql)\n    date = res[0][0]\n    return date", "func_src_after": "def get_first_ranked_month(db, scene, player):\n    sql = \"select date from ranks where scene='{scene}' and player='{player}' order by date limit 1;\"\n    args = {'scene': scene, 'player': player}\n    res = db.exec(sql, args)\n    date = res[0][0]\n    return date", "line_changes": {"deleted": [{"line_no": 2, "char_start": 47, "char_end": 160, "line": "    sql = \"select date from ranks where scene='{}' and player='{}' order by date limit 1;\".format(scene, player)\n"}, {"line_no": 3, "char_start": 160, "char_end": 183, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 2, "char_start": 47, "char_end": 149, "line": "    sql = \"select date from ranks where scene='{scene}' and player='{player}' order by date limit 1;\"\n"}, {"line_no": 3, "char_start": 149, "char_end": 195, "line": "    args = {'scene': scene, 'player': player}\n"}, {"line_no": 4, "char_start": 195, "char_end": 224, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 137, "char_end": 145, "chars": ".format("}, {"char_start": 158, "char_end": 159, "chars": ")"}], "added": [{"char_start": 95, "char_end": 100, "chars": "scene"}, {"char_start": 116, "char_end": 122, "chars": "player"}, {"char_start": 148, "char_end": 170, "chars": "\n    args = {'scene': "}, {"char_start": 177, "char_end": 178, "chars": "'"}, {"char_start": 184, "char_end": 194, "chars": "': player}"}, {"char_start": 216, "char_end": 222, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_last_ranked_month", "func_src_before": "def get_last_ranked_month(db, scene, player):\n    sql = \"select date from ranks where scene='{}' and player='{}' order by date desc limit 1;\".format(scene, player)\n    res = db.exec(sql)\n    date = res[0][0]\n    return date", "func_src_after": "def get_last_ranked_month(db, scene, player):\n    sql = \"select date from ranks where scene='{scene}' and player='{player}' order by date desc limit 1;\"\n    args = {'scene': scene, 'player': player}\n    res = db.exec(sql, args)\n    date = res[0][0]\n    return date", "line_changes": {"deleted": [{"line_no": 2, "char_start": 46, "char_end": 164, "line": "    sql = \"select date from ranks where scene='{}' and player='{}' order by date desc limit 1;\".format(scene, player)\n"}, {"line_no": 3, "char_start": 164, "char_end": 187, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 2, "char_start": 46, "char_end": 153, "line": "    sql = \"select date from ranks where scene='{scene}' and player='{player}' order by date desc limit 1;\"\n"}, {"line_no": 3, "char_start": 153, "char_end": 199, "line": "    args = {'scene': scene, 'player': player}\n"}, {"line_no": 4, "char_start": 199, "char_end": 228, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 141, "char_end": 149, "chars": ".format("}, {"char_start": 162, "char_end": 163, "chars": ")"}], "added": [{"char_start": 94, "char_end": 99, "chars": "scene"}, {"char_start": 115, "char_end": 121, "chars": "player"}, {"char_start": 152, "char_end": 174, "chars": "\n    args = {'scene': "}, {"char_start": 181, "char_end": 182, "chars": "'"}, {"char_start": 188, "char_end": 198, "chars": "': player}"}, {"char_start": 220, "char_end": 226, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_monthly_ranks_for_scene", "func_src_before": "def get_monthly_ranks_for_scene(db, scene, tag):\n\n    sql = \"SELECT date, rank FROM ranks WHERE scene='{}' AND player='{}'\".format(scene, tag)\n    res = db.exec(sql)\n\n    res = [r for r in res if played_during_month(db, scene, tag, get_previous_month(r[0]))]\n\n    # Build up a dict of {date: rank}\n    ranks = {}\n    for r in res:\n        ranks[r[0]] = r[1]\n\n    return ranks", "func_src_after": "def get_monthly_ranks_for_scene(db, scene, tag):\n\n    sql = \"SELECT date, rank FROM ranks WHERE scene='{scene}' AND player='{tag}'\"\n    args = {'scene': scene, 'tag': tag}\n    res = db.exec(sql, args)\n\n    res = [r for r in res if played_during_month(db, scene, tag, get_previous_month(r[0]))]\n\n    # Build up a dict of {date: rank}\n    ranks = {}\n    for r in res:\n        ranks[r[0]] = r[1]\n\n    return ranks", "line_changes": {"deleted": [{"line_no": 3, "char_start": 50, "char_end": 143, "line": "    sql = \"SELECT date, rank FROM ranks WHERE scene='{}' AND player='{}'\".format(scene, tag)\n"}, {"line_no": 4, "char_start": 143, "char_end": 166, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 3, "char_start": 50, "char_end": 132, "line": "    sql = \"SELECT date, rank FROM ranks WHERE scene='{scene}' AND player='{tag}'\"\n"}, {"line_no": 4, "char_start": 132, "char_end": 172, "line": "    args = {'scene': scene, 'tag': tag}\n"}, {"line_no": 5, "char_start": 172, "char_end": 201, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 120, "char_end": 131, "chars": "}'\".format("}, {"char_start": 141, "char_end": 142, "chars": ")"}], "added": [{"char_start": 104, "char_end": 109, "chars": "scene"}, {"char_start": 125, "char_end": 153, "chars": "tag}'\"\n    args = {'scene': "}, {"char_start": 160, "char_end": 161, "chars": "'"}, {"char_start": 164, "char_end": 171, "chars": "': tag}"}, {"char_start": 193, "char_end": 199, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_ranking_graph_data", "func_src_before": "def get_ranking_graph_data(db, tag):\n    # First, we have to find out which scenes this player is ranked in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{}'\".format(tag)\n    scenes = db.exec(sql)\n    scenes = [s[0] for s in scenes]\n\n    # Get the first time we were ranked in each of these scenes\n    first_months = [get_first_ranked_month(db, s, tag) for s in scenes]\n    last_months = [get_last_ranked_month(db, s, tag) for s in scenes]\n\n    first_month = min(first_months)\n    last_month = max(last_months)\n\n    # Get a list of each month that we want to know the ranks for\n    iterated_months = iter_months(first_month, last_month, include_last=True)\n\n    # Get individual rankings per month, per scene\n    arank = get_monthly_ranks_for_scene(db, 'austin', 'christmasmike')\n\n    monthly_ranks_per_scene = {s:get_monthly_ranks_for_scene(db, s, tag) for s in scenes}\n\n    ranks_per_scene = {s:[] for s in scenes}\n    # Reformat this data to use with Zing\n    for month in iterated_months:\n        for s in scenes:\n            scene_ranks = monthly_ranks_per_scene[s]\n            if month in scene_ranks:\n                ranks_per_scene[s].append([month, scene_ranks[month]])\n\n    \n\n    return ranks_per_scene, iterated_months", "func_src_after": "def get_ranking_graph_data(db, tag):\n    # First, we have to find out which scenes this player is ranked in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{tag}'\"\n    args = {'tag': tag}\n    scenes = db.exec(sql, args)\n    scenes = [s[0] for s in scenes]\n\n    # Get the first time we were ranked in each of these scenes\n    first_months = [get_first_ranked_month(db, s, tag) for s in scenes]\n    last_months = [get_last_ranked_month(db, s, tag) for s in scenes]\n\n    first_month = min(first_months)\n    last_month = max(last_months)\n\n    # Get a list of each month that we want to know the ranks for\n    iterated_months = iter_months(first_month, last_month, include_last=True)\n\n    monthly_ranks_per_scene = {s:get_monthly_ranks_for_scene(db, s, tag) for s in scenes}\n\n    ranks_per_scene = {s:[] for s in scenes}\n    # Reformat this data to use with Zing\n    for month in iterated_months:\n        for s in scenes:\n            scene_ranks = monthly_ranks_per_scene[s]\n            if month in scene_ranks:\n                ranks_per_scene[s].append([month, scene_ranks[month]])\n\n    \n\n    return ranks_per_scene, iterated_months", "line_changes": {"deleted": [{"line_no": 3, "char_start": 108, "char_end": 183, "line": "    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{}'\".format(tag)\n"}, {"line_no": 4, "char_start": 183, "char_end": 209, "line": "    scenes = db.exec(sql)\n"}, {"line_no": 18, "char_start": 720, "char_end": 791, "line": "    arank = get_monthly_ranks_for_scene(db, 'austin', 'christmasmike')\n"}, {"line_no": 19, "char_start": 791, "char_end": 792, "line": "\n"}], "added": [{"line_no": 3, "char_start": 108, "char_end": 174, "line": "    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{tag}'\"\n"}, {"line_no": 4, "char_start": 174, "char_end": 198, "line": "    args = {'tag': tag}\n"}, {"line_no": 5, "char_start": 198, "char_end": 230, "line": "    scenes = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 167, "char_end": 178, "chars": "}'\".format("}, {"char_start": 181, "char_end": 182, "chars": ")"}, {"char_start": 669, "char_end": 792, "chars": "    # Get individual rankings per month, per scene\n    arank = get_monthly_ranks_for_scene(db, 'austin', 'christmasmike')\n\n"}], "added": [{"char_start": 167, "char_end": 193, "chars": "tag}'\"\n    args = {'tag': "}, {"char_start": 196, "char_end": 197, "chars": "}"}, {"char_start": 222, "char_end": 228, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_bracket_placings_in_scene", "func_src_before": "def get_bracket_placings_in_scene(db, scene, tag):\n    sql = \"select distinct matches.date, placings.place from placings join matches on \\\n            matches.url=placings.url where scene='{}' and ((player1='{}' and placings.player=player1) or \\\n            (player2='{}' and placings.player=player2));\".format(scene, tag, tag)\n    print(sql)\n    res = db.exec(sql)\n\n    # Convert all placings to ints\n    res = [[r[0], int(r[1])] for r in res]\n    return res", "func_src_after": "def get_bracket_placings_in_scene(db, scene, tag):\n    sql = \"select distinct matches.date, placings.place from placings join matches on \\\n            matches.url=placings.url where scene='{scene}' and ((player1='{tag_one}' and placings.player=player1) or \\\n            (player2='{tag_two}' and placings.player=player2));\"\n    args = {'scene': scene, 'tag_one': tag, 'tag_two': tag}\n    res = db.exec(sql, args)\n\n    # Convert all placings to ints\n    res = [[r[0], int(r[1])] for r in res]\n    return res", "line_changes": {"deleted": [{"line_no": 3, "char_start": 139, "char_end": 246, "line": "            matches.url=placings.url where scene='{}' and ((player1='{}' and placings.player=player1) or \\\n"}, {"line_no": 4, "char_start": 246, "char_end": 328, "line": "            (player2='{}' and placings.player=player2));\".format(scene, tag, tag)\n"}, {"line_no": 5, "char_start": 328, "char_end": 343, "line": "    print(sql)\n"}, {"line_no": 6, "char_start": 343, "char_end": 366, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 3, "char_start": 139, "char_end": 258, "line": "            matches.url=placings.url where scene='{scene}' and ((player1='{tag_one}' and placings.player=player1) or \\\n"}, {"line_no": 4, "char_start": 258, "char_end": 323, "line": "            (player2='{tag_two}' and placings.player=player2));\"\n"}, {"line_no": 5, "char_start": 323, "char_end": 383, "line": "    args = {'scene': scene, 'tag_one': tag, 'tag_two': tag}\n"}, {"line_no": 6, "char_start": 383, "char_end": 412, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 303, "char_end": 311, "chars": ".format("}, {"char_start": 321, "char_end": 342, "chars": ", tag)\n    print(sql)"}], "added": [{"char_start": 190, "char_end": 195, "chars": "scene"}, {"char_start": 214, "char_end": 221, "chars": "tag_one"}, {"char_start": 281, "char_end": 288, "chars": "tag_two"}, {"char_start": 322, "char_end": 361, "chars": "\n    args = {'scene': scene, 'tag_one':"}, {"char_start": 367, "char_end": 368, "chars": "'"}, {"char_start": 371, "char_end": 382, "chars": "_two': tag}"}, {"char_start": 404, "char_end": 410, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_bracket_graph_data", "func_src_before": "def get_bracket_graph_data(db, tag):\n    # First, we have to find out which scenes this player has brackets in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{}'\".format(tag)\n    scenes = db.exec(sql)\n    scenes = [s[0] for s in scenes]\n\n    bracket_placings_by_scene = {s: get_bracket_placings_in_scene(db, s, tag) for s in scenes}\n\n    return bracket_placings_by_scene", "func_src_after": "def get_bracket_graph_data(db, tag):\n    # First, we have to find out which scenes this player has brackets in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{tag}'\"\n    args = {'tag': tag}\n    scenes = db.exec(sql, args)\n    scenes = [s[0] for s in scenes]\n\n    bracket_placings_by_scene = {s: get_bracket_placings_in_scene(db, s, tag) for s in scenes}\n\n    return bracket_placings_by_scene", "line_changes": {"deleted": [{"line_no": 3, "char_start": 111, "char_end": 186, "line": "    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{}'\".format(tag)\n"}, {"line_no": 4, "char_start": 186, "char_end": 212, "line": "    scenes = db.exec(sql)\n"}], "added": [{"line_no": 3, "char_start": 111, "char_end": 177, "line": "    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{tag}'\"\n"}, {"line_no": 4, "char_start": 177, "char_end": 201, "line": "    args = {'tag': tag}\n"}, {"line_no": 5, "char_start": 201, "char_end": 233, "line": "    scenes = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 170, "char_end": 181, "chars": "}'\".format("}, {"char_start": 184, "char_end": 185, "chars": ")"}], "added": [{"char_start": 170, "char_end": 196, "chars": "tag}'\"\n    args = {'tag': "}, {"char_start": 199, "char_end": 200, "chars": "}"}, {"char_start": 225, "char_end": 231, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_tournaments_during_month", "func_src_before": "def get_tournaments_during_month(db, scene, date):\n    y, m, d = date.split('-')\n    ym_date = '{}-{}'.format(y, m)\n    sql = \"select url, date from matches where scene='{}' and date like '%{}%' group by url, date order by date\".format(scene, ym_date)\n    res = db.exec(sql)\n    urls = [r[0] for r in res]\n    return urls", "func_src_after": "def get_tournaments_during_month(db, scene, date):\n    y, m, d = date.split('-')\n    ym_date = '{}-{}'.format(y, m)\n    sql = \"select url, date from matches where scene='{scene}' and date like '%{date}%' group by url, date order by date\"\n    args = {'scene': scene, 'date': ym_date}\n    res = db.exec(sql, args)\n    urls = [r[0] for r in res]\n    return urls", "line_changes": {"deleted": [{"line_no": 4, "char_start": 116, "char_end": 252, "line": "    sql = \"select url, date from matches where scene='{}' and date like '%{}%' group by url, date order by date\".format(scene, ym_date)\n"}, {"line_no": 5, "char_start": 252, "char_end": 275, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 4, "char_start": 116, "char_end": 238, "line": "    sql = \"select url, date from matches where scene='{scene}' and date like '%{date}%' group by url, date order by date\"\n"}, {"line_no": 5, "char_start": 238, "char_end": 283, "line": "    args = {'scene': scene, 'date': ym_date}\n"}, {"line_no": 6, "char_start": 283, "char_end": 312, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 228, "char_end": 242, "chars": ".format(scene,"}, {"char_start": 250, "char_end": 251, "chars": ")"}], "added": [{"char_start": 171, "char_end": 176, "chars": "scene"}, {"char_start": 196, "char_end": 200, "chars": "date"}, {"char_start": 237, "char_end": 273, "chars": "\n    args = {'scene': scene, 'date':"}, {"char_start": 281, "char_end": 282, "chars": "}"}, {"char_start": 304, "char_end": 310, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_n_tournaments_before_date", "func_src_before": "def get_n_tournaments_before_date(db, scene, date, limit):\n    sql = \"select url, date from matches where scene='{}' and date<='{}' group by url, date order by date desc limit {};\".format(scene, date, limit)\n    res = db.exec(sql)\n    urls = [r[0] for r in res]\n    return urls, date", "func_src_after": "def get_n_tournaments_before_date(db, scene, date, limit):\n    sql = \"select url, date from matches where scene='{scene}' and date<='{date}' group by url, date order by date desc limit {limit};\"\n    args = {'scene': scene, 'date': date, 'limit': limit}\n    res = db.exec(sql, args)\n    urls = [r[0] for r in res]\n    return urls, date", "line_changes": {"deleted": [{"line_no": 2, "char_start": 59, "char_end": 208, "line": "    sql = \"select url, date from matches where scene='{}' and date<='{}' group by url, date order by date desc limit {};\".format(scene, date, limit)\n"}, {"line_no": 3, "char_start": 208, "char_end": 231, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 2, "char_start": 59, "char_end": 195, "line": "    sql = \"select url, date from matches where scene='{scene}' and date<='{date}' group by url, date order by date desc limit {limit};\"\n"}, {"line_no": 3, "char_start": 195, "char_end": 253, "line": "    args = {'scene': scene, 'date': date, 'limit': limit}\n"}, {"line_no": 4, "char_start": 253, "char_end": 282, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 177, "char_end": 194, "chars": "};\".format(scene,"}, {"char_start": 206, "char_end": 207, "chars": ")"}], "added": [{"char_start": 114, "char_end": 119, "chars": "scene"}, {"char_start": 134, "char_end": 138, "chars": "date"}, {"char_start": 186, "char_end": 230, "chars": "limit};\"\n    args = {'scene': scene, 'date':"}, {"char_start": 237, "char_end": 238, "chars": "'"}, {"char_start": 243, "char_end": 252, "chars": "': limit}"}, {"char_start": 274, "char_end": 280, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_n_tournaments_after_date", "func_src_before": "def get_n_tournaments_after_date(db, scene, date, limit):\n    sql = \"select url, date from matches where scene='{}' and date>='{}' group by url, date order by date desc limit {};\".format(scene, date, limit)\n    res = db.exec(sql)\n    urls = [r[0] for r in res]\n    return urls, date", "func_src_after": "def get_n_tournaments_after_date(db, scene, date, limit):\n    sql = \"select url, date from matches where scene='{scene}' and date>='{date}' group by url, date order by date desc limit {limit};\"\n    args = {'scene': scene, 'date': date, 'limit': limit}\n    res = db.exec(sql, args)\n    urls = [r[0] for r in res]\n    return urls, date", "line_changes": {"deleted": [{"line_no": 2, "char_start": 58, "char_end": 207, "line": "    sql = \"select url, date from matches where scene='{}' and date>='{}' group by url, date order by date desc limit {};\".format(scene, date, limit)\n"}, {"line_no": 3, "char_start": 207, "char_end": 230, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 2, "char_start": 58, "char_end": 194, "line": "    sql = \"select url, date from matches where scene='{scene}' and date>='{date}' group by url, date order by date desc limit {limit};\"\n"}, {"line_no": 3, "char_start": 194, "char_end": 252, "line": "    args = {'scene': scene, 'date': date, 'limit': limit}\n"}, {"line_no": 4, "char_start": 252, "char_end": 281, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 176, "char_end": 193, "chars": "};\".format(scene,"}, {"char_start": 205, "char_end": 206, "chars": ")"}], "added": [{"char_start": 113, "char_end": 118, "chars": "scene"}, {"char_start": 133, "char_end": 137, "chars": "date"}, {"char_start": 185, "char_end": 229, "chars": "limit};\"\n    args = {'scene': scene, 'date':"}, {"char_start": 236, "char_end": 237, "chars": "'"}, {"char_start": 242, "char_end": 251, "chars": "': limit}"}, {"char_start": 273, "char_end": 279, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "get_matches_from_urls", "func_src_before": "def get_matches_from_urls(db, urls):\n    matches = set()\n    for url in urls:\n        sql = \"SELECT * FROM matches WHERE url='{}';\".format(url)\n        res = set(db.exec(sql))\n        matches |= set(res)\n\n    return matches", "func_src_after": "def get_matches_from_urls(db, urls):\n    matches = set()\n    for url in urls:\n        sql = \"SELECT * FROM matches WHERE url='{url}';\"\n        args = {'url': url}\n        res = set(db.exec(sql, args))\n        matches |= set(res)\n\n    return matches", "line_changes": {"deleted": [{"line_no": 4, "char_start": 78, "char_end": 144, "line": "        sql = \"SELECT * FROM matches WHERE url='{}';\".format(url)\n"}, {"line_no": 5, "char_start": 144, "char_end": 176, "line": "        res = set(db.exec(sql))\n"}], "added": [{"line_no": 4, "char_start": 78, "char_end": 135, "line": "        sql = \"SELECT * FROM matches WHERE url='{url}';\"\n"}, {"line_no": 5, "char_start": 135, "char_end": 163, "line": "        args = {'url': url}\n"}, {"line_no": 6, "char_start": 163, "char_end": 201, "line": "        res = set(db.exec(sql, args))\n"}]}, "char_changes": {"deleted": [{"char_start": 131, "char_end": 139, "chars": ".format("}, {"char_start": 142, "char_end": 143, "chars": ")"}], "added": [{"char_start": 127, "char_end": 130, "chars": "url"}, {"char_start": 134, "char_end": 162, "chars": "\n        args = {'url': url}"}, {"char_start": 192, "char_end": 198, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089"}
{"func_name": "player", "func_src_before": "@endpoints.route(\"/player\")\ndef player():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=\"christmasmike\").capitalize()\n    sql = \"SELECT count(*) FROM matches WHERE winner='{}'\".format(tag)\n    wins = db.exec(sql)[0][0]\n    \n    sql = \"SELECT count(*) FROM matches WHERE (player1='{}' or player2='{}') AND NOT winner='{}'\".format(tag, tag, tag)\n    losses = db.exec(sql)[0][0]\n\n    percentage = (0.0+int(1000*((0.0+wins)/(0.0+losses+wins))))/10\n\n    sql = \"select rank from players join ranks where players.scene=ranks.scene and players.tag=ranks.player and players.tag='{}' order by date desc limit 1;\".format(tag)\n    res = db.exec(sql)\n    rank = 0\n    if len(res) > 0:\n        rank = res[0][0]\n\n\n    sql = \"SELECT scene FROM players WHERE tag='{}'\".format(tag)\n    scene = db.exec(sql)[0][0].capitalize()\n\n    ranks_data, months_ranked = bracket_utils.get_ranking_graph_data(db, tag)\n    ranks_data = json.dumps(ranks_data)\n    months_ranked = json.dumps(months_ranked)\n\n    brackets_data = bracket_utils.get_bracket_graph_data(db, tag)\n    months_played = []\n    for s in brackets_data:\n        months_played.extend([bracket[0] for bracket in brackets_data[s]])\n\n    months_played = sorted(months_played)\n\n    return render_template('libraries/html/player.html', tag=tag, wins=wins, losses=losses, percentage=percentage, rank=rank, scene=scene, ranks_data=ranks_data, months_ranked=months_ranked, brackets_data=brackets_data, months_played=months_played)", "func_src_after": "@endpoints.route(\"/player\")\ndef player():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=\"christmasmike\").capitalize()\n    sql = \"SELECT count(*) FROM matches WHERE winner='{tag}'\"\n    args = {'tag': tag}\n    wins = db.exec(sql, args)[0][0]\n    \n    sql = \"SELECT count(*) FROM matches WHERE (player1='{tag}' or player2='{tag}') AND NOT winner='{tag}'\"\n    args = {'tag': tag}\n    losses = db.exec(sql, args)[0][0]\n\n    percentage = (0.0+int(1000*((0.0+wins)/(0.0+losses+wins))))/10\n\n    sql = \"select rank, players.scene from players join ranks where players.scene=ranks.scene and players.tag=ranks.player and players.tag='{tag}' order by date desc limit 1;\"\n    args = {'tag': tag}\n    res = db.exec(sql, args)\n    rank = 0\n    scene = ''\n    if len(res) > 0:\n        rank = res[0][0]\n        scene = res[0][1]\n\n\n    ranks_data, months_ranked = bracket_utils.get_ranking_graph_data(db, tag)\n    ranks_data = json.dumps(ranks_data)\n    months_ranked = json.dumps(months_ranked)\n\n    brackets_data = bracket_utils.get_bracket_graph_data(db, tag)\n    months_played = []\n    for s in brackets_data:\n        months_played.extend([bracket[0] for bracket in brackets_data[s]])\n\n    months_played = sorted(months_played)\n\n    return render_template('libraries/html/player.html', tag=tag, wins=wins, losses=losses, percentage=percentage, rank=rank, scene=scene, ranks_data=ranks_data, months_ranked=months_ranked, brackets_data=brackets_data, months_played=months_played)", "line_changes": {"deleted": [{"line_no": 7, "char_start": 149, "char_end": 220, "line": "    sql = \"SELECT count(*) FROM matches WHERE winner='{}'\".format(tag)\n"}, {"line_no": 8, "char_start": 220, "char_end": 250, "line": "    wins = db.exec(sql)[0][0]\n"}, {"line_no": 10, "char_start": 255, "char_end": 375, "line": "    sql = \"SELECT count(*) FROM matches WHERE (player1='{}' or player2='{}') AND NOT winner='{}'\".format(tag, tag, tag)\n"}, {"line_no": 11, "char_start": 375, "char_end": 407, "line": "    losses = db.exec(sql)[0][0]\n"}, {"line_no": 15, "char_start": 476, "char_end": 646, "line": "    sql = \"select rank from players join ranks where players.scene=ranks.scene and players.tag=ranks.player and players.tag='{}' order by date desc limit 1;\".format(tag)\n"}, {"line_no": 16, "char_start": 646, "char_end": 669, "line": "    res = db.exec(sql)\n"}, {"line_no": 22, "char_start": 730, "char_end": 795, "line": "    sql = \"SELECT scene FROM players WHERE tag='{}'\".format(tag)\n"}, {"line_no": 23, "char_start": 795, "char_end": 839, "line": "    scene = db.exec(sql)[0][0].capitalize()\n"}, {"line_no": 24, "char_start": 839, "char_end": 840, "line": "\n"}], "added": [{"line_no": 7, "char_start": 149, "char_end": 211, "line": "    sql = \"SELECT count(*) FROM matches WHERE winner='{tag}'\"\n"}, {"line_no": 8, "char_start": 211, "char_end": 235, "line": "    args = {'tag': tag}\n"}, {"line_no": 9, "char_start": 235, "char_end": 271, "line": "    wins = db.exec(sql, args)[0][0]\n"}, {"line_no": 11, "char_start": 276, "char_end": 383, "line": "    sql = \"SELECT count(*) FROM matches WHERE (player1='{tag}' or player2='{tag}') AND NOT winner='{tag}'\"\n"}, {"line_no": 12, "char_start": 383, "char_end": 407, "line": "    args = {'tag': tag}\n"}, {"line_no": 13, "char_start": 407, "char_end": 445, "line": "    losses = db.exec(sql, args)[0][0]\n"}, {"line_no": 17, "char_start": 514, "char_end": 690, "line": "    sql = \"select rank, players.scene from players join ranks where players.scene=ranks.scene and players.tag=ranks.player and players.tag='{tag}' order by date desc limit 1;\"\n"}, {"line_no": 18, "char_start": 690, "char_end": 714, "line": "    args = {'tag': tag}\n"}, {"line_no": 19, "char_start": 714, "char_end": 743, "line": "    res = db.exec(sql, args)\n"}, {"line_no": 21, "char_start": 756, "char_end": 771, "line": "    scene = ''\n"}, {"line_no": 24, "char_start": 817, "char_end": 843, "line": "        scene = res[0][1]\n"}]}, "char_changes": {"deleted": [{"char_start": 204, "char_end": 215, "chars": "}'\".format("}, {"char_start": 218, "char_end": 219, "chars": ")"}, {"char_start": 349, "char_end": 365, "chars": "}'\".format(tag, "}, {"char_start": 368, "char_end": 369, "chars": ","}, {"char_start": 373, "char_end": 374, "chars": ")"}, {"char_start": 633, "char_end": 641, "chars": ".format("}, {"char_start": 644, "char_end": 645, "chars": ")"}, {"char_start": 728, "char_end": 730, "chars": "\n\n"}, {"char_start": 734, "char_end": 838, "chars": "sql = \"SELECT scene FROM players WHERE tag='{}'\".format(tag)\n    scene = db.exec(sql)[0][0].capitalize()"}], "added": [{"char_start": 204, "char_end": 230, "chars": "tag}'\"\n    args = {'tag': "}, {"char_start": 233, "char_end": 234, "chars": "}"}, {"char_start": 257, "char_end": 263, "chars": ", args"}, {"char_start": 333, "char_end": 336, "chars": "tag"}, {"char_start": 352, "char_end": 355, "chars": "tag"}, {"char_start": 376, "char_end": 396, "chars": "tag}'\"\n    args = {'"}, {"char_start": 399, "char_end": 401, "chars": "':"}, {"char_start": 405, "char_end": 406, "chars": "}"}, {"char_start": 431, "char_end": 437, "chars": ", args"}, {"char_start": 536, "char_end": 551, "chars": ", players.scene"}, {"char_start": 655, "char_end": 658, "chars": "tag"}, {"char_start": 689, "char_end": 709, "chars": "\n    args = {'tag': "}, {"char_start": 712, "char_end": 713, "chars": "}"}, {"char_start": 735, "char_end": 741, "chars": ", args"}, {"char_start": 756, "char_end": 771, "chars": "    scene = ''\n"}, {"char_start": 821, "char_end": 843, "chars": "    scene = res[0][1]\n"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "ranks", "func_src_before": "@endpoints.route(\"/ranks\")\ndef ranks():\n    if db == None:\n        init()\n\n    scene = request.args.get('scene', default='austin')\n    date = request.args.get('date')\n \n    # If no date was provided, pick the date of the latest tournament\n    if date == None:\n        sql = \"SELECT distinct date FROM ranks WHERE scene='{}' ORDER BY date DESC LIMIT 1;\".format(scene)\n        res = db.exec(sql)\n        date = res[0][0]\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM ranks WHERE scene = '{}' and date='{}'\".format(scene, date)\n    res = db.exec(sql)\n\n    # Make a dict out of this data\n    # eg {'christmasmike': 50}\n    cur_ranks = {}\n    for r in res:\n        tag = r[1]\n        rank = r[2]\n\n        cur_ranks[tag] = rank\n\n    # Now get the ranks from last month, so we know if these players went up or down\n    y, m, d = date.split('-')\n    prev_date = bracket_utils.get_previous_month(date)\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM ranks WHERE scene = '{}' and date='{}'\".format(scene, prev_date)\n    res = db.exec(sql)\n\n    # Make a dict out of this data\n    # eg {'christmasmike': 50}\n    prev_ranks = {}\n    for r in res:\n        tag = r[1]\n        rank = r[2]\n\n        prev_ranks[tag] = rank\n\n    return render_template('libraries/html/ranks.html', cur_ranks=cur_ranks, prev_ranks=prev_ranks, scene=scene, date=date)", "func_src_after": "@endpoints.route(\"/ranks\")\ndef ranks():\n    if db == None:\n        init()\n\n    scene = request.args.get('scene', default='austin')\n    date = request.args.get('date')\n \n    # If no date was provided, pick the date of the latest tournament\n    if date == None:\n        sql = \"SELECT distinct date FROM ranks WHERE scene='{scene}' ORDER BY date DESC LIMIT 1;\"\n        args = {'scene': scene}\n        res = db.exec(sql, args)\n        date = res[0][0]\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM ranks WHERE scene = '{scene}' and date='{date}'\"\n    args = {'scene': scene, 'date': date}\n    res = db.exec(sql, args)\n\n    # Make a dict out of this data\n    # eg {'christmasmike': 50}\n    cur_ranks = {}\n    for r in res:\n        tag = r[1]\n        rank = r[2]\n\n        cur_ranks[tag] = rank\n\n    # Now get the ranks from last month, so we know if these players went up or down\n    y, m, d = date.split('-')\n    prev_date = bracket_utils.get_previous_month(date)\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM ranks WHERE scene = '{scene}' and date='{date}'\"\n    args = {'scene': scene, 'date': prev_date}\n    res = db.exec(sql, args)\n\n    # Make a dict out of this data\n    # eg {'christmasmike': 50}\n    prev_ranks = {}\n    for r in res:\n        tag = r[1]\n        rank = r[2]\n\n        prev_ranks[tag] = rank\n\n    return render_template('libraries/html/ranks.html', cur_ranks=cur_ranks, prev_ranks=prev_ranks, scene=scene, date=date)", "line_changes": {"deleted": [{"line_no": 11, "char_start": 260, "char_end": 367, "line": "        sql = \"SELECT distinct date FROM ranks WHERE scene='{}' ORDER BY date DESC LIMIT 1;\".format(scene)\n"}, {"line_no": 12, "char_start": 367, "char_end": 394, "line": "        res = db.exec(sql)\n"}, {"line_no": 16, "char_start": 480, "char_end": 565, "line": "    sql = \"SELECT * FROM ranks WHERE scene = '{}' and date='{}'\".format(scene, date)\n"}, {"line_no": 17, "char_start": 565, "char_end": 588, "line": "    res = db.exec(sql)\n"}, {"line_no": 33, "char_start": 994, "char_end": 1084, "line": "    sql = \"SELECT * FROM ranks WHERE scene = '{}' and date='{}'\".format(scene, prev_date)\n"}, {"line_no": 34, "char_start": 1084, "char_end": 1107, "line": "    res = db.exec(sql)\n"}], "added": [{"line_no": 11, "char_start": 260, "char_end": 358, "line": "        sql = \"SELECT distinct date FROM ranks WHERE scene='{scene}' ORDER BY date DESC LIMIT 1;\"\n"}, {"line_no": 12, "char_start": 358, "char_end": 390, "line": "        args = {'scene': scene}\n"}, {"line_no": 13, "char_start": 390, "char_end": 423, "line": "        res = db.exec(sql, args)\n"}, {"line_no": 17, "char_start": 509, "char_end": 583, "line": "    sql = \"SELECT * FROM ranks WHERE scene = '{scene}' and date='{date}'\"\n"}, {"line_no": 18, "char_start": 583, "char_end": 625, "line": "    args = {'scene': scene, 'date': date}\n"}, {"line_no": 19, "char_start": 625, "char_end": 654, "line": "    res = db.exec(sql, args)\n"}, {"line_no": 35, "char_start": 1060, "char_end": 1134, "line": "    sql = \"SELECT * FROM ranks WHERE scene = '{scene}' and date='{date}'\"\n"}, {"line_no": 36, "char_start": 1134, "char_end": 1181, "line": "    args = {'scene': scene, 'date': prev_date}\n"}, {"line_no": 37, "char_start": 1181, "char_end": 1210, "line": "    res = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 352, "char_end": 366, "chars": ".format(scene)"}, {"char_start": 541, "char_end": 552, "chars": "}'\".format("}, {"char_start": 563, "char_end": 564, "chars": ")"}, {"char_start": 1055, "char_end": 1072, "chars": "}'\".format(scene,"}, {"char_start": 1082, "char_end": 1083, "chars": ")"}], "added": [{"char_start": 321, "char_end": 326, "chars": "scene"}, {"char_start": 357, "char_end": 389, "chars": "\n        args = {'scene': scene}"}, {"char_start": 415, "char_end": 421, "chars": ", args"}, {"char_start": 556, "char_end": 561, "chars": "scene"}, {"char_start": 575, "char_end": 604, "chars": "date}'\"\n    args = {'scene': "}, {"char_start": 611, "char_end": 612, "chars": "'"}, {"char_start": 616, "char_end": 624, "chars": "': date}"}, {"char_start": 646, "char_end": 652, "chars": ", args"}, {"char_start": 1107, "char_end": 1112, "chars": "scene"}, {"char_start": 1126, "char_end": 1169, "chars": "date}'\"\n    args = {'scene': scene, 'date':"}, {"char_start": 1179, "char_end": 1180, "chars": "}"}, {"char_start": 1202, "char_end": 1208, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "wins", "func_src_before": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '\"+str(player)+\"' ORDER BY date DESC;\"\n    result = db.exec(sql)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '{player}' ORDER BY date DESC;\"\n    args = {'player': player}\n    result = db.exec(sql, args)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "line_changes": {"deleted": [{"line_no": 7, "char_start": 135, "char_end": 222, "line": "    sql = \"SELECT * FROM matches WHERE winner = '\"+str(player)+\"' ORDER BY date DESC;\"\n"}, {"line_no": 8, "char_start": 222, "char_end": 248, "line": "    result = db.exec(sql)\n"}], "added": [{"line_no": 7, "char_start": 135, "char_end": 215, "line": "    sql = \"SELECT * FROM matches WHERE winner = '{player}' ORDER BY date DESC;\"\n"}, {"line_no": 8, "char_start": 215, "char_end": 245, "line": "    args = {'player': player}\n"}, {"line_no": 9, "char_start": 245, "char_end": 277, "line": "    result = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 184, "char_end": 190, "chars": "\"+str("}, {"char_start": 196, "char_end": 199, "chars": ")+\""}], "added": [{"char_start": 184, "char_end": 185, "chars": "{"}, {"char_start": 191, "char_end": 192, "chars": "}"}, {"char_start": 215, "char_end": 245, "chars": "    args = {'player': player}\n"}, {"char_start": 269, "char_end": 275, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "losses", "func_src_before": "@endpoints.route(\"/losses\")\ndef losses():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '\"+str(player)+\"' OR \"\\\n            +\"player2 = '\"+str(player)+\"') AND winner != '\"+str(player)+\"' ORDER BY date DESC;\"\n    result = db.exec(sql)\n\n    result = [str(x) for x in result]\n    return json.dumps('\\n'.join(result))", "func_src_after": "@endpoints.route(\"/losses\")\ndef losses():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '{player}' OR \"\\\n            +\"player2 = '{player}') AND winner != '{player}' ORDER BY date DESC;\"\n    args  = {'player': player}\n    result = db.exec(sql, args)\n\n    result = [str(x) for x in result]\n    return json.dumps('\\n'.join(result))", "line_changes": {"deleted": [{"line_no": 7, "char_start": 139, "char_end": 213, "line": "    sql = \"SELECT * FROM matches WHERE (player1 = '\"+str(player)+\"' OR \"\\\n"}, {"line_no": 8, "char_start": 213, "char_end": 309, "line": "            +\"player2 = '\"+str(player)+\"') AND winner != '\"+str(player)+\"' ORDER BY date DESC;\"\n"}, {"line_no": 9, "char_start": 309, "char_end": 335, "line": "    result = db.exec(sql)\n"}], "added": [{"line_no": 7, "char_start": 139, "char_end": 206, "line": "    sql = \"SELECT * FROM matches WHERE (player1 = '{player}' OR \"\\\n"}, {"line_no": 8, "char_start": 206, "char_end": 288, "line": "            +\"player2 = '{player}') AND winner != '{player}' ORDER BY date DESC;\"\n"}, {"line_no": 9, "char_start": 288, "char_end": 319, "line": "    args  = {'player': player}\n"}, {"line_no": 10, "char_start": 319, "char_end": 351, "line": "    result = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 190, "char_end": 196, "chars": "\"+str("}, {"char_start": 202, "char_end": 205, "chars": ")+\""}, {"char_start": 238, "char_end": 244, "chars": "\"+str("}, {"char_start": 250, "char_end": 253, "chars": ")+\""}, {"char_start": 271, "char_end": 277, "chars": "\"+str("}, {"char_start": 283, "char_end": 286, "chars": ")+\""}], "added": [{"char_start": 190, "char_end": 191, "chars": "{"}, {"char_start": 197, "char_end": 198, "chars": "}"}, {"char_start": 231, "char_end": 232, "chars": "{"}, {"char_start": 238, "char_end": 239, "chars": "}"}, {"char_start": 257, "char_end": 258, "chars": "{"}, {"char_start": 264, "char_end": 265, "chars": "}"}, {"char_start": 288, "char_end": 319, "chars": "    args  = {'player': player}\n"}, {"char_start": 343, "char_end": 349, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "h2h", "func_src_before": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '\"+str(player1)+\"' OR \"\\\n            +\"player2 = '\"+str(player1)+\"') AND (player1 = '\"+str(player2)+\"' OR \"\\\n            +\"player2 = '\"+str(player2)+\"') ORDER BY date DESC;\"\n    result = db.exec(sql)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '{player1}' OR \"\\\n            +\"player2 = '{player1}') AND (player1 = '{player2}' OR \"\\\n            +\"player2 = '{player2}') ORDER BY date DESC;\"\n    args = {'player1': player1, 'player2': player2}\n    result = db.exec(sql, args)\n    return json.dumps(result)", "line_changes": {"deleted": [{"line_no": 8, "char_start": 199, "char_end": 274, "line": "    sql = \"SELECT * FROM matches WHERE (player1 = '\"+str(player1)+\"' OR \"\\\n"}, {"line_no": 9, "char_start": 274, "char_end": 358, "line": "            +\"player2 = '\"+str(player1)+\"') AND (player1 = '\"+str(player2)+\"' OR \"\\\n"}, {"line_no": 10, "char_start": 358, "char_end": 423, "line": "            +\"player2 = '\"+str(player2)+\"') ORDER BY date DESC;\"\n"}, {"line_no": 11, "char_start": 423, "char_end": 449, "line": "    result = db.exec(sql)\n"}], "added": [{"line_no": 8, "char_start": 199, "char_end": 267, "line": "    sql = \"SELECT * FROM matches WHERE (player1 = '{player1}' OR \"\\\n"}, {"line_no": 9, "char_start": 267, "char_end": 337, "line": "            +\"player2 = '{player1}') AND (player1 = '{player2}' OR \"\\\n"}, {"line_no": 10, "char_start": 337, "char_end": 395, "line": "            +\"player2 = '{player2}') ORDER BY date DESC;\"\n"}, {"line_no": 11, "char_start": 395, "char_end": 447, "line": "    args = {'player1': player1, 'player2': player2}\n"}, {"line_no": 12, "char_start": 447, "char_end": 479, "line": "    result = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 250, "char_end": 256, "chars": "\"+str("}, {"char_start": 263, "char_end": 266, "chars": ")+\""}, {"char_start": 299, "char_end": 305, "chars": "\"+str("}, {"char_start": 312, "char_end": 315, "chars": ")+\""}, {"char_start": 334, "char_end": 340, "chars": "\"+str("}, {"char_start": 347, "char_end": 350, "chars": ")+\""}, {"char_start": 383, "char_end": 389, "chars": "\"+str("}, {"char_start": 396, "char_end": 399, "chars": ")+\""}], "added": [{"char_start": 250, "char_end": 251, "chars": "{"}, {"char_start": 258, "char_end": 259, "chars": "}"}, {"char_start": 292, "char_end": 293, "chars": "{"}, {"char_start": 300, "char_end": 301, "chars": "}"}, {"char_start": 320, "char_end": 321, "chars": "{"}, {"char_start": 328, "char_end": 329, "chars": "}"}, {"char_start": 362, "char_end": 363, "chars": "{"}, {"char_start": 370, "char_end": 371, "chars": "}"}, {"char_start": 395, "char_end": 447, "chars": "    args = {'player1': player1, 'player2': player2}\n"}, {"char_start": 471, "char_end": 477, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "placings", "func_src_before": "@endpoints.route(\"/placings\")\ndef placings():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default='christmas mike')\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM placings WHERE player = '{}'\".format(tag)\n    results = list(db.exec(sql))\n    results.sort(key=lambda x: int(x[2]))\n\n    return json.dumps(results)", "func_src_after": "@endpoints.route(\"/placings\")\ndef placings():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default='christmas mike')\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM placings WHERE player = '{tag}'\"\n    args = {'tag': tag}\n    results = list(db.exec(sql, args))\n    results.sort(key=lambda x: int(x[2]))\n\n    return json.dumps(results)", "line_changes": {"deleted": [{"line_no": 9, "char_start": 202, "char_end": 269, "line": "    sql = \"SELECT * FROM placings WHERE player = '{}'\".format(tag)\n"}, {"line_no": 10, "char_start": 269, "char_end": 302, "line": "    results = list(db.exec(sql))\n"}], "added": [{"line_no": 9, "char_start": 202, "char_end": 260, "line": "    sql = \"SELECT * FROM placings WHERE player = '{tag}'\"\n"}, {"line_no": 10, "char_start": 260, "char_end": 284, "line": "    args = {'tag': tag}\n"}, {"line_no": 11, "char_start": 284, "char_end": 323, "line": "    results = list(db.exec(sql, args))\n"}]}, "char_changes": {"deleted": [{"char_start": 253, "char_end": 264, "chars": "}'\".format("}, {"char_start": 267, "char_end": 268, "chars": ")"}], "added": [{"char_start": 253, "char_end": 279, "chars": "tag}'\"\n    args = {'tag': "}, {"char_start": 282, "char_end": 283, "chars": "}"}, {"char_start": 314, "char_end": 320, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "matches_at_date", "func_src_before": "@endpoints.route('/matches_at_date')\ndef matches_at_date():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n\n    if tag and date:\n        y, m, d = date.split('-')\n        previous_m = '12' if m == '01' else str(int(m)-1)\n        previous_m = previous_m.zfill(2)\n        previous_y = str(int(y)-1) if m == '01' else y\n        previous_date = '{}-{}-{}'.format(previous_y, previous_m, d)\n        sql = \"select * from matches where (player1='{}' or player2='{}') and date<='{}' and date>='{}'\".format(tag, tag, date, previous_date); \n\n        data = db.exec(sql)\n\n        return json.dumps(data)\n    \n    return ''", "func_src_after": "@endpoints.route('/matches_at_date')\ndef matches_at_date():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n\n    if tag and date:\n        y, m, d = date.split('-')\n        previous_m = '12' if m == '01' else str(int(m)-1)\n        previous_m = previous_m.zfill(2)\n        previous_y = str(int(y)-1) if m == '01' else y\n        previous_date = '{}-{}-{}'.format(previous_y, previous_m, d)\n        sql = \"select * from matches where (player1='{tag}' or player2='{tag}') and date<='{date}' and date>='{prev_date}'\"\n        args = {'tag': tag, 'date': date, 'prev_date': previous_date}\n\n        data = db.exec(sql, args)\n\n        return json.dumps(data)\n    \n    return ''", "line_changes": {"deleted": [{"line_no": 15, "char_start": 472, "char_end": 617, "line": "        sql = \"select * from matches where (player1='{}' or player2='{}') and date<='{}' and date>='{}'\".format(tag, tag, date, previous_date); \n"}, {"line_no": 17, "char_start": 618, "char_end": 646, "line": "        data = db.exec(sql)\n"}], "added": [{"line_no": 15, "char_start": 472, "char_end": 596, "line": "        sql = \"select * from matches where (player1='{tag}' or player2='{tag}') and date<='{date}' and date>='{prev_date}'\"\n"}, {"line_no": 16, "char_start": 596, "char_end": 666, "line": "        args = {'tag': tag, 'date': date, 'prev_date': previous_date}\n"}, {"line_no": 18, "char_start": 667, "char_end": 701, "line": "        data = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 573, "char_end": 584, "chars": "}'\".format("}, {"char_start": 587, "char_end": 588, "chars": ","}, {"char_start": 594, "char_end": 599, "chars": "date,"}, {"char_start": 613, "char_end": 616, "chars": "); "}], "added": [{"char_start": 526, "char_end": 529, "chars": "tag"}, {"char_start": 545, "char_end": 548, "chars": "tag"}, {"char_start": 564, "char_end": 568, "chars": "date"}, {"char_start": 583, "char_end": 613, "chars": "prev_date}'\"\n        args = {'"}, {"char_start": 616, "char_end": 618, "chars": "':"}, {"char_start": 624, "char_end": 650, "chars": "'date': date, 'prev_date':"}, {"char_start": 664, "char_end": 665, "chars": "}"}, {"char_start": 693, "char_end": 699, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "tournament_wins", "func_src_before": "@endpoints.route('/tournament_wins')\ndef tournament_wins():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n\n    if tag and date:\n        sql = \"select player1, place, date, score from matches join placings on matches.url=placings.url and matches.player1=placings.player \\\n                where winner='{}' and player2='{}' and date='{}';\".format(tag, tag, date)\n        data = db.exec(sql)\n        sql = \"select player2, place, date, score from matches join placings on matches.url=placings.url and matches.player2=placings.player \\\n                where winner='{}' and player1='{}' and date='{}';\".format(tag, tag, date)\n        data = data + db.exec(sql)\n\n        data = [r for r in data]\n        data.sort(key=lambda x: int(x[1]))\n\n        # Before we return this data, reformat score data from [2,1] -> 2 - 1, for eg\n        def reformat(score):\n            score = score.replace('[', '')\n            score = score.replace(']', '')\n            win, loss = score.split(',')\n            score = '{} - {}'.format(win, loss)\n            return score\n        data = [[r[0], r[1], r[2], reformat(r[3])] for r in data]\n        return json.dumps(data)\n    \n    return ''", "func_src_after": "@endpoints.route('/tournament_wins')\ndef tournament_wins():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n\n    if tag and date:\n        sql = \"select player1, place, date, score from matches join placings on matches.url=placings.url and matches.player1=placings.player \\\n                where winner='{tag}' and player2='{tag}' and date='{date}';\"\n        args = {'tag': tag, 'date': date}\n        data = db.exec(sql, args)\n\n        sql = \"select player2, place, date, score from matches join placings on matches.url=placings.url and matches.player2=placings.player \\\n                where winner='{tag}' and player1='{tag}' and date='{date}';\"\n        data = data + db.exec(sql, args)\n\n        data = [r for r in data]\n        data.sort(key=lambda x: int(x[1]))\n\n        # Before we return this data, reformat score data from [2,1] -> 2 - 1, for eg\n        def reformat(score):\n            score = score.replace('[', '')\n            score = score.replace(']', '')\n            win, loss = score.split(',')\n            score = '{} - {}'.format(win, loss)\n            return score\n        data = [[r[0], r[1], r[2], reformat(r[3])] for r in data]\n        return json.dumps(data)\n    \n    return ''", "line_changes": {"deleted": [{"line_no": 11, "char_start": 358, "char_end": 448, "line": "                where winner='{}' and player2='{}' and date='{}';\".format(tag, tag, date)\n"}, {"line_no": 12, "char_start": 448, "char_end": 476, "line": "        data = db.exec(sql)\n"}, {"line_no": 14, "char_start": 619, "char_end": 709, "line": "                where winner='{}' and player1='{}' and date='{}';\".format(tag, tag, date)\n"}, {"line_no": 15, "char_start": 709, "char_end": 744, "line": "        data = data + db.exec(sql)\n"}], "added": [{"line_no": 11, "char_start": 358, "char_end": 435, "line": "                where winner='{tag}' and player2='{tag}' and date='{date}';\"\n"}, {"line_no": 12, "char_start": 435, "char_end": 477, "line": "        args = {'tag': tag, 'date': date}\n"}, {"line_no": 13, "char_start": 477, "char_end": 511, "line": "        data = db.exec(sql, args)\n"}, {"line_no": 14, "char_start": 511, "char_end": 512, "line": "\n"}, {"line_no": 16, "char_start": 655, "char_end": 732, "line": "                where winner='{tag}' and player1='{tag}' and date='{date}';\"\n"}, {"line_no": 17, "char_start": 732, "char_end": 773, "line": "        data = data + db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 420, "char_end": 432, "chars": "}';\".format("}, {"char_start": 435, "char_end": 436, "chars": ","}, {"char_start": 446, "char_end": 447, "chars": ")"}, {"char_start": 685, "char_end": 708, "chars": ".format(tag, tag, date)"}], "added": [{"char_start": 389, "char_end": 392, "chars": "tag"}, {"char_start": 409, "char_end": 412, "chars": "tag"}, {"char_start": 426, "char_end": 452, "chars": "date}';\"\n        args = {'"}, {"char_start": 455, "char_end": 457, "chars": "':"}, {"char_start": 463, "char_end": 464, "chars": "'"}, {"char_start": 468, "char_end": 476, "chars": "': date}"}, {"char_start": 503, "char_end": 509, "chars": ", args"}, {"char_start": 511, "char_end": 512, "chars": "\n"}, {"char_start": 686, "char_end": 689, "chars": "tag"}, {"char_start": 706, "char_end": 709, "chars": "tag"}, {"char_start": 723, "char_end": 727, "chars": "date"}, {"char_start": 765, "char_end": 771, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "tournament_losses", "func_src_before": "@endpoints.route('/tournament_losses')\ndef tournament_losses():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n\n    if tag and date:\n        sql = \"select player1, place, date, score from matches join placings on matches.url=placings.url and matches.player1=placings.player \\\n                where winner!='{}' and player2='{}' and date='{}';\".format(tag, tag, date)\n        data = db.exec(sql)\n\n        sql = \"select player2, place, date, score from matches join placings on matches.url=placings.url and matches.player2=placings.player \\\n                where winner!='{}' and player1='{}' and date='{}';\".format(tag, tag, date)\n        data = data + db.exec(sql)\n\n        data = [r for r in data]\n        data.sort(key=lambda x: int(x[1]))\n\n        # Before we return this data, reformat score data from [2,1] -> 2 - 1, for eg\n        def reformat(score):\n            score = score.replace('[', '')\n            score = score.replace(']', '')\n            win, loss = score.split(',')\n            score = '{} - {}'.format(win, loss)\n            return score\n        data = [[r[0], r[1], r[2], reformat(r[3])] for r in data]\n        return json.dumps(data)\n    \n    return ''", "func_src_after": "@endpoints.route('/tournament_losses')\ndef tournament_losses():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n\n    if tag and date:\n        sql = \"select player1, place, date, score from matches join placings on matches.url=placings.url and matches.player1=placings.player \\\n                where winner!='{tag}' and player2='{tag}' and date='{date}';\"\n        args = {'tag': tag, 'date': date}\n        data = db.exec(sql, args)\n\n        sql = \"select player2, place, date, score from matches join placings on matches.url=placings.url and matches.player2=placings.player \\\n                where winner!='{tag}' and player1='{tag}' and date='{date}';\"\n        data = data + db.exec(sql, args)\n\n        data = [r for r in data]\n        data.sort(key=lambda x: int(x[1]))\n\n        # Before we return this data, reformat score data from [2,1] -> 2 - 1, for eg\n        def reformat(score):\n            score = score.replace('[', '')\n            score = score.replace(']', '')\n            win, loss = score.split(',')\n            score = '{} - {}'.format(win, loss)\n            return score\n        data = [[r[0], r[1], r[2], reformat(r[3])] for r in data]\n        return json.dumps(data)\n    \n    return ''", "line_changes": {"deleted": [{"line_no": 11, "char_start": 362, "char_end": 453, "line": "                where winner!='{}' and player2='{}' and date='{}';\".format(tag, tag, date)\n"}, {"line_no": 12, "char_start": 453, "char_end": 481, "line": "        data = db.exec(sql)\n"}, {"line_no": 15, "char_start": 625, "char_end": 716, "line": "                where winner!='{}' and player1='{}' and date='{}';\".format(tag, tag, date)\n"}, {"line_no": 16, "char_start": 716, "char_end": 751, "line": "        data = data + db.exec(sql)\n"}], "added": [{"line_no": 11, "char_start": 362, "char_end": 440, "line": "                where winner!='{tag}' and player2='{tag}' and date='{date}';\"\n"}, {"line_no": 12, "char_start": 440, "char_end": 482, "line": "        args = {'tag': tag, 'date': date}\n"}, {"line_no": 13, "char_start": 482, "char_end": 516, "line": "        data = db.exec(sql, args)\n"}, {"line_no": 16, "char_start": 660, "char_end": 738, "line": "                where winner!='{tag}' and player1='{tag}' and date='{date}';\"\n"}, {"line_no": 17, "char_start": 738, "char_end": 779, "line": "        data = data + db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 425, "char_end": 437, "chars": "}';\".format("}, {"char_start": 440, "char_end": 441, "chars": ","}, {"char_start": 451, "char_end": 452, "chars": ")"}, {"char_start": 692, "char_end": 715, "chars": ".format(tag, tag, date)"}], "added": [{"char_start": 394, "char_end": 397, "chars": "tag"}, {"char_start": 414, "char_end": 417, "chars": "tag"}, {"char_start": 431, "char_end": 457, "chars": "date}';\"\n        args = {'"}, {"char_start": 460, "char_end": 462, "chars": "':"}, {"char_start": 468, "char_end": 469, "chars": "'"}, {"char_start": 473, "char_end": 481, "chars": "': date}"}, {"char_start": 508, "char_end": 514, "chars": ", args"}, {"char_start": 692, "char_end": 695, "chars": "tag"}, {"char_start": 712, "char_end": 715, "chars": "tag"}, {"char_start": 729, "char_end": 733, "chars": "date"}, {"char_start": 771, "char_end": 777, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "big_wins", "func_src_before": "@endpoints.route('/big_wins')\ndef big_wins():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n    scene = request.args.get('scene', default=None)\n    \n    valid = not (tag == None and date == None)\n    if valid:\n        # This sql statement is a bit of a doozy...\n        select = 'select ranks.player, ranks.rank, matches.date, matches.score'\n        frm = 'from matches join ranks where ((ranks.player=matches.player1 and matches.player2=\"{}\")'.format(tag)\n        player_where = 'or (ranks.player=matches.player2 and matches.player1=\"{}\")) and winner=\"{}\"'.format(tag, tag)\n        date_where = 'and matches.scene=ranks.scene and datediff(ranks.date, matches.date)<=31 and ranks.date>matches.date'\n        also_date_where = 'and ranks.date=\"{}\"'.format(date)\n        scene_where = 'and ranks.scene=\"{}\"'.format(scene)\n        order = 'order by rank;'\n\n\n        sql = '{} {} {} {} {} {} {}'.format(select, frm, player_where, date_where, also_date_where, scene_where, order)\n        data = db.exec(sql)\n\n        # Before we return this data, reformat score data from [2,1] -> 2 - 1, for eg\n        def reformat(score):\n            score = score.replace('[', '')\n            score = score.replace(']', '')\n            win, loss = score.split(',')\n            score = '{} - {}'.format(win, loss)\n            return score\n        data = [[r[0], r[1], r[2], reformat(r[3])] for r in data]\n        return json.dumps(data)\n\n    return ''", "func_src_after": "@endpoints.route('/big_wins')\ndef big_wins():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n    scene = request.args.get('scene', default=None)\n    \n    valid = not (tag == None and date == None)\n    if valid:\n        # This sql statement is a bit of a doozy...\n        select = 'select ranks.player, ranks.rank, matches.date, matches.score'\n        frm = 'from matches join ranks where ((ranks.player=matches.player1 and matches.player2=\"{tag}\")'\n        player_where = 'or (ranks.player=matches.player2 and matches.player1=\"{tag}\")) and winner=\"{tag}\"'\n        date_where = 'and matches.scene=ranks.scene and datediff(ranks.date, matches.date)<=31 and ranks.date>matches.date'\n        also_date_where = 'and ranks.date=\"{date}\"'\n        scene_where = 'and ranks.scene=\"{scene}\"'\n        order = 'order by rank;'\n\n        args = {'tag': tag, 'date': date, 'scene': scene}\n\n\n        sql = '{} {} {} {} {} {} {}'.format(select, frm, player_where, date_where, also_date_where, scene_where, order)\n        data = db.exec(sql, args)\n\n        # Before we return this data, reformat score data from [2,1] -> 2 - 1, for eg\n        def reformat(score):\n            score = score.replace('[', '')\n            score = score.replace(']', '')\n            win, loss = score.split(',')\n            score = '{} - {}'.format(win, loss)\n            return score\n        data = [[r[0], r[1], r[2], reformat(r[3])] for r in data]\n        return json.dumps(data)\n\n    return ''", "line_changes": {"deleted": [{"line_no": 14, "char_start": 429, "char_end": 544, "line": "        frm = 'from matches join ranks where ((ranks.player=matches.player1 and matches.player2=\"{}\")'.format(tag)\n"}, {"line_no": 15, "char_start": 544, "char_end": 662, "line": "        player_where = 'or (ranks.player=matches.player2 and matches.player1=\"{}\")) and winner=\"{}\"'.format(tag, tag)\n"}, {"line_no": 17, "char_start": 786, "char_end": 847, "line": "        also_date_where = 'and ranks.date=\"{}\"'.format(date)\n"}, {"line_no": 18, "char_start": 847, "char_end": 906, "line": "        scene_where = 'and ranks.scene=\"{}\"'.format(scene)\n"}, {"line_no": 23, "char_start": 1061, "char_end": 1089, "line": "        data = db.exec(sql)\n"}], "added": [{"line_no": 14, "char_start": 429, "char_end": 535, "line": "        frm = 'from matches join ranks where ((ranks.player=matches.player1 and matches.player2=\"{tag}\")'\n"}, {"line_no": 15, "char_start": 535, "char_end": 642, "line": "        player_where = 'or (ranks.player=matches.player2 and matches.player1=\"{tag}\")) and winner=\"{tag}\"'\n"}, {"line_no": 17, "char_start": 766, "char_end": 818, "line": "        also_date_where = 'and ranks.date=\"{date}\"'\n"}, {"line_no": 18, "char_start": 818, "char_end": 868, "line": "        scene_where = 'and ranks.scene=\"{scene}\"'\n"}, {"line_no": 21, "char_start": 902, "char_end": 960, "line": "        args = {'tag': tag, 'date': date, 'scene': scene}\n"}, {"line_no": 22, "char_start": 960, "char_end": 961, "line": "\n"}, {"line_no": 25, "char_start": 1082, "char_end": 1116, "line": "        data = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 531, "char_end": 543, "chars": ".format(tag)"}, {"char_start": 644, "char_end": 661, "chars": ".format(tag, tag)"}, {"char_start": 830, "char_end": 841, "chars": "}\"'.format("}, {"char_start": 845, "char_end": 846, "chars": ")"}, {"char_start": 888, "char_end": 899, "chars": "}\"'.format("}, {"char_start": 904, "char_end": 905, "chars": ")"}], "added": [{"char_start": 527, "char_end": 530, "chars": "tag"}, {"char_start": 614, "char_end": 617, "chars": "tag"}, {"char_start": 635, "char_end": 638, "chars": "tag"}, {"char_start": 814, "char_end": 817, "chars": "}\"'"}, {"char_start": 864, "char_end": 867, "chars": "}\"'"}, {"char_start": 902, "char_end": 961, "chars": "        args = {'tag': tag, 'date': date, 'scene': scene}\n\n"}, {"char_start": 1108, "char_end": 1114, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "bad_losses", "func_src_before": "@endpoints.route('/bad_losses')\ndef bad_losses():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n    scene = request.args.get('scene', default=None)\n\n    if tag and date:\n        # This sql statement is a bit of a doozy...\n        select = 'select ranks.player, ranks.rank, matches.date, matches.score'\n        frm = 'from matches join ranks where ((ranks.player=matches.player1 and matches.player2=\"{}\")'.format(tag)\n        player_where = 'or (ranks.player=matches.player2 and matches.player1=\"{}\")) and not winner=\"{}\"'.format(tag, tag)\n        date_where = 'and matches.scene=ranks.scene and datediff(ranks.date, matches.date)<=31 and ranks.date>matches.date'\n        also_date_where = 'and ranks.date=\"{}\"'.format(date)\n        scene_where = 'and ranks.scene=\"{}\"'.format(scene)\n        order = 'order by rank desc;'\n\n        sql = '{} {} {} {} {} {} {}'.format(select, frm, player_where, date_where, also_date_where, scene_where, order)\n        data = db.exec(sql)\n\n        # Before we return this data, reformat score data from [2,1] -> 1-2, for eg\n        def reformat(score):\n            score = score.replace('[', '')\n            score = score.replace(']', '')\n            win, loss = score.split(',')\n            score = '{} - {}'.format(loss, win)\n            return score\n        data = [[r[0], r[1], r[2], reformat(r[3])] for r in data]\n\n        return json.dumps(data)\n    \n    return ''", "func_src_after": "@endpoints.route('/bad_losses')\ndef bad_losses():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default=None)\n    date = request.args.get('date', default=None)\n    scene = request.args.get('scene', default=None)\n\n    if tag and date:\n        # This sql statement is a bit of a doozy...\n        select = 'select ranks.player, ranks.rank, matches.date, matches.score'\n        frm = 'from matches join ranks where ((ranks.player=matches.player1 and matches.player2=\"{tag}\")'\n        player_where = 'or (ranks.player=matches.player2 and matches.player1=\"{tag}\")) and not winner=\"{tag}\"'\n        date_where = 'and matches.scene=ranks.scene and datediff(ranks.date, matches.date)<=31 and ranks.date>matches.date'\n        also_date_where = 'and ranks.date=\"{date}\"'\n        scene_where = 'and ranks.scene=\"{scene}\"'\n        order = 'order by rank desc;'\n\n        args = {'tag': tag, 'date': date, 'scene': scene}\n\n        sql = '{} {} {} {} {} {} {}'.format(select, frm, player_where, date_where, also_date_where, scene_where, order)\n        data = db.exec(sql, args)\n\n        # Before we return this data, reformat score data from [2,1] -> 1-2, for eg\n        def reformat(score):\n            score = score.replace('[', '')\n            score = score.replace(']', '')\n            win, loss = score.split(',')\n            score = '{} - {}'.format(loss, win)\n            return score\n        data = [[r[0], r[1], r[2], reformat(r[3])] for r in data]\n\n        return json.dumps(data)\n    \n    return ''", "line_changes": {"deleted": [{"line_no": 13, "char_start": 389, "char_end": 504, "line": "        frm = 'from matches join ranks where ((ranks.player=matches.player1 and matches.player2=\"{}\")'.format(tag)\n"}, {"line_no": 14, "char_start": 504, "char_end": 626, "line": "        player_where = 'or (ranks.player=matches.player2 and matches.player1=\"{}\")) and not winner=\"{}\"'.format(tag, tag)\n"}, {"line_no": 16, "char_start": 750, "char_end": 811, "line": "        also_date_where = 'and ranks.date=\"{}\"'.format(date)\n"}, {"line_no": 17, "char_start": 811, "char_end": 870, "line": "        scene_where = 'and ranks.scene=\"{}\"'.format(scene)\n"}, {"line_no": 21, "char_start": 1029, "char_end": 1057, "line": "        data = db.exec(sql)\n"}], "added": [{"line_no": 13, "char_start": 389, "char_end": 495, "line": "        frm = 'from matches join ranks where ((ranks.player=matches.player1 and matches.player2=\"{tag}\")'\n"}, {"line_no": 14, "char_start": 495, "char_end": 606, "line": "        player_where = 'or (ranks.player=matches.player2 and matches.player1=\"{tag}\")) and not winner=\"{tag}\"'\n"}, {"line_no": 16, "char_start": 730, "char_end": 782, "line": "        also_date_where = 'and ranks.date=\"{date}\"'\n"}, {"line_no": 17, "char_start": 782, "char_end": 832, "line": "        scene_where = 'and ranks.scene=\"{scene}\"'\n"}, {"line_no": 20, "char_start": 871, "char_end": 929, "line": "        args = {'tag': tag, 'date': date, 'scene': scene}\n"}, {"line_no": 21, "char_start": 929, "char_end": 930, "line": "\n"}, {"line_no": 23, "char_start": 1050, "char_end": 1084, "line": "        data = db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 491, "char_end": 503, "chars": ".format(tag)"}, {"char_start": 608, "char_end": 625, "chars": ".format(tag, tag)"}, {"char_start": 794, "char_end": 805, "chars": "}\"'.format("}, {"char_start": 809, "char_end": 810, "chars": ")"}, {"char_start": 852, "char_end": 863, "chars": "}\"'.format("}, {"char_start": 868, "char_end": 869, "chars": ")"}], "added": [{"char_start": 487, "char_end": 490, "chars": "tag"}, {"char_start": 574, "char_end": 577, "chars": "tag"}, {"char_start": 599, "char_end": 602, "chars": "tag"}, {"char_start": 778, "char_end": 781, "chars": "}\"'"}, {"char_start": 828, "char_end": 831, "chars": "}\"'"}, {"char_start": 871, "char_end": 930, "chars": "        args = {'tag': tag, 'date': date, 'scene': scene}\n\n"}, {"char_start": 1076, "char_end": 1082, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089"}
{"func_name": "process", "func_src_before": "    def process(self, bracket, scene, display_name, new_bracket=False):\n        # Before we do anything, check if this url has been analyzed already, and bomb out\n        sql = \"SELECT * FROM analyzed WHERE base_url = '\" + str(bracket) + \"';\"\n        result = self.db.exec(sql)\n        if len(result) > 0:\n            LOG.info('tried to analyze {}, but has already been done.'.format(bracket))\n            return\n\n        # Send this bracket to get_results\n        # We know the bracket is valid if it is from smashgg\n        if 'smash.gg' in bracket:\n            success = get_results.process(bracket, scene, self.db, display_name)\n            if success:\n                self.insert_placing_data(bracket, new_bracket)\n            else:\n                #TODO add this URL to a table called 'failed_smashgg_brackets' or something\n                LOG.exc('Analyzing smashgg tournament {} was not successful'.format(bracket))\n\n        else:\n            html, status = bracket_utils.hit_url(bracket)\n            if status == 200 and bracket_utils.is_valid(html):\n                get_results.process(bracket, scene, self.db, display_name)\n                self.insert_placing_data(bracket, new_bracket)", "func_src_after": "    def process(self, bracket, scene, display_name, new_bracket=False):\n        # There are some brackets that have been blacklisted. Skip these brackets\n        if bracket in constants.BLACKLIST:\n            LOG.info('Skipping bracket due to blacklisting: {}'.format(bracket))\n            return\n\n        # Before we do anything, check if this url has been analyzed already, and bomb out\n        sql = \"SELECT * FROM analyzed WHERE base_url = '{bracket}';\"\n        args = {'bracket': bracket}\n        result = self.db.exec(sql, args)\n        if len(result) > 0:\n            LOG.info('tried to analyze {}, but has already been done.'.format(bracket))\n            return\n\n        # Send this bracket to get_results\n        # We know the bracket is valid if it is from smashgg\n        if 'smash.gg' in bracket:\n            success = get_results.process(bracket, scene, self.db, display_name, new_bracket)\n            if success:\n                self.insert_placing_data(bracket, new_bracket)\n            else:\n                #TODO add this URL to a table called 'failed_smashgg_brackets' or something\n                LOG.exc('Analyzing smashgg tournament {} was not successful'.format(bracket))\n\n        else:\n            html, status = bracket_utils.hit_url(bracket)\n            if status == 200 and bracket_utils.is_valid(html):\n                get_results.process(bracket, scene, self.db, display_name, new_bracket)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 163, "char_end": 243, "line": "        sql = \"SELECT * FROM analyzed WHERE base_url = '\" + str(bracket) + \"';\"\n"}, {"line_no": 4, "char_start": 243, "char_end": 278, "line": "        result = self.db.exec(sql)\n"}, {"line_no": 12, "char_start": 552, "char_end": 633, "line": "            success = get_results.process(bracket, scene, self.db, display_name)\n"}, {"line_no": 22, "char_start": 1060, "char_end": 1135, "line": "                get_results.process(bracket, scene, self.db, display_name)\n"}, {"line_no": 23, "char_start": 1135, "char_end": 1197, "line": "                self.insert_placing_data(bracket, new_bracket)\n"}], "added": [{"line_no": 3, "char_start": 154, "char_end": 197, "line": "        if bracket in constants.BLACKLIST:\n"}, {"line_no": 4, "char_start": 197, "char_end": 278, "line": "            LOG.info('Skipping bracket due to blacklisting: {}'.format(bracket))\n"}, {"line_no": 5, "char_start": 278, "char_end": 297, "line": "            return\n"}, {"line_no": 6, "char_start": 297, "char_end": 298, "line": "\n"}, {"line_no": 8, "char_start": 389, "char_end": 458, "line": "        sql = \"SELECT * FROM analyzed WHERE base_url = '{bracket}';\"\n"}, {"line_no": 9, "char_start": 458, "char_end": 494, "line": "        args = {'bracket': bracket}\n"}, {"line_no": 10, "char_start": 494, "char_end": 535, "line": "        result = self.db.exec(sql, args)\n"}, {"line_no": 18, "char_start": 809, "char_end": 903, "line": "            success = get_results.process(bracket, scene, self.db, display_name, new_bracket)\n"}, {"line_no": 28, "char_start": 1330, "char_end": 1417, "line": "                get_results.process(bracket, scene, self.db, display_name, new_bracket)\n"}]}, "char_changes": {"deleted": [{"char_start": 219, "char_end": 242, "chars": "\" + str(bracket) + \"';\""}, {"char_start": 1133, "char_end": 1183, "chars": ")\n                self.insert_placing_data(bracket"}], "added": [{"char_start": 72, "char_end": 298, "chars": "        # There are some brackets that have been blacklisted. Skip these brackets\n        if bracket in constants.BLACKLIST:\n            LOG.info('Skipping bracket due to blacklisting: {}'.format(bracket))\n            return\n\n"}, {"char_start": 445, "char_end": 493, "chars": "{bracket}';\"\n        args = {'bracket': bracket}"}, {"char_start": 527, "char_end": 533, "chars": ", args"}, {"char_start": 888, "char_end": 901, "chars": ", new_bracket"}, {"char_start": 1330, "char_end": 1330, "chars": ""}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "process_data.py", "vul_type": "cwe-089"}
{"func_name": "insert_placing_data", "func_src_before": "    def insert_placing_data(self, bracket, new_bracket):\n        LOG.info('we have called insert placing data on bracket {}'.format(bracket))\n        # Get the html from the 'standings' of this tournament\n        tournament_placings = bracket_utils.get_tournament_placings(bracket)\n\n        for player, placing in tournament_placings.items():\n            player = sanitize_tag(player)\n\n            # Coalesce tag\n            player = get_coalesced_tag(player)\n            sql = \"INSERT INTO placings (url, player, place) VALUES \" \\\n                    + \" ('{}', '{}', '{}')\".format(bracket, player, placing)\n\n            self.db.exec(sql)\n\n            if 'christmasmike' == player and new_bracket:\n                if placing < 10:\n                    msg = \"Congrats on making {} dude! You're the best.\".format(placing)\n                    tweet(msg)\n\n        LOG.info(\"tournament placings for {} are {}\".format(bracket, tournament_placings))", "func_src_after": "    def insert_placing_data(self, bracket, new_bracket):\n        # Get the html from the 'standings' of this tournament\n        tournament_placings = bracket_utils.get_tournament_placings(bracket)\n\n        for player, placing in tournament_placings.items():\n            player = sanitize_tag(player)\n\n            # Coalesce tag\n            player = get_coalesced_tag(player)\n            sql = \"INSERT INTO placings (url, player, place) VALUES ('{url}', '{player}', '{place}')\"\n            args = {'url': bracket, 'player': player, 'place': placing}\n\n            self.db.exec(sql, args)\n\n            if 'christmasmike' == player and new_bracket:\n                if placing < 10:\n                    msg = \"Congrats on making {} dude! You're the best.\".format(placing)\n                    tweet(msg)\n\n        LOG.info(\"tournament placings for {} are {}\".format(bracket, tournament_placings))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 57, "char_end": 142, "line": "        LOG.info('we have called insert placing data on bracket {}'.format(bracket))\n"}, {"line_no": 11, "char_start": 460, "char_end": 532, "line": "            sql = \"INSERT INTO placings (url, player, place) VALUES \" \\\n"}, {"line_no": 12, "char_start": 532, "char_end": 609, "line": "                    + \" ('{}', '{}', '{}')\".format(bracket, player, placing)\n"}, {"line_no": 14, "char_start": 610, "char_end": 640, "line": "            self.db.exec(sql)\n"}], "added": [{"line_no": 10, "char_start": 375, "char_end": 477, "line": "            sql = \"INSERT INTO placings (url, player, place) VALUES ('{url}', '{player}', '{place}')\"\n"}, {"line_no": 11, "char_start": 477, "char_end": 549, "line": "            args = {'url': bracket, 'player': player, 'place': placing}\n"}, {"line_no": 13, "char_start": 550, "char_end": 586, "line": "            self.db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 57, "char_end": 142, "chars": "        LOG.info('we have called insert placing data on bracket {}'.format(bracket))\n"}, {"char_start": 528, "char_end": 599, "chars": "\" \\\n                    + \" ('{}', '{}', '{}')\".format(bracket, player,"}, {"char_start": 607, "char_end": 608, "chars": ")"}], "added": [{"char_start": 443, "char_end": 539, "chars": "('{url}', '{player}', '{place}')\"\n            args = {'url': bracket, 'player': player, 'place':"}, {"char_start": 547, "char_end": 548, "chars": "}"}, {"char_start": 578, "char_end": 584, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "process_data.py", "vul_type": "cwe-089"}
{"func_name": "check_and_update_ranks", "func_src_before": "    def check_and_update_ranks(self, scene):\n        # There are 2 cases here:\n        #   1) Ranks have never been calculated for this scene before\n        #       - This means we need to calculate what the ranks were every month of this scenes history\n        #       - We should only do this if ranks don't already exist for this scene\n        #   2) Ranks have been calculated for this scene before\n        #       - We already have bulk ranks. We should check if it has been more than 1 month since we last\n        #           calculated ranks. If so, calculate again with the brackets that have come out this month\n\n        LOG.info('About to check if ranks need updating for {}'.format(scene))\n        # First, do we have any ranks for this scene already?\n        sql = 'select count(*) from ranks where scene=\"{}\";'.format(scene)\n        res = self.db.exec(sql)\n        count = res[0][0]\n\n        n = 5 if (scene == 'pro' or scene == 'pro_wiiu') else constants.TOURNAMENTS_PER_RANK\n        if count == 0:\n            LOG.info('Detected that we need to bulk update ranks for {}'.format(scene))\n            # Alright, we have nothing. Bulk update ranks\n            first_month = bracket_utils.get_first_month(self.db, scene)\n            last_month = bracket_utils.get_last_month(self.db, scene)\n            \n            # Iterate through all tournaments going month by month, and calculate ranks\n            months = bracket_utils.iter_months(first_month, last_month, include_first=False, include_last=True)\n            for month in months:\n                urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                self.process_ranks(scene, urls, month)\n        else:\n\n            # Get the date of the last time we calculated ranks\n            sql = \"select date from ranks where scene='{}' order by date desc limit 1;\".format(scene)\n            res = self.db.exec(sql)\n            last_rankings_date = res[0][0]\n\n            # Check to see if it's been more than 1 month since we last calculated ranks\n            more_than_one_month = bracket_utils.has_month_passed(last_rankings_date)\n            if more_than_one_month:\n                # Get only the last n tournaments, so it doesn't take too long to process\n                today = datetime.datetime.today().strftime('%Y-%m-%d')\n                msg = 'Detected that we need up update monthly ranks for {}, on {}'.format(scene, today)\n                LOG.info(msg)\n\n                # We should only ever calculate ranks on the 1st. If today is not the first, log error\n                if not today.split('-')[-1] == '1':\n                    LOG.exc('We are calculating ranks today, {}, but it isnt the first'.format(today))\n\n                months = bracket_utils.iter_months(last_rankings_date, today, include_first=False, include_last=True)\n                for month in months:\n                    # Make sure that we actually have matches during this month\n                    # Say we are trying to calculate ranks for 2018-05-01, the player would need to have matches during 2018-04-01, 2018-04-30\n                    prev_date = bracket_utils.get_previous_month(month)\n                    brackets_during_month = bracket_utils.get_tournaments_during_month(self.db, scene, prev_date)\n\n                    if len(brackets_during_month) > 0:\n                        tweet('Calculating {} ranks for {}'.format(month, scene))\n                        urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                        self.process_ranks(scene, urls, month)\n\n            else:\n                LOG.info('It has not yet been 1 month since we calculated ranks for {}. Skipping'.format(scene))", "func_src_after": "    def check_and_update_ranks(self, scene):\n        # There are 2 cases here:\n        #   1) Ranks have never been calculated for this scene before\n        #       - This means we need to calculate what the ranks were every month of this scenes history\n        #       - We should only do this if ranks don't already exist for this scene\n        #   2) Ranks have been calculated for this scene before\n        #       - We already have bulk ranks. We should check if it has been more than 1 month since we last\n        #           calculated ranks. If so, calculate again with the brackets that have come out this month\n\n        LOG.info('About to check if ranks need updating for {}'.format(scene))\n        # First, do we have any ranks for this scene already?\n        sql = 'select count(*) from ranks where scene=\"{scene}\";'\n        args = {'scene': scene}\n        res = self.db.exec(sql, args)\n        count = res[0][0]\n\n        n = 5 if (scene == 'pro' or scene == 'pro_wiiu') else constants.TOURNAMENTS_PER_RANK\n        if count == 0:\n            LOG.info('Detected that we need to bulk update ranks for {}'.format(scene))\n            # Alright, we have nothing. Bulk update ranks\n            first_month = bracket_utils.get_first_month(self.db, scene)\n            last_month = bracket_utils.get_last_month(self.db, scene)\n            \n            # Iterate through all tournaments going month by month, and calculate ranks\n            months = bracket_utils.iter_months(first_month, last_month, include_first=False, include_last=True)\n            for month in months:\n                urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                self.process_ranks(scene, urls, month)\n        else:\n\n            # Get the date of the last time we calculated ranks\n            sql = \"select date from ranks where scene='{scene}' order by date desc limit 1;\"\n            args = {'scene': scene}\n            res = self.db.exec(sql, args)\n            last_rankings_date = res[0][0]\n\n            # Check to see if it's been more than 1 month since we last calculated ranks\n            more_than_one_month = bracket_utils.has_month_passed(last_rankings_date)\n            if more_than_one_month:\n                # Get only the last n tournaments, so it doesn't take too long to process\n                today = datetime.datetime.today().strftime('%Y-%m-%d')\n                msg = 'Detected that we need up update monthly ranks for {}, on {}'.format(scene, today)\n                LOG.info(msg)\n\n                # We should only ever calculate ranks on the 1st. If today is not the first, log error\n                if not today.split('-')[-1] == '1':\n                    LOG.exc('We are calculating ranks today, {}, but it isnt the first'.format(today))\n\n                months = bracket_utils.iter_months(last_rankings_date, today, include_first=False, include_last=True)\n                for month in months:\n                    # Make sure that we actually have matches during this month\n                    # Say we are trying to calculate ranks for 2018-05-01, the player would need to have matches during 2018-04-01, 2018-04-30\n                    prev_date = bracket_utils.get_previous_month(month)\n                    brackets_during_month = bracket_utils.get_tournaments_during_month(self.db, scene, prev_date)\n\n                    if len(brackets_during_month) > 0:\n                        tweet('Calculating {} ranks for {}'.format(month, scene))\n                        urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                        self.process_ranks(scene, urls, month)\n\n            else:\n                LOG.info('It has not yet been 1 month since we calculated ranks for {}. Skipping'.format(scene))", "line_changes": {"deleted": [{"line_no": 12, "char_start": 763, "char_end": 838, "line": "        sql = 'select count(*) from ranks where scene=\"{}\";'.format(scene)\n"}, {"line_no": 13, "char_start": 838, "char_end": 870, "line": "        res = self.db.exec(sql)\n"}, {"line_no": 31, "char_start": 1777, "char_end": 1879, "line": "            sql = \"select date from ranks where scene='{}' order by date desc limit 1;\".format(scene)\n"}, {"line_no": 32, "char_start": 1879, "char_end": 1915, "line": "            res = self.db.exec(sql)\n"}], "added": [{"line_no": 12, "char_start": 763, "char_end": 829, "line": "        sql = 'select count(*) from ranks where scene=\"{scene}\";'\n"}, {"line_no": 13, "char_start": 829, "char_end": 861, "line": "        args = {'scene': scene}\n"}, {"line_no": 14, "char_start": 861, "char_end": 899, "line": "        res = self.db.exec(sql, args)\n"}, {"line_no": 32, "char_start": 1806, "char_end": 1899, "line": "            sql = \"select date from ranks where scene='{scene}' order by date desc limit 1;\"\n"}, {"line_no": 33, "char_start": 1899, "char_end": 1935, "line": "            args = {'scene': scene}\n"}, {"line_no": 34, "char_start": 1935, "char_end": 1977, "line": "            res = self.db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 819, "char_end": 837, "chars": "}\";'.format(scene)"}, {"char_start": 1864, "char_end": 1878, "chars": ".format(scene)"}], "added": [{"char_start": 819, "char_end": 860, "chars": "scene}\";'\n        args = {'scene': scene}"}, {"char_start": 891, "char_end": 897, "chars": ", args"}, {"char_start": 1862, "char_end": 1867, "chars": "scene"}, {"char_start": 1898, "char_end": 1934, "chars": "\n            args = {'scene': scene}"}, {"char_start": 1969, "char_end": 1975, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "process_data.py", "vul_type": "cwe-089"}
{"func_name": "process_ranks", "func_src_before": "    def process_ranks(self, scene, urls, recent_date):\n        PLAYER1 = 0\n        PLAYER2 = 1\n        WINNER = 2\n        DATE = 3\n        SCENE = 4\n\n        # make sure if we already have calculated ranks for these players at this time, we do not do it again\n        sql = \"SELECT * FROM ranks WHERE scene = '{}' AND date='{}';\".format(str(scene), recent_date)\n        res = self.db.exec(sql)\n        if len(res) > 0:\n            LOG.info('We have already calculated ranks for {} on date {}. SKipping'.format(scene, recent_date))\n            return\n\n        matches = bracket_utils.get_matches_from_urls(self.db, urls)\n        LOG.info('About to start processing ranks for scene {} on {}'.format(scene, recent_date))\n\n        # Iterate through each match, and build up our dict\n        win_loss_dict = {}\n        for match in matches:\n            p1 = match[PLAYER1]\n            p2 = match[PLAYER2]\n            winner = match[WINNER]\n            date = match[DATE]\n\n            #Add p1 to the dict\n            if p1 not in win_loss_dict:\n                win_loss_dict[p1] = {}\n\n            if p2 not in win_loss_dict[p1]:\n                win_loss_dict[p1][p2] = []\n\n            # Add an entry to represent this match to p1\n            win_loss_dict[p1][p2].append((date, winner == p1))\n\n            # add p2 to the dict\n            if p2 not in win_loss_dict:\n                win_loss_dict[p2] = {}\n\n            if p1 not in win_loss_dict[p2]:\n                win_loss_dict[p2][p1] = []\n\n            win_loss_dict[p2][p1].append((date, winner == p2))\n\n        ranks = get_ranks(win_loss_dict)\n\n        tag_rank_map = {}\n        for i, x in enumerate(ranks):\n            points, player = x\n            rank = len(ranks) - i\n\n            sql = \"INSERT INTO ranks (scene, player, rank, points, date) VALUES ('{}', '{}', '{}', '{}', '{}');\"\\\n                    .format(str(scene), str(player), int(rank), str(points), str(recent_date))\n            self.db.exec(sql)\n\n            # Only count this player if this is the scene he/she belongs to\n            sql = \"SELECT scene FROM players WHERE tag='{}';\".format(player)\n            res = self.db.exec(sql)\n\n            if len(res) == 0 or res[0][0] == scene:\n                # Also create a list to update the player web\n                map = {'rank':rank, 'total_ranked':len(ranks)}\n                tag_rank_map[player] = map\n\n        player_web.update_ranks(tag_rank_map)", "func_src_after": "    def process_ranks(self, scene, urls, recent_date):\n        PLAYER1 = 0\n        PLAYER2 = 1\n        WINNER = 2\n        DATE = 3\n        SCENE = 4\n\n        # make sure if we already have calculated ranks for these players at this time, we do not do it again\n        sql = \"SELECT * FROM ranks WHERE scene = '{scene}' AND date='{date}';\"\n        args = {'scene': scene, 'date': recent_date}\n        res = self.db.exec(sql, args)\n        if len(res) > 0:\n            LOG.info('We have already calculated ranks for {} on date {}. SKipping'.format(scene, recent_date))\n            return\n\n        matches = bracket_utils.get_matches_from_urls(self.db, urls)\n        LOG.info('About to start processing ranks for scene {} on {}'.format(scene, recent_date))\n\n        # Iterate through each match, and build up our dict\n        win_loss_dict = {}\n        for match in matches:\n            p1 = match[PLAYER1]\n            p2 = match[PLAYER2]\n            winner = match[WINNER]\n            date = match[DATE]\n\n            #Add p1 to the dict\n            if p1 not in win_loss_dict:\n                win_loss_dict[p1] = {}\n\n            if p2 not in win_loss_dict[p1]:\n                win_loss_dict[p1][p2] = []\n\n            # Add an entry to represent this match to p1\n            win_loss_dict[p1][p2].append((date, winner == p1))\n\n            # add p2 to the dict\n            if p2 not in win_loss_dict:\n                win_loss_dict[p2] = {}\n\n            if p1 not in win_loss_dict[p2]:\n                win_loss_dict[p2][p1] = []\n\n            win_loss_dict[p2][p1].append((date, winner == p2))\n\n        ranks = get_ranks(win_loss_dict)\n\n        tag_rank_map = {}\n        for i, x in enumerate(ranks):\n            points, player = x\n            rank = len(ranks) - i\n\n            sql = \"INSERT INTO ranks (scene, player, rank, points, date) VALUES ('{scene}', '{player}', '{rank}', '{points}', '{recent_date}');\"\n            args = {'scene': scene, 'player': player, 'rank': rank, 'points': points, 'recent_date': recent_date}\n            self.db.exec(sql, args)\n\n            # Only count this player if this is the scene he/she belongs to\n            sql = \"SELECT scene FROM players WHERE tag='{player}';\"\n            args = {'player': player}\n            res = self.db.exec(sql, args)\n\n            if len(res) == 0 or res[0][0] == scene:\n                # Also create a list to update the player web\n                map = {'rank':rank, 'total_ranked':len(ranks)}\n                tag_rank_map[player] = map\n\n        player_web.update_ranks(tag_rank_map)", "line_changes": {"deleted": [{"line_no": 9, "char_start": 260, "char_end": 362, "line": "        sql = \"SELECT * FROM ranks WHERE scene = '{}' AND date='{}';\".format(str(scene), recent_date)\n"}, {"line_no": 10, "char_start": 362, "char_end": 394, "line": "        res = self.db.exec(sql)\n"}, {"line_no": 52, "char_start": 1725, "char_end": 1839, "line": "            sql = \"INSERT INTO ranks (scene, player, rank, points, date) VALUES ('{}', '{}', '{}', '{}', '{}');\"\\\n"}, {"line_no": 53, "char_start": 1839, "char_end": 1934, "line": "                    .format(str(scene), str(player), int(rank), str(points), str(recent_date))\n"}, {"line_no": 54, "char_start": 1934, "char_end": 1964, "line": "            self.db.exec(sql)\n"}, {"line_no": 57, "char_start": 2041, "char_end": 2118, "line": "            sql = \"SELECT scene FROM players WHERE tag='{}';\".format(player)\n"}, {"line_no": 58, "char_start": 2118, "char_end": 2154, "line": "            res = self.db.exec(sql)\n"}], "added": [{"line_no": 9, "char_start": 260, "char_end": 339, "line": "        sql = \"SELECT * FROM ranks WHERE scene = '{scene}' AND date='{date}';\"\n"}, {"line_no": 10, "char_start": 339, "char_end": 392, "line": "        args = {'scene': scene, 'date': recent_date}\n"}, {"line_no": 11, "char_start": 392, "char_end": 430, "line": "        res = self.db.exec(sql, args)\n"}, {"line_no": 53, "char_start": 1761, "char_end": 1906, "line": "            sql = \"INSERT INTO ranks (scene, player, rank, points, date) VALUES ('{scene}', '{player}', '{rank}', '{points}', '{recent_date}');\"\n"}, {"line_no": 54, "char_start": 1906, "char_end": 2020, "line": "            args = {'scene': scene, 'player': player, 'rank': rank, 'points': points, 'recent_date': recent_date}\n"}, {"line_no": 55, "char_start": 2020, "char_end": 2056, "line": "            self.db.exec(sql, args)\n"}, {"line_no": 58, "char_start": 2133, "char_end": 2201, "line": "            sql = \"SELECT scene FROM players WHERE tag='{player}';\"\n"}, {"line_no": 59, "char_start": 2201, "char_end": 2239, "line": "            args = {'player': player}\n"}, {"line_no": 60, "char_start": 2239, "char_end": 2281, "line": "            res = self.db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 325, "char_end": 348, "chars": "}';\".format(str(scene),"}, {"char_start": 360, "char_end": 361, "chars": ")"}, {"char_start": 1826, "char_end": 1832, "chars": "}', '{"}, {"char_start": 1837, "char_end": 1838, "chars": "\\"}, {"char_start": 1851, "char_end": 1871, "chars": "        .format(str("}, {"char_start": 1876, "char_end": 1877, "chars": ")"}, {"char_start": 1879, "char_end": 1883, "chars": "str("}, {"char_start": 1889, "char_end": 1890, "chars": ")"}, {"char_start": 1892, "char_end": 1896, "chars": "int("}, {"char_start": 1900, "char_end": 1901, "chars": ")"}, {"char_start": 1903, "char_end": 1907, "chars": "str("}, {"char_start": 1913, "char_end": 1914, "chars": ")"}, {"char_start": 1916, "char_end": 1920, "chars": "str("}, {"char_start": 1931, "char_end": 1933, "chars": "))"}, {"char_start": 2098, "char_end": 2110, "chars": "}';\".format("}, {"char_start": 2116, "char_end": 2117, "chars": ")"}], "added": [{"char_start": 311, "char_end": 316, "chars": "scene"}, {"char_start": 330, "char_end": 364, "chars": "date}';\"\n        args = {'scene': "}, {"char_start": 370, "char_end": 378, "chars": " 'date':"}, {"char_start": 390, "char_end": 391, "chars": "}"}, {"char_start": 422, "char_end": 428, "chars": ", args"}, {"char_start": 1844, "char_end": 1849, "chars": "scene"}, {"char_start": 1855, "char_end": 1861, "chars": "player"}, {"char_start": 1867, "char_end": 1871, "chars": "rank"}, {"char_start": 1877, "char_end": 1900, "chars": "points}', '{recent_date"}, {"char_start": 1918, "char_end": 1935, "chars": "args = {'scene': "}, {"char_start": 1942, "char_end": 1952, "chars": "'player': "}, {"char_start": 1960, "char_end": 1968, "chars": "'rank': "}, {"char_start": 1974, "char_end": 1984, "chars": "'points': "}, {"char_start": 1992, "char_end": 2007, "chars": "'recent_date': "}, {"char_start": 2018, "char_end": 2019, "chars": "}"}, {"char_start": 2048, "char_end": 2054, "chars": ", args"}, {"char_start": 2190, "char_end": 2231, "chars": "player}';\"\n            args = {'player': "}, {"char_start": 2237, "char_end": 2238, "chars": "}"}, {"char_start": 2273, "char_end": 2279, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "process_data.py", "vul_type": "cwe-089"}
{"func_name": "analyze_smashgg", "func_src_before": "    def analyze_smashgg(self, urls, name):\n        LOG.info('we are about to analyze scene {} with {} brackets'.format(name, len(urls)))\n        for url in urls:\n            # Before we process this URL, check to see if we already have\n            sql = \"SELECT * FROM analyzed where base_url='{}'\".format(url)\n            res = self.db.exec(sql)\n            if len(res) == 0:\n\n                display_name = bracket_utils.get_display_base(url)\n\n                # We don't care about doubles tournaments\n                if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                    LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                    continue\n\n                LOG.info('About to process pro bracket {}'.format(url))\n                self.data_processor.process(url, name, display_name)\n            else:\n                LOG.info(\"Skpping pro bracket because it has already been analyzed: {}\".format(url))", "func_src_after": "    def analyze_smashgg(self, urls, name):\n        LOG.info('we are about to analyze scene {} with {} brackets'.format(name, len(urls)))\n        for url in urls:\n            # Before we process this URL, check to see if we already have\n            sql = \"SELECT * FROM analyzed where base_url='{url}'\"\n            args = {'url':url}\n            res = self.db.exec(sql, args)\n            if len(res) == 0:\n\n                display_name = bracket_utils.get_display_base(url)\n\n                # We don't care about doubles tournaments\n                if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                    LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                    continue\n\n                LOG.info('About to process pro bracket {}'.format(url))\n                self.data_processor.process(url, name, display_name)\n            else:\n                LOG.info(\"Skpping pro bracket because it has already been analyzed: {}\".format(url))", "line_changes": {"deleted": [{"line_no": 5, "char_start": 236, "char_end": 311, "line": "            sql = \"SELECT * FROM analyzed where base_url='{}'\".format(url)\n"}, {"line_no": 6, "char_start": 311, "char_end": 347, "line": "            res = self.db.exec(sql)\n"}], "added": [{"line_no": 5, "char_start": 236, "char_end": 302, "line": "            sql = \"SELECT * FROM analyzed where base_url='{url}'\"\n"}, {"line_no": 6, "char_start": 302, "char_end": 333, "line": "            args = {'url':url}\n"}, {"line_no": 7, "char_start": 333, "char_end": 375, "line": "            res = self.db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 295, "char_end": 310, "chars": "}'\".format(url)"}], "added": [{"char_start": 295, "char_end": 328, "chars": "url}'\"\n            args = {'url':"}, {"char_start": 331, "char_end": 332, "chars": "}"}, {"char_start": 367, "char_end": 373, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089"}
{"func_name": "analyze_scene", "func_src_before": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{}';\".format(user)\n            results = self.db.exec(sql)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{}' AND user='{}';\".format(bracket, user)\n                    results = self.db.exec(sql)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(bracket, user, name)\n                        self.db.exec(sql)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(url, user, name)\n                    self.db.exec(sql)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '\" + str(base_url) + \"';\"\n            result = self.db.exec(sql)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last=\" + str(new_last) + \" where base_url = '\"+str(base_url)+\"';\"\n                    self.db.exec(sql)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES (\"\n                sql += \"'\"+str(base_url)+\"', \"+str(first)+ \", \"+str(last)+\", '\"+str(name)+\"');\"\n                self.db.exec(sql)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "func_src_after": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{user}';\"\n            args = {'user': user}\n            results = self.db.exec(sql, args)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{bracket}' AND user='{user}';\"\n                    args = {'bracket': bracket, 'user': user}\n                    results = self.db.exec(sql, args)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{bracket}', '{user}', '{name}');\"\n                        args = {'bracket': bracket, 'user':user, 'name':name}\n                        self.db.exec(sql, args)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{url}', '{user}', '{name}');\"\n                    args = {'url': url, 'user':user, 'name':name}\n                    self.db.exec(sql, args)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '{base_url}';\"\n            args = {'base_url': base_url}\n            result = self.db.exec(sql, args)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last={new_last} where base_url='{base_url}';\"\n                    args = {'new_last': new_last, 'base_url': base_url}\n                    self.db.exec(sql, args)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES ('{base_url}', '{first}', '{last}', '{name}');\"\n                args = {'base_url': base_url, 'first': first, 'last': last, 'name': name}\n                self.db.exec(sql, args)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 402, "char_end": 480, "line": "            sql = \"SELECT * FROM user_analyzed WHERE user='{}';\".format(user)\n"}, {"line_no": 11, "char_start": 480, "char_end": 520, "line": "            results = self.db.exec(sql)\n"}, {"line_no": 21, "char_start": 1217, "char_end": 1325, "line": "                    sql = \"SELECT * FROM user_analyzed WHERE url='{}' AND user='{}';\".format(bracket, user)\n"}, {"line_no": 22, "char_start": 1325, "char_end": 1373, "line": "                    results = self.db.exec(sql)\n"}, {"line_no": 36, "char_start": 2156, "char_end": 2288, "line": "                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(bracket, user, name)\n"}, {"line_no": 37, "char_start": 2288, "char_end": 2330, "line": "                        self.db.exec(sql)\n"}, {"line_no": 58, "char_start": 3400, "char_end": 3524, "line": "                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(url, user, name)\n"}, {"line_no": 59, "char_start": 3524, "char_end": 3562, "line": "                    self.db.exec(sql)\n"}, {"line_no": 68, "char_start": 3918, "char_end": 4010, "line": "            sql = \"SELECT first,last FROM valids WHERE base_url = '\" + str(base_url) + \"';\"\n"}, {"line_no": 69, "char_start": 4010, "char_end": 4049, "line": "            result = self.db.exec(sql)\n"}, {"line_no": 93, "char_start": 5077, "char_end": 5188, "line": "                    sql = \"UPDATE valids SET last=\" + str(new_last) + \" where base_url = '\"+str(base_url)+\"';\"\n"}, {"line_no": 94, "char_start": 5188, "char_end": 5226, "line": "                    self.db.exec(sql)\n"}, {"line_no": 117, "char_start": 6425, "char_end": 6508, "line": "                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES (\"\n"}, {"line_no": 118, "char_start": 6508, "char_end": 6604, "line": "                sql += \"'\"+str(base_url)+\"', \"+str(first)+ \", \"+str(last)+\", '\"+str(name)+\"');\"\n"}, {"line_no": 119, "char_start": 6604, "char_end": 6638, "line": "                self.db.exec(sql)\n"}], "added": [{"line_no": 10, "char_start": 402, "char_end": 471, "line": "            sql = \"SELECT * FROM user_analyzed WHERE user='{user}';\"\n"}, {"line_no": 11, "char_start": 471, "char_end": 505, "line": "            args = {'user': user}\n"}, {"line_no": 12, "char_start": 505, "char_end": 551, "line": "            results = self.db.exec(sql, args)\n"}, {"line_no": 22, "char_start": 1248, "char_end": 1345, "line": "                    sql = \"SELECT * FROM user_analyzed WHERE url='{bracket}' AND user='{user}';\"\n"}, {"line_no": 23, "char_start": 1345, "char_end": 1407, "line": "                    args = {'bracket': bracket, 'user': user}\n"}, {"line_no": 24, "char_start": 1407, "char_end": 1461, "line": "                    results = self.db.exec(sql, args)\n"}, {"line_no": 38, "char_start": 2244, "char_end": 2363, "line": "                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{bracket}', '{user}', '{name}');\"\n"}, {"line_no": 39, "char_start": 2363, "char_end": 2441, "line": "                        args = {'bracket': bracket, 'user':user, 'name':name}\n"}, {"line_no": 40, "char_start": 2441, "char_end": 2489, "line": "                        self.db.exec(sql, args)\n"}, {"line_no": 61, "char_start": 3559, "char_end": 3670, "line": "                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{url}', '{user}', '{name}');\"\n"}, {"line_no": 62, "char_start": 3670, "char_end": 3736, "line": "                    args = {'url': url, 'user':user, 'name':name}\n"}, {"line_no": 63, "char_start": 3736, "char_end": 3780, "line": "                    self.db.exec(sql, args)\n"}, {"line_no": 72, "char_start": 4136, "char_end": 4217, "line": "            sql = \"SELECT first,last FROM valids WHERE base_url = '{base_url}';\"\n"}, {"line_no": 73, "char_start": 4217, "char_end": 4259, "line": "            args = {'base_url': base_url}\n"}, {"line_no": 74, "char_start": 4259, "char_end": 4304, "line": "            result = self.db.exec(sql, args)\n"}, {"line_no": 98, "char_start": 5332, "char_end": 5423, "line": "                    sql = \"UPDATE valids SET last={new_last} where base_url='{base_url}';\"\n"}, {"line_no": 99, "char_start": 5423, "char_end": 5495, "line": "                    args = {'new_last': new_last, 'base_url': base_url}\n"}, {"line_no": 100, "char_start": 5495, "char_end": 5539, "line": "                    self.db.exec(sql, args)\n"}, {"line_no": 123, "char_start": 6738, "char_end": 6866, "line": "                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES ('{base_url}', '{first}', '{last}', '{name}');\"\n"}, {"line_no": 124, "char_start": 6866, "char_end": 6956, "line": "                args = {'base_url': base_url, 'first': first, 'last': last, 'name': name}\n"}, {"line_no": 125, "char_start": 6956, "char_end": 6996, "line": "                self.db.exec(sql, args)\n"}]}, "char_changes": {"deleted": [{"char_start": 462, "char_end": 474, "chars": "}';\".format("}, {"char_start": 478, "char_end": 479, "chars": ")"}, {"char_start": 1298, "char_end": 1310, "chars": "}';\".format("}, {"char_start": 1323, "char_end": 1324, "chars": ")"}, {"char_start": 2259, "char_end": 2267, "chars": ".format("}, {"char_start": 2286, "char_end": 2287, "chars": ")"}, {"char_start": 3499, "char_end": 3512, "chars": ".format(url, "}, {"char_start": 3522, "char_end": 3523, "chars": ")"}, {"char_start": 3985, "char_end": 4009, "chars": "\" + str(base_url) + \"';\""}, {"char_start": 5127, "char_end": 5135, "chars": "\" + str("}, {"char_start": 5143, "char_end": 5148, "chars": ") + \""}, {"char_start": 5163, "char_end": 5173, "chars": " = '\"+str("}, {"char_start": 5181, "char_end": 5187, "chars": ")+\"';\""}, {"char_start": 6506, "char_end": 6603, "chars": "\"\n                sql += \"'\"+str(base_url)+\"', \"+str(first)+ \", \"+str(last)+\", '\"+str(name)+\"');\""}], "added": [{"char_start": 462, "char_end": 504, "chars": "user}';\"\n            args = {'user': user}"}, {"char_start": 543, "char_end": 549, "chars": ", args"}, {"char_start": 1315, "char_end": 1322, "chars": "bracket"}, {"char_start": 1336, "char_end": 1384, "chars": "user}';\"\n                    args = {'bracket': "}, {"char_start": 1393, "char_end": 1394, "chars": "'"}, {"char_start": 1398, "char_end": 1406, "chars": "': user}"}, {"char_start": 1453, "char_end": 1459, "chars": ", args"}, {"char_start": 2330, "char_end": 2337, "chars": "bracket"}, {"char_start": 2343, "char_end": 2347, "chars": "user"}, {"char_start": 2353, "char_end": 2357, "chars": "name"}, {"char_start": 2362, "char_end": 2406, "chars": "\n                        args = {'bracket': "}, {"char_start": 2415, "char_end": 2422, "chars": "'user':"}, {"char_start": 2428, "char_end": 2429, "chars": "'"}, {"char_start": 2433, "char_end": 2440, "chars": "':name}"}, {"char_start": 2481, "char_end": 2487, "chars": ", args"}, {"char_start": 3641, "char_end": 3644, "chars": "url"}, {"char_start": 3650, "char_end": 3654, "chars": "user"}, {"char_start": 3660, "char_end": 3664, "chars": "name"}, {"char_start": 3669, "char_end": 3717, "chars": "\n                    args = {'url': url, 'user':"}, {"char_start": 3723, "char_end": 3724, "chars": "'"}, {"char_start": 3728, "char_end": 3735, "chars": "':name}"}, {"char_start": 3772, "char_end": 3778, "chars": ", args"}, {"char_start": 4203, "char_end": 4258, "chars": "{base_url}';\"\n            args = {'base_url': base_url}"}, {"char_start": 4296, "char_end": 4302, "chars": ", args"}, {"char_start": 5382, "char_end": 5383, "chars": "{"}, {"char_start": 5391, "char_end": 5392, "chars": "}"}, {"char_start": 5407, "char_end": 5494, "chars": "='{base_url}';\"\n                    args = {'new_last': new_last, 'base_url': base_url}"}, {"char_start": 5531, "char_end": 5537, "chars": ", args"}, {"char_start": 6819, "char_end": 6955, "chars": "'{base_url}', '{first}', '{last}', '{name}');\"\n                args = {'base_url': base_url, 'first': first, 'last': last, 'name': name}"}, {"char_start": 6988, "char_end": 6994, "chars": ", args"}]}, "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089"}
{"func_name": "create_cf_base", "func_src_before": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table \" + i + \" (problems INTEGER, diff CHAR)\")\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "func_src_after": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table ? (problems INTEGER, diff CHAR)\", (i,))\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "line_changes": {"deleted": [{"line_no": 10, "char_start": 360, "char_end": 437, "line": "        conn.execute(\"create table \" + i + \" (problems INTEGER, diff CHAR)\")\n"}, {"line_no": 37, "char_start": 1385, "char_end": 1468, "line": "                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n"}], "added": [{"line_no": 10, "char_start": 360, "char_end": 435, "line": "        conn.execute(\"create table ? (problems INTEGER, diff CHAR)\", (i,))\n"}, {"line_no": 37, "char_start": 1383, "char_end": 1461, "line": "                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n"}]}, "char_changes": {"deleted": [{"char_start": 395, "char_end": 404, "chars": "\" + i + \""}, {"char_start": 1431, "char_end": 1443, "chars": "\" + s[3] + \""}], "added": [{"char_start": 395, "char_end": 396, "chars": "?"}, {"char_start": 427, "char_end": 433, "chars": ", (i,)"}, {"char_start": 1429, "char_end": 1430, "chars": "?"}, {"char_start": 1448, "char_end": 1454, "chars": "s[3], "}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createcfbase.py", "vul_type": "cwe-089"}
{"func_name": "create_theory_table", "func_src_before": "def create_theory_table(): #create EMPTY theory table\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    for i in available_tags:\n        conn.execute(\"create table \" + str(i) + \" (link STRING)\")\n    theory.commit()\n    theory.close()", "func_src_after": "def create_theory_table(): #create EMPTY theory table\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    for i in available_tags:\n        conn.execute(\"create table \" + i + \" (link STRING)\")\n    theory.commit()\n    theory.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 199, "char_end": 265, "line": "        conn.execute(\"create table \" + str(i) + \" (link STRING)\")\n"}], "added": [{"line_no": 5, "char_start": 199, "char_end": 260, "line": "        conn.execute(\"create table \" + i + \" (link STRING)\")\n"}]}, "char_changes": {"deleted": [{"char_start": 238, "char_end": 244, "chars": "str(i)"}], "added": [{"char_start": 238, "char_end": 239, "chars": "i"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createcfbase.py", "vul_type": "cwe-089"}
{"func_name": "init_user", "func_src_before": "def init_user(username, chat_id):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor.execute(\"CREATE TABLE result (problem INTEGER, diff STRING, verdict STRING)\")\n    cursor2.execute(\"SELECT * FROM problems\")\n    x = cursor2.fetchone()\n    while x != None:\n        cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n        x = cursor2.fetchone()\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    old = \"\"\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try = soup.find(attrs={\"class\":\"status-small\"})\n    if not last_try == None:\n        last_try = str(last_try).split()\n        last_try = str(last_try[2]) + str(last_try[3])\n\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    cursor.execute(\"select * from result where problem = '\" + s[3] + \"'and diff = '\" + s[4] + \"'\")\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" + s[4] + \"'\")\n                    if x != None and x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = '\" + s2[1] +\"' where problem = '\" + s[3] + \"' and diff = '\" + s[4] + \"'\")\n\n    conn.commit()\n    conn.close()\n    conn2.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from last_update_problemset\")\n    last_problem = conn.fetchone()\n    conn.execute(\"select * from users where chat_id = '\" + str(chat_id) + \"'\")\n    x = conn.fetchone()\n    if x == None:\n        conn.execute(\"insert into users values (?, ?, ?, ?, ?)\", (chat_id, username, str(last_try), str(last_problem[0]), 1))\n    else:\n        conn.execute(\"update users set username = '\" + str(username) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n        conn.execute(\"update users set last_update = '\" + str(last_try) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n        conn.execute(\"update users set last_problem = '\" + str(last_problem[0]) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n        conn.execute(\"update users set state = '\" + str(1) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    settings.commit()\n    settings.close()", "func_src_after": "def init_user(username, chat_id):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor.execute(\"CREATE TABLE result (problem INTEGER, diff STRING, verdict STRING)\")\n    cursor2.execute(\"SELECT * FROM problems\")\n    x = cursor2.fetchone()\n    while x != None:\n        cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n        x = cursor2.fetchone()\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try = soup.find(attrs={\"class\":\"status-small\"})\n    if not last_try == None:\n        last_try = str(last_try).split()\n        last_try = str(last_try[2]) + str(last_try[3])\n\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    cursor.execute(\"select * from result where problem = ? and diff = ?\", (s[3], s[4]))\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n                    if x != None and x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n    conn.commit()\n    conn.close()\n    conn2.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from last_update_problemset\")\n    last_problem = conn.fetchone()\n    conn.execute(\"select * from users where chat_id = ?\", (str(chat_id),))\n    x = conn.fetchone()\n    if x == None:\n        conn.execute(\"insert into users values (?, ?, ?, ?, ?)\", (chat_id, username, str(last_try), str(last_problem[0]), 1))\n    else:\n        conn.execute(\"update users set username = ? where chat_id = ?\", (str(username), str(chat_id)))\n        conn.execute(\"update users set last_update = ? where chat_id = ?\", (str(last_try), str(chat_id)))\n        conn.execute(\"update users set last_problem = ? where chat_id = ?\", (str(last_problem[0]), str(chat_id)))\n        conn.execute(\"update users set state = ? where chat_id = ?\", (str(1), str(chat_id)))\n    settings.commit()\n    settings.close()", "line_changes": {"deleted": [{"line_no": 22, "char_start": 893, "char_end": 894, "line": "\n"}, {"line_no": 23, "char_start": 894, "char_end": 907, "line": "    old = \"\"\n"}, {"line_no": 44, "char_start": 1799, "char_end": 1914, "line": "                    cursor.execute(\"select * from result where problem = '\" + s[3] + \"'and diff = '\" + s[4] + \"'\")\n"}, {"line_no": 47, "char_start": 2008, "char_end": 2151, "line": "                        cursor.execute(\"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" + s[4] + \"'\")\n"}, {"line_no": 49, "char_start": 2202, "char_end": 2344, "line": "                        cursor.execute(\"update result set verdict = '\" + s2[1] +\"' where problem = '\" + s[3] + \"' and diff = '\" + s[4] + \"'\")\n"}, {"line_no": 50, "char_start": 2344, "char_end": 2345, "line": "\n"}, {"line_no": 54, "char_start": 2398, "char_end": 2399, "line": "\n"}, {"line_no": 59, "char_start": 2613, "char_end": 2692, "line": "    conn.execute(\"select * from users where chat_id = '\" + str(chat_id) + \"'\")\n"}, {"line_no": 64, "char_start": 2870, "char_end": 2985, "line": "        conn.execute(\"update users set username = '\" + str(username) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n"}, {"line_no": 65, "char_start": 2985, "char_end": 3103, "line": "        conn.execute(\"update users set last_update = '\" + str(last_try) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n"}, {"line_no": 66, "char_start": 3103, "char_end": 3229, "line": "        conn.execute(\"update users set last_problem = '\" + str(last_problem[0]) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n"}, {"line_no": 67, "char_start": 3229, "char_end": 3334, "line": "        conn.execute(\"update users set state = '\" + str(1) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n"}], "added": [{"line_no": 42, "char_start": 1785, "char_end": 1889, "line": "                    cursor.execute(\"select * from result where problem = ? and diff = ?\", (s[3], s[4]))\n"}, {"line_no": 45, "char_start": 1983, "char_end": 2107, "line": "                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n"}, {"line_no": 47, "char_start": 2158, "char_end": 2282, "line": "                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n"}, {"line_no": 55, "char_start": 2549, "char_end": 2624, "line": "    conn.execute(\"select * from users where chat_id = ?\", (str(chat_id),))\n"}, {"line_no": 60, "char_start": 2802, "char_end": 2905, "line": "        conn.execute(\"update users set username = ? where chat_id = ?\", (str(username), str(chat_id)))\n"}, {"line_no": 61, "char_start": 2905, "char_end": 3011, "line": "        conn.execute(\"update users set last_update = ? where chat_id = ?\", (str(last_try), str(chat_id)))\n"}, {"line_no": 62, "char_start": 3011, "char_end": 3125, "line": "        conn.execute(\"update users set last_problem = ? where chat_id = ?\", (str(last_problem[0]), str(chat_id)))\n"}, {"line_no": 63, "char_start": 3125, "char_end": 3218, "line": "        conn.execute(\"update users set state = ? where chat_id = ?\", (str(1), str(chat_id)))\n"}]}, "char_changes": {"deleted": [{"char_start": 892, "char_end": 906, "chars": "\n\n    old = \"\""}, {"char_start": 1872, "char_end": 1912, "chars": "'\" + s[3] + \"'and diff = '\" + s[4] + \"'\""}, {"char_start": 2076, "char_end": 2091, "chars": "'\" + s2[1] + \"'"}, {"char_start": 2108, "char_end": 2149, "chars": "'\" + s[3] + \"' and diff = '\" + s[4] + \"'\""}, {"char_start": 2270, "char_end": 2284, "chars": "'\" + s2[1] +\"'"}, {"char_start": 2301, "char_end": 2344, "chars": "'\" + s[3] + \"' and diff = '\" + s[4] + \"'\")\n"}, {"char_start": 2398, "char_end": 2399, "chars": "\n"}, {"char_start": 2667, "char_end": 2672, "chars": "'\" + "}, {"char_start": 2684, "char_end": 2690, "chars": " + \"'\""}, {"char_start": 2920, "char_end": 2964, "chars": "'\" + str(username) + \"' where chat_id = '\" +"}, {"char_start": 2977, "char_end": 2983, "chars": " + \"'\""}, {"char_start": 3038, "char_end": 3082, "chars": "'\" + str(last_try) + \"' where chat_id = '\" +"}, {"char_start": 3095, "char_end": 3101, "chars": " + \"'\""}, {"char_start": 3157, "char_end": 3208, "chars": "'\" + str(last_problem[0]) + \"' where chat_id = '\" +"}, {"char_start": 3221, "char_end": 3227, "chars": " + \"'\""}, {"char_start": 3276, "char_end": 3292, "chars": "'\" + str(1) + \"'"}, {"char_start": 3309, "char_end": 3313, "chars": "'\" +"}, {"char_start": 3326, "char_end": 3332, "chars": " + \"'\""}], "added": [{"char_start": 1858, "char_end": 1887, "chars": "? and diff = ?\", (s[3], s[4])"}, {"char_start": 2051, "char_end": 2052, "chars": "?"}, {"char_start": 2069, "char_end": 2105, "chars": "? and diff = ?\", (s2[1], s[3], s[4])"}, {"char_start": 2226, "char_end": 2227, "chars": "?"}, {"char_start": 2244, "char_end": 2281, "chars": "? and diff = ?\", (s2[1], s[3], s[4]))"}, {"char_start": 2603, "char_end": 2608, "chars": "?\", ("}, {"char_start": 2620, "char_end": 2622, "chars": ",)"}, {"char_start": 2852, "char_end": 2889, "chars": "? where chat_id = ?\", (str(username),"}, {"char_start": 2902, "char_end": 2903, "chars": ")"}, {"char_start": 2958, "char_end": 2995, "chars": "? where chat_id = ?\", (str(last_try),"}, {"char_start": 3008, "char_end": 3009, "chars": ")"}, {"char_start": 3065, "char_end": 3109, "chars": "? where chat_id = ?\", (str(last_problem[0]),"}, {"char_start": 3122, "char_end": 3123, "chars": ")"}, {"char_start": 3172, "char_end": 3173, "chars": "?"}, {"char_start": 3190, "char_end": 3202, "chars": "?\", (str(1),"}, {"char_start": 3215, "char_end": 3216, "chars": ")"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createuserbase.py", "vul_type": "cwe-089"}
{"func_name": "get_unsolved_problem", "func_src_before": "def get_unsolved_problem(tag, username):\n    tasks = list()\n    list_of_current_tags = list()\n    list_of_current_diff = list()\n\n    def find_intersection(tag):\n        conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n        conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n        cursor = conn.cursor()\n        cursor2 = conn2.cursor()\n        cursor2.execute(\"SELECT * FROM \" + tag)\n        a = list()\n        problem_and_diff = cursor2.fetchone()\n\n        while problem_and_diff != None:\n            cursor.execute(\"SELECT * FROM result WHERE problem = '\" + str(problem_and_diff[0]) + \"' AND diff = '\" + str(problem_and_diff[1]) + \"' AND NOT verdict = 'OK'\")\n            problem_and_diff_and_ok = cursor.fetchone()\n            if problem_and_diff_and_ok != None and problem_and_diff_and_ok in tasks:\n                a.append(problem_and_diff_and_ok)\n            problem_and_diff = cursor2.fetchone()\n\n        conn.close()\n        conn2.close()\n        return a\n\n\n    list_of_current_tags = list()\n    for i in available_tags:\n        if i in tag:\n            list_of_current_tags.append(i)\n\n    list_of_current_diff = list()\n    for i in available_diff:\n        if i in tag:\n            list_of_current_diff.append(i)\n    f = False\n    if len(list_of_current_tags) == 0 and list_of_current_diff !=0:\n        list_of_current_tags = available_tags.copy()\n        f = True\n    if len(list_of_current_tags) == 0 and len(list_of_current_diff) == 0:\n        return \"Plz try again\"\n    if len(list_of_current_diff) == 0 and len(list_of_current_tags) != 0:\n        list_of_current_diff = available_diff.copy()\n        f = True\n\n\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor2.execute(\"SELECT * FROM \" + list_of_current_tags[0])\n    problem_and_diff = cursor2.fetchone()\n\n    while problem_and_diff != None:\n        if problem_and_diff[1] in list_of_current_diff:\n            cursor.execute(\"SELECT * FROM result WHERE problem = '\" + str(problem_and_diff[0]) + \"' AND diff = '\" + str(\n                problem_and_diff[1]) + \"' AND NOT verdict = 'OK'\")\n            problem_and_diff_and_ok = cursor.fetchone()\n            if problem_and_diff_and_ok != None:\n                tasks.append(problem_and_diff_and_ok)\n        problem_and_diff = cursor2.fetchone()\n\n    conn.close()\n    conn2.close()\n    if not f:\n        for i in range(1, len(list_of_current_tags)):\n            tasks = find_intersection(list_of_current_tags[i])\n\n    random.seed()\n    if len(tasks) > 0:\n        ind1 = random.randint(0, len(tasks) - 1)\n        s1 = str(tasks[ind1][0]) + '/' + tasks[ind1][1]\n        tasks.pop(ind1)\n        return 'http://codeforces.com/problemset/problem/' + s1\n    else:\n        return \"You have solved all tasks with this tag, nice!\"", "func_src_after": "def get_unsolved_problem(tag, username):\n    tasks = list()\n    list_of_current_tags = checking_request_tags(tag)\n    list_of_current_diff = checking_request_diff(tag)\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor2.execute(\"SELECT * FROM \" + list_of_current_tags[0])\n    problem_and_diff = cursor2.fetchone()\n    while problem_and_diff != None:\n        if problem_and_diff[1] in list_of_current_diff:\n            cursor.execute(\"SELECT * FROM result WHERE problem = ? AND diff = ? AND NOT verdict = 'OK'\", (problem_and_diff[0], problem_and_diff[1]))\n            problem_and_diff_and_ok = cursor.fetchone()\n            if problem_and_diff_and_ok != None:\n                tasks.append(problem_and_diff_and_ok)\n        problem_and_diff = cursor2.fetchone()\n    conn.close()\n    conn2.close()\n    tasks = get_array_of_tasks(list_of_current_tags, tasks, username)\n    random.seed()\n    if len(tasks) > 0:\n        ind1 = random.randint(0, len(tasks) - 1)\n        s1 = str(tasks[ind1][0]) + '/' + tasks[ind1][1]\n        tasks.pop(ind1)\n        return 'http://codeforces.com/problemset/problem/' + s1\n    else:\n        return \"You have solved all tasks with this tag, nice!\"", "line_changes": {"deleted": [{"line_no": 53, "char_start": 2058, "char_end": 2059, "line": "\n"}, {"line_no": 56, "char_start": 2151, "char_end": 2272, "line": "            cursor.execute(\"SELECT * FROM result WHERE problem = '\" + str(problem_and_diff[0]) + \"' AND diff = '\" + str(\n"}, {"line_no": 57, "char_start": 2272, "char_end": 2339, "line": "                problem_and_diff[1]) + \"' AND NOT verdict = 'OK'\")\n"}, {"line_no": 62, "char_start": 2543, "char_end": 2544, "line": "\n"}, {"line_no": 65, "char_start": 2579, "char_end": 2593, "line": "    if not f:\n"}, {"line_no": 66, "char_start": 2593, "char_end": 2647, "line": "        for i in range(1, len(list_of_current_tags)):\n"}, {"line_no": 67, "char_start": 2647, "char_end": 2710, "line": "            tasks = find_intersection(list_of_current_tags[i])\n"}, {"line_no": 68, "char_start": 2710, "char_end": 2711, "line": "\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 41, "line": "def get_unsolved_problem(tag, username):\n"}, {"line_no": 2, "char_start": 41, "char_end": 60, "line": "    tasks = list()\n"}, {"line_no": 3, "char_start": 60, "char_end": 114, "line": "    list_of_current_tags = checking_request_tags(tag)\n"}, {"line_no": 4, "char_start": 114, "char_end": 168, "line": "    list_of_current_diff = checking_request_diff(tag)\n"}, {"line_no": 13, "char_start": 610, "char_end": 759, "line": "            cursor.execute(\"SELECT * FROM result WHERE problem = ? AND diff = ? AND NOT verdict = 'OK'\", (problem_and_diff[0], problem_and_diff[1]))\n"}, {"line_no": 20, "char_start": 998, "char_end": 1068, "line": "    tasks = get_array_of_tasks(list_of_current_tags, tasks, username)\n"}]}, "char_changes": {"deleted": [{"char_start": 87, "char_end": 1707, "chars": "list()\n    list_of_current_diff = list()\n\n    def find_intersection(tag):\n        conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n        conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n        cursor = conn.cursor()\n        cursor2 = conn2.cursor()\n        cursor2.execute(\"SELECT * FROM \" + tag)\n        a = list()\n        problem_and_diff = cursor2.fetchone()\n\n        while problem_and_diff != None:\n            cursor.execute(\"SELECT * FROM result WHERE problem = '\" + str(problem_and_diff[0]) + \"' AND diff = '\" + str(problem_and_diff[1]) + \"' AND NOT verdict = 'OK'\")\n            problem_and_diff_and_ok = cursor.fetchone()\n            if problem_and_diff_and_ok != None and problem_and_diff_and_ok in tasks:\n                a.append(problem_and_diff_and_ok)\n            problem_and_diff = cursor2.fetchone()\n\n        conn.close()\n        conn2.close()\n        return a\n\n\n    list_of_current_tags = list()\n    for i in available_tags:\n        if i in tag:\n            list_of_current_tags.append(i)\n\n    list_of_current_diff = list()\n    for i in available_diff:\n        if i in tag:\n            list_of_current_diff.append(i)\n    f = False\n    if len(list_of_current_tags) == 0 and list_of_current_diff !=0:\n        list_of_current_tags = available_tags.copy()\n        f = True\n    if len(list_of_current_tags) == 0 and len(list_of_current_diff) == 0:\n        return \"Plz try again\"\n    if len(list_of_current_diff) == 0 and len(list_of_current_tags) != 0:\n        list_of_current_diff = available_diff.copy()\n        f = True\n\n"}, {"char_start": 2058, "char_end": 2059, "chars": "\n"}, {"char_start": 2216, "char_end": 2337, "chars": "'\" + str(problem_and_diff[0]) + \"' AND diff = '\" + str(\n                problem_and_diff[1]) + \"' AND NOT verdict = 'OK'\""}, {"char_start": 2543, "char_end": 2544, "chars": "\n"}, {"char_start": 2583, "char_end": 2710, "chars": "if not f:\n        for i in range(1, len(list_of_current_tags)):\n            tasks = find_intersection(list_of_current_tags[i])\n"}], "added": [{"char_start": 87, "char_end": 167, "chars": "checking_request_tags(tag)\n    list_of_current_diff = checking_request_diff(tag)"}, {"char_start": 675, "char_end": 757, "chars": "? AND diff = ? AND NOT verdict = 'OK'\", (problem_and_diff[0], problem_and_diff[1])"}, {"char_start": 1002, "char_end": 1067, "chars": "tasks = get_array_of_tasks(list_of_current_tags, tasks, username)"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/problem.py", "vul_type": "cwe-089"}
{"func_name": "create_stats_picture", "func_src_before": "def create_stats_picture(username):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    a = list()\n    b = list()\n    leg = list()\n    sum = 0\n    for i in available_tags:\n        cursor2.execute(\"SELECT * FROM \" + str(i))\n        x = cursor2.fetchone()\n        count = 0\n        while x != None:\n            cursor.execute(\"SELECT * FROM result WHERE problem = '\" + str(x[0]) + \"' AND diff = '\" + str(\n                x[1]) + \"' AND verdict = 'OK'\")\n            y = cursor.fetchone()\n            if y != None:\n                count += 1\n            x = cursor2.fetchone()\n        a.append(Pair(count, i))\n        sum += count\n\n    conn.close()\n    conn2.close()\n    if sum == 0:\n        return True\n    for i in range(len(a)):\n        if a[i].first / sum != 0:\n            b.append(a[i].first / sum)\n            leg.append(a[i].second)\n\n    fig1, ax1 = plt.subplots()\n    ax1.pie(b,  autopct='%1.1f%%',\n            shadow=True, startangle=90)\n    ax1.axis('equal')\n    ax1.legend(leg)\n    path = os.path.join(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\", username + '.png')\n    if os.path.exists(path):\n        os.remove(path)\n    plt.savefig(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + \".png\")\n    plt.close()\n    return False", "func_src_after": "def create_stats_picture(username):\n    data_for_plot = list()\n    leg = list()\n    list_tags_stats = count_stats(username)\n    sum = 0\n    for i in range(len(list_tags_stats)):\n        sum += list_tags_stats[i].first\n    for i in range(len(list_tags_stats)):\n        if list_tags_stats[i].first / sum != 0:\n            data_for_plot.append(list_tags_stats[i].first / sum)\n            leg.append(list_tags_stats[i].second)\n\n    fig1, ax1 = plt.subplots()\n    ax1.pie(data_for_plot,  autopct='%1.1f%%',\n            shadow=True, startangle=90)\n    ax1.axis('equal')\n    ax1.legend(leg)\n    path = os.path.join(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\", username + '.png')\n    if os.path.exists(path):\n        os.remove(path)\n    plt.savefig(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + \".png\")\n    plt.close()\n    return False", "line_changes": {"deleted": [{"line_no": 34, "char_start": 1065, "char_end": 1100, "line": "    ax1.pie(b,  autopct='%1.1f%%',\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 36, "line": "def create_stats_picture(username):\n"}, {"line_no": 2, "char_start": 36, "char_end": 63, "line": "    data_for_plot = list()\n"}, {"line_no": 3, "char_start": 63, "char_end": 80, "line": "    leg = list()\n"}, {"line_no": 4, "char_start": 80, "char_end": 124, "line": "    list_tags_stats = count_stats(username)\n"}, {"line_no": 5, "char_start": 124, "char_end": 136, "line": "    sum = 0\n"}, {"line_no": 6, "char_start": 136, "char_end": 178, "line": "    for i in range(len(list_tags_stats)):\n"}, {"line_no": 7, "char_start": 178, "char_end": 218, "line": "        sum += list_tags_stats[i].first\n"}, {"line_no": 8, "char_start": 218, "char_end": 260, "line": "    for i in range(len(list_tags_stats)):\n"}, {"line_no": 9, "char_start": 260, "char_end": 308, "line": "        if list_tags_stats[i].first / sum != 0:\n"}, {"line_no": 10, "char_start": 308, "char_end": 373, "line": "            data_for_plot.append(list_tags_stats[i].first / sum)\n"}, {"line_no": 11, "char_start": 373, "char_end": 423, "line": "            leg.append(list_tags_stats[i].second)\n"}, {"line_no": 14, "char_start": 455, "char_end": 502, "line": "    ax1.pie(data_for_plot,  autopct='%1.1f%%',\n"}]}, "char_changes": {"deleted": [{"char_start": 40, "char_end": 799, "chars": "conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    a = list()\n    b = list()\n    leg = list()\n    sum = 0\n    for i in available_tags:\n        cursor2.execute(\"SELECT * FROM \" + str(i))\n        x = cursor2.fetchone()\n        count = 0\n        while x != None:\n            cursor.execute(\"SELECT * FROM result WHERE problem = '\" + str(x[0]) + \"' AND diff = '\" + str(\n                x[1]) + \"' AND verdict = 'OK'\")\n            y = cursor.fetchone()\n            if y != None:\n                count += 1\n            x = cursor2.fetchone()\n        a.append(Pair(count, i"}, {"char_start": 817, "char_end": 980, "chars": "count\n\n    conn.close()\n    conn2.close()\n    if sum == 0:\n        return True\n    for i in range(len(a)):\n        if a[i].first / sum != 0:\n            b.append(a"}, {"char_start": 1020, "char_end": 1021, "chars": "a"}, {"char_start": 1077, "char_end": 1078, "chars": "b"}], "added": [{"char_start": 40, "char_end": 174, "chars": "data_for_plot = list()\n    leg = list()\n    list_tags_stats = count_stats(username)\n    sum = 0\n    for i in range(len(list_tags_stats"}, {"char_start": 176, "char_end": 177, "chars": ":"}, {"char_start": 193, "char_end": 356, "chars": "list_tags_stats[i].first\n    for i in range(len(list_tags_stats)):\n        if list_tags_stats[i].first / sum != 0:\n            data_for_plot.append(list_tags_stats"}, {"char_start": 396, "char_end": 411, "chars": "list_tags_stats"}, {"char_start": 467, "char_end": 480, "chars": "data_for_plot"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/problem.py", "vul_type": "cwe-089"}
{"func_name": "create_text_stats", "func_src_before": "def create_text_stats(username):\n    verdict = {\"COMPILATION_ERROR\" : 0, \"OK\" : 0, \"TIME_LIMIT_EXCEEDED\" : 0, \"WRONG_ANSWER\" : 0, \"RUNTIME_ERROR\" : 0, \"MEMORY_LIMIT_EXCEEDED\" : 0}\n    colors = ['red', 'green', 'tan', 'blue', 'purple', 'orange']\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    count = 0\n    a = list()\n    b = list()\n    for i in available_tags:\n        cursor2.execute(\"SELECT * FROM \" + str(i))\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"SELECT * FROM result WHERE problem = '\" + str(x[0]) + \"' AND diff = '\" + str(x[1]) + \"'\")\n            y = cursor.fetchone()\n            if y != None:\n                for j in verdict.keys():\n                    if y[2] == j:\n                        verdict[j] += 1\n                        count += 1\n\n            x = cursor2.fetchone()\n\n    for i in verdict.keys():\n        a.append(i)\n        b.append(verdict[i])\n    fig1, ax1 = plt.subplots()\n    ax1.pie(b, labels = b, colors = colors,\n            shadow=True, startangle=90)\n    ax1.axis('equal')\n    ax1.legend(a)\n    ax1.set_title('How many different verdict in last status of problem you have: ')\n    path = os.path.join(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\", username + '.png')\n    if os.path.exists(path):\n        os.remove(path)\n    plt.savefig(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + \".png\")\n    conn.close()\n    conn2.close()\n    plt.close()\n    s = username + \" has at least one submissions in \" + str(count) + \" problems\"\n    return s", "func_src_after": "def create_text_stats(username):\n    list_tags_stats = list()\n    data_for_plot = list()\n    verdict = count_stats_for_second_plot(username)\n    for i in verdict.keys():\n        list_tags_stats.append(i)\n        data_for_plot.append(verdict[i])\n    fig1, ax1 = plt.subplots()\n    ax1.pie(data_for_plot, labels = data_for_plot, colors = colors,\n            shadow=True, startangle=90)\n    ax1.axis('equal')\n    ax1.legend(list_tags_stats)\n    ax1.set_title('How many different verdict in last status of problem you have: ')\n    path = os.path.join(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\", username + '.png')\n    if os.path.exists(path):\n        os.remove(path)\n    plt.savefig(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + \".png\")\n    plt.close()\n    return True", "line_changes": {"deleted": [{"line_no": 26, "char_start": 1063, "char_end": 1083, "line": "        a.append(i)\n"}, {"line_no": 27, "char_start": 1083, "char_end": 1112, "line": "        b.append(verdict[i])\n"}, {"line_no": 29, "char_start": 1143, "char_end": 1187, "line": "    ax1.pie(b, labels = b, colors = colors,\n"}, {"line_no": 32, "char_start": 1249, "char_end": 1267, "line": "    ax1.legend(a)\n"}, {"line_no": 38, "char_start": 1600, "char_end": 1617, "line": "    conn.close()\n"}, {"line_no": 39, "char_start": 1617, "char_end": 1635, "line": "    conn2.close()\n"}, {"line_no": 41, "char_start": 1651, "char_end": 1733, "line": "    s = username + \" has at least one submissions in \" + str(count) + \" problems\"\n"}, {"line_no": 42, "char_start": 1733, "char_end": 1745, "line": "    return s\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 33, "line": "def create_text_stats(username):\n"}, {"line_no": 2, "char_start": 33, "char_end": 62, "line": "    list_tags_stats = list()\n"}, {"line_no": 3, "char_start": 62, "char_end": 89, "line": "    data_for_plot = list()\n"}, {"line_no": 4, "char_start": 89, "char_end": 141, "line": "    verdict = count_stats_for_second_plot(username)\n"}, {"line_no": 6, "char_start": 170, "char_end": 204, "line": "        list_tags_stats.append(i)\n"}, {"line_no": 7, "char_start": 204, "char_end": 245, "line": "        data_for_plot.append(verdict[i])\n"}, {"line_no": 9, "char_start": 276, "char_end": 344, "line": "    ax1.pie(data_for_plot, labels = data_for_plot, colors = colors,\n"}, {"line_no": 12, "char_start": 406, "char_end": 438, "line": "    ax1.legend(list_tags_stats)\n"}, {"line_no": 19, "char_start": 787, "char_end": 802, "line": "    return True\n"}]}, "char_changes": {"deleted": [{"char_start": 37, "char_end": 859, "chars": "verdict = {\"COMPILATION_ERROR\" : 0, \"OK\" : 0, \"TIME_LIMIT_EXCEEDED\" : 0, \"WRONG_ANSWER\" : 0, \"RUNTIME_ERROR\" : 0, \"MEMORY_LIMIT_EXCEEDED\" : 0}\n    colors = ['red', 'green', 'tan', 'blue', 'purple', 'orange']\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    count = 0\n    a = list()\n    b = list()\n    for i in available_tags:\n        cursor2.execute(\"SELECT * FROM \" + str(i))\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"SELECT * FROM result WHERE problem = '\" + str(x[0]) + \"' AND diff = '\" + str(x[1]) + \"'\")\n            y = cursor.fetchone()\n            if y != None:\n            "}, {"char_start": 867, "char_end": 868, "chars": "j"}, {"char_start": 896, "char_end": 1072, "chars": "            if y[2] == j:\n                        verdict[j] += 1\n                        count += 1\n\n            x = cursor2.fetchone()\n\n    for i in verdict.keys():\n        a"}, {"char_start": 1091, "char_end": 1092, "chars": "b"}, {"char_start": 1155, "char_end": 1168, "chars": "b, labels = b"}, {"char_start": 1264, "char_end": 1265, "chars": "a"}, {"char_start": 1604, "char_end": 1745, "chars": "conn.close()\n    conn2.close()\n    plt.close()\n    s = username + \" has at least one submissions in \" + str(count) + \" problems\"\n    return s"}], "added": [{"char_start": 37, "char_end": 141, "chars": "list_tags_stats = list()\n    data_for_plot = list()\n    verdict = count_stats_for_second_plot(username)\n"}, {"char_start": 149, "char_end": 150, "chars": "i"}, {"char_start": 178, "char_end": 193, "chars": "list_tags_stats"}, {"char_start": 212, "char_end": 225, "chars": "data_for_plot"}, {"char_start": 288, "char_end": 325, "chars": "data_for_plot, labels = data_for_plot"}, {"char_start": 421, "char_end": 436, "chars": "list_tags_stats"}, {"char_start": 775, "char_end": 802, "chars": "plt.close()\n    return True"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/problem.py", "vul_type": "cwe-089"}
{"func_name": "cf_update", "func_src_before": "def cf_update():\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = settings.cursor()\n    cursor.execute(\"select * from last_update_problemset\")\n    x = cursor.fetchone()\n\n    last_try = x[0]\n\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    available_tags = {'math', \"strings\", \"trees\", \"graphs\", \"dp\", \"greedy\"}\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = ''\n    b = 0\n    f = False\n    last_update = last_try\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        v = False\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    if s[3] + s[4] == last_try:\n                        v = True\n                        break\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n\n        if v:\n            break\n\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update last_update_problemset set problem = '\" + str(last_update) + \"' where problem = '\" + str(last_try) + \"'\")\n    settings.commit()\n    settings.close()", "func_src_after": "def cf_update():\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = settings.cursor()\n    cursor.execute(\"select * from last_update_problemset\")\n    x = cursor.fetchone()\n\n    last_try = x[0]\n\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    available_tags = {'math', \"strings\", \"trees\", \"graphs\", \"dp\", \"greedy\"}\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = ''\n    b = 0\n    f = False\n    last_update = last_try\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        v = False\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    if s[3] + s[4] == last_try:\n                        v = True\n                        break\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n\n        if v:\n            break\n\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update last_update_problemset set problem = ? where problem = ?\", (str(last_update), str(last_try)))\n    settings.commit()\n    settings.close()", "line_changes": {"deleted": [{"line_no": 47, "char_start": 1667, "char_end": 1750, "line": "                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n"}, {"line_no": 57, "char_start": 1942, "char_end": 2073, "line": "    conn.execute(\"update last_update_problemset set problem = '\" + str(last_update) + \"' where problem = '\" + str(last_try) + \"'\")\n"}], "added": [{"line_no": 47, "char_start": 1667, "char_end": 1745, "line": "                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n"}, {"line_no": 57, "char_start": 1937, "char_end": 2056, "line": "    conn.execute(\"update last_update_problemset set problem = ? where problem = ?\", (str(last_update), str(last_try)))\n"}]}, "char_changes": {"deleted": [{"char_start": 1713, "char_end": 1725, "chars": "\" + s[3] + \""}, {"char_start": 2004, "char_end": 2051, "chars": "'\" + str(last_update) + \"' where problem = '\" +"}, {"char_start": 2065, "char_end": 2071, "chars": " + \"'\""}], "added": [{"char_start": 1713, "char_end": 1714, "chars": "?"}, {"char_start": 1732, "char_end": 1738, "chars": "s[3], "}, {"char_start": 1999, "char_end": 2039, "chars": "? where problem = ?\", (str(last_update),"}, {"char_start": 2053, "char_end": 2054, "chars": ")"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089"}
{"func_name": "update_user", "func_src_before": "def update_user(username, chat_id, last_update):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor_settings = settings.cursor()\n    cursor_settings.execute(\"select last_problem from users where chat_id = '\" + str(chat_id) + \"'\")\n    update_eq = cursor_settings.fetchone()\n    cursor_settings.execute(\"select * from last_update_problemset\")\n    update_base = cursor_settings.fetchone()\n    last_problem = update_base[0]\n    if update_eq[0] != update_base[0]:\n        cursor2.execute(\"SELECT * FROM problems\")\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"select * from result where problem = '\" + str(x[0]) + \"' and diff = '\" + str(x[1]) + \"'\")\n            x2 = cursor.fetchone()\n            if x2 == None:\n                cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n            last_problem = x\n            x = cursor2.fetchone()\n        conn2.close()\n        settings.close()\n    if len(last_problem) == 2:\n        last_problem = last_problem[0] + last_problem[1]\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    v = False\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try_new = soup.find(attrs={\"class\": \"status-small\"})\n    last_try_new = str(last_try_new).split()\n    last_try_new = str(last_try_new[2]) + str(last_try_new[3])\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        j = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        last_try = soup.find_all(attrs={\"class\": \"status-small\"})\n        for link in soup.find_all('a'):\n            last_try_date = str(last_try[j]).split()\n            last_try_date = str(last_try_date[2]) + str(last_try_date[3])\n            if last_try_date == last_update:\n                v = True\n                break\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    j += 1\n                    cursor.execute(\"select * from result where problem = '\" + s[3] + \"'and diff = '\" + s[4] + \"'\")\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\n                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\")\n                    if x[2] != 'OK':\n                        cursor.execute(\n                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\")\n        if v:\n            break\n\n    conn.commit()\n    conn.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set username = '\" + str(username) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    conn.execute(\"update users set last_update = '\" + str(last_try_new) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    conn.execute(\"update users set last_problem = '\" + str(last_problem) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n\n    settings.commit()\n    settings.close()", "func_src_after": "def update_user(username, chat_id, last_update):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor_settings = settings.cursor()\n    cursor_settings.execute(\"select last_problem from users where chat_id = ?\", (str(chat_id), ))\n    update_eq = cursor_settings.fetchone()\n    cursor_settings.execute(\"select * from last_update_problemset\")\n    update_base = cursor_settings.fetchone()\n    last_problem = update_base[0]\n    if update_eq[0] != update_base[0]:\n        cursor2.execute(\"SELECT * FROM problems\")\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"select * from result where problem = ? and diff = ?\", (str(x[0]), str(x[1])))\n            x2 = cursor.fetchone()\n            if x2 == None:\n                cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n            last_problem = x\n            x = cursor2.fetchone()\n        conn2.close()\n        settings.close()\n    if len(last_problem) == 2:\n        last_problem = last_problem[0] + last_problem[1]\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    v = False\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try_new = soup.find(attrs={\"class\": \"status-small\"})\n    last_try_new = str(last_try_new).split()\n    last_try_new = str(last_try_new[2]) + str(last_try_new[3])\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        j = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        last_try = soup.find_all(attrs={\"class\": \"status-small\"})\n        for link in soup.find_all('a'):\n            last_try_date = str(last_try[j]).split()\n            last_try_date = str(last_try_date[2]) + str(last_try_date[3])\n            if last_try_date == last_update:\n                v = True\n                break\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    j += 1\n                    cursor.execute(\"select * from result where problem = ? and diff = ?\", (s[3], s[4]))\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n                    if x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n        if v:\n            break\n\n    conn.commit()\n    conn.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set username = ? where chat_id = ?\", (str(username), str(chat_id)))\n    conn.execute(\"update users set last_update = ? where chat_id = ?\", (str(last_try_new), str(chat_id)))\n    conn.execute(\"update users set last_problem = ? where chat_id = ?\", (str(last_problem), str(chat_id)))\n\n    settings.commit()\n    settings.close()", "line_changes": {"deleted": [{"line_no": 8, "char_start": 426, "char_end": 527, "line": "    cursor_settings.execute(\"select last_problem from users where chat_id = '\" + str(chat_id) + \"'\")\n"}, {"line_no": 17, "char_start": 862, "char_end": 980, "line": "            cursor.execute(\"select * from result where problem = '\" + str(x[0]) + \"' and diff = '\" + str(x[1]) + \"'\")\n"}, {"line_no": 65, "char_start": 2870, "char_end": 2985, "line": "                    cursor.execute(\"select * from result where problem = '\" + s[3] + \"'and diff = '\" + s[4] + \"'\")\n"}, {"line_no": 68, "char_start": 3079, "char_end": 3119, "line": "                        cursor.execute(\n"}, {"line_no": 69, "char_start": 3119, "char_end": 3239, "line": "                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n"}, {"line_no": 70, "char_start": 3239, "char_end": 3279, "line": "                            s[4] + \"'\")\n"}, {"line_no": 72, "char_start": 3316, "char_end": 3356, "line": "                        cursor.execute(\n"}, {"line_no": 73, "char_start": 3356, "char_end": 3476, "line": "                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n"}, {"line_no": 74, "char_start": 3476, "char_end": 3516, "line": "                            s[4] + \"'\")\n"}, {"line_no": 83, "char_start": 3707, "char_end": 3818, "line": "    conn.execute(\"update users set username = '\" + str(username) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n"}, {"line_no": 84, "char_start": 3818, "char_end": 3936, "line": "    conn.execute(\"update users set last_update = '\" + str(last_try_new) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n"}, {"line_no": 85, "char_start": 3936, "char_end": 4055, "line": "    conn.execute(\"update users set last_problem = '\" + str(last_problem) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n"}], "added": [{"line_no": 8, "char_start": 426, "char_end": 524, "line": "    cursor_settings.execute(\"select last_problem from users where chat_id = ?\", (str(chat_id), ))\n"}, {"line_no": 17, "char_start": 859, "char_end": 965, "line": "            cursor.execute(\"select * from result where problem = ? and diff = ?\", (str(x[0]), str(x[1])))\n"}, {"line_no": 65, "char_start": 2855, "char_end": 2959, "line": "                    cursor.execute(\"select * from result where problem = ? and diff = ?\", (s[3], s[4]))\n"}, {"line_no": 68, "char_start": 3053, "char_end": 3177, "line": "                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n"}, {"line_no": 70, "char_start": 3214, "char_end": 3338, "line": "                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n"}, {"line_no": 79, "char_start": 3529, "char_end": 3628, "line": "    conn.execute(\"update users set username = ? where chat_id = ?\", (str(username), str(chat_id)))\n"}, {"line_no": 80, "char_start": 3628, "char_end": 3734, "line": "    conn.execute(\"update users set last_update = ? where chat_id = ?\", (str(last_try_new), str(chat_id)))\n"}, {"line_no": 81, "char_start": 3734, "char_end": 3841, "line": "    conn.execute(\"update users set last_problem = ? where chat_id = ?\", (str(last_problem), str(chat_id)))\n"}]}, "char_changes": {"deleted": [{"char_start": 502, "char_end": 507, "chars": "'\" + "}, {"char_start": 519, "char_end": 525, "chars": " + \"'\""}, {"char_start": 927, "char_end": 962, "chars": "'\" + str(x[0]) + \"' and diff = '\" +"}, {"char_start": 972, "char_end": 978, "chars": " + \"'\""}, {"char_start": 2943, "char_end": 2983, "chars": "'\" + s[3] + \"'and diff = '\" + s[4] + \"'\""}, {"char_start": 3118, "char_end": 3147, "chars": "\n                            "}, {"char_start": 3176, "char_end": 3191, "chars": "'\" + s2[1] + \"'"}, {"char_start": 3208, "char_end": 3277, "chars": "'\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\""}, {"char_start": 3355, "char_end": 3384, "chars": "\n                            "}, {"char_start": 3413, "char_end": 3428, "chars": "'\" + s2[1] + \"'"}, {"char_start": 3445, "char_end": 3514, "chars": "'\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\""}, {"char_start": 3753, "char_end": 3797, "chars": "'\" + str(username) + \"' where chat_id = '\" +"}, {"char_start": 3810, "char_end": 3816, "chars": " + \"'\""}, {"char_start": 3867, "char_end": 3915, "chars": "'\" + str(last_try_new) + \"' where chat_id = '\" +"}, {"char_start": 3928, "char_end": 3934, "chars": " + \"'\""}, {"char_start": 3986, "char_end": 4034, "chars": "'\" + str(last_problem) + \"' where chat_id = '\" +"}, {"char_start": 4047, "char_end": 4053, "chars": " + \"'\""}], "added": [{"char_start": 502, "char_end": 507, "chars": "?\", ("}, {"char_start": 519, "char_end": 522, "chars": ", )"}, {"char_start": 924, "char_end": 952, "chars": "? and diff = ?\", (str(x[0]),"}, {"char_start": 962, "char_end": 963, "chars": ")"}, {"char_start": 2928, "char_end": 2957, "chars": "? and diff = ?\", (s[3], s[4])"}, {"char_start": 3121, "char_end": 3122, "chars": "?"}, {"char_start": 3139, "char_end": 3175, "chars": "? and diff = ?\", (s2[1], s[3], s[4])"}, {"char_start": 3282, "char_end": 3283, "chars": "?"}, {"char_start": 3300, "char_end": 3336, "chars": "? and diff = ?\", (s2[1], s[3], s[4])"}, {"char_start": 3575, "char_end": 3612, "chars": "? where chat_id = ?\", (str(username),"}, {"char_start": 3625, "char_end": 3626, "chars": ")"}, {"char_start": 3677, "char_end": 3718, "chars": "? where chat_id = ?\", (str(last_try_new),"}, {"char_start": 3731, "char_end": 3732, "chars": ")"}, {"char_start": 3784, "char_end": 3825, "chars": "? where chat_id = ?\", (str(last_problem),"}, {"char_start": 3838, "char_end": 3839, "chars": ")"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089"}
{"func_name": "update_theory_base", "func_src_before": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into \" + str(tag) + \" values (?)\", (str(link), ))\n    theory.commit()\n    theory.close()", "func_src_after": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into ? values (?)\", (tag, str(link)))\n    theory.commit()\n    theory.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 151, "char_end": 226, "line": "    conn.execute(\"insert into \" + str(tag) + \" values (?)\", (str(link), ))\n"}], "added": [{"line_no": 4, "char_start": 151, "char_end": 214, "line": "    conn.execute(\"insert into ? values (?)\", (tag, str(link)))\n"}]}, "char_changes": {"deleted": [{"char_start": 181, "char_end": 197, "chars": "\" + str(tag) + \""}, {"char_start": 221, "char_end": 223, "chars": ", "}], "added": [{"char_start": 181, "char_end": 182, "chars": "?"}, {"char_start": 197, "char_end": 202, "chars": "tag, "}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089"}
{"func_name": "get_current_state", "func_src_before": "def get_current_state(chat_id):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__))+\"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(chat_id) + \"'\")\n    name = conn.fetchone()\n    if name != None:\n        return name[4]\n    else:\n        return False\n    settings.close()", "func_src_after": "def get_current_state(chat_id):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__))+\"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(chat_id),))\n    name = conn.fetchone()\n    if name != None:\n        return name[4]\n    else:\n        return False\n    settings.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 159, "char_end": 238, "line": "    conn.execute(\"select * from users where chat_id = '\" + str(chat_id) + \"'\")\n"}], "added": [{"line_no": 4, "char_start": 159, "char_end": 234, "line": "    conn.execute(\"select * from users where chat_id = ?\", (str(chat_id),))\n"}]}, "char_changes": {"deleted": [{"char_start": 213, "char_end": 218, "chars": "'\" + "}, {"char_start": 230, "char_end": 236, "chars": " + \"'\""}], "added": [{"char_start": 213, "char_end": 218, "chars": "?\", ("}, {"char_start": 230, "char_end": 232, "chars": ",)"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089"}
{"func_name": "set_state", "func_src_before": "def set_state(chat_id, value):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set state ='\" + str(value) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    settings.commit()\n    settings.close()", "func_src_after": "def set_state(chat_id, value):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set state = ? where chat_id = ?\", (str(value), str(chat_id)))\n    settings.commit()\n    settings.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 160, "char_end": 264, "line": "    conn.execute(\"update users set state ='\" + str(value) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n"}], "added": [{"line_no": 4, "char_start": 160, "char_end": 253, "line": "    conn.execute(\"update users set state = ? where chat_id = ?\", (str(value), str(chat_id)))\n"}]}, "char_changes": {"deleted": [{"char_start": 202, "char_end": 222, "chars": "'\" + str(value) + \"'"}, {"char_start": 239, "char_end": 243, "chars": "'\" +"}, {"char_start": 256, "char_end": 262, "chars": " + \"'\""}], "added": [{"char_start": 202, "char_end": 204, "chars": " ?"}, {"char_start": 221, "char_end": 237, "chars": "?\", (str(value),"}, {"char_start": 250, "char_end": 251, "chars": ")"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089"}
{"func_name": "get_login", "func_src_before": "@bot.message_handler(commands =['login'])\ndef get_login(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    if name != None:\n        bot.send_message(message.chat.id, \"Previous handle: \" + str(name[1]))\n    else:\n        bot.send_message(message.chat.id, \"Previous handle: None\")\n    settings.close()\n    bot.send_message(message.chat.id, \"Type new handle: \")\n    set_state(message.chat.id, config.States.S_LOGIN.value)", "func_src_after": "@bot.message_handler(commands =['login'])\ndef get_login(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    if name != None:\n        bot.send_message(message.chat.id, \"Previous handle: \" + str(name[1]))\n    else:\n        bot.send_message(message.chat.id, \"Previous handle: None\")\n    settings.close()\n    bot.send_message(message.chat.id, \"Type new handle: \")\n    set_state(message.chat.id, config.States.S_LOGIN.value)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 195, "char_end": 282, "line": "    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n"}], "added": [{"line_no": 5, "char_start": 195, "char_end": 278, "line": "    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n"}]}, "char_changes": {"deleted": [{"char_start": 249, "char_end": 254, "chars": "'\" + "}, {"char_start": 274, "char_end": 280, "chars": " + \"'\""}], "added": [{"char_start": 249, "char_end": 254, "chars": "?\", ("}, {"char_start": 274, "char_end": 276, "chars": ",)"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089"}
{"func_name": "get_login2", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "line_changes": {"deleted": [{"line_no": 9, "char_start": 465, "char_end": 466, "line": "\n"}, {"line_no": 10, "char_start": 466, "char_end": 553, "line": "    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n"}], "added": [{"line_no": 9, "char_start": 465, "char_end": 548, "line": "    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n"}]}, "char_changes": {"deleted": [{"char_start": 465, "char_end": 466, "chars": "\n"}, {"char_start": 520, "char_end": 525, "chars": "'\" + "}, {"char_start": 545, "char_end": 551, "chars": " + \"'\""}], "added": [{"char_start": 519, "char_end": 524, "chars": "?\", ("}, {"char_start": 544, "char_end": 546, "chars": ",)"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089"}
{"func_name": "get_task", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_GET_TASK.value)\ndef get_task(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    if name == None:\n        bot.send_message(message.chat.id, \"You should login before get tasks.\")\n    else:\n        bases.update.update_user(name[1], name[0], name[2])\n        bot.send_message(message.chat.id, bases.problem.get_unsolved_problem(message.text, name[1]))\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_GET_TASK.value)\ndef get_task(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    if name == None:\n        bot.send_message(message.chat.id, \"You should login before get tasks.\")\n    else:\n        bases.update.update_user(name[1], name[0], name[2])\n        bot.send_message(message.chat.id, bases.problem.get_unsolved_problem(message.text, name[1]))\n    set_state(message.chat.id, config.States.S_START.value)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 266, "char_end": 353, "line": "    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n"}], "added": [{"line_no": 5, "char_start": 266, "char_end": 349, "line": "    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n"}]}, "char_changes": {"deleted": [{"char_start": 320, "char_end": 325, "chars": "'\" + "}, {"char_start": 345, "char_end": 351, "chars": " + \"'\""}], "added": [{"char_start": 320, "char_end": 325, "chars": "?\", ("}, {"char_start": 345, "char_end": 347, "chars": ",)"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089"}
{"func_name": "stats", "func_src_before": "@bot.message_handler(commands=['stats'])\ndef stats(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    if name != None:\n        bases.update.update_user(name[1], name[0], name[2])\n        bases.problem.create_text_stats(name[1])\n        img = open(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\users\\\\\" + name[1] + \".png\", \"rb\")\n        bot.send_photo(message.chat.id, img)\n        img.close()\n        if bases.problem.create_stats_picture(name[1]):\n            bot.send_message(message.chat.id, \"Sorry, you haven't solved tasks.\")\n            return 0\n        img = open(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\users\\\\\" + name[1] + \".png\", \"rb\")\n        bot.send_photo(message.chat.id, img)\n        img.close()\n    else:\n        bot.send_message(message.chat.id, \"You should login before getting statistic.\")", "func_src_after": "@bot.message_handler(commands=['stats'])\ndef stats(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    if name != None:\n        bases.update.update_user(name[1], name[0], name[2])\n        bases.problem.create_text_stats(name[1])\n        img = open(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\users\\\\\" + name[1] + \".png\", \"rb\")\n        bot.send_photo(message.chat.id, img)\n        img.close()\n        if bases.problem.create_stats_picture(name[1]):\n            bot.send_message(message.chat.id, \"Sorry, you haven't solved tasks.\")\n            return 0\n        img = open(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\users\\\\\" + name[1] + \".png\", \"rb\")\n        bot.send_photo(message.chat.id, img)\n        img.close()\n    else:\n        bot.send_message(message.chat.id, \"You should login before getting statistic.\")", "line_changes": {"deleted": [{"line_no": 5, "char_start": 190, "char_end": 277, "line": "    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n"}], "added": [{"line_no": 5, "char_start": 190, "char_end": 273, "line": "    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n"}]}, "char_changes": {"deleted": [{"char_start": 244, "char_end": 249, "chars": "'\" + "}, {"char_start": 269, "char_end": 275, "chars": " + \"'\""}], "added": [{"char_start": 244, "char_end": 249, "chars": "?\", ("}, {"char_start": 269, "char_end": 271, "chars": ",)"}]}, "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089"}
{"func_name": "get_metadata", "func_src_before": "@app.route(\"/get-metadata\")\ndef get_metadata():\n    full_start_time = datetime.now()\n    start_time = datetime.now()\n\n    # Get parameters from querystring\n    num_classes = int(request.args.get('n'))\n    raw_stats = request.args.get('stats')\n\n    # replace all maths operators to get list of all the stats we need\n    search_stats = raw_stats.upper().replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\") \\\n        .replace(\"+\", \",\").replace(\"-\", \",\").replace(\"/\", \",\").replace(\"*\", \",\").split(\",\")\n\n    # TODO: add support for numbers in equations - need to strip them from search_stats list\n\n    # equation_stats = raw_stats.lower().split(\",\")\n\n    # print(equation_stats)\n    # print(search_stats)\n\n    # get stats tuple for query input (convert to lower case)\n    search_stats_tuple = tuple([stat.lower() for stat in search_stats])\n\n    # get all boundary names in all zoom levels\n    boundary_names = list()\n\n    for zoom_level in range(0, 16):\n        bdy_name = utils.get_boundary_name(zoom_level)\n\n        if bdy_name not in boundary_names:\n            boundary_names.append(bdy_name)\n\n    # get stats metadata, including the all important table number and map type (raw values based or normalised by pop)\n    sql = \"SELECT lower(sequential_id) AS id, \" \\\n          \"lower(table_number) AS \\\"table\\\", \" \\\n          \"replace(long_id, '_', ' ') AS description, \" \\\n          \"column_heading_description AS type, \" \\\n          \"CASE WHEN lower(long_id) LIKE '%%median%%' OR lower(long_id) LIKE '%%average%%' THEN 'values' \" \\\n          \"ELSE 'normalised' END AS maptype \" \\\n          \"FROM {0}.metadata_stats \" \\\n          \"WHERE lower(sequential_id) IN %s \" \\\n          \"ORDER BY sequential_id\".format(settings[\"data_schema\"], )\n\n    with get_db_cursor() as pg_cur:\n        try:\n            pg_cur.execute(sql, (search_stats_tuple,))\n        except psycopg2.Error:\n            return \"I can't SELECT :\\n\\n\" + sql\n\n        # Retrieve the results of the query\n        rows = pg_cur.fetchall()\n\n    # output is the main content, row_output is the content from each record returned\n    response_dict = dict()\n    response_dict[\"type\"] = \"StatsCollection\"\n    response_dict[\"classes\"] = num_classes\n\n    output_array = list()\n\n    # get metadata for all boundaries (done in one go for frontend performance)\n    for boundary_name in boundary_names:\n        output_dict = dict()\n        output_dict[\"boundary\"] = boundary_name\n\n        boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n\n        # # get id and area fields for boundary\n        # bdy_id_field = \"\"\n        # bdy_area_field = \"\"\n\n        # for boundary_dict in settings['bdy_table_dicts']:\n            # if boundary_dict[\"boundary\"] == boundary_name:\n                # bdy_id_field = boundary_dict[\"id_field\"]\n                # bdy_area_field = boundary_dict[\"area_field\"]\n\n        i = 0\n        feature_array = list()\n\n        # For each row returned assemble a dictionary\n        for row in rows:\n            feature_dict = dict(row)\n            feature_dict[\"id\"] = feature_dict[\"id\"].lower()\n            feature_dict[\"table\"] = feature_dict[\"table\"].lower()\n\n            data_table = \"{0}.{1}_{2}\".format(settings[\"data_schema\"], boundary_name, feature_dict[\"table\"])\n\n            # get the values for the map classes\n            with get_db_cursor() as pg_cur:\n                stat_field = \"CASE WHEN bdy.population > 0 THEN tab.{0} / bdy.population * 100.0 ELSE 0 END\" \\\n                    .format(feature_dict[\"id\"], )\n                feature_dict[\"classes\"] = utils.get_equal_interval_bins(data_table, boundary_table, stat_field, pg_cur, settings)\n\n                # add dict to output array of metadata\n                feature_array.append(feature_dict)\n\n            i += 1\n\n        output_dict[\"stats\"] = feature_array\n        output_array.append(output_dict)\n\n        print(\"Got metadata for {0} in {1}\".format(boundary_name, datetime.now() - start_time))\n\n    # Assemble the JSON\n    response_dict[\"boundaries\"] = output_array\n\n    print(\"Returned metadata in {0}\".format(datetime.now() - full_start_time))\n\n    return Response(json.dumps(response_dict), mimetype='application/json')", "func_src_after": "@app.route(\"/get-metadata\")\ndef get_metadata():\n    full_start_time = datetime.now()\n    start_time = datetime.now()\n\n    # Get parameters from querystring\n    num_classes = int(request.args.get('n'))\n    raw_stats = request.args.get('stats')\n\n    # replace all maths operators to get list of all the stats we need\n    search_stats = raw_stats.upper().replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\") \\\n        .replace(\"+\", \",\").replace(\"-\", \",\").replace(\"/\", \",\").replace(\"*\", \",\").split(\",\")\n\n    # TODO: add support for numbers in equations - need to strip them from search_stats list\n\n    # equation_stats = raw_stats.lower().split(\",\")\n\n    # print(equation_stats)\n    # print(search_stats)\n\n    # get stats tuple for query input (convert to lower case)\n    search_stats_tuple = tuple([stat.lower() for stat in search_stats])\n\n    # get all boundary names in all zoom levels\n    boundary_names = list()\n\n    for zoom_level in range(0, 16):\n        bdy_name = utils.get_boundary_name(zoom_level)\n\n        if bdy_name not in boundary_names:\n            boundary_names.append(bdy_name)\n\n    # get stats metadata, including the all important table number and map type (raw values based or normalised by pop)\n    sql = \"SELECT lower(sequential_id) AS id, \" \\\n          \"lower(table_number) AS \\\"table\\\", \" \\\n          \"replace(long_id, '_', ' ') AS description, \" \\\n          \"column_heading_description AS type, \" \\\n          \"CASE WHEN lower(long_id) LIKE '%%median%%' OR lower(long_id) LIKE '%%average%%' THEN 'values' \" \\\n          \"ELSE 'normalised' END AS maptype \" \\\n          \"FROM {0}.metadata_stats \" \\\n          \"WHERE lower(sequential_id) IN %s \" \\\n          \"ORDER BY sequential_id\".format(settings[\"data_schema\"], )\n\n    with get_db_cursor() as pg_cur:\n        try:\n            pg_cur.execute(sql, (search_stats_tuple,))\n        except psycopg2.Error:\n            return \"I can't SELECT :\\n\\n\" + sql\n\n        # Retrieve the results of the query\n        rows = pg_cur.fetchall()\n\n    # output is the main content, row_output is the content from each record returned\n    response_dict = dict()\n    response_dict[\"type\"] = \"StatsCollection\"\n    response_dict[\"classes\"] = num_classes\n\n    # output_array = list()\n\n    # # get metadata for all boundaries (done in one go for frontend performance)\n    # for boundary_name in boundary_names:\n    #     output_dict = dict()\n    #     output_dict[\"boundary\"] = boundary_name\n    #\n    #     boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n\n    feature_array = list()\n\n    # For each row returned assemble a dictionary\n    for row in rows:\n        feature_dict = dict(row)\n        feature_dict[\"id\"] = feature_dict[\"id\"].lower()\n        feature_dict[\"table\"] = feature_dict[\"table\"].lower()\n\n        for boundary_name in boundary_names:\n            boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n\n            data_table = \"{0}.{1}_{2}\".format(settings[\"data_schema\"], boundary_name, feature_dict[\"table\"])\n\n            # get the values for the map classes\n            with get_db_cursor() as pg_cur:\n                stat_field = \"CASE WHEN bdy.population > 0 THEN tab.{0} / bdy.population * 100.0 ELSE 0 END\" \\\n                    .format(feature_dict[\"id\"], )\n                feature_dict[boundary_name] = utils.get_equal_interval_bins(\n                    data_table, boundary_table, stat_field, pg_cur, settings)\n\n        # add dict to output array of metadata\n        feature_array.append(feature_dict)\n\n    response_dict[\"stat\"] = feature_array\n    # output_array.append(output_dict)\n\n    # print(\"Got metadata for {0} in {1}\".format(boundary_name, datetime.now() - start_time))\n\n    # # Assemble the JSON\n    # response_dict[\"boundaries\"] = output_array\n\n    print(\"Returned metadata in {0}\".format(datetime.now() - full_start_time))\n\n    return Response(json.dumps(response_dict), mimetype='application/json')", "line_changes": {"deleted": [{"line_no": 58, "char_start": 2199, "char_end": 2225, "line": "    output_array = list()\n"}, {"line_no": 61, "char_start": 2306, "char_end": 2347, "line": "    for boundary_name in boundary_names:\n"}, {"line_no": 62, "char_start": 2347, "char_end": 2376, "line": "        output_dict = dict()\n"}, {"line_no": 63, "char_start": 2376, "char_end": 2424, "line": "        output_dict[\"boundary\"] = boundary_name\n"}, {"line_no": 65, "char_start": 2425, "char_end": 2506, "line": "        boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n"}, {"line_no": 66, "char_start": 2506, "char_end": 2507, "line": "\n"}, {"line_no": 70, "char_start": 2613, "char_end": 2614, "line": "\n"}, {"line_no": 76, "char_start": 2858, "char_end": 2872, "line": "        i = 0\n"}, {"line_no": 77, "char_start": 2872, "char_end": 2903, "line": "        feature_array = list()\n"}, {"line_no": 80, "char_start": 2958, "char_end": 2983, "line": "        for row in rows:\n"}, {"line_no": 81, "char_start": 2983, "char_end": 3020, "line": "            feature_dict = dict(row)\n"}, {"line_no": 82, "char_start": 3020, "char_end": 3080, "line": "            feature_dict[\"id\"] = feature_dict[\"id\"].lower()\n"}, {"line_no": 83, "char_start": 3080, "char_end": 3146, "line": "            feature_dict[\"table\"] = feature_dict[\"table\"].lower()\n"}, {"line_no": 91, "char_start": 3511, "char_end": 3641, "line": "                feature_dict[\"classes\"] = utils.get_equal_interval_bins(data_table, boundary_table, stat_field, pg_cur, settings)\n"}, {"line_no": 92, "char_start": 3641, "char_end": 3642, "line": "\n"}, {"line_no": 94, "char_start": 3697, "char_end": 3748, "line": "                feature_array.append(feature_dict)\n"}, {"line_no": 96, "char_start": 3749, "char_end": 3768, "line": "            i += 1\n"}, {"line_no": 98, "char_start": 3769, "char_end": 3814, "line": "        output_dict[\"stats\"] = feature_array\n"}, {"line_no": 99, "char_start": 3814, "char_end": 3855, "line": "        output_array.append(output_dict)\n"}, {"line_no": 101, "char_start": 3856, "char_end": 3952, "line": "        print(\"Got metadata for {0} in {1}\".format(boundary_name, datetime.now() - start_time))\n"}, {"line_no": 104, "char_start": 3977, "char_end": 4024, "line": "    response_dict[\"boundaries\"] = output_array\n"}], "added": [{"line_no": 67, "char_start": 2524, "char_end": 2551, "line": "    feature_array = list()\n"}, {"line_no": 70, "char_start": 2602, "char_end": 2623, "line": "    for row in rows:\n"}, {"line_no": 71, "char_start": 2623, "char_end": 2656, "line": "        feature_dict = dict(row)\n"}, {"line_no": 72, "char_start": 2656, "char_end": 2712, "line": "        feature_dict[\"id\"] = feature_dict[\"id\"].lower()\n"}, {"line_no": 73, "char_start": 2712, "char_end": 2774, "line": "        feature_dict[\"table\"] = feature_dict[\"table\"].lower()\n"}, {"line_no": 75, "char_start": 2775, "char_end": 2820, "line": "        for boundary_name in boundary_names:\n"}, {"line_no": 76, "char_start": 2820, "char_end": 2905, "line": "            boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n"}, {"line_no": 84, "char_start": 3270, "char_end": 3347, "line": "                feature_dict[boundary_name] = utils.get_equal_interval_bins(\n"}, {"line_no": 85, "char_start": 3347, "char_end": 3425, "line": "                    data_table, boundary_table, stat_field, pg_cur, settings)\n"}, {"line_no": 88, "char_start": 3473, "char_end": 3516, "line": "        feature_array.append(feature_dict)\n"}, {"line_no": 90, "char_start": 3517, "char_end": 3559, "line": "    response_dict[\"stat\"] = feature_array\n"}]}, "char_changes": {"deleted": [{"char_start": 2507, "char_end": 2876, "chars": "        # # get id and area fields for boundary\n        # bdy_id_field = \"\"\n        # bdy_area_field = \"\"\n\n        # for boundary_dict in settings['bdy_table_dicts']:\n            # if boundary_dict[\"boundary\"] == boundary_name:\n                # bdy_id_field = boundary_dict[\"id_field\"]\n                # bdy_area_field = boundary_dict[\"area_field\"]\n\n        i = 0\n    "}, {"char_start": 2904, "char_end": 2908, "chars": "    "}, {"char_start": 2962, "char_end": 2963, "chars": " "}, {"char_start": 2963, "char_end": 2966, "chars": "   "}, {"char_start": 2983, "char_end": 2987, "chars": "    "}, {"char_start": 3028, "char_end": 3031, "chars": "   "}, {"char_start": 3031, "char_end": 3032, "chars": " "}, {"char_start": 3080, "char_end": 3084, "chars": "    "}, {"char_start": 3540, "char_end": 3549, "chars": "\"classes\""}, {"char_start": 3650, "char_end": 3655, "chars": "     "}, {"char_start": 3655, "char_end": 3658, "chars": "   "}, {"char_start": 3705, "char_end": 3712, "chars": "       "}, {"char_start": 3712, "char_end": 3713, "chars": " "}, {"char_start": 3753, "char_end": 3783, "chars": "        i += 1\n\n        output"}, {"char_start": 3794, "char_end": 3795, "chars": "s"}, {"char_start": 3818, "char_end": 3820, "chars": "  "}, {"char_start": 3820, "char_end": 3821, "chars": " "}, {"char_start": 3860, "char_end": 3863, "chars": "   "}], "added": [{"char_start": 2202, "char_end": 2204, "chars": " #"}, {"char_start": 2233, "char_end": 2235, "chars": " #"}, {"char_start": 2313, "char_end": 2315, "chars": " #"}, {"char_start": 2356, "char_end": 2358, "chars": " #"}, {"char_start": 2387, "char_end": 2389, "chars": " #"}, {"char_start": 2434, "char_end": 2439, "chars": "    #"}, {"char_start": 2443, "char_end": 2445, "chars": " #"}, {"char_start": 2775, "char_end": 2906, "chars": "        for boundary_name in boundary_names:\n            boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n\n"}, {"char_start": 3299, "char_end": 3312, "chars": "boundary_name"}, {"char_start": 3346, "char_end": 3367, "chars": "\n                    "}, {"char_start": 3521, "char_end": 3529, "chars": "response"}, {"char_start": 3563, "char_end": 3564, "chars": "#"}, {"char_start": 3603, "char_end": 3604, "chars": "#"}, {"char_start": 3699, "char_end": 3701, "chars": " #"}, {"char_start": 3723, "char_end": 3725, "chars": " #"}]}, "commit_link": "github.com/minus34/census-loader/commit/c1066ccb2ae7402ff1bd26a7e5378c21d9455624", "file_name": "web/server.py", "vul_type": "cwe-089"}
{"func_name": "get_data", "func_src_before": "@app.route(\"/get-data\")\ndef get_data():\n    full_start_time = datetime.now()\n    start_time = datetime.now()\n\n    # Get parameters from querystring\n\n    map_left = request.args.get('ml')\n    map_bottom = request.args.get('mb')\n    map_right = request.args.get('mr')\n    map_top = request.args.get('mt')\n\n    stat_id = request.args.get('s')\n    table_id = request.args.get('t')\n    boundary_name = request.args.get('b')\n    zoom_level = int(request.args.get('z'))\n\n    # get the number of decimal places for the output GeoJSON to reduce response size & speed up rendering\n    decimal_places = utils.get_decimal_places(zoom_level)\n\n    # TODO: add support for equations\n\n    # get the boundary table name from zoom level\n    if boundary_name is None:\n        boundary_name = utils.get_boundary_name(zoom_level)\n\n    display_zoom = str(zoom_level).zfill(2)\n\n    stat_table_name = boundary_name + \"_\" + table_id\n\n    boundary_table_name = \"{0}\".format(boundary_name)\n\n    with get_db_cursor() as pg_cur:\n        print(\"Connected to database in {0}\".format(datetime.now() - start_time))\n        start_time = datetime.now()\n\n        envelope_sql = \"ST_MakeEnvelope({0}, {1}, {2}, {3}, 4283)\".format(map_left, map_bottom, map_right, map_top)\n        geom_sql = \"geojson_{0}\".format(display_zoom)\n\n        sql = \"SELECT bdy.id, bdy.name, bdy.population, tab.{0} / bdy.area AS density, \" \\\n              \"CASE WHEN bdy.population > 0 THEN tab.{0} / bdy.population * 100.0 ELSE 0 END AS percent, \" \\\n              \"tab.{0}, {1} AS geometry \" \\\n              \"FROM {2}.{3} AS bdy \" \\\n              \"INNER JOIN {4}.{5} AS tab ON bdy.id = tab.{6} \" \\\n              \"WHERE bdy.geom && {7}\" \\\n            .format(stat_id, geom_sql, settings['web_schema'], boundary_table_name, settings['data_schema'],\n                    stat_table_name, settings['region_id_field'], envelope_sql)\n\n        try:\n            pg_cur.execute(sql)\n        except psycopg2.Error:\n            return \"I can't SELECT : \" + sql\n\n        # print(\"Ran query in {0}\".format(datetime.now() - start_time))\n        # start_time = datetime.now()\n\n        # Retrieve the results of the query\n        rows = pg_cur.fetchall()\n        # row_count = pg_cur.rowcount\n\n        # Get the column names returned\n        col_names = [desc[0] for desc in pg_cur.description]\n\n    print(\"Got records from Postgres in {0}\".format(datetime.now() - start_time))\n    start_time = datetime.now()\n\n    # # Find the index of the column that holds the geometry\n    # geom_index = col_names.index(\"geometry\")\n\n    # output is the main content, row_output is the content from each record returned\n    output_dict = dict()\n    output_dict[\"type\"] = \"FeatureCollection\"\n\n    i = 0\n    feature_array = list()\n\n    # For each row returned...\n    for row in rows:\n        feature_dict = dict()\n        feature_dict[\"type\"] = \"Feature\"\n\n        properties_dict = dict()\n\n        # For each field returned, assemble the feature and properties dictionaries\n        for col in col_names:\n            if col == 'geometry':\n                feature_dict[\"geometry\"] = ast.literal_eval(str(row[col]))\n            elif col == 'id':\n                feature_dict[\"id\"] = row[col]\n            else:\n                properties_dict[col] = row[col]\n\n        feature_dict[\"properties\"] = properties_dict\n\n        feature_array.append(feature_dict)\n\n        # start over\n        i += 1\n\n    # Assemble the GeoJSON\n    output_dict[\"features\"] = feature_array\n\n    print(\"Parsed records into JSON in {1}\".format(i, datetime.now() - start_time))\n    print(\"Returned {0} records  {1}\".format(i, datetime.now() - full_start_time))\n\n    return Response(json.dumps(output_dict), mimetype='application/json')", "func_src_after": "@app.route(\"/get-data\")\ndef get_data():\n    full_start_time = datetime.now()\n    start_time = datetime.now()\n\n    # Get parameters from querystring\n\n    map_left = request.args.get('ml')\n    map_bottom = request.args.get('mb')\n    map_right = request.args.get('mr')\n    map_top = request.args.get('mt')\n\n    stat_id = request.args.get('s')\n    table_id = request.args.get('t')\n    boundary_name = request.args.get('b')\n    zoom_level = int(request.args.get('z'))\n\n    # # get the number of decimal places for the output GeoJSON to reduce response size & speed up rendering\n    # decimal_places = utils.get_decimal_places(zoom_level)\n\n    # TODO: add support for equations\n\n    # get the boundary table name from zoom level\n    if boundary_name is None:\n        boundary_name = utils.get_boundary_name(zoom_level)\n\n    display_zoom = str(zoom_level).zfill(2)\n\n    # stat_table_name = boundary_name + \"_\" + table_id\n    #\n    # boundary_table_name = \"{0}\".format(boundary_name)\n\n    with get_db_cursor() as pg_cur:\n        print(\"Connected to database in {0}\".format(datetime.now() - start_time))\n        start_time = datetime.now()\n\n        # envelope_sql = \"ST_MakeEnvelope({0}, {1}, {2}, {3}, 4283)\".format(map_left, map_bottom, map_right, map_top)\n        # geom_sql = \"geojson_{0}\".format(display_zoom)\n\n        # build SQL with SQL injection protection\n        sql = \"SELECT bdy.id, bdy.name, bdy.population, tab.%s / bdy.area AS density, \" \\\n              \"CASE WHEN bdy.population > 0 THEN tab.%s / bdy.population * 100.0 ELSE 0 END AS percent, \" \\\n              \"tab.%s, geojson_%s AS geometry \" \\\n              \"FROM {0}.%s AS bdy \" \\\n              \"INNER JOIN {1}.%s_%s AS tab ON bdy.id = tab.{2} \" \\\n              \"WHERE bdy.geom && ST_MakeEnvelope(%s, %s, %s, %s, 4283)\" \\\n            .format(settings['web_schema'], settings['data_schema'], settings['region_id_field'])\n\n        try:\n            pg_cur.execute(sql, (stat_id, stat_id, stat_id, display_zoom, boundary_name, boundary_name, table_id, map_left, map_bottom, map_right, map_top))\n        except psycopg2.Error:\n            return \"I can't SELECT : \" + sql\n\n        # print(\"Ran query in {0}\".format(datetime.now() - start_time))\n        # start_time = datetime.now()\n\n        # Retrieve the results of the query\n        rows = pg_cur.fetchall()\n        # row_count = pg_cur.rowcount\n\n        # Get the column names returned\n        col_names = [desc[0] for desc in pg_cur.description]\n\n    print(\"Got records from Postgres in {0}\".format(datetime.now() - start_time))\n    start_time = datetime.now()\n\n    # # Find the index of the column that holds the geometry\n    # geom_index = col_names.index(\"geometry\")\n\n    # output is the main content, row_output is the content from each record returned\n    output_dict = dict()\n    output_dict[\"type\"] = \"FeatureCollection\"\n\n    i = 0\n    feature_array = list()\n\n    # For each row returned...\n    for row in rows:\n        feature_dict = dict()\n        feature_dict[\"type\"] = \"Feature\"\n\n        properties_dict = dict()\n\n        # For each field returned, assemble the feature and properties dictionaries\n        for col in col_names:\n            if col == 'geometry':\n                feature_dict[\"geometry\"] = ast.literal_eval(str(row[col]))\n            elif col == 'id':\n                feature_dict[\"id\"] = row[col]\n            else:\n                properties_dict[col] = row[col]\n\n        feature_dict[\"properties\"] = properties_dict\n\n        feature_array.append(feature_dict)\n\n        # start over\n        i += 1\n\n    # Assemble the GeoJSON\n    output_dict[\"features\"] = feature_array\n\n    print(\"Parsed records into JSON in {1}\".format(i, datetime.now() - start_time))\n    print(\"Returned {0} records  {1}\".format(i, datetime.now() - full_start_time))\n\n    return Response(json.dumps(output_dict), mimetype='application/json')", "line_changes": {"deleted": [{"line_no": 19, "char_start": 571, "char_end": 629, "line": "    decimal_places = utils.get_decimal_places(zoom_level)\n"}, {"line_no": 29, "char_start": 855, "char_end": 908, "line": "    stat_table_name = boundary_name + \"_\" + table_id\n"}, {"line_no": 30, "char_start": 908, "char_end": 909, "line": "\n"}, {"line_no": 31, "char_start": 909, "char_end": 963, "line": "    boundary_table_name = \"{0}\".format(boundary_name)\n"}, {"line_no": 37, "char_start": 1119, "char_end": 1235, "line": "        envelope_sql = \"ST_MakeEnvelope({0}, {1}, {2}, {3}, 4283)\".format(map_left, map_bottom, map_right, map_top)\n"}, {"line_no": 38, "char_start": 1235, "char_end": 1289, "line": "        geom_sql = \"geojson_{0}\".format(display_zoom)\n"}, {"line_no": 40, "char_start": 1290, "char_end": 1381, "line": "        sql = \"SELECT bdy.id, bdy.name, bdy.population, tab.{0} / bdy.area AS density, \" \\\n"}, {"line_no": 41, "char_start": 1381, "char_end": 1490, "line": "              \"CASE WHEN bdy.population > 0 THEN tab.{0} / bdy.population * 100.0 ELSE 0 END AS percent, \" \\\n"}, {"line_no": 42, "char_start": 1490, "char_end": 1534, "line": "              \"tab.{0}, {1} AS geometry \" \\\n"}, {"line_no": 43, "char_start": 1534, "char_end": 1573, "line": "              \"FROM {2}.{3} AS bdy \" \\\n"}, {"line_no": 44, "char_start": 1573, "char_end": 1638, "line": "              \"INNER JOIN {4}.{5} AS tab ON bdy.id = tab.{6} \" \\\n"}, {"line_no": 45, "char_start": 1638, "char_end": 1678, "line": "              \"WHERE bdy.geom && {7}\" \\\n"}, {"line_no": 46, "char_start": 1678, "char_end": 1787, "line": "            .format(stat_id, geom_sql, settings['web_schema'], boundary_table_name, settings['data_schema'],\n"}, {"line_no": 47, "char_start": 1787, "char_end": 1867, "line": "                    stat_table_name, settings['region_id_field'], envelope_sql)\n"}, {"line_no": 50, "char_start": 1881, "char_end": 1913, "line": "            pg_cur.execute(sql)\n"}], "added": [{"line_no": 41, "char_start": 1357, "char_end": 1447, "line": "        sql = \"SELECT bdy.id, bdy.name, bdy.population, tab.%s / bdy.area AS density, \" \\\n"}, {"line_no": 42, "char_start": 1447, "char_end": 1555, "line": "              \"CASE WHEN bdy.population > 0 THEN tab.%s / bdy.population * 100.0 ELSE 0 END AS percent, \" \\\n"}, {"line_no": 43, "char_start": 1555, "char_end": 1605, "line": "              \"tab.%s, geojson_%s AS geometry \" \\\n"}, {"line_no": 44, "char_start": 1605, "char_end": 1643, "line": "              \"FROM {0}.%s AS bdy \" \\\n"}, {"line_no": 45, "char_start": 1643, "char_end": 1710, "line": "              \"INNER JOIN {1}.%s_%s AS tab ON bdy.id = tab.{2} \" \\\n"}, {"line_no": 46, "char_start": 1710, "char_end": 1784, "line": "              \"WHERE bdy.geom && ST_MakeEnvelope(%s, %s, %s, %s, 4283)\" \\\n"}, {"line_no": 47, "char_start": 1784, "char_end": 1882, "line": "            .format(settings['web_schema'], settings['data_schema'], settings['region_id_field'])\n"}, {"line_no": 50, "char_start": 1896, "char_end": 2053, "line": "            pg_cur.execute(sql, (stat_id, stat_id, stat_id, display_zoom, boundary_name, boundary_name, table_id, map_left, map_bottom, map_right, map_top))\n"}]}, "char_changes": {"deleted": [{"char_start": 1350, "char_end": 1353, "chars": "{0}"}, {"char_start": 1434, "char_end": 1437, "chars": "{0}"}, {"char_start": 1509, "char_end": 1517, "chars": "{0}, {1}"}, {"char_start": 1555, "char_end": 1556, "chars": "2"}, {"char_start": 1558, "char_end": 1561, "chars": "{3}"}, {"char_start": 1600, "char_end": 1601, "chars": "4"}, {"char_start": 1603, "char_end": 1606, "chars": "{5}"}, {"char_start": 1631, "char_end": 1632, "chars": "6"}, {"char_start": 1671, "char_end": 1674, "chars": "{7}"}, {"char_start": 1698, "char_end": 1717, "chars": "stat_id, geom_sql, "}, {"char_start": 1740, "char_end": 1761, "chars": " boundary_table_name,"}, {"char_start": 1786, "char_end": 1823, "chars": "\n                    stat_table_name,"}, {"char_start": 1851, "char_end": 1865, "chars": ", envelope_sql"}], "added": [{"char_start": 469, "char_end": 471, "chars": " #"}, {"char_start": 576, "char_end": 578, "chars": " #"}, {"char_start": 862, "char_end": 864, "chars": " #"}, {"char_start": 914, "char_end": 919, "chars": "    #"}, {"char_start": 923, "char_end": 925, "chars": " #"}, {"char_start": 1139, "char_end": 1141, "chars": " #"}, {"char_start": 1257, "char_end": 1259, "chars": " #"}, {"char_start": 1307, "char_end": 1357, "chars": "        # build SQL with SQL injection protection\n"}, {"char_start": 1417, "char_end": 1419, "chars": "%s"}, {"char_start": 1500, "char_end": 1502, "chars": "%s"}, {"char_start": 1574, "char_end": 1588, "chars": "%s, geojson_%s"}, {"char_start": 1626, "char_end": 1627, "chars": "0"}, {"char_start": 1629, "char_end": 1631, "chars": "%s"}, {"char_start": 1670, "char_end": 1671, "chars": "1"}, {"char_start": 1673, "char_end": 1678, "chars": "%s_%s"}, {"char_start": 1703, "char_end": 1704, "chars": "2"}, {"char_start": 1743, "char_end": 1780, "chars": "ST_MakeEnvelope(%s, %s, %s, %s, 4283)"}, {"char_start": 1926, "char_end": 2051, "chars": ", (stat_id, stat_id, stat_id, display_zoom, boundary_name, boundary_name, table_id, map_left, map_bottom, map_right, map_top)"}]}, "commit_link": "github.com/minus34/census-loader/commit/c1066ccb2ae7402ff1bd26a7e5378c21d9455624", "file_name": "web/server.py", "vul_type": "cwe-089"}
{"func_name": "get_equal_interval_bins", "func_src_before": "def get_equal_interval_bins(data_table, boundary_table, stat_field, pg_cur, settings):\n\n    sql = \"SELECT MIN({0}) AS min, MAX({0}) AS max FROM {1}  AS tab \" \\\n          \"INNER JOIN {2} AS bdy ON tab.{3} = bdy.id \" \\\n          \"WHERE {0} > 0 AND {0} < 100.0\"\\\n        .format(stat_field, data_table, boundary_table, settings['region_id_field'])\n\n    try:\n        pg_cur.execute(sql)\n        row = pg_cur.fetchone()\n\n    except Exception as ex:\n        print(\"{0} - {1} Failed: {2}\".format(data_table, stat_field, ex))\n        return list()\n\n    output_list = list()\n\n    min = row[\"min\"]\n    max = row[\"max\"]\n    delta = (max - min) / float(settings[\"num_classes\"])\n    currVal = min\n\n    # print(\"{0} : from {1} to {2}\".format(boundary_table, min, max))\n\n    for i in range(0, settings[\"num_classes\"]):\n        output_list.append(currVal)\n        currVal += delta\n\n    return output_list", "func_src_after": "def get_equal_interval_bins(data_table, boundary_table, stat_field, pg_cur, settings):\n\n    # filter to avoid small populations influencing the map classes\n    sql = \"SELECT MIN(%s) AS min, MAX(%s) AS max FROM %s AS tab \" \\\n          \"INNER JOIN %s AS bdy ON tab.{0} = bdy.id \" \\\n          \"WHERE %s > 0 AND %s < 100.0 \" \\\n          \"AND bdy.population > 5\"\\\n        .format(settings['region_id_field'])\n\n    try:\n        pg_cur.execute(sql, (AsIs(stat_field), AsIs(stat_field), AsIs(data_table), AsIs(boundary_table),\n                             AsIs(stat_field), AsIs(stat_field)))\n        row = pg_cur.fetchone()\n\n    except Exception as ex:\n        print(\"{0} - {1} Failed: {2}\".format(data_table, stat_field, ex))\n        return list()\n\n    output_list = list()\n\n    min = row[\"min\"]\n    max = row[\"max\"]\n    delta = (max - min) / float(settings[\"num_classes\"])\n    currVal = min\n\n    # print(\"{0} : from {1} to {2}\".format(boundary_table, min, max))\n\n    for i in range(0, settings[\"num_classes\"]):\n        output_list.append(currVal)\n        currVal += delta\n\n    return output_list", "line_changes": {"deleted": [{"line_no": 3, "char_start": 88, "char_end": 160, "line": "    sql = \"SELECT MIN({0}) AS min, MAX({0}) AS max FROM {1}  AS tab \" \\\n"}, {"line_no": 4, "char_start": 160, "char_end": 217, "line": "          \"INNER JOIN {2} AS bdy ON tab.{3} = bdy.id \" \\\n"}, {"line_no": 5, "char_start": 217, "char_end": 260, "line": "          \"WHERE {0} > 0 AND {0} < 100.0\"\\\n"}, {"line_no": 6, "char_start": 260, "char_end": 345, "line": "        .format(stat_field, data_table, boundary_table, settings['region_id_field'])\n"}, {"line_no": 9, "char_start": 355, "char_end": 383, "line": "        pg_cur.execute(sql)\n"}], "added": [{"line_no": 4, "char_start": 156, "char_end": 224, "line": "    sql = \"SELECT MIN(%s) AS min, MAX(%s) AS max FROM %s AS tab \" \\\n"}, {"line_no": 5, "char_start": 224, "char_end": 280, "line": "          \"INNER JOIN %s AS bdy ON tab.{0} = bdy.id \" \\\n"}, {"line_no": 6, "char_start": 280, "char_end": 323, "line": "          \"WHERE %s > 0 AND %s < 100.0 \" \\\n"}, {"line_no": 7, "char_start": 323, "char_end": 359, "line": "          \"AND bdy.population > 5\"\\\n"}, {"line_no": 8, "char_start": 359, "char_end": 404, "line": "        .format(settings['region_id_field'])\n"}, {"line_no": 11, "char_start": 414, "char_end": 519, "line": "        pg_cur.execute(sql, (AsIs(stat_field), AsIs(stat_field), AsIs(data_table), AsIs(boundary_table),\n"}, {"line_no": 12, "char_start": 519, "char_end": 585, "line": "                             AsIs(stat_field), AsIs(stat_field)))\n"}]}, "char_changes": {"deleted": [{"char_start": 110, "char_end": 113, "chars": "{0}"}, {"char_start": 127, "char_end": 130, "chars": "{0}"}, {"char_start": 144, "char_end": 148, "chars": "{1} "}, {"char_start": 182, "char_end": 185, "chars": "{2}"}, {"char_start": 201, "char_end": 202, "chars": "3"}, {"char_start": 234, "char_end": 237, "chars": "{0}"}, {"char_start": 246, "char_end": 249, "chars": "{0}"}, {"char_start": 257, "char_end": 260, "chars": "\"\\\n"}, {"char_start": 268, "char_end": 316, "chars": ".format(stat_field, data_table, boundary_table, "}], "added": [{"char_start": 88, "char_end": 156, "chars": "    # filter to avoid small populations influencing the map classes\n"}, {"char_start": 178, "char_end": 180, "chars": "%s"}, {"char_start": 194, "char_end": 196, "chars": "%s"}, {"char_start": 210, "char_end": 212, "chars": "%s"}, {"char_start": 246, "char_end": 248, "chars": "%s"}, {"char_start": 264, "char_end": 265, "chars": "0"}, {"char_start": 297, "char_end": 299, "chars": "%s"}, {"char_start": 308, "char_end": 310, "chars": "%s"}, {"char_start": 318, "char_end": 325, "chars": " \" \\\n  "}, {"char_start": 333, "char_end": 375, "chars": "\"AND bdy.population > 5\"\\\n        .format("}, {"char_start": 440, "char_end": 583, "chars": ", (AsIs(stat_field), AsIs(stat_field), AsIs(data_table), AsIs(boundary_table),\n                             AsIs(stat_field), AsIs(stat_field))"}]}, "commit_link": "github.com/minus34/census-loader/commit/e049d1a159a69443747bee0a412a1c1ba379f164", "file_name": "utils.py", "vul_type": "cwe-089"}
{"func_name": "get_metadata", "func_src_before": "@app.route(\"/get-metadata\")\ndef get_metadata():\n    full_start_time = datetime.now()\n    start_time = datetime.now()\n\n    # Get parameters from querystring\n    num_classes = int(request.args.get('n'))\n    raw_stats = request.args.get('stats')\n\n    # replace all maths operators to get list of all the stats we need\n    search_stats = raw_stats.upper().replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\") \\\n        .replace(\"+\", \",\").replace(\"-\", \",\").replace(\"/\", \",\").replace(\"*\", \",\").split(\",\")\n\n    # TODO: add support for numbers in equations - need to strip them from search_stats list\n\n    # equation_stats = raw_stats.lower().split(\",\")\n\n    # print(equation_stats)\n    # print(search_stats)\n\n    # get stats tuple for query input (convert to lower case)\n    search_stats_tuple = tuple([stat.lower() for stat in search_stats])\n\n    # get all boundary names in all zoom levels\n    boundary_names = list()\n\n    for zoom_level in range(0, 16):\n        bdy_name = utils.get_boundary_name(zoom_level)\n\n        if bdy_name not in boundary_names:\n            boundary_names.append(bdy_name)\n\n    # get stats metadata, including the all important table number and map type (raw values based or normalised by pop)\n    sql = \"SELECT lower(sequential_id) AS id, \" \\\n          \"lower(table_number) AS \\\"table\\\", \" \\\n          \"replace(long_id, '_', ' ') AS description, \" \\\n          \"column_heading_description AS type, \" \\\n          \"CASE WHEN lower(long_id) LIKE '%%median%%' OR lower(long_id) LIKE '%%average%%' THEN 'values' \" \\\n          \"ELSE 'normalised' END AS maptype \" \\\n          \"FROM {0}.metadata_stats \" \\\n          \"WHERE lower(sequential_id) IN %s \" \\\n          \"ORDER BY sequential_id\".format(settings[\"data_schema\"], )\n\n    with get_db_cursor() as pg_cur:\n        try:\n            pg_cur.execute(sql, (search_stats_tuple,))\n        except psycopg2.Error:\n            return \"I can't SELECT :\\n\\n\" + sql\n\n        # Retrieve the results of the query\n        rows = pg_cur.fetchall()\n\n    # output is the main content, row_output is the content from each record returned\n    response_dict = dict()\n    response_dict[\"type\"] = \"StatsCollection\"\n    response_dict[\"classes\"] = num_classes\n\n    # output_array = list()\n\n    # # get metadata for all boundaries (done in one go for frontend performance)\n    # for boundary_name in boundary_names:\n    #     output_dict = dict()\n    #     output_dict[\"boundary\"] = boundary_name\n    #\n    #     boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n\n    feature_array = list()\n\n    # For each row returned assemble a dictionary\n    for row in rows:\n        feature_dict = dict(row)\n        feature_dict[\"id\"] = feature_dict[\"id\"].lower()\n        feature_dict[\"table\"] = feature_dict[\"table\"].lower()\n\n        for boundary_name in boundary_names:\n            boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n\n            data_table = \"{0}.{1}_{2}\".format(settings[\"data_schema\"], boundary_name, feature_dict[\"table\"])\n\n            # get the values for the map classes\n            with get_db_cursor() as pg_cur:\n                stat_field = \"CASE WHEN bdy.population > 0 THEN tab.{0} / bdy.population * 100.0 ELSE 0 END\" \\\n                    .format(feature_dict[\"id\"], )\n                feature_dict[boundary_name] = utils.get_equal_interval_bins(\n                    data_table, boundary_table, stat_field, pg_cur, settings)\n\n        # add dict to output array of metadata\n        feature_array.append(feature_dict)\n\n    response_dict[\"stats\"] = feature_array\n    # output_array.append(output_dict)\n\n    # print(\"Got metadata for {0} in {1}\".format(boundary_name, datetime.now() - start_time))\n\n    # # Assemble the JSON\n    # response_dict[\"boundaries\"] = output_array\n\n    print(\"Returned metadata in {0}\".format(datetime.now() - full_start_time))\n\n    return Response(json.dumps(response_dict), mimetype='application/json')", "func_src_after": "@app.route(\"/get-metadata\")\ndef get_metadata():\n    full_start_time = datetime.now()\n    start_time = datetime.now()\n\n    # Get parameters from querystring\n    num_classes = int(request.args.get('n'))\n    raw_stats = request.args.get('stats')\n\n    # replace all maths operators to get list of all the stats we need\n    search_stats = raw_stats.upper().replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\") \\\n        .replace(\"+\", \",\").replace(\"-\", \",\").replace(\"/\", \",\").replace(\"*\", \",\").split(\",\")\n\n    # TODO: add support for numbers in equations - need to strip them from search_stats list\n\n    # equation_stats = raw_stats.lower().split(\",\")\n\n    # print(equation_stats)\n    # print(search_stats)\n\n    # get stats tuple for query input (convert to lower case)\n    search_stats_tuple = tuple([stat.lower() for stat in search_stats])\n\n    # get all boundary names in all zoom levels\n    boundary_names = list()\n\n    for zoom_level in range(0, 16):\n        bdy_name = utils.get_boundary_name(zoom_level)\n\n        if bdy_name not in boundary_names:\n            boundary_names.append(bdy_name)\n\n    # get stats metadata, including the all important table number and map type (raw values based or normalised by pop)\n    sql = \"SELECT lower(sequential_id) AS id, \" \\\n          \"lower(table_number) AS \\\"table\\\", \" \\\n          \"replace(long_id, '_', ' ') AS description, \" \\\n          \"column_heading_description AS type, \" \\\n          \"CASE WHEN lower(long_id) LIKE '%%median%%' OR lower(long_id) LIKE '%%average%%' THEN 'values' \" \\\n          \"ELSE 'percent' END AS maptype \" \\\n          \"FROM {0}.metadata_stats \" \\\n          \"WHERE lower(sequential_id) IN %s \" \\\n          \"ORDER BY sequential_id\".format(settings[\"data_schema\"], )\n\n    with get_db_cursor() as pg_cur:\n        try:\n            pg_cur.execute(sql, (search_stats_tuple,))\n        except psycopg2.Error:\n            return \"I can't SELECT:<br/><br/>\" + sql\n\n        # Retrieve the results of the query\n        rows = pg_cur.fetchall()\n\n    # output is the main content, row_output is the content from each record returned\n    response_dict = dict()\n    response_dict[\"type\"] = \"StatsCollection\"\n    response_dict[\"classes\"] = num_classes\n\n    # output_array = list()\n\n    # # get metadata for all boundaries (done in one go for frontend performance)\n    # for boundary_name in boundary_names:\n    #     output_dict = dict()\n    #     output_dict[\"boundary\"] = boundary_name\n    #\n    #     boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n\n    feature_array = list()\n\n    # For each row returned assemble a dictionary\n    for row in rows:\n        feature_dict = dict(row)\n        feature_dict[\"id\"] = feature_dict[\"id\"].lower()\n        feature_dict[\"table\"] = feature_dict[\"table\"].lower()\n\n        for boundary_name in boundary_names:\n            boundary_table = \"{0}.{1}\".format(settings[\"web_schema\"], boundary_name)\n\n            data_table = \"{0}.{1}_{2}\".format(settings[\"data_schema\"], boundary_name, feature_dict[\"table\"])\n\n            # get the values for the map classes\n            with get_db_cursor() as pg_cur:\n                stat_field = \"CASE WHEN bdy.population > 0 THEN tab.{0} / bdy.population * 100.0 ELSE 0 END\" \\\n                    .format(feature_dict[\"id\"], )\n                feature_dict[boundary_name] = utils.get_equal_interval_bins(\n                    data_table, boundary_table, stat_field, pg_cur, settings)\n\n        # add dict to output array of metadata\n        feature_array.append(feature_dict)\n\n    response_dict[\"stats\"] = feature_array\n    # output_array.append(output_dict)\n\n    # print(\"Got metadata for {0} in {1}\".format(boundary_name, datetime.now() - start_time))\n\n    # # Assemble the JSON\n    # response_dict[\"boundaries\"] = output_array\n\n    print(\"Returned metadata in {0}\".format(datetime.now() - full_start_time))\n\n    return Response(json.dumps(response_dict), mimetype='application/json')", "line_changes": {"deleted": [{"line_no": 39, "char_start": 1529, "char_end": 1577, "line": "          \"ELSE 'normalised' END AS maptype \" \\\n"}, {"line_no": 48, "char_start": 1869, "char_end": 1917, "line": "            return \"I can't SELECT :\\n\\n\" + sql\n"}], "added": [{"line_no": 39, "char_start": 1529, "char_end": 1574, "line": "          \"ELSE 'percent' END AS maptype \" \\\n"}, {"line_no": 48, "char_start": 1866, "char_end": 1919, "line": "            return \"I can't SELECT:<br/><br/>\" + sql\n"}]}, "char_changes": {"deleted": [{"char_start": 1546, "char_end": 1556, "chars": "normalised"}, {"char_start": 1903, "char_end": 1909, "chars": " :\\n\\n"}], "added": [{"char_start": 1546, "char_end": 1553, "chars": "percent"}, {"char_start": 1900, "char_end": 1911, "chars": ":<br/><br/>"}]}, "commit_link": "github.com/minus34/census-loader/commit/e049d1a159a69443747bee0a412a1c1ba379f164", "file_name": "web/server.py", "vul_type": "cwe-089"}
{"func_name": "get_data", "func_src_before": "@app.route(\"/get-data\")\ndef get_data():\n    full_start_time = datetime.now()\n    start_time = datetime.now()\n\n    # Get parameters from querystring\n\n    map_left = request.args.get('ml')\n    map_bottom = request.args.get('mb')\n    map_right = request.args.get('mr')\n    map_top = request.args.get('mt')\n\n    stat_id = request.args.get('s')\n    table_id = request.args.get('t')\n    boundary_name = request.args.get('b')\n    zoom_level = int(request.args.get('z'))\n\n    # # get the number of decimal places for the output GeoJSON to reduce response size & speed up rendering\n    # decimal_places = utils.get_decimal_places(zoom_level)\n\n    # TODO: add support for equations\n\n    # get the boundary table name from zoom level\n    if boundary_name is None:\n        boundary_name = utils.get_boundary_name(zoom_level)\n\n    display_zoom = str(zoom_level).zfill(2)\n\n    # stat_table_name = boundary_name + \"_\" + table_id\n    #\n    # boundary_table_name = \"{0}\".format(boundary_name)\n\n    with get_db_cursor() as pg_cur:\n        print(\"Connected to database in {0}\".format(datetime.now() - start_time))\n        start_time = datetime.now()\n\n        # envelope_sql = \"ST_MakeEnvelope({0}, {1}, {2}, {3}, 4283)\".format(map_left, map_bottom, map_right, map_top)\n        # geom_sql = \"geojson_{0}\".format(display_zoom)\n\n        # build SQL with SQL injection protection\n        sql = \"SELECT bdy.id, bdy.name, bdy.population, tab.%s / bdy.area AS density, \" \\\n              \"CASE WHEN bdy.population > 0 THEN tab.%s / bdy.population * 100.0 ELSE 0 END AS percent, \" \\\n              \"tab.%s, geojson_%s AS geometry \" \\\n              \"FROM {0}.%s AS bdy \" \\\n              \"INNER JOIN {1}.%s_%s AS tab ON bdy.id = tab.{2} \" \\\n              \"WHERE bdy.geom && ST_MakeEnvelope(%s, %s, %s, %s, 4283) LIMIT ALL\" \\\n            .format(settings['web_schema'], settings['data_schema'], settings['region_id_field'])\n\n        try:\n            # print(pg_cur.mogrify(sql, (AsIs(stat_id), AsIs(stat_id), AsIs(stat_id), AsIs(display_zoom), AsIs(boundary_name), AsIs(boundary_name), AsIs(table_id), AsIs(map_left), AsIs(map_bottom), AsIs(map_right), AsIs(map_top))))\n\n            # yes, this is ridiculous - if someone can find a shorthand way of doing this then great!\n            pg_cur.execute(sql, (AsIs(stat_id), AsIs(stat_id), AsIs(stat_id), AsIs(display_zoom),\n                                 AsIs(boundary_name), AsIs(boundary_name), AsIs(table_id), AsIs(map_left),\n                                 AsIs(map_bottom), AsIs(map_right), AsIs(map_top)))\n        except psycopg2.Error:\n            return \"I can't SELECT : \" + sql\n\n        # print(\"Ran query in {0}\".format(datetime.now() - start_time))\n        # start_time = datetime.now()\n\n        # Retrieve the results of the query\n        rows = pg_cur.fetchall()\n        # row_count = pg_cur.rowcount\n\n        # Get the column names returned\n        col_names = [desc[0] for desc in pg_cur.description]\n\n    print(\"Got records from Postgres in {0}\".format(datetime.now() - start_time))\n    start_time = datetime.now()\n\n    # # Find the index of the column that holds the geometry\n    # geom_index = col_names.index(\"geometry\")\n\n    # output is the main content, row_output is the content from each record returned\n    output_dict = dict()\n    output_dict[\"type\"] = \"FeatureCollection\"\n\n    i = 0\n    feature_array = list()\n\n    # For each row returned...\n    for row in rows:\n        feature_dict = dict()\n        feature_dict[\"type\"] = \"Feature\"\n\n        properties_dict = dict()\n\n        # For each field returned, assemble the feature and properties dictionaries\n        for col in col_names:\n            if col == 'geometry':\n                feature_dict[\"geometry\"] = ast.literal_eval(str(row[col]))\n            elif col == 'id':\n                feature_dict[\"id\"] = row[col]\n            else:\n                properties_dict[col] = row[col]\n\n        feature_dict[\"properties\"] = properties_dict\n\n        feature_array.append(feature_dict)\n\n        # start over\n        i += 1\n\n    # Assemble the GeoJSON\n    output_dict[\"features\"] = feature_array\n\n    print(\"Parsed records into JSON in {1}\".format(i, datetime.now() - start_time))\n    print(\"Returned {0} records  {1}\".format(i, datetime.now() - full_start_time))\n\n    return Response(json.dumps(output_dict), mimetype='application/json')", "func_src_after": "@app.route(\"/get-data\")\ndef get_data():\n    full_start_time = datetime.now()\n    start_time = datetime.now()\n\n    # Get parameters from querystring\n\n    map_left = request.args.get('ml')\n    map_bottom = request.args.get('mb')\n    map_right = request.args.get('mr')\n    map_top = request.args.get('mt')\n\n    stat_id = request.args.get('s')\n    table_id = request.args.get('t')\n    boundary_name = request.args.get('b')\n    zoom_level = int(request.args.get('z'))\n\n    # TODO: add support for equations\n\n    # get the boundary table name from zoom level\n    if boundary_name is None:\n        boundary_name = utils.get_boundary_name(zoom_level)\n\n    display_zoom = str(zoom_level).zfill(2)\n\n    with get_db_cursor() as pg_cur:\n        print(\"Connected to database in {0}\".format(datetime.now() - start_time))\n        start_time = datetime.now()\n\n        # envelope_sql = \"ST_MakeEnvelope({0}, {1}, {2}, {3}, 4283)\".format(map_left, map_bottom, map_right, map_top)\n        # geom_sql = \"geojson_{0}\".format(display_zoom)\n\n        # build SQL with SQL injection protection\n        sql = \"SELECT bdy.id, bdy.name, bdy.population, tab.%s / bdy.area AS density, \" \\\n              \"CASE WHEN bdy.population > 0 THEN tab.%s / bdy.population * 100.0 ELSE 0 END AS percent, \" \\\n              \"tab.%s, geojson_%s AS geometry \" \\\n              \"FROM {0}.%s AS bdy \" \\\n              \"INNER JOIN {1}.%s_%s AS tab ON bdy.id = tab.{2} \" \\\n              \"WHERE bdy.geom && ST_MakeEnvelope(%s, %s, %s, %s, 4283)\" \\\n            .format(settings['web_schema'], settings['data_schema'], settings['region_id_field'])\n\n        try:\n            # yes, this is ridiculous - if someone can find a shorthand way of doing this then great!\n            pg_cur.execute(sql, (AsIs(stat_id), AsIs(stat_id), AsIs(stat_id), AsIs(display_zoom),\n                                 AsIs(boundary_name), AsIs(boundary_name), AsIs(table_id), AsIs(map_left),\n                                 AsIs(map_bottom), AsIs(map_right), AsIs(map_top)))\n        except psycopg2.Error:\n            return \"I can't SELECT:<br/><br/>\" + sql\n\n        # Retrieve the results of the query\n        rows = pg_cur.fetchall()\n\n        # Get the column names returned\n        col_names = [desc[0] for desc in pg_cur.description]\n\n    print(\"Got records from Postgres in {0}\".format(datetime.now() - start_time))\n    start_time = datetime.now()\n\n    # output is the main content, row_output is the content from each record returned\n    output_dict = dict()\n    output_dict[\"type\"] = \"FeatureCollection\"\n\n    i = 0\n    feature_array = list()\n\n    # For each row returned...\n    for row in rows:\n        feature_dict = dict()\n        feature_dict[\"type\"] = \"Feature\"\n\n        properties_dict = dict()\n\n        # For each field returned, assemble the feature and properties dictionaries\n        for col in col_names:\n            if col == 'geometry':\n                feature_dict[\"geometry\"] = ast.literal_eval(str(row[col]))\n            elif col == 'id':\n                feature_dict[\"id\"] = row[col]\n            else:\n                properties_dict[col] = row[col]\n\n        feature_dict[\"properties\"] = properties_dict\n\n        feature_array.append(feature_dict)\n\n        # start over\n        i += 1\n\n    # Assemble the GeoJSON\n    output_dict[\"features\"] = feature_array\n\n    print(\"Parsed records into JSON in {1}\".format(i, datetime.now() - start_time))\n    print(\"Returned {0} records  {1}\".format(i, datetime.now() - full_start_time))\n\n    return Response(json.dumps(output_dict), mimetype='application/json')", "line_changes": {"deleted": [{"line_no": 20, "char_start": 633, "char_end": 634, "line": "\n"}, {"line_no": 32, "char_start": 976, "char_end": 977, "line": "\n"}, {"line_no": 46, "char_start": 1710, "char_end": 1794, "line": "              \"WHERE bdy.geom && ST_MakeEnvelope(%s, %s, %s, %s, 4283) LIMIT ALL\" \\\n"}, {"line_no": 51, "char_start": 2138, "char_end": 2139, "line": "\n"}, {"line_no": 57, "char_start": 2561, "char_end": 2606, "line": "            return \"I can't SELECT : \" + sql\n"}, {"line_no": 58, "char_start": 2606, "char_end": 2607, "line": "\n"}, {"line_no": 74, "char_start": 3159, "char_end": 3160, "line": "\n"}], "added": [{"line_no": 39, "char_start": 1422, "char_end": 1496, "line": "              \"WHERE bdy.geom && ST_MakeEnvelope(%s, %s, %s, %s, 4283)\" \\\n"}, {"line_no": 48, "char_start": 2030, "char_end": 2083, "line": "            return \"I can't SELECT:<br/><br/>\" + sql\n"}]}, "char_changes": {"deleted": [{"char_start": 464, "char_end": 634, "chars": "    # # get the number of decimal places for the output GeoJSON to reduce response size & speed up rendering\n    # decimal_places = utils.get_decimal_places(zoom_level)\n\n"}, {"char_start": 859, "char_end": 977, "chars": "    # stat_table_name = boundary_name + \"_\" + table_id\n    #\n    # boundary_table_name = \"{0}\".format(boundary_name)\n\n"}, {"char_start": 1780, "char_end": 1790, "chars": " LIMIT ALL"}, {"char_start": 1906, "char_end": 2139, "chars": "            # print(pg_cur.mogrify(sql, (AsIs(stat_id), AsIs(stat_id), AsIs(stat_id), AsIs(display_zoom), AsIs(boundary_name), AsIs(boundary_name), AsIs(table_id), AsIs(map_left), AsIs(map_bottom), AsIs(map_right), AsIs(map_top))))\n\n"}, {"char_start": 2595, "char_end": 2716, "chars": " : \" + sql\n\n        # print(\"Ran query in {0}\".format(datetime.now() - start_time))\n        # start_time = datetime.now()"}, {"char_start": 2794, "char_end": 2832, "chars": "\n        # row_count = pg_cur.rowcount"}, {"char_start": 3051, "char_end": 3160, "chars": "    # # Find the index of the column that holds the geometry\n    # geom_index = col_names.index(\"geometry\")\n\n"}], "added": [{"char_start": 502, "char_end": 502, "chars": ""}, {"char_start": 2064, "char_end": 2082, "chars": ":<br/><br/>\" + sql"}, {"char_start": 2346, "char_end": 2346, "chars": ""}]}, "commit_link": "github.com/minus34/census-loader/commit/e049d1a159a69443747bee0a412a1c1ba379f164", "file_name": "web/server.py", "vul_type": "cwe-089"}
{"func_name": "system_search", "func_src_before": "    def system_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        table = conn.execute(f\"select * from populated where lower(name) = '{search}'\")\r\n        results = table.fetchone()\r\n        if not results:\r\n            table = conn.execute(f\"select * from systems where lower(name) = '{search}'\")\r\n            results = table.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in table.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[1:], results[1:]) if field)\r\n        else:\r\n            return 'No systems found.'", "func_src_after": "    def system_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        table = conn.execute('select * from populated where lower(name) = ?', (search,))\r\n        results = table.fetchone()\r\n        if not results:\r\n            table = conn.execute('select * from systems where lower(name) = ?', (search,))\r\n            results = table.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in table.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[1:], results[1:]) if field)\r\n        else:\r\n            return 'No systems found.'", "line_changes": {"deleted": [{"line_no": 4, "char_start": 126, "char_end": 215, "line": "        table = conn.execute(f\"select * from populated where lower(name) = '{search}'\")\r\n"}, {"line_no": 7, "char_start": 276, "char_end": 367, "line": "            table = conn.execute(f\"select * from systems where lower(name) = '{search}'\")\r\n"}], "added": [{"line_no": 4, "char_start": 126, "char_end": 216, "line": "        table = conn.execute('select * from populated where lower(name) = ?', (search,))\r\n"}, {"line_no": 7, "char_start": 277, "char_end": 369, "line": "            table = conn.execute('select * from systems where lower(name) = ?', (search,))\r\n"}]}, "char_changes": {"deleted": [{"char_start": 155, "char_end": 157, "chars": "f\""}, {"char_start": 201, "char_end": 203, "chars": "'{"}, {"char_start": 209, "char_end": 212, "chars": "}'\""}, {"char_start": 309, "char_end": 311, "chars": "f\""}, {"char_start": 353, "char_end": 355, "chars": "'{"}, {"char_start": 361, "char_end": 364, "chars": "}'\""}], "added": [{"char_start": 155, "char_end": 156, "chars": "'"}, {"char_start": 200, "char_end": 205, "chars": "?', ("}, {"char_start": 211, "char_end": 213, "chars": ",)"}, {"char_start": 310, "char_end": 311, "chars": "'"}, {"char_start": 353, "char_end": 358, "chars": "?', ("}, {"char_start": 364, "char_end": 366, "chars": ",)"}]}, "commit_link": "github.com/BeatButton/beattie/commit/ab36b2053ee09faf4cc9a279cf7a4c010864cb29", "file_name": "eddb.py", "vul_type": "cwe-089"}
{"func_name": "station_search", "func_src_before": "    def station_search(self, search, target_system=None, ctx=None):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        if ',' in search:\r\n            search, target_system = (i.strip() for i in search.split(','))\r\n\r\n        query = f\"select * from stations where lower(name) = '{search}'\"\r\n\r\n        if target_system is not None: \r\n            target_system = target_system.lower()\r\n            table = conn.execute(f\"select id from populated where lower(name)='{target_system}'\")\r\n            results = table.fetchone()\r\n            if results:\r\n                target_system = results[0]\r\n                query += f\" and system_id = {target_system}\"\r\n            else:\r\n                return 'System not found.'\r\n\r\n        result = conn.execute(query)\r\n        results = result.fetchall()\r\n\r\n        if len(results) == 1:\r\n            keys = tuple(i[0] for i in result.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[2:], results[0][2:]) if field)\r\n        elif not results:\r\n            return 'Station not found.'\r\n        else:\r\n            return 'Multiple stations found, please specify system.'", "func_src_after": "    def station_search(self, search, target_system=None, ctx=None):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        if ',' in search:\r\n            search, target_system = (i.strip() for i in search.split(','))\r\n\r\n        query = 'select * from stations where lower(name) = ?'\r\n\r\n        if target_system is not None: \r\n            target_system = target_system.lower()\r\n            table = conn.execute('select id from populated where lower(name)=?', (target_system,))\r\n            results = table.fetchone()\r\n            if results:\r\n                target_system = results[0]\r\n                query += \" and system_id = ?\"\r\n            else:\r\n                return 'System not found.'\r\n\r\n        args = (search,)\r\n        if target_system:\r\n            args = args + (target_system,)\r\n            \r\n        result = conn.execute(query, args)\r\n        results = result.fetchall()\r\n\r\n        if len(results) == 1:\r\n            keys = tuple(i[0] for i in result.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[2:], results[0][2:]) if field)\r\n        elif not results:\r\n            return 'Station not found.'\r\n        else:\r\n            return 'Multiple stations found, please specify system.'", "line_changes": {"deleted": [{"line_no": 7, "char_start": 262, "char_end": 336, "line": "        query = f\"select * from stations where lower(name) = '{search}'\"\r\n"}, {"line_no": 11, "char_start": 429, "char_end": 528, "line": "            table = conn.execute(f\"select id from populated where lower(name)='{target_system}'\")\r\n"}, {"line_no": 15, "char_start": 637, "char_end": 699, "line": "                query += f\" and system_id = {target_system}\"\r\n"}, {"line_no": 19, "char_start": 764, "char_end": 802, "line": "        result = conn.execute(query)\r\n"}], "added": [{"line_no": 7, "char_start": 262, "char_end": 326, "line": "        query = 'select * from stations where lower(name) = ?'\r\n"}, {"line_no": 11, "char_start": 419, "char_end": 519, "line": "            table = conn.execute('select id from populated where lower(name)=?', (target_system,))\r\n"}, {"line_no": 15, "char_start": 628, "char_end": 675, "line": "                query += \" and system_id = ?\"\r\n"}, {"line_no": 19, "char_start": 740, "char_end": 766, "line": "        args = (search,)\r\n"}, {"line_no": 20, "char_start": 766, "char_end": 793, "line": "        if target_system:\r\n"}, {"line_no": 21, "char_start": 793, "char_end": 837, "line": "            args = args + (target_system,)\r\n"}, {"line_no": 22, "char_start": 837, "char_end": 851, "line": "            \r\n"}, {"line_no": 23, "char_start": 851, "char_end": 895, "line": "        result = conn.execute(query, args)\r\n"}]}, "char_changes": {"deleted": [{"char_start": 278, "char_end": 280, "chars": "f\""}, {"char_start": 324, "char_end": 334, "chars": "{search}'\""}, {"char_start": 462, "char_end": 464, "chars": "f\""}, {"char_start": 507, "char_end": 509, "chars": "'{"}, {"char_start": 522, "char_end": 525, "chars": "}'\""}, {"char_start": 662, "char_end": 663, "chars": "f"}, {"char_start": 681, "char_end": 696, "chars": "{target_system}"}], "added": [{"char_start": 278, "char_end": 279, "chars": "'"}, {"char_start": 322, "char_end": 323, "chars": "?"}, {"char_start": 452, "char_end": 453, "chars": "'"}, {"char_start": 496, "char_end": 501, "chars": "?', ("}, {"char_start": 514, "char_end": 516, "chars": ",)"}, {"char_start": 671, "char_end": 672, "chars": "?"}, {"char_start": 740, "char_end": 851, "chars": "        args = (search,)\r\n        if target_system:\r\n            args = args + (target_system,)\r\n            \r\n"}, {"char_start": 886, "char_end": 892, "chars": ", args"}]}, "commit_link": "github.com/BeatButton/beattie/commit/ab36b2053ee09faf4cc9a279cf7a4c010864cb29", "file_name": "eddb.py", "vul_type": "cwe-089"}
{"func_name": "body_search", "func_src_before": "    def body_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        result = conn.execute(f\"select * from bodies where lower(name) = '{search}'\")\r\n        results = result.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in result.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[2:], results[2:]) if field)\r\n        else:\r\n            return 'No bodies found.'", "func_src_after": "    def body_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        result = conn.execute('select * from bodies where lower(name) = ?', (search,))\r\n        results = result.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in result.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[2:], results[2:]) if field)\r\n        else:\r\n            return 'No bodies found.'", "line_changes": {"deleted": [{"line_no": 4, "char_start": 124, "char_end": 211, "line": "        result = conn.execute(f\"select * from bodies where lower(name) = '{search}'\")\r\n"}], "added": [{"line_no": 4, "char_start": 124, "char_end": 212, "line": "        result = conn.execute('select * from bodies where lower(name) = ?', (search,))\r\n"}]}, "char_changes": {"deleted": [{"char_start": 154, "char_end": 156, "chars": "f\""}, {"char_start": 197, "char_end": 199, "chars": "'{"}, {"char_start": 205, "char_end": 208, "chars": "}'\""}], "added": [{"char_start": 154, "char_end": 155, "chars": "'"}, {"char_start": 196, "char_end": 201, "chars": "?', ("}, {"char_start": 207, "char_end": 209, "chars": ",)"}]}, "commit_link": "github.com/BeatButton/beattie/commit/ab36b2053ee09faf4cc9a279cf7a4c010864cb29", "file_name": "eddb.py", "vul_type": "cwe-089"}
{"func_name": "commodity_search", "func_src_before": "    def commodity_search(self, search):\r\n        search = search.lower().split(', ')\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n\r\n        if len(search) == 1:\r\n            table = conn.execute(f\"select * from commodities where lower(name)='{search[0]}'\")\r\n            result = table.fetchone()\r\n            if result:\r\n                keys = tuple(i[0] for i in table.description)\r\n                return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                                 for key, field in zip(keys[1:], result[1:]))\r\n        \r\n        elif len(search) < 4:\r\n            table = conn.execute(f\"select id from commodities where lower(name)='{search[0]}'\")\r\n            result = table.fetchone()\r\n            if not result:\r\n                return 'Commodity not found.'\r\n            commodity_id = result[0]\r\n\r\n            query = f\"select id from stations where lower(name)='{search[1]}'\"\r\n            \r\n            if len(search) == 3:\r\n                table = conn.execute(f\"select id from systems where lower(name)='{search[2]}'\")\r\n                result = table.fetchone()\r\n                if not result:\r\n                    return 'System not found.'\r\n                system_id = result[0]\r\n                query += f\" and system_id={system_id}\"\r\n            table = conn.execute(query)\r\n            result = table.fetchall()\r\n            if not result:\r\n                return 'Station not found.'\r\n            elif len(result) > 1:\r\n                return 'Multiple stations found, please specify system.'\r\n            station_id = result[0][0]\r\n\r\n            table = conn.execute(f\"select * from listings where station_id={station_id} \"\r\n                                 f\"and commodity_id={commodity_id}\")\r\n            result = table.fetchone()\r\n            if not result:\r\n                return 'Commodity not available to be bought or sold at station.'\r\n\r\n            keys = (i[0] for i in table.description)\r\n            result = {k: v for k, v in zip(keys, result)}\r\n            result.pop('station_id')\r\n            result.pop('commodity_id')\r\n            result.pop('id')\r\n            ret = f'Commodity: {search[0].title()}\\n'\r\n            if len(search) > 1:\r\n                ret += f'Station: {search[1].title()}\\n'\r\n            if len(search) > 2:\r\n                ret += f'System: {search[2].title()}\\n'\r\n            return ret +('\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in result.items()))\r\n\r\n        else:\r\n            return 'Too many commas. What does that even mean.'", "func_src_after": "    def commodity_search(self, search):\r\n        search = search.lower().split(', ')\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n\r\n        if len(search) == 1:\r\n            table = conn.execute('select * from commodities where lower(name)=?', (search[0],))\r\n            result = table.fetchone()\r\n            if result:\r\n                keys = tuple(i[0] for i in table.description)\r\n                return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                                 for key, field in zip(keys[1:], result[1:]))\r\n        \r\n        elif len(search) < 4:\r\n            table = conn.execute('select id from commodities where lower(name)=?', (search[0],))\r\n            result = table.fetchone()\r\n            if not result:\r\n                return 'Commodity not found.'\r\n            commodity_id = result[0]\r\n\r\n            query = 'select id from stations where lower(name)=?'\r\n            args = (search[1],)\r\n            \r\n            if len(search) == 3:\r\n                table = conn.execute('select id from systems where lower(name)=?', (search[2],))\r\n                result = table.fetchone()\r\n                if not result:\r\n                    return 'System not found.'\r\n                system_id = result[0]\r\n                query += ' and system_id=?'\r\n                args = args + (system_id,)\r\n            table = conn.execute(query, args)\r\n            result = table.fetchall()\r\n            if not result:\r\n                return 'Station not found.'\r\n            elif len(result) > 1:\r\n                return 'Multiple stations found, please specify system.'\r\n            station_id = result[0][0]\r\n\r\n            table = conn.execute('select * from listings where station_id=? '\r\n                                 'and commodity_id=?', (station_id, commodity_id))\r\n            result = table.fetchone()\r\n            if not result:\r\n                return 'Commodity not available to be bought or sold at station.'\r\n\r\n            keys = (i[0] for i in table.description)\r\n            result = {k: v for k, v in zip(keys, result)}\r\n            result.pop('station_id')\r\n            result.pop('commodity_id')\r\n            result.pop('id')\r\n            ret = f'Commodity: {search[0].title()}\\n'\r\n            if len(search) > 1:\r\n                ret += f'Station: {search[1].title()}\\n'\r\n            if len(search) > 2:\r\n                ret += f'System: {search[2].title()}\\n'\r\n            return ret +('\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in result.items()))\r\n\r\n        else:\r\n            return 'Too many commas. What does that even mean.'", "line_changes": {"deleted": [{"line_no": 6, "char_start": 173, "char_end": 269, "line": "            table = conn.execute(f\"select * from commodities where lower(name)='{search[0]}'\")\r\n"}, {"line_no": 14, "char_start": 593, "char_end": 690, "line": "            table = conn.execute(f\"select id from commodities where lower(name)='{search[0]}'\")\r\n"}, {"line_no": 20, "char_start": 844, "char_end": 924, "line": "            query = f\"select id from stations where lower(name)='{search[1]}'\"\r\n"}, {"line_no": 23, "char_start": 972, "char_end": 1069, "line": "                table = conn.execute(f\"select id from systems where lower(name)='{search[2]}'\")\r\n"}, {"line_no": 28, "char_start": 1231, "char_end": 1287, "line": "                query += f\" and system_id={system_id}\"\r\n"}, {"line_no": 29, "char_start": 1287, "char_end": 1328, "line": "            table = conn.execute(query)\r\n"}, {"line_no": 37, "char_start": 1590, "char_end": 1681, "line": "            table = conn.execute(f\"select * from listings where station_id={station_id} \"\r\n"}, {"line_no": 38, "char_start": 1681, "char_end": 1751, "line": "                                 f\"and commodity_id={commodity_id}\")\r\n"}], "added": [{"line_no": 6, "char_start": 173, "char_end": 270, "line": "            table = conn.execute('select * from commodities where lower(name)=?', (search[0],))\r\n"}, {"line_no": 14, "char_start": 594, "char_end": 692, "line": "            table = conn.execute('select id from commodities where lower(name)=?', (search[0],))\r\n"}, {"line_no": 20, "char_start": 846, "char_end": 913, "line": "            query = 'select id from stations where lower(name)=?'\r\n"}, {"line_no": 21, "char_start": 913, "char_end": 946, "line": "            args = (search[1],)\r\n"}, {"line_no": 24, "char_start": 994, "char_end": 1092, "line": "                table = conn.execute('select id from systems where lower(name)=?', (search[2],))\r\n"}, {"line_no": 29, "char_start": 1254, "char_end": 1299, "line": "                query += ' and system_id=?'\r\n"}, {"line_no": 30, "char_start": 1299, "char_end": 1343, "line": "                args = args + (system_id,)\r\n"}, {"line_no": 31, "char_start": 1343, "char_end": 1390, "line": "            table = conn.execute(query, args)\r\n"}, {"line_no": 39, "char_start": 1652, "char_end": 1731, "line": "            table = conn.execute('select * from listings where station_id=? '\r\n"}, {"line_no": 40, "char_start": 1731, "char_end": 1815, "line": "                                 'and commodity_id=?', (station_id, commodity_id))\r\n"}]}, "char_changes": {"deleted": [{"char_start": 206, "char_end": 208, "chars": "f\""}, {"char_start": 252, "char_end": 254, "chars": "'{"}, {"char_start": 263, "char_end": 266, "chars": "}'\""}, {"char_start": 626, "char_end": 628, "chars": "f\""}, {"char_start": 673, "char_end": 675, "chars": "'{"}, {"char_start": 684, "char_end": 687, "chars": "}'\""}, {"char_start": 864, "char_end": 866, "chars": "f\""}, {"char_start": 908, "char_end": 910, "chars": "'{"}, {"char_start": 919, "char_end": 922, "chars": "}'\""}, {"char_start": 1009, "char_end": 1011, "chars": "f\""}, {"char_start": 1052, "char_end": 1054, "chars": "'{"}, {"char_start": 1063, "char_end": 1066, "chars": "}'\""}, {"char_start": 1256, "char_end": 1258, "chars": "f\""}, {"char_start": 1273, "char_end": 1274, "chars": "{"}, {"char_start": 1283, "char_end": 1285, "chars": "}\""}, {"char_start": 1623, "char_end": 1625, "chars": "f\""}, {"char_start": 1665, "char_end": 1679, "chars": "{station_id} \""}, {"char_start": 1714, "char_end": 1716, "chars": "f\""}, {"char_start": 1733, "char_end": 1734, "chars": "{"}, {"char_start": 1746, "char_end": 1748, "chars": "}\""}], "added": [{"char_start": 206, "char_end": 207, "chars": "'"}, {"char_start": 251, "char_end": 256, "chars": "?', ("}, {"char_start": 265, "char_end": 267, "chars": ",)"}, {"char_start": 627, "char_end": 628, "chars": "'"}, {"char_start": 673, "char_end": 678, "chars": "?', ("}, {"char_start": 687, "char_end": 689, "chars": ",)"}, {"char_start": 866, "char_end": 867, "chars": "'"}, {"char_start": 909, "char_end": 933, "chars": "?'\r\n            args = ("}, {"char_start": 942, "char_end": 944, "chars": ",)"}, {"char_start": 1031, "char_end": 1032, "chars": "'"}, {"char_start": 1073, "char_end": 1078, "chars": "?', ("}, {"char_start": 1087, "char_end": 1089, "chars": ",)"}, {"char_start": 1279, "char_end": 1280, "chars": "'"}, {"char_start": 1295, "char_end": 1330, "chars": "?'\r\n                args = args + ("}, {"char_start": 1339, "char_end": 1341, "chars": ",)"}, {"char_start": 1381, "char_end": 1387, "chars": ", args"}, {"char_start": 1685, "char_end": 1686, "chars": "'"}, {"char_start": 1726, "char_end": 1729, "chars": "? '"}, {"char_start": 1764, "char_end": 1765, "chars": "'"}, {"char_start": 1782, "char_end": 1799, "chars": "?', (station_id, "}, {"char_start": 1811, "char_end": 1812, "chars": ")"}]}, "commit_link": "github.com/BeatButton/beattie/commit/ab36b2053ee09faf4cc9a279cf7a4c010864cb29", "file_name": "eddb.py", "vul_type": "cwe-089"}
{"func_name": "getAlcoholByName", "func_src_before": "def getAlcoholByName(name):\n    name = fixTypingErrors(name)\n    QUERY = (\n        \"SELECT barnivore_product_name, barnivore_status, barnivore_country \" + \n        \"FROM barnivore_product \" +\n        \"WHERE lower(barnivore_product_name) like lower('% \\%s %')\"\n    )\n    \n    try:\n        conn = psycopg2.connect(connectionString)\n        cur = conn.cursor()\n        cur.execute(QUERY, (name))\n        result = cur.fetchall()\n\n    except(psycopg2.DatabaseError, e):\n        print('Error %s' % e)    \n\n    finally:\n        if conn:\n            conn.close()\n\n    return result", "func_src_after": "def getAlcoholByName(name):\n    name = fixTypingErrors(name)\n    name = \"%\" + name + \"%\"\n    QUERY = (\n        \"SELECT barnivore_product_name, barnivore_status, barnivore_country \" + \n        \"FROM barnivore_product \" +\n        \"WHERE lower(barnivore_product_name) like lower(%s)\"\n    )\n        \n    try:\n        conn = psycopg2.connect(connectionString)\n        cur = conn.cursor()\n        cur.execute(QUERY, (name,))\n        result = cur.fetchall()\n\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)    \n\n    finally:\n        if conn:\n            conn.close()\n\n    return result", "line_changes": {"deleted": [{"line_no": 6, "char_start": 192, "char_end": 260, "line": "        \"WHERE lower(barnivore_product_name) like lower('% \\%s %')\"\n"}, {"line_no": 8, "char_start": 266, "char_end": 271, "line": "    \n"}, {"line_no": 12, "char_start": 358, "char_end": 393, "line": "        cur.execute(QUERY, (name))\n"}, {"line_no": 15, "char_start": 426, "char_end": 465, "line": "    except(psycopg2.DatabaseError, e):\n"}], "added": [{"line_no": 3, "char_start": 61, "char_end": 89, "line": "    name = \"%\" + name + \"%\"\n"}, {"line_no": 7, "char_start": 220, "char_end": 281, "line": "        \"WHERE lower(barnivore_product_name) like lower(%s)\"\n"}, {"line_no": 9, "char_start": 287, "char_end": 296, "line": "        \n"}, {"line_no": 13, "char_start": 383, "char_end": 419, "line": "        cur.execute(QUERY, (name,))\n"}, {"line_no": 16, "char_start": 452, "char_end": 492, "line": "    except psycopg2.DatabaseError as e:\n"}]}, "char_changes": {"deleted": [{"char_start": 248, "char_end": 257, "chars": "'% \\%s %'"}, {"char_start": 436, "char_end": 437, "chars": "("}, {"char_start": 459, "char_end": 460, "chars": ","}, {"char_start": 462, "char_end": 463, "chars": ")"}], "added": [{"char_start": 61, "char_end": 89, "chars": "    name = \"%\" + name + \"%\"\n"}, {"char_start": 276, "char_end": 278, "chars": "%s"}, {"char_start": 291, "char_end": 295, "chars": "    "}, {"char_start": 415, "char_end": 416, "chars": ","}, {"char_start": 462, "char_end": 463, "chars": " "}, {"char_start": 485, "char_end": 488, "chars": " as"}]}, "commit_link": "github.com/maxh213/VeganAlcoholCheckerTwitterBot/commit/e2a3b30c88279d3171fd360749b8909489aa4f55", "file_name": "getAlcohol.py", "vul_type": "cwe-089"}
{"func_name": "getLastReplied", "func_src_before": "def getLastReplied(messageType):\n    QUERY = (\n        \"SELECT item_id from twitter_bot_vac_last_replied_id where name = '{0}'\"\n    ).format(messageType)\n    \n    try:\n        conn = psycopg2.connect(connectionString)\n        cur = conn.cursor()\n        cur.execute(QUERY)\n        result = cur.fetchone()\n\n    except(psycopg2.DatabaseError, e):\n        print('Error %s' % e)    \n\n    finally:\n        if conn:\n            conn.close()\n\n    return result[0]", "func_src_after": "def getLastReplied(messageType):\n    QUERY = (\n        \"SELECT item_id from twitter_bot_vac_last_replied_id where name = '{0}'\"\n    ).format(messageType)\n    \n    try:\n        conn = psycopg2.connect(connectionString)\n        cur = conn.cursor()\n        cur.execute(QUERY)\n        result = cur.fetchone()\n\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)    \n\n    finally:\n        if conn:\n            conn.close()\n\n    return result[0]", "line_changes": {"deleted": [{"line_no": 12, "char_start": 306, "char_end": 345, "line": "    except(psycopg2.DatabaseError, e):\n"}], "added": [{"line_no": 12, "char_start": 306, "char_end": 346, "line": "    except psycopg2.DatabaseError as e:\n"}]}, "char_changes": {"deleted": [{"char_start": 316, "char_end": 317, "chars": "("}, {"char_start": 339, "char_end": 340, "chars": ","}, {"char_start": 342, "char_end": 343, "chars": ")"}], "added": [{"char_start": 316, "char_end": 317, "chars": " "}, {"char_start": 339, "char_end": 342, "chars": " as"}]}, "commit_link": "github.com/maxh213/VeganAlcoholCheckerTwitterBot/commit/e2a3b30c88279d3171fd360749b8909489aa4f55", "file_name": "lastReplied.py", "vul_type": "cwe-089"}
{"func_name": "setLastReplied", "func_src_before": "def setLastReplied(messageType, itemId):\n    QUERY = (\n        \"UPDATE twitter_bot_vac_last_replied_id SET item_id = '${0}' WHERE name = '${1}'\"\n    ).format(itemId, messageType)\n    \n    try:\n        conn = psycopg2.connect(connectionString)\n        cur = conn.cursor()\n        cur.execute(QUERY)\n        conn.commit()\n        cur.close()\n\n    except(psycopg2.DatabaseError, e):\n        print('Error %s' % e)    \n\n    finally:\n        if conn:\n            conn.close()", "func_src_after": "def setLastReplied(messageType, itemId):\n    QUERY = (\n        \"UPDATE twitter_bot_vac_last_replied_id SET item_id = '{0}' WHERE name = '{1}'\"\n    ).format(itemId, messageType)\n    \n    try:\n        conn = psycopg2.connect(connectionString)\n        cur = conn.cursor()\n        cur.execute(QUERY)\n        conn.commit()\n        cur.close()\n\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)    \n\n    finally:\n        if conn:\n            conn.close()", "line_changes": {"deleted": [{"line_no": 3, "char_start": 55, "char_end": 145, "line": "        \"UPDATE twitter_bot_vac_last_replied_id SET item_id = '${0}' WHERE name = '${1}'\"\n"}, {"line_no": 13, "char_start": 341, "char_end": 380, "line": "    except(psycopg2.DatabaseError, e):\n"}], "added": [{"line_no": 3, "char_start": 55, "char_end": 143, "line": "        \"UPDATE twitter_bot_vac_last_replied_id SET item_id = '{0}' WHERE name = '{1}'\"\n"}, {"line_no": 13, "char_start": 339, "char_end": 379, "line": "    except psycopg2.DatabaseError as e:\n"}]}, "char_changes": {"deleted": [{"char_start": 118, "char_end": 119, "chars": "$"}, {"char_start": 138, "char_end": 139, "chars": "$"}, {"char_start": 351, "char_end": 352, "chars": "("}, {"char_start": 374, "char_end": 375, "chars": ","}, {"char_start": 377, "char_end": 378, "chars": ")"}], "added": [{"char_start": 349, "char_end": 350, "chars": " "}, {"char_start": 372, "char_end": 375, "chars": " as"}]}, "commit_link": "github.com/maxh213/VeganAlcoholCheckerTwitterBot/commit/e2a3b30c88279d3171fd360749b8909489aa4f55", "file_name": "lastReplied.py", "vul_type": "cwe-089"}
{"func_name": "registerPlayer", "func_src_before": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n  \n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n  \n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute('INSERT INTO players (player_name) VALUES (%s)', (name,))\n    db.commit()\n    db.close()", "func_src_after": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n  \n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n  \n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n    clean_name = bleach.clean(name)\n    db = connect()\n    c = db.cursor()\n    c.execute('INSERT INTO players (player_name) VALUES (%s)', (clean_name,))\n    db.commit()\n    db.close()", "line_changes": {"deleted": [{"line_no": 12, "char_start": 346, "char_end": 418, "line": "    c.execute('INSERT INTO players (player_name) VALUES (%s)', (name,))\n"}], "added": [{"line_no": 10, "char_start": 307, "char_end": 343, "line": "    clean_name = bleach.clean(name)\n"}, {"line_no": 13, "char_start": 382, "char_end": 460, "line": "    c.execute('INSERT INTO players (player_name) VALUES (%s)', (clean_name,))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 307, "char_end": 343, "chars": "    clean_name = bleach.clean(name)\n"}, {"char_start": 446, "char_end": 452, "chars": "clean_"}]}, "commit_link": "github.com/toriancrane/tournament-results-database/commit/a59992dc5124a8c7292a6f4fbb1c5cf4bc521484", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "playerStandings", "func_src_before": "def playerStandings():\n    \"\"\"Returns a list of the players and their win records, sorted by wins.\n\n    The first entry in the list should be the player in first place, or a player\n    tied for first place if there is currently a tie.\n\n    Returns:\n      A list of tuples, each of which contains (id, name, wins, matches):\n        id: the player's unique id (assigned by the database)\n        name: the player's full name (as registered)\n        wins: the number of matches the player has won\n        matches: the number of matches the player has played\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    sql = (\"SELECT player_id, player_name, COUNT(matches.winner) AS wins, \"\n             \"(SELECT total_matches FROM total_view WHERE total_view.player_id = players.player_id) \"\n             \"FROM players LEFT JOIN matches \"\n             \"ON players.player_id = matches.winner \"\n             \"GROUP BY players.player_id, players.player_name \"\n             \"ORDER BY wins DESC\")\n    c.execute(sql)\n    results = c.fetchall()\n    db.close()\n    return results", "func_src_after": "def playerStandings():\n    \"\"\"Returns a list of the players and their win records, sorted by wins.\n\n    The first entry in the list should be the player in first place, or a player\n    tied for first place if there is currently a tie.\n\n    Returns:\n      A list of tuples, each of which contains (id, name, wins, matches):\n        id: the player's unique id (assigned by the database)\n        name: the player's full name (as registered)\n        wins: the number of matches the player has won\n        matches: the number of matches the player has played\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    sql = (\"SELECT player_id, player_name, COUNT(matches.winner) AS wins, \"\n             \"(SELECT total_matches FROM total_view \"\n             \"WHERE total_view.player_id = players.player_id) \"\n             \"FROM players LEFT JOIN matches \"\n             \"ON players.player_id = matches.winner \"\n             \"GROUP BY players.player_id, players.player_name \"\n             \"ORDER BY wins DESC\")\n    c.execute(sql)\n    results = c.fetchall()\n    db.close()\n    return results", "line_changes": {"deleted": [{"line_no": 17, "char_start": 677, "char_end": 779, "line": "             \"(SELECT total_matches FROM total_view WHERE total_view.player_id = players.player_id) \"\n"}], "added": [{"line_no": 17, "char_start": 677, "char_end": 731, "line": "             \"(SELECT total_matches FROM total_view \"\n"}, {"line_no": 18, "char_start": 731, "char_end": 795, "line": "             \"WHERE total_view.player_id = players.player_id) \"\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 729, "char_end": 745, "chars": "\"\n             \""}]}, "commit_link": "github.com/toriancrane/tournament-results-database/commit/a59992dc5124a8c7292a6f4fbb1c5cf4bc521484", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute('INSERT INTO matches (winner, loser) '\n              'VALUES (%s, %s)', (winner, loser,))\n    db.commit()\n    db.close()", "func_src_after": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    clean_winner = bleach.clean(winner)\n    clean_loser = bleach.clean(loser)\n    db = connect()\n    c = db.cursor()\n    c.execute('INSERT INTO matches (winner, loser) '\n              'VALUES (%s, %s)', (clean_winner, clean_loser,))\n    db.commit()\n    db.close()", "line_changes": {"deleted": [{"line_no": 11, "char_start": 311, "char_end": 362, "line": "              'VALUES (%s, %s)', (winner, loser,))\n"}], "added": [{"line_no": 8, "char_start": 219, "char_end": 259, "line": "    clean_winner = bleach.clean(winner)\n"}, {"line_no": 9, "char_start": 259, "char_end": 297, "line": "    clean_loser = bleach.clean(loser)\n"}, {"line_no": 13, "char_start": 389, "char_end": 452, "line": "              'VALUES (%s, %s)', (clean_winner, clean_loser,))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 219, "char_end": 297, "chars": "    clean_winner = bleach.clean(winner)\n    clean_loser = bleach.clean(loser)\n"}, {"char_start": 423, "char_end": 429, "chars": "clean_"}, {"char_start": 437, "char_end": 443, "chars": "clean_"}]}, "commit_link": "github.com/toriancrane/tournament-results-database/commit/a59992dc5124a8c7292a6f4fbb1c5cf4bc521484", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "insertData", "func_src_before": "    def insertData(self, tableName, timeStamp, tableObj):\n        cols = \"\"\n        vals = \"\"\n        for key in tableObj:\n            cols = cols + \", %s\"\n            vals = vals + \", %s\"\n\n        nameList = []\n        valList = []\n        nameList.append(tableName)\n        for key in tableObj:\n            nameList.append(key)\n            valList.append(tableObj[key])\n\n        nameList = nameList + valList\n\n        cursor = self.connection.cursor()\n        try:\n            cursor.execute(\"INSERT INTO %s (TIMESTAMP\" + cols + \") VALUES (%s,\" + vals + \")\", nameList)\n            print('posted successfully!')\n            self.connection.commit()\n        except psycopg2.Error as e:\n            cursor.close();\n            print(\"Insert Error: %s\".format(e))\n\n            #was this error due to adding a field?\n            if e == missing_column:\n                print(\"Attempting to alter table!\")\n                #column_name = err.toString().split(\"\\\"\")[1];\n                columnName = \"\"\n\n                params = []\n                try:\n                    t = self.__getType(tableObj[columnName]);\n                    params.append(tableName);\n                    params.append(columnkName);\n                    params.append(t);\n                except TypeError as e:\n                    print(\"Got a type error %s\".format(e))\n                    print('Error with field %s'.format(columnName))\n                    print('Table alteration failed')\n                    raise e\n\n                #print(params)\n                try:\n                    cursor = self.connection.cursor()\n                    cursor.execute(\"ALTER TABLE %s ADD COLUMN %s %s\", params)\n                    self.connection.commit()\n                except psycopg2.Error as e:\n                    print(\"Failed to alter table with error e\".format(e))\n\n                print(\"Table alteration succeeded - attempting to insert again\")\n\n                try:\n                    self.insertData(tableName, timeStamp, tableObj)\n                    print('posted successfully!')\n                except:\n                    print(\"Unexpected error when reinserted!\")\n\n            #was this error due to missing the table entirely?\n            elif e == missing_table:\n                try:\n                    self.createTable(tableName, tableObj)\n                    print(\"Created table successfully - reinserting\")\n                except psycopg2.Error as e:\n                    print(\"Failed to create table??: %s\".format(e))\n                    raise\n\n                try:\n                    self.insertData(tableName, timeStamp, tableObj)\n                    print('posted successfully!')\n                except:\n                    print(\"Unexpected error when reinserted!\")\n                    raise", "func_src_after": "    def insertData(self, tableName, timeStamp, tableObj):\n        cols = \"\"\n        vals = \"\"\n        for key in tableObj:\n            cols = cols + \", {}\"\n            vals = vals + \", %s\"\n\n        identifierList = []\n        identifierList.append(sql.Identifier(tableName))\n        for key in tableObj:\n            identifierList.append(sql.Identifier(key))\n\n        valList = []\n        valList.append(timeStamp)\n        for key in tableObj:\n            valList.append(tableObj[key])\n\n\n        cursor = self.connection.cursor()\n        try:\n            cursor.execute(sql.SQL(\"INSERT INTO {} (TIMESTAMP\" + cols + \") VALUES (%s\" + vals + \")\")\n                    .format(*identifierList),valList)\n            print('posted successfully!')\n            self.connection.commit()\n        except psycopg2.Error as e:\n            cursor.close();\n            self.connection.rollback()\n            print(\"Insert Error: {}\".format(e))\n            print(e.pgcode)\n            #was this error due to a missing table?\n            if e.pgcode == '42P01':\n                print('Trying to create table')\n                try:\n                    self.createTable(tableName, tableObj)\n                    print(\"Created table successfully - reinserting\")\n                except psycopg2.Error as e:\n                    print(\"Failed to create table??: {}\".format(e))\n                    raise\n\n                try:\n                    self.insertData(tableName, timeStamp, tableObj)\n                    print('reinserted successfully!')\n                except:\n                    print(\"Unexpected error when reinserted!\")\n                    raise\n\n            #was this error due to missing the table entirely?\n            elif e.pgcode == '42703':\n                columnName = e.pgerror.split('\"')[1]\n                print(\"Attempting to add column {}\".format(columnName))\n\n                identifierList = []\n                typeName = None\n                try:\n                    typeName = self.__getType(tableObj[columnName]);\n                except TypeError as e:\n                    print(\"Got a type error {}\".format(e))\n                    print('Error with field {}'.format(columnName))\n                    print('Table alteration failed')\n                    raise e\n\n                identifierList.append(sql.Identifier(tableName));\n                identifierList.append(sql.Identifier(columnName));\n\n                query = \"ALTER TABLE {} ADD COLUMN {}\" + typeName\n\n                try:\n                    cursor = self.connection.cursor()\n                    cursor.execute(sql.SQL(query).format(*identifierList))\n                    self.connection.commit()\n                    print(\"Table alteration succeeded - attempting to insert again\")\n                except psycopg2.Error as e:\n                    self.connection.rollback()\n                    print(\"Failed to alter table with error {}\".format(e))\n\n\n                try:\n                    self.insertData(tableName, timeStamp, tableObj)\n                    print('reinserted successfully!')\n                except:\n                    print(\"Unexpected error when reinserted!\")", "line_changes": {"deleted": [{"line_no": 5, "char_start": 123, "char_end": 156, "line": "            cols = cols + \", %s\"\n"}, {"line_no": 8, "char_start": 190, "char_end": 212, "line": "        nameList = []\n"}, {"line_no": 10, "char_start": 233, "char_end": 268, "line": "        nameList.append(tableName)\n"}, {"line_no": 12, "char_start": 297, "char_end": 330, "line": "            nameList.append(key)\n"}, {"line_no": 15, "char_start": 373, "char_end": 411, "line": "        nameList = nameList + valList\n"}, {"line_no": 19, "char_start": 467, "char_end": 571, "line": "            cursor.execute(\"INSERT INTO %s (TIMESTAMP\" + cols + \") VALUES (%s,\" + vals + \")\", nameList)\n"}, {"line_no": 24, "char_start": 714, "char_end": 762, "line": "            print(\"Insert Error: %s\".format(e))\n"}, {"line_no": 27, "char_start": 814, "char_end": 850, "line": "            if e == missing_column:\n"}, {"line_no": 28, "char_start": 850, "char_end": 902, "line": "                print(\"Attempting to alter table!\")\n"}, {"line_no": 30, "char_start": 964, "char_end": 996, "line": "                columnName = \"\"\n"}, {"line_no": 32, "char_start": 997, "char_end": 1025, "line": "                params = []\n"}, {"line_no": 34, "char_start": 1046, "char_end": 1108, "line": "                    t = self.__getType(tableObj[columnName]);\n"}, {"line_no": 35, "char_start": 1108, "char_end": 1154, "line": "                    params.append(tableName);\n"}, {"line_no": 36, "char_start": 1154, "char_end": 1202, "line": "                    params.append(columnkName);\n"}, {"line_no": 37, "char_start": 1202, "char_end": 1240, "line": "                    params.append(t);\n"}, {"line_no": 39, "char_start": 1279, "char_end": 1338, "line": "                    print(\"Got a type error %s\".format(e))\n"}, {"line_no": 40, "char_start": 1338, "char_end": 1406, "line": "                    print('Error with field %s'.format(columnName))\n"}, {"line_no": 47, "char_start": 1594, "char_end": 1672, "line": "                    cursor.execute(\"ALTER TABLE %s ADD COLUMN %s %s\", params)\n"}, {"line_no": 50, "char_start": 1761, "char_end": 1835, "line": "                    print(\"Failed to alter table with error e\".format(e))\n"}, {"line_no": 52, "char_start": 1836, "char_end": 1917, "line": "                print(\"Table alteration succeeded - attempting to insert again\")\n"}, {"line_no": 56, "char_start": 2007, "char_end": 2057, "line": "                    print('posted successfully!')\n"}], "added": [{"line_no": 5, "char_start": 123, "char_end": 156, "line": "            cols = cols + \", {}\"\n"}, {"line_no": 8, "char_start": 190, "char_end": 218, "line": "        identifierList = []\n"}, {"line_no": 9, "char_start": 218, "char_end": 275, "line": "        identifierList.append(sql.Identifier(tableName))\n"}, {"line_no": 10, "char_start": 275, "char_end": 304, "line": "        for key in tableObj:\n"}, {"line_no": 11, "char_start": 304, "char_end": 359, "line": "            identifierList.append(sql.Identifier(key))\n"}, {"line_no": 12, "char_start": 359, "char_end": 360, "line": "\n"}, {"line_no": 14, "char_start": 381, "char_end": 415, "line": "        valList.append(timeStamp)\n"}, {"line_no": 21, "char_start": 543, "char_end": 644, "line": "            cursor.execute(sql.SQL(\"INSERT INTO {} (TIMESTAMP\" + cols + \") VALUES (%s\" + vals + \")\")\n"}, {"line_no": 22, "char_start": 644, "char_end": 698, "line": "                    .format(*identifierList),valList)\n"}, {"line_no": 27, "char_start": 841, "char_end": 880, "line": "            self.connection.rollback()\n"}, {"line_no": 28, "char_start": 880, "char_end": 928, "line": "            print(\"Insert Error: {}\".format(e))\n"}, {"line_no": 29, "char_start": 928, "char_end": 956, "line": "            print(e.pgcode)\n"}, {"line_no": 31, "char_start": 1008, "char_end": 1044, "line": "            if e.pgcode == '42P01':\n"}, {"line_no": 32, "char_start": 1044, "char_end": 1092, "line": "                print('Trying to create table')\n"}, {"line_no": 33, "char_start": 1092, "char_end": 1113, "line": "                try:\n"}, {"line_no": 34, "char_start": 1113, "char_end": 1171, "line": "                    self.createTable(tableName, tableObj)\n"}, {"line_no": 35, "char_start": 1171, "char_end": 1241, "line": "                    print(\"Created table successfully - reinserting\")\n"}, {"line_no": 36, "char_start": 1241, "char_end": 1285, "line": "                except psycopg2.Error as e:\n"}, {"line_no": 37, "char_start": 1285, "char_end": 1353, "line": "                    print(\"Failed to create table??: {}\".format(e))\n"}, {"line_no": 38, "char_start": 1353, "char_end": 1379, "line": "                    raise\n"}, {"line_no": 40, "char_start": 1380, "char_end": 1401, "line": "                try:\n"}, {"line_no": 41, "char_start": 1401, "char_end": 1469, "line": "                    self.insertData(tableName, timeStamp, tableObj)\n"}, {"line_no": 42, "char_start": 1469, "char_end": 1523, "line": "                    print('reinserted successfully!')\n"}, {"line_no": 43, "char_start": 1523, "char_end": 1547, "line": "                except:\n"}, {"line_no": 44, "char_start": 1547, "char_end": 1610, "line": "                    print(\"Unexpected error when reinserted!\")\n"}, {"line_no": 45, "char_start": 1610, "char_end": 1636, "line": "                    raise\n"}, {"line_no": 48, "char_start": 1700, "char_end": 1738, "line": "            elif e.pgcode == '42703':\n"}, {"line_no": 49, "char_start": 1738, "char_end": 1791, "line": "                columnName = e.pgerror.split('\"')[1]\n"}, {"line_no": 50, "char_start": 1791, "char_end": 1863, "line": "                print(\"Attempting to add column {}\".format(columnName))\n"}, {"line_no": 51, "char_start": 1863, "char_end": 1864, "line": "\n"}, {"line_no": 52, "char_start": 1864, "char_end": 1900, "line": "                identifierList = []\n"}, {"line_no": 53, "char_start": 1900, "char_end": 1932, "line": "                typeName = None\n"}, {"line_no": 55, "char_start": 1953, "char_end": 2022, "line": "                    typeName = self.__getType(tableObj[columnName]);\n"}, {"line_no": 57, "char_start": 2061, "char_end": 2120, "line": "                    print(\"Got a type error {}\".format(e))\n"}, {"line_no": 58, "char_start": 2120, "char_end": 2188, "line": "                    print('Error with field {}'.format(columnName))\n"}, {"line_no": 62, "char_start": 2270, "char_end": 2336, "line": "                identifierList.append(sql.Identifier(tableName));\n"}, {"line_no": 63, "char_start": 2336, "char_end": 2403, "line": "                identifierList.append(sql.Identifier(columnName));\n"}, {"line_no": 64, "char_start": 2403, "char_end": 2404, "line": "\n"}, {"line_no": 65, "char_start": 2404, "char_end": 2470, "line": "                query = \"ALTER TABLE {} ADD COLUMN {}\" + typeName\n"}, {"line_no": 66, "char_start": 2470, "char_end": 2471, "line": "\n"}, {"line_no": 69, "char_start": 2546, "char_end": 2621, "line": "                    cursor.execute(sql.SQL(query).format(*identifierList))\n"}, {"line_no": 71, "char_start": 2666, "char_end": 2751, "line": "                    print(\"Table alteration succeeded - attempting to insert again\")\n"}, {"line_no": 73, "char_start": 2795, "char_end": 2842, "line": "                    self.connection.rollback()\n"}, {"line_no": 74, "char_start": 2842, "char_end": 2917, "line": "                    print(\"Failed to alter table with error {}\".format(e))\n"}, {"line_no": 79, "char_start": 3008, "char_end": 3062, "line": "                    print('reinserted successfully!')\n"}]}, "char_changes": {"deleted": [{"char_start": 152, "char_end": 154, "chars": "%s"}, {"char_start": 198, "char_end": 202, "chars": "name"}, {"char_start": 220, "char_end": 256, "chars": "valList = []\n        nameList.append"}, {"char_start": 309, "char_end": 313, "chars": "name"}, {"char_start": 325, "char_end": 329, "chars": "key)"}, {"char_start": 373, "char_end": 411, "chars": "        nameList = nameList + valList\n"}, {"char_start": 507, "char_end": 509, "chars": "%s"}, {"char_start": 544, "char_end": 545, "chars": ","}, {"char_start": 559, "char_end": 565, "chars": ", name"}, {"char_start": 747, "char_end": 749, "chars": "%s"}, {"char_start": 799, "char_end": 812, "chars": "dding a field"}, {"char_start": 830, "char_end": 848, "chars": " == missing_column"}, {"char_start": 872, "char_end": 880, "chars": "\"Attempt"}, {"char_start": 888, "char_end": 889, "chars": "l"}, {"char_start": 891, "char_end": 892, "chars": "r"}, {"char_start": 898, "char_end": 900, "chars": "!\""}, {"char_start": 918, "char_end": 1239, "chars": "#column_name = err.toString().split(\"\\\"\")[1];\n                columnName = \"\"\n\n                params = []\n                try:\n                    t = self.__getType(tableObj[columnName]);\n                    params.append(tableName);\n                    params.append(columnkName);\n                    params.append(t);"}, {"char_start": 1262, "char_end": 1277, "chars": " TypeError as e"}, {"char_start": 1306, "char_end": 1487, "chars": "Got a type error %s\".format(e))\n                    print('Error with field %s'.format(columnName))\n                    print('Table alteration failed')\n                    raise e\n"}, {"char_start": 1504, "char_end": 1505, "chars": "#"}, {"char_start": 1511, "char_end": 2784, "chars": "params)\n                try:\n                    cursor = self.connection.cursor()\n                    cursor.execute(\"ALTER TABLE %s ADD COLUMN %s %s\", params)\n                    self.connection.commit()\n                except psycopg2.Error as e:\n                    print(\"Failed to alter table with error e\".format(e))\n\n                print(\"Table alteration succeeded - attempting to insert again\")\n\n                try:\n                    self.insertData(tableName, timeStamp, tableObj)\n                    print('posted successfully!')\n                except:\n                    print(\"Unexpected error when reinserted!\")\n\n            #was this error due to missing the table entirely?\n            elif e == missing_table:\n                try:\n                    self.createTable(tableName, tableObj)\n                    print(\"Created table successfully - reinserting\")\n                except psycopg2.Error as e:\n                    print(\"Failed to create table??: %s\".format(e))\n                    raise\n\n                try:\n                    self.insertData(tableName, timeStamp, tableObj)\n                    print('posted successfully!')\n                except:\n                    print(\"Unexpected error when reinserted!\")\n                    raise"}], "added": [{"char_start": 152, "char_end": 154, "chars": "{}"}, {"char_start": 198, "char_end": 208, "chars": "identifier"}, {"char_start": 226, "char_end": 262, "chars": "identifierList.append(sql.Identifier"}, {"char_start": 273, "char_end": 274, "chars": ")"}, {"char_start": 316, "char_end": 443, "chars": "identifierList.append(sql.Identifier(key))\n\n        valList = []\n        valList.append(timeStamp)\n        for key in tableObj:"}, {"char_start": 570, "char_end": 578, "chars": "sql.SQL("}, {"char_start": 591, "char_end": 593, "chars": "{}"}, {"char_start": 642, "char_end": 692, "chars": ")\n                    .format(*identifierList),val"}, {"char_start": 841, "char_end": 880, "chars": "            self.connection.rollback()\n"}, {"char_start": 913, "char_end": 915, "chars": "{}"}, {"char_start": 928, "char_end": 955, "chars": "            print(e.pgcode)"}, {"char_start": 992, "char_end": 1006, "chars": " missing table"}, {"char_start": 1024, "char_end": 1042, "chars": ".pgcode == '42P01'"}, {"char_start": 1066, "char_end": 1070, "chars": "'Try"}, {"char_start": 1077, "char_end": 1080, "chars": "cre"}, {"char_start": 1089, "char_end": 1090, "chars": "'"}, {"char_start": 1108, "char_end": 1522, "chars": "try:\n                    self.createTable(tableName, tableObj)\n                    print(\"Created table successfully - reinserting\")\n                except psycopg2.Error as e:\n                    print(\"Failed to create table??: {}\".format(e))\n                    raise\n\n                try:\n                    self.insertData(tableName, timeStamp, tableObj)\n                    print('reinserted successfully!')"}, {"char_start": 1574, "char_end": 1790, "chars": "Unexpected error when reinserted!\")\n                    raise\n\n            #was this error due to missing the table entirely?\n            elif e.pgcode == '42703':\n                columnName = e.pgerror.split('\"')[1]"}, {"char_start": 1813, "char_end": 2021, "chars": "\"Attempting to add column {}\".format(columnName))\n\n                identifierList = []\n                typeName = None\n                try:\n                    typeName = self.__getType(tableObj[columnName]);"}, {"char_start": 2045, "char_end": 2049, "chars": "Type"}, {"char_start": 2088, "char_end": 2184, "chars": "Got a type error {}\".format(e))\n                    print('Error with field {}'.format(columnNam"}, {"char_start": 2188, "char_end": 2191, "chars": "   "}, {"char_start": 2207, "char_end": 2208, "chars": " "}, {"char_start": 2214, "char_end": 2215, "chars": "'"}, {"char_start": 2232, "char_end": 2240, "chars": "failed')"}, {"char_start": 2257, "char_end": 2270, "chars": "    raise e\n\n"}, {"char_start": 2286, "char_end": 3148, "chars": "identifierList.append(sql.Identifier(tableName));\n                identifierList.append(sql.Identifier(columnName));\n\n                query = \"ALTER TABLE {} ADD COLUMN {}\" + typeName\n\n                try:\n                    cursor = self.connection.cursor()\n                    cursor.execute(sql.SQL(query).format(*identifierList))\n                    self.connection.commit()\n                    print(\"Table alteration succeeded - attempting to insert again\")\n                except psycopg2.Error as e:\n                    self.connection.rollback()\n                    print(\"Failed to alter table with error {}\".format(e))\n\n\n                try:\n                    self.insertData(tableName, timeStamp, tableObj)\n                    print('reinserted successfully!')\n                except:\n                    print(\"Unexpected error when reinserted!\")"}]}, "commit_link": "github.com/conix-center/smart-cities-demo/commit/a2163f22a698f4df13152b919efb40cb6b593960", "file_name": "data-ingester/timescale_poster/timescale_poster.py", "vul_type": "cwe-089"}
{"func_name": "createTable", "func_src_before": "    def createTable(self, tableName, tableObj):\n        #find the number of columns in the in the tableobj and create\n        #placeholders\n        cols = \"\"\n        for key in tableObj:\n            cols = cols + \", %s %s\"\n\n        #map the type of those objects to the correct postgres type\n        nameList = []\n        nameList.append(tableName)\n        for key in tableObj:\n            try:\n                t = self.__getType(tableObj[key])\n                nameList.append(key)\n                nameList.append(t)\n            except TypeError as e:\n                print('Error with object %s at key %s with value %s'.format(tableObj, key, tableObj[key]))\n                print(\"Caught error %s\".format(e))\n                raise e\n\n        cursor = self.connection.cursor()\n\n        try:\n            cursor.execute(\"CREATE TABLE %s (TIMESTAMP TIMESTAMPTZ NOT NULL\" + cols + \")\", nameList)\n        except psycopg2.Error as e:\n            print(\"CREATE TABLE Error: %s\".format(e))\n\n        self.connection.commit()", "func_src_after": "    def createTable(self, tableName, tableObj):\n        #find the number of columns in the in the tableobj and create\n        #placeholders\n        cols = \"\"\n        for key in tableObj:\n            cols = cols + \", {{}} {}\"\n\n        identifierList = []\n        typeList = []\n        identifierList.append(sql.Identifier(tableName))\n        for key in tableObj:\n            identifierList.append(sql.Identifier(key))\n            try:\n                t = self.__getType(tableObj[key])\n                typeList.append(t)\n            except TypeError as e:\n                print('Error with object {} at key {} with value {}'.format(tableObj, key, tableObj[key]))\n                print(\"Caught error {}\".format(e))\n                raise e\n\n        cursor = self.connection.cursor()\n\n        #This really really really should be safe because I'm only inserting a constrained set of types\n        query = (\"CREATE TABLE {{}} (TIMESTAMP TIMESTAMPTZ NOT NULL\" + cols + \")\").format(*typeList)\n        try:\n            cursor.execute(sql.SQL(query).format(*identifierList))\n        except psycopg2.Error as e:\n            cursor.close()\n            self.connection.rollback()\n            print(\"CREATE TABLE Error: {}\".format(e))\n            raise e\n\n        self.connection.commit()", "line_changes": {"deleted": [{"line_no": 6, "char_start": 187, "char_end": 223, "line": "            cols = cols + \", %s %s\"\n"}, {"line_no": 9, "char_start": 292, "char_end": 314, "line": "        nameList = []\n"}, {"line_no": 10, "char_start": 314, "char_end": 349, "line": "        nameList.append(tableName)\n"}, {"line_no": 14, "char_start": 445, "char_end": 482, "line": "                nameList.append(key)\n"}, {"line_no": 15, "char_start": 482, "char_end": 517, "line": "                nameList.append(t)\n"}, {"line_no": 17, "char_start": 552, "char_end": 659, "line": "                print('Error with object %s at key %s with value %s'.format(tableObj, key, tableObj[key]))\n"}, {"line_no": 18, "char_start": 659, "char_end": 710, "line": "                print(\"Caught error %s\".format(e))\n"}, {"line_no": 24, "char_start": 791, "char_end": 892, "line": "            cursor.execute(\"CREATE TABLE %s (TIMESTAMP TIMESTAMPTZ NOT NULL\" + cols + \")\", nameList)\n"}, {"line_no": 26, "char_start": 928, "char_end": 982, "line": "            print(\"CREATE TABLE Error: %s\".format(e))\n"}], "added": [{"line_no": 6, "char_start": 187, "char_end": 225, "line": "            cols = cols + \", {{}} {}\"\n"}, {"line_no": 8, "char_start": 226, "char_end": 254, "line": "        identifierList = []\n"}, {"line_no": 9, "char_start": 254, "char_end": 276, "line": "        typeList = []\n"}, {"line_no": 10, "char_start": 276, "char_end": 333, "line": "        identifierList.append(sql.Identifier(tableName))\n"}, {"line_no": 12, "char_start": 362, "char_end": 417, "line": "            identifierList.append(sql.Identifier(key))\n"}, {"line_no": 15, "char_start": 484, "char_end": 519, "line": "                typeList.append(t)\n"}, {"line_no": 17, "char_start": 554, "char_end": 661, "line": "                print('Error with object {} at key {} with value {}'.format(tableObj, key, tableObj[key]))\n"}, {"line_no": 18, "char_start": 661, "char_end": 712, "line": "                print(\"Caught error {}\".format(e))\n"}, {"line_no": 24, "char_start": 884, "char_end": 985, "line": "        query = (\"CREATE TABLE {{}} (TIMESTAMP TIMESTAMPTZ NOT NULL\" + cols + \")\").format(*typeList)\n"}, {"line_no": 26, "char_start": 998, "char_end": 1065, "line": "            cursor.execute(sql.SQL(query).format(*identifierList))\n"}, {"line_no": 28, "char_start": 1101, "char_end": 1128, "line": "            cursor.close()\n"}, {"line_no": 29, "char_start": 1128, "char_end": 1167, "line": "            self.connection.rollback()\n"}, {"line_no": 30, "char_start": 1167, "char_end": 1221, "line": "            print(\"CREATE TABLE Error: {}\".format(e))\n"}, {"line_no": 31, "char_start": 1221, "char_end": 1241, "line": "            raise e\n"}]}, "char_changes": {"deleted": [{"char_start": 216, "char_end": 221, "chars": "%s %s"}, {"char_start": 232, "char_end": 291, "chars": "#map the type of those objects to the correct postgres type"}, {"char_start": 300, "char_end": 303, "chars": "nam"}, {"char_start": 322, "char_end": 326, "chars": "name"}, {"char_start": 461, "char_end": 501, "chars": "nameList.append(key)\n                nam"}, {"char_start": 593, "char_end": 595, "chars": "%s"}, {"char_start": 603, "char_end": 605, "chars": "%s"}, {"char_start": 617, "char_end": 619, "chars": "%s"}, {"char_start": 695, "char_end": 697, "chars": "%s"}, {"char_start": 786, "char_end": 817, "chars": "try:\n            cursor.execute"}, {"char_start": 832, "char_end": 834, "chars": "%s"}, {"char_start": 880, "char_end": 886, "chars": ", name"}, {"char_start": 967, "char_end": 969, "chars": "%s"}], "added": [{"char_start": 216, "char_end": 223, "chars": "{{}} {}"}, {"char_start": 234, "char_end": 253, "chars": "identifierList = []"}, {"char_start": 262, "char_end": 265, "chars": "typ"}, {"char_start": 284, "char_end": 294, "chars": "identifier"}, {"char_start": 306, "char_end": 321, "chars": "sql.Identifier("}, {"char_start": 331, "char_end": 332, "chars": ")"}, {"char_start": 362, "char_end": 417, "chars": "            identifierList.append(sql.Identifier(key))\n"}, {"char_start": 500, "char_end": 503, "chars": "typ"}, {"char_start": 595, "char_end": 597, "chars": "{}"}, {"char_start": 605, "char_end": 607, "chars": "{}"}, {"char_start": 619, "char_end": 621, "chars": "{}"}, {"char_start": 697, "char_end": 699, "chars": "{}"}, {"char_start": 788, "char_end": 900, "chars": "#This really really really should be safe because I'm only inserting a constrained set of types\n        query = "}, {"char_start": 915, "char_end": 919, "chars": "{{}}"}, {"char_start": 965, "char_end": 1058, "chars": ").format(*typeList)\n        try:\n            cursor.execute(sql.SQL(query).format(*identifier"}, {"char_start": 1063, "char_end": 1064, "chars": ")"}, {"char_start": 1101, "char_end": 1167, "chars": "            cursor.close()\n            self.connection.rollback()\n"}, {"char_start": 1206, "char_end": 1208, "chars": "{}"}, {"char_start": 1220, "char_end": 1240, "chars": "\n            raise e"}]}, "commit_link": "github.com/conix-center/smart-cities-demo/commit/a2163f22a698f4df13152b919efb40cb6b593960", "file_name": "data-ingester/timescale_poster/timescale_poster.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 162, "char_end": 245, "line": "            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n"}, {"line_no": 7, "char_start": 293, "char_end": 331, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 5, "char_start": 162, "char_end": 230, "line": "            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 7, "char_start": 278, "char_end": 322, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 224, "char_end": 244, "chars": "'{}');\".format(data)"}], "added": [{"char_start": 224, "char_end": 229, "chars": "%s);\""}, {"char_start": 314, "char_end": 320, "chars": ", data"}]}, "commit_link": "github.com/rwolf527/crimemap/commit/50b0695e0b4c46165e6146f6fac4cd6871d9fdf6", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "get", "func_src_before": "\t@tornado.gen.coroutine\n\t@tornado.web.authenticated\n\tdef get(self):\n\t\tif not self.check_rights(CAN_SEE_REPORTS, render=False):\n\t\t\tself.render_json_error('\u0423 \u0432\u0430\u0441 \u043d\u0435\u0442 \u043f\u0440\u0430\u0432 \u043d\u0430 \u044d\u0442\u043e \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0435')\n\t\t\treturn\n\t\tyear = self.get_argument('year', None)\n\t\tif year is None:\n\t\t\tself.render_json_error('\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d \u0433\u043e\u0434')\n\t\t\treturn\n\t\tmonth = self.get_argument('month', None)\n\t\tif month is None:\n\t\t\tself.render_json_error('\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d \u043c\u0435\u0441\u044f\u0446')\n\t\t\treturn\n\t\tcolumns_bin = self.request.arguments.get('columns[]', None)\n\t\tif columns_bin is None:\n\t\t\tself.render_json_error('\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d\u044b \u043a\u043e\u043b\u043e\u043d\u043a\u0438')\n\t\t\treturn\n\t\tcolumns = [col.decode('utf-8') for col in columns_bin]\n\t\ttx = None\n\t\ttry:\n\t\t\ttx = yield pool.begin()\n\t\t\tboilers = yield get_boilers_month_values(tx, year,\n\t\t\t\t\t\t\t\t month, columns)\n\t\t\tself.render_json(boilers)\n\t\t\ttx.commit()\n\t\texcept:\n\t\t\tlogger.exception('Error with getting month parameter')\n\t\t\tif tx:\n\t\t\t\ttx.rollback()\n\t\t\tself.render_json_error('\u041d\u0430 \u0441\u0435\u0440\u0432\u0435\u0440\u0435 \u043f\u0440\u043e\u0438\u0437\u043e\u0448\u043b\u0430 \u043e\u0448\u0438\u0431\u043a\u0430, '\\\n\t\t\t\t\t       '\u043e\u0431\u0440\u0430\u0442\u0438\u0442\u0435\u0441\u044c \u043a \u0430\u0434\u043c\u0438\u043d\u0438\u0441\u0442\u0440\u0430\u0442\u043e\u0440\u0443')\n\t\t\treturn", "func_src_after": "\t@tornado.gen.coroutine\n\t@tornado.web.authenticated\n\tdef get(self):\n\t\tif not self.check_rights(CAN_SEE_REPORTS, render=False):\n\t\t\tself.render_json_error('\u0423 \u0432\u0430\u0441 \u043d\u0435\u0442 \u043f\u0440\u0430\u0432 \u043d\u0430 \u044d\u0442\u043e \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0435')\n\t\t\treturn\n\t\tyear = self.get_argument('year', None)\n\t\tif year is None:\n\t\t\tself.render_json_error('\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d \u0433\u043e\u0434')\n\t\t\treturn\n\t\tmonth = self.get_argument('month', None)\n\t\tif month is None:\n\t\t\tself.render_json_error('\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d \u043c\u0435\u0441\u044f\u0446')\n\t\t\treturn\n\t\tcolumns_bin = self.request.arguments.get('columns[]', None)\n\t\tif columns_bin is None:\n\t\t\tself.render_json_error('\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d\u044b \u043a\u043e\u043b\u043e\u043d\u043a\u0438')\n\t\t\treturn\n\t\tcolumns = []\n\t\tfor col in columns_bin:\n\t\t\t#\n\t\t\t# Need to decode, because it is handler for AJAX\n\t\t\t# that sends binary values.\n\t\t\t#\n\t\t\tcol = col.decode('utf-8')\n\t\t\t#\n\t\t\t# Protect from SQL injection\n\t\t\t#\n\t\t\tif col not in GetMonthParameterHandler.available_columns:\n\t\t\t\tself.render_json_error('\u041d\u0435\u043b\u044c\u0437\u044f \u043f\u043e\u043b\u0443\u0447\u0430\u0442\u044c '\\\n\t\t\t\t\t\t       '\u0441\u0442\u043e\u043b\u0431\u0435\u0446 {}'.format(col))\n\t\t\t\treturn\n\t\t\tcolumns.append(col)\n\t\ttx = None\n\t\ttry:\n\t\t\ttx = yield pool.begin()\n\t\t\tboilers = yield get_boilers_month_values(tx, year,\n\t\t\t\t\t\t\t\t month, columns)\n\t\t\tself.render_json(boilers)\n\t\t\ttx.commit()\n\t\texcept:\n\t\t\tlogger.exception('Error with getting month parameter')\n\t\t\tif tx:\n\t\t\t\ttx.rollback()\n\t\t\tself.render_json_error('\u041d\u0430 \u0441\u0435\u0440\u0432\u0435\u0440\u0435 \u043f\u0440\u043e\u0438\u0437\u043e\u0448\u043b\u0430 \u043e\u0448\u0438\u0431\u043a\u0430, '\\\n\t\t\t\t\t       '\u043e\u0431\u0440\u0430\u0442\u0438\u0442\u0435\u0441\u044c \u043a \u0430\u0434\u043c\u0438\u043d\u0438\u0441\u0442\u0440\u0430\u0442\u043e\u0440\u0443')\n\t\t\treturn", "line_changes": {"deleted": [{"line_no": 19, "char_start": 574, "char_end": 631, "line": "\t\tcolumns = [col.decode('utf-8') for col in columns_bin]\n"}], "added": [{"line_no": 19, "char_start": 574, "char_end": 589, "line": "\t\tcolumns = []\n"}, {"line_no": 20, "char_start": 589, "char_end": 615, "line": "\t\tfor col in columns_bin:\n"}, {"line_no": 25, "char_start": 708, "char_end": 737, "line": "\t\t\tcol = col.decode('utf-8')\n"}, {"line_no": 29, "char_start": 779, "char_end": 840, "line": "\t\t\tif col not in GetMonthParameterHandler.available_columns:\n"}, {"line_no": 30, "char_start": 840, "char_end": 887, "line": "\t\t\t\tself.render_json_error('\u041d\u0435\u043b\u044c\u0437\u044f \u043f\u043e\u043b\u0443\u0447\u0430\u0442\u044c '\\\n"}, {"line_no": 31, "char_start": 887, "char_end": 926, "line": "\t\t\t\t\t\t       '\u0441\u0442\u043e\u043b\u0431\u0435\u0446 {}'.format(col))\n"}, {"line_no": 32, "char_start": 926, "char_end": 937, "line": "\t\t\t\treturn\n"}, {"line_no": 33, "char_start": 937, "char_end": 960, "line": "\t\t\tcolumns.append(col)\n"}]}, "char_changes": {"deleted": [{"char_start": 587, "char_end": 630, "chars": "col.decode('utf-8') for col in columns_bin]"}], "added": [{"char_start": 587, "char_end": 959, "chars": "]\n\t\tfor col in columns_bin:\n\t\t\t#\n\t\t\t# Need to decode, because it is handler for AJAX\n\t\t\t# that sends binary values.\n\t\t\t#\n\t\t\tcol = col.decode('utf-8')\n\t\t\t#\n\t\t\t# Protect from SQL injection\n\t\t\t#\n\t\t\tif col not in GetMonthParameterHandler.available_columns:\n\t\t\t\tself.render_json_error('\u041d\u0435\u043b\u044c\u0437\u044f \u043f\u043e\u043b\u0443\u0447\u0430\u0442\u044c '\\\n\t\t\t\t\t\t       '\u0441\u0442\u043e\u043b\u0431\u0435\u0446 {}'.format(col))\n\t\t\t\treturn\n\t\t\tcolumns.append(col)"}]}, "commit_link": "github.com/Gerold103/volgograd/commit/7318b90893cf610c31d709423ad50b100cd9dde3", "file_name": "www/main.py", "vul_type": "cwe-089"}
{"func_name": "get_user_by_email", "func_src_before": "@tornado.gen.coroutine\ndef get_user_by_email(tx, cols, email):\n\tsql = \"SELECT {} FROM users WHERE email = %s\".format(cols)\n\tparams = (email)\n\tcursor = yield tx.execute(query=sql, params=params)\n\treturn cursor.fetchone()", "func_src_after": "@tornado.gen.coroutine\ndef get_user_by_email(tx, cols, email):\n\tsql = \"SELECT {} FROM users WHERE email = %s\".format(cols)\n\tparams = (email, )\n\tcursor = yield tx.execute(query=sql, params=params)\n\treturn cursor.fetchone()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 123, "char_end": 141, "line": "\tparams = (email)\n"}], "added": [{"line_no": 4, "char_start": 123, "char_end": 143, "line": "\tparams = (email, )\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 139, "char_end": 141, "chars": ", "}]}, "commit_link": "github.com/Gerold103/volgograd/commit/7318b90893cf610c31d709423ad50b100cd9dde3", "file_name": "www/query.py", "vul_type": "cwe-089"}
{"func_name": "edit_page", "func_src_before": "@app.route(\"/<page_name>/edit\")\ndef edit_page(page_name):\n    query = db.query(\"select * from page where title = '%s'\" % page_name).namedresult()\n    if len(query) == 0:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query\n        )\n    else:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query[0]\n        )", "func_src_after": "@app.route(\"/<page_name>/edit\")\ndef edit_page(page_name):\n    query = db.query(\"select * from page where title = $1\", page_name).namedresult()\n    if len(query) == 0:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query\n        )\n    else:\n        return render_template(\n            \"edit.html\",\n            page_name=page_name,\n            query=query[0]\n        )", "line_changes": {"deleted": [{"line_no": 3, "char_start": 58, "char_end": 146, "line": "    query = db.query(\"select * from page where title = '%s'\" % page_name).namedresult()\n"}], "added": [{"line_no": 3, "char_start": 58, "char_end": 143, "line": "    query = db.query(\"select * from page where title = $1\", page_name).namedresult()\n"}]}, "char_changes": {"deleted": [{"char_start": 113, "char_end": 120, "chars": "'%s'\" %"}], "added": [{"char_start": 113, "char_end": 117, "chars": "$1\","}]}, "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089"}
{"func_name": "search_pages", "func_src_before": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = '%s'\" % search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "func_src_after": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = $1\", search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 102, "char_end": 190, "line": "    page = db.query(\"select title from page where title = '%s'\" % search).namedresult()\n"}], "added": [{"line_no": 4, "char_start": 102, "char_end": 187, "line": "    page = db.query(\"select title from page where title = $1\", search).namedresult()\n"}]}, "char_changes": {"deleted": [{"char_start": 160, "char_end": 167, "chars": "'%s'\" %"}], "added": [{"char_start": 160, "char_end": 164, "chars": "$1\","}]}, "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089"}
{"func_name": "save_accepted_transaction", "func_src_before": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\"%(money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\" % (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, %s, now(), 'accepted' )\" % (project_id, user_id, money))\n        self.db.commit()", "func_src_after": "    def save_accepted_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"update users set money = money - %s where id = %s\", (money, user_id))\n        self.cursor.execute(\"update projects set money = money + %s where id = %s\", (money, project_id))\n        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, \"\n                            \"%s, now(), 'accepted' )\", (project_id, user_id, money))\n        self.db.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 69, "char_end": 167, "line": "        self.cursor.execute(\"update users set money = money - %s where id = %s\"%(money, user_id))\n"}, {"line_no": 3, "char_start": 167, "char_end": 273, "line": "        self.cursor.execute(\"update projects set money = money + %s where id = %s\" % (money, project_id))\n"}, {"line_no": 4, "char_start": 273, "char_end": 447, "line": "        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, %s, now(), 'accepted' )\" % (project_id, user_id, money))\n"}], "added": [{"line_no": 2, "char_start": 69, "char_end": 168, "line": "        self.cursor.execute(\"update users set money = money - %s where id = %s\", (money, user_id))\n"}, {"line_no": 3, "char_start": 168, "char_end": 273, "line": "        self.cursor.execute(\"update projects set money = money + %s where id = %s\", (money, project_id))\n"}, {"line_no": 4, "char_start": 273, "char_end": 392, "line": "        self.cursor.execute(\"insert into transactions (project_id, user_id, money, timestamp, state) values (%s, %s, \"\n"}, {"line_no": 5, "char_start": 392, "char_end": 477, "line": "                            \"%s, now(), 'accepted' )\", (project_id, user_id, money))\n"}]}, "char_changes": {"deleted": [{"char_start": 148, "char_end": 149, "chars": "%"}, {"char_start": 249, "char_end": 251, "chars": " %"}, {"char_start": 414, "char_end": 416, "chars": " %"}], "added": [{"char_start": 148, "char_end": 150, "chars": ", "}, {"char_start": 250, "char_end": 251, "chars": ","}, {"char_start": 390, "char_end": 421, "chars": "\"\n                            \""}, {"char_start": 445, "char_end": 446, "chars": ","}]}, "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089"}
{"func_name": "save_failure_transaction", "func_src_before": "    def save_failure_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"insert into transactions (project_id,user_id, money, timestamp, state) values (%s, %s, %s, now(), 'failed' )\" % (project_id, user_id, money))\n        self.db.commit()", "func_src_after": "    def save_failure_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"insert into transactions (project_id,user_id, money, timestamp, state) values (%s, %s, \"\n                            \"%s, now(), 'failed' )\", (project_id, user_id, money))\n        self.db.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 68, "char_end": 239, "line": "        self.cursor.execute(\"insert into transactions (project_id,user_id, money, timestamp, state) values (%s, %s, %s, now(), 'failed' )\" % (project_id, user_id, money))\n"}], "added": [{"line_no": 2, "char_start": 68, "char_end": 186, "line": "        self.cursor.execute(\"insert into transactions (project_id,user_id, money, timestamp, state) values (%s, %s, \"\n"}, {"line_no": 3, "char_start": 186, "char_end": 269, "line": "                            \"%s, now(), 'failed' )\", (project_id, user_id, money))\n"}]}, "char_changes": {"deleted": [{"char_start": 206, "char_end": 208, "chars": " %"}], "added": [{"char_start": 184, "char_end": 215, "chars": "\"\n                            \""}, {"char_start": 237, "char_end": 238, "chars": ","}]}, "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089"}
{"func_name": "check_if_this_project_is_in_database", "func_src_before": "    def check_if_this_project_is_in_database(self, project_id):\n        self.cursor.execute(\"SELECT count(id) FROM projects where id = %s\" % project_id)\n        return self.cursor.fetchall()[0][0] == 1", "func_src_after": "    def check_if_this_project_is_in_database(self, project_id):\n        self.cursor.execute(\"SELECT count(id) FROM projects where id = %s\", (project_id,))\n        return self.cursor.fetchall()[0][0] == 1", "line_changes": {"deleted": [{"line_no": 2, "char_start": 64, "char_end": 153, "line": "        self.cursor.execute(\"SELECT count(id) FROM projects where id = %s\" % project_id)\n"}], "added": [{"line_no": 2, "char_start": 64, "char_end": 155, "line": "        self.cursor.execute(\"SELECT count(id) FROM projects where id = %s\", (project_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 138, "char_end": 141, "chars": " % "}], "added": [{"char_start": 138, "char_end": 141, "chars": ", ("}, {"char_start": 151, "char_end": 153, "chars": ",)"}]}, "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089"}
{"func_name": "can_user_pass_that_amount_of_money", "func_src_before": "    def can_user_pass_that_amount_of_money(self, user_id, money):\n        self.cursor.execute(\"SELECT count(id) FROM kickstarter.users where id = %s and money >= %s\" % (user_id, money))\n        return self.cursor.fetchall()[0][0]", "func_src_after": "    def can_user_pass_that_amount_of_money(self, user_id, money):\n        self.cursor.execute(\"SELECT count(id) FROM kickstarter.users where id = %s and money >= %s\", (user_id, money))\n        return self.cursor.fetchall()[0][0]", "line_changes": {"deleted": [{"line_no": 2, "char_start": 66, "char_end": 186, "line": "        self.cursor.execute(\"SELECT count(id) FROM kickstarter.users where id = %s and money >= %s\" % (user_id, money))\n"}], "added": [{"line_no": 2, "char_start": 66, "char_end": 185, "line": "        self.cursor.execute(\"SELECT count(id) FROM kickstarter.users where id = %s and money >= %s\", (user_id, money))\n"}]}, "char_changes": {"deleted": [{"char_start": 165, "char_end": 167, "chars": " %"}], "added": [{"char_start": 165, "char_end": 166, "chars": ","}]}, "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089"}
{"func_name": "render_page_name", "func_src_before": "@app.route('/<page_name>')\ndef render_page_name(page_name):\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    wiki_page = query.namedresult()\n    has_content = False\n    page_is_taken = False\n    if len(wiki_page) < 1:\n        content = \"\"\n    else:\n        page_is_taken = True\n        content = wiki_page[0].content\n    if len(content) > 0:\n        has_content = True\n    else:\n        pass\n    content = markdown.markdown(wiki_linkify(content))\n    return render_template(\n        'pageholder.html',\n        page_is_taken = page_is_taken,\n        page_name = page_name,\n        markdown = markdown,\n        wiki_linkify = wiki_linkify,\n        has_content = has_content,\n        content = content\n    )", "func_src_after": "@app.route('/<page_name>')\ndef render_page_name(page_name):\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    wiki_page = query.namedresult()\n    has_content = False\n    page_is_taken = False\n    if len(wiki_page) < 1:\n        content = \"\"\n    else:\n        page_is_taken = True\n        content = wiki_page[0].content\n    if len(content) > 0:\n        has_content = True\n    else:\n        pass\n    content = markdown.markdown(wiki_linkify(content))\n    return render_template(\n        'pageholder.html',\n        page_is_taken = page_is_taken,\n        page_name = page_name,\n        markdown = markdown,\n        wiki_linkify = wiki_linkify,\n        has_content = has_content,\n        content = content\n    )", "line_changes": {"deleted": [{"line_no": 3, "char_start": 60, "char_end": 300, "line": "    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n"}], "added": [{"line_no": 3, "char_start": 60, "char_end": 297, "line": "    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n"}]}, "char_changes": {"deleted": [{"char_start": 243, "char_end": 247, "chars": "'%s'"}, {"char_start": 286, "char_end": 288, "chars": " %"}], "added": [{"char_start": 243, "char_end": 245, "chars": "$1"}, {"char_start": 284, "char_end": 285, "chars": ","}]}, "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089"}
{"func_name": "render_page_edit", "func_src_before": "@app.route('/<page_name>/edit')\ndef render_page_edit(page_name):\n    query = db.query(\"select page_content.content from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    wiki_page = query.namedresult()\n    if len(wiki_page) > 0:\n        content = wiki_page[0].content\n    else:\n        content = \"\"\n    return render_template(\n        'edit_page.html',\n        page_name = page_name,\n        content = content\n    )", "func_src_after": "@app.route('/<page_name>/edit')\ndef render_page_edit(page_name):\n    query = db.query(\"select page_content.content from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    wiki_page = query.namedresult()\n    if len(wiki_page) > 0:\n        content = wiki_page[0].content\n    else:\n        content = \"\"\n    return render_template(\n        'edit_page.html',\n        page_name = page_name,\n        content = content\n    )", "line_changes": {"deleted": [{"line_no": 3, "char_start": 65, "char_end": 254, "line": "    query = db.query(\"select page_content.content from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n"}], "added": [{"line_no": 3, "char_start": 65, "char_end": 251, "line": "    query = db.query(\"select page_content.content from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n"}]}, "char_changes": {"deleted": [{"char_start": 197, "char_end": 201, "chars": "'%s'"}, {"char_start": 240, "char_end": 242, "chars": " %"}], "added": [{"char_start": 197, "char_end": 199, "chars": "$1"}, {"char_start": 238, "char_end": 239, "chars": ","}]}, "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089"}
{"func_name": "save_page_edit", "func_src_before": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "func_src_after": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "line_changes": {"deleted": [{"line_no": 6, "char_start": 214, "char_end": 454, "line": "    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n"}], "added": [{"line_no": 6, "char_start": 214, "char_end": 451, "line": "    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n"}]}, "char_changes": {"deleted": [{"char_start": 397, "char_end": 401, "chars": "'%s'"}, {"char_start": 440, "char_end": 442, "chars": " %"}], "added": [{"char_start": 397, "char_end": 399, "chars": "$1"}, {"char_start": 438, "char_end": 439, "chars": ","}]}, "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089"}
{"func_name": "view_page_history", "func_src_before": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = '%s'\" % page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "func_src_after": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = $1\", page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "line_changes": {"deleted": [{"line_no": 3, "char_start": 69, "char_end": 239, "line": "    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = '%s'\" % page_name)\n"}], "added": [{"line_no": 3, "char_start": 69, "char_end": 236, "line": "    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = $1\", page_name)\n"}]}, "char_changes": {"deleted": [{"char_start": 220, "char_end": 227, "chars": "'%s'\" %"}], "added": [{"char_start": 220, "char_end": 224, "chars": "$1\","}]}, "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089"}
{"func_name": "view_page_record", "func_src_before": "@app.route('/<page_name>/history/record')\ndef view_page_record(page_name):\n    content_id = request.args.get('id')\n    query = db.query(\"select page_content.content, page_content.timestamp from page, page_content where page.id = page_content.page_id and page_content.id = '%s'\" % content_id)\n    page_record = query.namedresult()[0]\n\n    return render_template(\n        'page_record.html',\n        page_name = page_name,\n        page_record = page_record\n    )", "func_src_after": "@app.route('/<page_name>/history/record')\ndef view_page_record(page_name):\n    content_id = request.args.get('id')\n    query = db.query(\"select page_content.content, page_content.timestamp from page, page_content where page.id = page_content.page_id and page_content.id = $1\", content_id)\n    page_record = query.namedresult()[0]\n\n    return render_template(\n        'page_record.html',\n        page_name = page_name,\n        page_record = page_record\n    )", "line_changes": {"deleted": [{"line_no": 4, "char_start": 115, "char_end": 292, "line": "    query = db.query(\"select page_content.content, page_content.timestamp from page, page_content where page.id = page_content.page_id and page_content.id = '%s'\" % content_id)\n"}], "added": [{"line_no": 4, "char_start": 115, "char_end": 289, "line": "    query = db.query(\"select page_content.content, page_content.timestamp from page, page_content where page.id = page_content.page_id and page_content.id = $1\", content_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 272, "char_end": 279, "chars": "'%s'\" %"}], "added": [{"char_start": 272, "char_end": 276, "chars": "$1\","}]}, "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089"}
{"func_name": "change_message", "func_src_before": "    def change_message(self, new_message, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET message = '{}'\n            WHERE client_id = '{}'\n        \"\"\".format(new_message, logged_user.get_client_id())\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql)\n        self.__conn.commit()\n        logged_user.set_message(new_message)", "func_src_after": "    def change_message(self, new_message, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET message = ?\n            WHERE client_id = ?\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql, (new_message, logged_user.get_client_id()))\n        self.__conn.commit()\n        logged_user.set_message(new_message)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 108, "char_end": 139, "line": "            SET message = '{}'\n"}, {"line_no": 5, "char_start": 139, "char_end": 174, "line": "            WHERE client_id = '{}'\n"}, {"line_no": 6, "char_start": 174, "char_end": 235, "line": "        \"\"\".format(new_message, logged_user.get_client_id())\n"}, {"line_no": 10, "char_start": 275, "char_end": 310, "line": "        cursor.execute(update_sql)\n"}], "added": [{"line_no": 4, "char_start": 108, "char_end": 136, "line": "            SET message = ?\n"}, {"line_no": 5, "char_start": 136, "char_end": 168, "line": "            WHERE client_id = ?\n"}, {"line_no": 6, "char_start": 168, "char_end": 180, "line": "        \"\"\"\n"}, {"line_no": 10, "char_start": 220, "char_end": 299, "line": "        cursor.execute(update_sql, (new_message, logged_user.get_client_id()))\n"}]}, "char_changes": {"deleted": [{"char_start": 134, "char_end": 138, "chars": "'{}'"}, {"char_start": 169, "char_end": 173, "chars": "'{}'"}, {"char_start": 185, "char_end": 234, "chars": ".format(new_message, logged_user.get_client_id())"}], "added": [{"char_start": 134, "char_end": 135, "chars": "?"}, {"char_start": 166, "char_end": 167, "chars": "?"}, {"char_start": 253, "char_end": 297, "chars": ", (new_message, logged_user.get_client_id())"}]}, "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089"}
{"func_name": "change_pass", "func_src_before": "    def change_pass(self, new_pass, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET password = '{}'\n            WHERE client_id = '{}'\n        \"\"\".format(new_pass, logged_user.get_client_id())\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql)\n        self.__conn.commit()", "func_src_after": "    def change_pass(self, new_pass, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET password = ?\n            WHERE client_id = ?\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql, (new_pass, logged_user.get_client_id()))\n        self.__conn.commit()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 102, "char_end": 134, "line": "            SET password = '{}'\n"}, {"line_no": 5, "char_start": 134, "char_end": 169, "line": "            WHERE client_id = '{}'\n"}, {"line_no": 6, "char_start": 169, "char_end": 227, "line": "        \"\"\".format(new_pass, logged_user.get_client_id())\n"}, {"line_no": 10, "char_start": 267, "char_end": 302, "line": "        cursor.execute(update_sql)\n"}], "added": [{"line_no": 4, "char_start": 102, "char_end": 131, "line": "            SET password = ?\n"}, {"line_no": 5, "char_start": 131, "char_end": 163, "line": "            WHERE client_id = ?\n"}, {"line_no": 6, "char_start": 163, "char_end": 175, "line": "        \"\"\"\n"}, {"line_no": 10, "char_start": 215, "char_end": 291, "line": "        cursor.execute(update_sql, (new_pass, logged_user.get_client_id()))\n"}]}, "char_changes": {"deleted": [{"char_start": 129, "char_end": 133, "chars": "'{}'"}, {"char_start": 164, "char_end": 168, "chars": "'{}'"}, {"char_start": 180, "char_end": 226, "chars": ".format(new_pass, logged_user.get_client_id())"}], "added": [{"char_start": 129, "char_end": 130, "chars": "?"}, {"char_start": 161, "char_end": 162, "chars": "?"}, {"char_start": 248, "char_end": 289, "chars": ", (new_pass, logged_user.get_client_id())"}]}, "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089"}
{"func_name": "login", "func_src_before": "    def login(self, username, password):\n        select_query = \"\"\"\n            SELECT client_id, username, balance, message\n            FROM Clients\n            WHERE username = '{}' AND password = '{}'\n            LIMIT 1\n        \"\"\".format(username, password)\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(select_query)\n        user = cursor.fetchone()\n\n        if(user):\n            return Client(user[0], user[1], user[2], user[3])\n        else:\n            return False", "func_src_after": "    def login(self, username, password):\n        select_query = \"\"\"\n            SELECT client_id, username, balance, message\n            FROM Clients\n            WHERE username = ? AND password = ?\n            LIMIT 1\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(select_query, (username, password))\n        user = cursor.fetchone()\n\n        if(user):\n            return Client(user[0], user[1], user[2], user[3])\n        else:\n            return False", "line_changes": {"deleted": [{"line_no": 5, "char_start": 150, "char_end": 204, "line": "            WHERE username = '{}' AND password = '{}'\n"}, {"line_no": 7, "char_start": 224, "char_end": 263, "line": "        \"\"\".format(username, password)\n"}, {"line_no": 11, "char_start": 303, "char_end": 340, "line": "        cursor.execute(select_query)\n"}], "added": [{"line_no": 5, "char_start": 150, "char_end": 198, "line": "            WHERE username = ? AND password = ?\n"}, {"line_no": 7, "char_start": 218, "char_end": 230, "line": "        \"\"\"\n"}, {"line_no": 11, "char_start": 270, "char_end": 329, "line": "        cursor.execute(select_query, (username, password))\n"}]}, "char_changes": {"deleted": [{"char_start": 179, "char_end": 183, "chars": "'{}'"}, {"char_start": 199, "char_end": 203, "chars": "'{}'"}, {"char_start": 235, "char_end": 262, "chars": ".format(username, password)"}], "added": [{"char_start": 179, "char_end": 180, "chars": "?"}, {"char_start": 196, "char_end": 197, "chars": "?"}, {"char_start": 305, "char_end": 327, "chars": ", (username, password)"}]}, "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089"}
{"func_name": "deleteMatches", "func_src_before": "def deleteMatches():\n    \"\"\"Remove all the match records from the database.\"\"\"\n    conn = connect()\n    c = conn.cursor()\n    c.execute(\"delete from matches\")\n    conn.commit()\n    conn.close()", "func_src_after": "def deleteMatches():\n    \"\"\"Remove all the match records from the database.\"\"\"\n    with connect_db() as c:\n        c.execute(\"delete from matches\")", "line_changes": {"deleted": [{"line_no": 3, "char_start": 79, "char_end": 100, "line": "    conn = connect()\n"}, {"line_no": 4, "char_start": 100, "char_end": 122, "line": "    c = conn.cursor()\n"}, {"line_no": 5, "char_start": 122, "char_end": 159, "line": "    c.execute(\"delete from matches\")\n"}, {"line_no": 6, "char_start": 159, "char_end": 177, "line": "    conn.commit()\n"}, {"line_no": 7, "char_start": 177, "char_end": 193, "line": "    conn.close()\n"}], "added": [{"line_no": 3, "char_start": 79, "char_end": 107, "line": "    with connect_db() as c:\n"}, {"line_no": 4, "char_start": 107, "char_end": 147, "line": "        c.execute(\"delete from matches\")\n"}]}, "char_changes": {"deleted": [{"char_start": 83, "char_end": 89, "chars": "conn ="}, {"char_start": 97, "char_end": 122, "chars": "()\n    c = conn.cursor()\n"}, {"char_start": 158, "char_end": 193, "chars": "\n    conn.commit()\n    conn.close()"}], "added": [{"char_start": 83, "char_end": 87, "chars": "with"}, {"char_start": 95, "char_end": 111, "chars": "_db() as c:\n    "}]}, "commit_link": "github.com/jboludae/FSND_tournament_results/commit/7d5fca15d6eb4df8c5d5009fbebc1475c5abc686", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "deletePlayers", "func_src_before": "def deletePlayers():\n    \"\"\"Remove all the player records from the database.\"\"\"\n    conn = connect()\n    c = conn.cursor()\n    c.execute(\"delete from players\")\n    conn.commit()\n    conn.close()", "func_src_after": "def deletePlayers():\n    \"\"\"Remove all the player records from the database.\"\"\"\n    with connect_db() as c:\n        c.execute(\"delete from players\")", "line_changes": {"deleted": [{"line_no": 3, "char_start": 80, "char_end": 101, "line": "    conn = connect()\n"}, {"line_no": 4, "char_start": 101, "char_end": 123, "line": "    c = conn.cursor()\n"}, {"line_no": 5, "char_start": 123, "char_end": 160, "line": "    c.execute(\"delete from players\")\n"}, {"line_no": 6, "char_start": 160, "char_end": 178, "line": "    conn.commit()\n"}, {"line_no": 7, "char_start": 178, "char_end": 194, "line": "    conn.close()\n"}], "added": [{"line_no": 3, "char_start": 80, "char_end": 108, "line": "    with connect_db() as c:\n"}, {"line_no": 4, "char_start": 108, "char_end": 148, "line": "        c.execute(\"delete from players\")\n"}]}, "char_changes": {"deleted": [{"char_start": 84, "char_end": 90, "chars": "conn ="}, {"char_start": 98, "char_end": 123, "chars": "()\n    c = conn.cursor()\n"}, {"char_start": 159, "char_end": 194, "chars": "\n    conn.commit()\n    conn.close()"}], "added": [{"char_start": 84, "char_end": 88, "chars": "with"}, {"char_start": 96, "char_end": 112, "chars": "_db() as c:\n    "}]}, "commit_link": "github.com/jboludae/FSND_tournament_results/commit/7d5fca15d6eb4df8c5d5009fbebc1475c5abc686", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "countPlayers", "func_src_before": "def countPlayers():\n    \"\"\"Returns the number of players currently registered.\"\"\"\n    conn = connect()\n    c = conn.cursor()\n    c.execute(\"select count(*) from players\")\n    results = c.fetchone()\n    conn.close()\n    return int(results[0])", "func_src_after": "def countPlayers():\n    \"\"\"Returns the number of players currently registered.\"\"\"\n    with connect_db() as c:\n        c.execute(\"select count(*) from players\")\n        results = c.fetchone()\n        return int(results[0])", "line_changes": {"deleted": [{"line_no": 3, "char_start": 82, "char_end": 103, "line": "    conn = connect()\n"}, {"line_no": 4, "char_start": 103, "char_end": 125, "line": "    c = conn.cursor()\n"}, {"line_no": 5, "char_start": 125, "char_end": 171, "line": "    c.execute(\"select count(*) from players\")\n"}, {"line_no": 6, "char_start": 171, "char_end": 198, "line": "    results = c.fetchone()\n"}, {"line_no": 7, "char_start": 198, "char_end": 215, "line": "    conn.close()\n"}, {"line_no": 8, "char_start": 215, "char_end": 241, "line": "    return int(results[0])\n"}], "added": [{"line_no": 3, "char_start": 82, "char_end": 110, "line": "    with connect_db() as c:\n"}, {"line_no": 4, "char_start": 110, "char_end": 160, "line": "        c.execute(\"select count(*) from players\")\n"}, {"line_no": 5, "char_start": 160, "char_end": 191, "line": "        results = c.fetchone()\n"}, {"line_no": 6, "char_start": 191, "char_end": 221, "line": "        return int(results[0])\n"}]}, "char_changes": {"deleted": [{"char_start": 86, "char_end": 92, "chars": "conn ="}, {"char_start": 100, "char_end": 125, "chars": "()\n    c = conn.cursor()\n"}, {"char_start": 202, "char_end": 215, "chars": "conn.close()\n"}], "added": [{"char_start": 86, "char_end": 90, "chars": "with"}, {"char_start": 98, "char_end": 114, "chars": "_db() as c:\n    "}, {"char_start": 160, "char_end": 164, "chars": "    "}]}, "commit_link": "github.com/jboludae/FSND_tournament_results/commit/7d5fca15d6eb4df8c5d5009fbebc1475c5abc686", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "registerPlayer", "func_src_before": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n  \n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n  \n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n    name = bleach.clean(name)\n    conn = connect()\n    c = conn.cursor()\n    # -->(%s ,0 ,0)\",(name,)<-- this syntax is important to ' are inserted safely\n    c.execute(\"insert into players (name_player) values (%s)\",(name,))\n    conn.commit()\n    conn.close()", "func_src_after": "def registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n  \n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n  \n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n    with connect_db() as c:\n        # -->(%s ,0 ,0)\",(name,)<-- this syntax is important to ' are inserted safely\n        c.execute(\"insert into players (name_player) values (%s)\",(name,))", "line_changes": {"deleted": [{"line_no": 10, "char_start": 307, "char_end": 337, "line": "    name = bleach.clean(name)\n"}, {"line_no": 11, "char_start": 337, "char_end": 358, "line": "    conn = connect()\n"}, {"line_no": 12, "char_start": 358, "char_end": 380, "line": "    c = conn.cursor()\n"}, {"line_no": 14, "char_start": 462, "char_end": 533, "line": "    c.execute(\"insert into players (name_player) values (%s)\",(name,))\n"}, {"line_no": 15, "char_start": 533, "char_end": 551, "line": "    conn.commit()\n"}, {"line_no": 16, "char_start": 551, "char_end": 567, "line": "    conn.close()\n"}], "added": [{"line_no": 10, "char_start": 307, "char_end": 335, "line": "    with connect_db() as c:\n"}, {"line_no": 12, "char_start": 421, "char_end": 495, "line": "        c.execute(\"insert into players (name_player) values (%s)\",(name,))\n"}]}, "char_changes": {"deleted": [{"char_start": 311, "char_end": 380, "chars": "name = bleach.clean(name)\n    conn = connect()\n    c = conn.cursor()\n"}, {"char_start": 532, "char_end": 567, "chars": "\n    conn.commit()\n    conn.close()"}], "added": [{"char_start": 311, "char_end": 339, "chars": "with connect_db() as c:\n    "}, {"char_start": 425, "char_end": 426, "chars": " "}, {"char_start": 426, "char_end": 429, "chars": "   "}]}, "commit_link": "github.com/jboludae/FSND_tournament_results/commit/7d5fca15d6eb4df8c5d5009fbebc1475c5abc686", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "playerStandings", "func_src_before": "def playerStandings():\n    \"\"\"Returns a list of the players and their win records, sorted by wins.\n\n    The first entry in the list should be the player in first place, or a player\n    tied for first place if there is currently a tie.\n\n    Returns:\n      A list of tuples, each of which contains (id, name, wins, matches):\n        id: the player's unique id (assigned by the database)\n        name: the player's full name (as registered)\n        wins: the number of matches the player has won\n        matches: the number of matches the player has played\n    \"\"\"\n    conn = connect()\n    c = conn.cursor()\n    c.execute(\"select * from ranking order by count_wins desc\")\n    results = c.fetchall()\n    conn.commit()\n    conn.close()\n    return results", "func_src_after": "def playerStandings():\n    \"\"\"Returns a list of the players and their win records, sorted by wins.\n\n    The first entry in the list should be the player in first place, or a player\n    tied for first place if there is currently a tie.\n\n    Returns:\n      A list of tuples, each of which contains (id, name, wins, matches):\n        id: the player's unique id (assigned by the database)\n        name: the player's full name (as registered)\n        wins: the number of matches the player has won\n        matches: the number of matches the player has played\n    \"\"\"\n    with connect_db() as c:\n        c.execute(\"select * from ranking order by count_wins desc\")\n        results = c.fetchall()\n        return results", "line_changes": {"deleted": [{"line_no": 14, "char_start": 562, "char_end": 583, "line": "    conn = connect()\n"}, {"line_no": 15, "char_start": 583, "char_end": 605, "line": "    c = conn.cursor()\n"}, {"line_no": 16, "char_start": 605, "char_end": 669, "line": "    c.execute(\"select * from ranking order by count_wins desc\")\n"}, {"line_no": 17, "char_start": 669, "char_end": 696, "line": "    results = c.fetchall()\n"}, {"line_no": 18, "char_start": 696, "char_end": 714, "line": "    conn.commit()\n"}, {"line_no": 19, "char_start": 714, "char_end": 731, "line": "    conn.close()\n"}, {"line_no": 20, "char_start": 731, "char_end": 749, "line": "    return results\n"}], "added": [{"line_no": 14, "char_start": 562, "char_end": 590, "line": "    with connect_db() as c:\n"}, {"line_no": 15, "char_start": 590, "char_end": 658, "line": "        c.execute(\"select * from ranking order by count_wins desc\")\n"}, {"line_no": 16, "char_start": 658, "char_end": 689, "line": "        results = c.fetchall()\n"}, {"line_no": 17, "char_start": 689, "char_end": 711, "line": "        return results\n"}]}, "char_changes": {"deleted": [{"char_start": 566, "char_end": 572, "chars": "conn ="}, {"char_start": 580, "char_end": 605, "chars": "()\n    c = conn.cursor()\n"}, {"char_start": 700, "char_end": 731, "chars": "conn.commit()\n    conn.close()\n"}], "added": [{"char_start": 566, "char_end": 570, "chars": "with"}, {"char_start": 578, "char_end": 594, "chars": "_db() as c:\n    "}, {"char_start": 658, "char_end": 662, "chars": "    "}]}, "commit_link": "github.com/jboludae/FSND_tournament_results/commit/7d5fca15d6eb4df8c5d5009fbebc1475c5abc686", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    conn = connect()\n    c = conn.cursor()\n    # Insert match into matches table\n    c.execute(\"insert into matches (winner, loser) values ({0},{1})\".format(winner, loser))\n    conn.commit()\n\n    conn.close()", "func_src_after": "def reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    with connect_db() as c:\n        # Insert match into matches table\n       c.execute(\"insert into matches (winner, loser) values (%s,%s)\",(winner, loser,))", "line_changes": {"deleted": [{"line_no": 8, "char_start": 219, "char_end": 240, "line": "    conn = connect()\n"}, {"line_no": 9, "char_start": 240, "char_end": 262, "line": "    c = conn.cursor()\n"}, {"line_no": 11, "char_start": 300, "char_end": 392, "line": "    c.execute(\"insert into matches (winner, loser) values ({0},{1})\".format(winner, loser))\n"}, {"line_no": 12, "char_start": 392, "char_end": 410, "line": "    conn.commit()\n"}, {"line_no": 13, "char_start": 410, "char_end": 411, "line": "\n"}, {"line_no": 14, "char_start": 411, "char_end": 427, "line": "    conn.close()\n"}], "added": [{"line_no": 8, "char_start": 219, "char_end": 247, "line": "    with connect_db() as c:\n"}, {"line_no": 10, "char_start": 289, "char_end": 376, "line": "       c.execute(\"insert into matches (winner, loser) values (%s,%s)\",(winner, loser,))\n"}]}, "char_changes": {"deleted": [{"char_start": 223, "char_end": 229, "chars": "conn ="}, {"char_start": 237, "char_end": 262, "chars": "()\n    c = conn.cursor()\n"}, {"char_start": 359, "char_end": 426, "chars": "{0},{1})\".format(winner, loser))\n    conn.commit()\n\n    conn.close("}], "added": [{"char_start": 223, "char_end": 227, "chars": "with"}, {"char_start": 235, "char_end": 251, "chars": "_db() as c:\n    "}, {"char_start": 289, "char_end": 292, "chars": "   "}, {"char_start": 351, "char_end": 375, "chars": "%s,%s)\",(winner, loser,)"}]}, "commit_link": "github.com/jboludae/FSND_tournament_results/commit/7d5fca15d6eb4df8c5d5009fbebc1475c5abc686", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "swissPairings", "func_src_before": "def swissPairings():\n    \"\"\"Returns a list of pairs of players for the next round of a match.\n  \n    Assuming that there are an even number of players registered, each player\n    appears exactly once in the pairings.  Each player is paired with another\n    player with an equal or nearly-equal win record, that is, a player adjacent\n    to him or her in the standings.\n  \n    Returns:\n      A list of tuples, each of which contains (id1, name1, id2, name2)\n        id1: the first player's unique id\n        name1: the first player's name\n        id2: the second player's unique id\n        name2: the second player's name\n    \"\"\"\n    conn = connect()\n    c = conn.cursor()\n    c.execute(\"select * from ranking order by count_wins desc\")\n    players_list = c.fetchall()\n    num_games = len(players_list)/2\n    result = []\n\n    for game in range(num_games):\n        first_player_index = game*2\n        second_player_index = first_player_index + 1\n        first_player_tuple = players_list[first_player_index]\n        second_player_tuple = players_list[second_player_index]\n        result.append((first_player_tuple[0], first_player_tuple[1], second_player_tuple[0], second_player_tuple[1]))\n    conn.close()\n    return result", "func_src_after": "def swissPairings():\n    \"\"\"Returns a list of pairs of players for the next round of a match.\n  \n    Assuming that there are an even number of players registered, each player\n    appears exactly once in the pairings.  Each player is paired with another\n    player with an equal or nearly-equal win record, that is, a player adjacent\n    to him or her in the standings.\n  \n    Returns:\n      A list of tuples, each of which contains (id1, name1, id2, name2)\n        id1: the first player's unique id\n        name1: the first player's name\n        id2: the second player's unique id\n        name2: the second player's name\n    \"\"\"\n    with connect_db() as c:\n        c.execute(\"select * from ranking order by count_wins desc\")\n        players_list = c.fetchall()\n        num_games = len(players_list)/2\n        result = []\n\n        for game in range(num_games):\n            first_player_index = game*2\n            second_player_index = first_player_index + 1\n            first_player_tuple = players_list[first_player_index]\n            second_player_tuple = players_list[second_player_index]\n            result.append((first_player_tuple[0], first_player_tuple[1], second_player_tuple[0], second_player_tuple[1]))\n        return result", "line_changes": {"deleted": [{"line_no": 16, "char_start": 629, "char_end": 650, "line": "    conn = connect()\n"}, {"line_no": 17, "char_start": 650, "char_end": 672, "line": "    c = conn.cursor()\n"}, {"line_no": 18, "char_start": 672, "char_end": 736, "line": "    c.execute(\"select * from ranking order by count_wins desc\")\n"}, {"line_no": 19, "char_start": 736, "char_end": 768, "line": "    players_list = c.fetchall()\n"}, {"line_no": 20, "char_start": 768, "char_end": 804, "line": "    num_games = len(players_list)/2\n"}, {"line_no": 21, "char_start": 804, "char_end": 820, "line": "    result = []\n"}, {"line_no": 22, "char_start": 820, "char_end": 821, "line": "\n"}, {"line_no": 23, "char_start": 821, "char_end": 855, "line": "    for game in range(num_games):\n"}, {"line_no": 24, "char_start": 855, "char_end": 891, "line": "        first_player_index = game*2\n"}, {"line_no": 25, "char_start": 891, "char_end": 944, "line": "        second_player_index = first_player_index + 1\n"}, {"line_no": 26, "char_start": 944, "char_end": 1006, "line": "        first_player_tuple = players_list[first_player_index]\n"}, {"line_no": 27, "char_start": 1006, "char_end": 1070, "line": "        second_player_tuple = players_list[second_player_index]\n"}, {"line_no": 28, "char_start": 1070, "char_end": 1188, "line": "        result.append((first_player_tuple[0], first_player_tuple[1], second_player_tuple[0], second_player_tuple[1]))\n"}, {"line_no": 29, "char_start": 1188, "char_end": 1205, "line": "    conn.close()\n"}, {"line_no": 30, "char_start": 1205, "char_end": 1222, "line": "    return result\n"}], "added": [{"line_no": 16, "char_start": 629, "char_end": 657, "line": "    with connect_db() as c:\n"}, {"line_no": 17, "char_start": 657, "char_end": 725, "line": "        c.execute(\"select * from ranking order by count_wins desc\")\n"}, {"line_no": 18, "char_start": 725, "char_end": 761, "line": "        players_list = c.fetchall()\n"}, {"line_no": 19, "char_start": 761, "char_end": 801, "line": "        num_games = len(players_list)/2\n"}, {"line_no": 20, "char_start": 801, "char_end": 821, "line": "        result = []\n"}, {"line_no": 21, "char_start": 821, "char_end": 822, "line": "\n"}, {"line_no": 22, "char_start": 822, "char_end": 860, "line": "        for game in range(num_games):\n"}, {"line_no": 23, "char_start": 860, "char_end": 900, "line": "            first_player_index = game*2\n"}, {"line_no": 24, "char_start": 900, "char_end": 957, "line": "            second_player_index = first_player_index + 1\n"}, {"line_no": 25, "char_start": 957, "char_end": 1023, "line": "            first_player_tuple = players_list[first_player_index]\n"}, {"line_no": 26, "char_start": 1023, "char_end": 1091, "line": "            second_player_tuple = players_list[second_player_index]\n"}, {"line_no": 27, "char_start": 1091, "char_end": 1213, "line": "            result.append((first_player_tuple[0], first_player_tuple[1], second_player_tuple[0], second_player_tuple[1]))\n"}, {"line_no": 28, "char_start": 1213, "char_end": 1234, "line": "        return result\n"}]}, "char_changes": {"deleted": [{"char_start": 633, "char_end": 639, "chars": "conn ="}, {"char_start": 647, "char_end": 672, "chars": "()\n    c = conn.cursor()\n"}, {"char_start": 1192, "char_end": 1205, "chars": "conn.close()\n"}], "added": [{"char_start": 633, "char_end": 637, "chars": "with"}, {"char_start": 645, "char_end": 661, "chars": "_db() as c:\n    "}, {"char_start": 725, "char_end": 729, "chars": "    "}, {"char_start": 765, "char_end": 768, "chars": "   "}, {"char_start": 768, "char_end": 769, "chars": " "}, {"char_start": 801, "char_end": 805, "chars": "    "}, {"char_start": 826, "char_end": 827, "chars": " "}, {"char_start": 827, "char_end": 830, "chars": "   "}, {"char_start": 868, "char_end": 870, "chars": "  "}, {"char_start": 870, "char_end": 872, "chars": "  "}, {"char_start": 900, "char_end": 904, "chars": "    "}, {"char_start": 957, "char_end": 961, "chars": "    "}, {"char_start": 1031, "char_end": 1035, "chars": "    "}, {"char_start": 1091, "char_end": 1095, "chars": "    "}]}, "commit_link": "github.com/jboludae/FSND_tournament_results/commit/7d5fca15d6eb4df8c5d5009fbebc1475c5abc686", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "create_user", "func_src_before": "def create_user(username, password):\n    \n    # check for nd.edu email\n    address = username[-6:-1] + username[len(username) - 1]\n    if address == \"nd.edu\":\n        # check for existence of username already\n\n        conn = sqlite3.connect(db_path)\n        with conn:\n            c = conn.cursor()\n            sql = \"select * from userInfo where username = \" + \"'\" + username + \"'\" \n            c.execute(sql)\n            user = c.fetchone()\n            if user:\n                return False, \"User already exists\"\n            else: # add user to the db\n                pass_hash = pbkdf2_sha256.encrypt(password, rounds=200, salt_size=16)\n                sql = 'insert into userInfo values(\"' + username + '\", \"' + pass_hash + '\")'\n                c.execute(sql)\n                return True, \"User created successfully\"\n\n    else:\n        return False, \"Please register with a valid nd.edu email address\"", "func_src_after": "def create_user(username, password):\n    \n    # check for nd.edu email\n    address = username[-6:-1] + username[len(username) - 1]\n    if address == \"nd.edu\":\n        # check for existence of username already\n\n        conn = sqlite3.connect(db_path)\n        with conn:\n            c = conn.cursor()\n            sql = \"select * from userInfo where username = \" + \"'\" + username + \"'\" \n            c.execute(sql)\n            user = c.fetchone()\n            if user:\n                return False, \"User already exists\"\n            else: # add user to the db\n                pass_hash = pbkdf2_sha256.encrypt(password, rounds=200, salt_size=16)\n                #sql = 'insert into userInfo values(\"' + username + '\", \"' + pass_hash + '\")'\n                data = [username, pass_hash]\n                c.executemany('INSERT INTO userInfo VALUES(?,?)',(data,))\n                #c.execute(sql)\n                return True, \"User created successfully\"\n\n    else:\n        return False, \"Please register with a valid nd.edu email address\"", "line_changes": {"deleted": [{"line_no": 18, "char_start": 641, "char_end": 734, "line": "                sql = 'insert into userInfo values(\"' + username + '\", \"' + pass_hash + '\")'\n"}, {"line_no": 19, "char_start": 734, "char_end": 765, "line": "                c.execute(sql)\n"}], "added": [{"line_no": 19, "char_start": 735, "char_end": 780, "line": "                data = [username, pass_hash]\n"}, {"line_no": 20, "char_start": 780, "char_end": 854, "line": "                c.executemany('INSERT INTO userInfo VALUES(?,?)',(data,))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 657, "char_end": 658, "chars": "#"}, {"char_start": 751, "char_end": 871, "chars": "data = [username, pass_hash]\n                c.executemany('INSERT INTO userInfo VALUES(?,?)',(data,))\n                #"}]}, "commit_link": "github.com/piercecunneen/ND-Class-Info-and-Teacher-Ratings-website/commit/be1f496cdb59df49a367234aa0386cb81cbf534f", "file_name": "password.py", "vul_type": "cwe-089"}
{"func_name": "getQueue", "func_src_before": "    def getQueue(self, numberOfLinks=10):\n        self.cursor.execute(\"SELECT url FROM queue WHERE visited = '0' LIMIT {};\".format(numberOfLinks))\n        result = self.cursor.fetchall()\n        self.remove(result)\n        return result", "func_src_after": "    def getQueue(self, numberOfLinks=10):\n        self.cursor.execute(\"SELECT url FROM queue WHERE visited = '0' LIMIT ?;\", numberOfLinks)\n        result = self.cursor.fetchall()\n        self.remove(result)\n        return result", "line_changes": {"deleted": [{"line_no": 2, "char_start": 42, "char_end": 147, "line": "        self.cursor.execute(\"SELECT url FROM queue WHERE visited = '0' LIMIT {};\".format(numberOfLinks))\n"}], "added": [{"line_no": 2, "char_start": 42, "char_end": 139, "line": "        self.cursor.execute(\"SELECT url FROM queue WHERE visited = '0' LIMIT ?;\", numberOfLinks)\n"}]}, "char_changes": {"deleted": [{"char_start": 119, "char_end": 131, "chars": "{};\".format("}, {"char_start": 145, "char_end": 146, "chars": ")"}], "added": [{"char_start": 119, "char_end": 124, "chars": "?;\", "}]}, "commit_link": "github.com/jappe999/WebScraper/commit/46a4e0843aa44d903293637afad53dfcbc37b480", "file_name": "beta/database.py", "vul_type": "cwe-089"}
{"func_name": "writeToDb", "func_src_before": "    def writeToDb(self, url):\n        try:\n            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES ('{}', '0');\".format(url))\n            self.db.commit()\n        except Exception as e:\n            print(e)", "func_src_after": "    def writeToDb(self, url):\n        try:\n            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES (?, '0');\", url)\n            self.db.commit()\n        except Exception as e:\n            print(e)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 43, "char_end": 143, "line": "            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES ('{}', '0');\".format(url))\n"}], "added": [{"line_no": 3, "char_start": 43, "char_end": 133, "line": "            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES (?, '0');\", url)\n"}]}, "char_changes": {"deleted": [{"char_start": 117, "char_end": 121, "chars": "'{}'"}, {"char_start": 129, "char_end": 137, "chars": ".format("}, {"char_start": 141, "char_end": 142, "chars": ")"}], "added": [{"char_start": 117, "char_end": 118, "chars": "?"}, {"char_start": 126, "char_end": 128, "chars": ", "}]}, "commit_link": "github.com/jappe999/WebScraper/commit/46a4e0843aa44d903293637afad53dfcbc37b480", "file_name": "beta/database.py", "vul_type": "cwe-089"}
{"func_name": "remove", "func_src_before": "    def remove(self, obj):\n        sql = \"UPDATE queue SET visited='1' WHERE url = '{}';\"\n        for line in obj:\n            url = re.sub(\"[\\(\\)\\']\", \"\", line[0])\n            t = Thread(target=self.execute(sql.format(url)))\n            t.daemon = True\n            t.start()", "func_src_after": "    def remove(self, obj):\n        for line in obj:\n            url = line[0]\n            t = Thread(target=self.updateQueue(sql, url))\n            t.daemon = True\n            t.start()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 27, "char_end": 90, "line": "        sql = \"UPDATE queue SET visited='1' WHERE url = '{}';\"\n"}, {"line_no": 4, "char_start": 115, "char_end": 165, "line": "            url = re.sub(\"[\\(\\)\\']\", \"\", line[0])\n"}, {"line_no": 5, "char_start": 165, "char_end": 226, "line": "            t = Thread(target=self.execute(sql.format(url)))\n"}], "added": [{"line_no": 3, "char_start": 52, "char_end": 78, "line": "            url = line[0]\n"}, {"line_no": 4, "char_start": 78, "char_end": 136, "line": "            t = Thread(target=self.updateQueue(sql, url))\n"}]}, "char_changes": {"deleted": [{"char_start": 27, "char_end": 90, "chars": "        sql = \"UPDATE queue SET visited='1' WHERE url = '{}';\"\n"}, {"char_start": 132, "char_end": 155, "chars": " re.sub(\"[\\(\\)\\']\", \"\","}, {"char_start": 163, "char_end": 164, "chars": ")"}, {"char_start": 200, "char_end": 219, "chars": "execute(sql.format("}, {"char_start": 224, "char_end": 225, "chars": ")"}], "added": [{"char_start": 113, "char_end": 130, "chars": "updateQueue(sql, "}]}, "commit_link": "github.com/jappe999/WebScraper/commit/46a4e0843aa44d903293637afad53dfcbc37b480", "file_name": "beta/database.py", "vul_type": "cwe-089"}
{"func_name": "verify_account", "func_src_before": "        def verify_account(self, email, user_password):\n                query = \"SELECT Pass FROM user WHERE Email = '\" + email +\"'\"\n                self.cursor.execute(query)\n                fetch = self.cursor.fetchone()\n                password = \" \".join(map(str, fetch))\n                return check_password_hash(password, user_password)", "func_src_after": "        def verify_account(self, email, user_password):\n                #query = \"SELECT Pass FROM user WHERE Email = '\" + email +\"'\"\n                query = \"SELECT Pass FROM user WHERE Email = %s\"\n                self.cursor.execute(query, (email, ))\n                fetch = self.cursor.fetchone()\n                password = \" \".join(map(str, fetch))\n                return check_password_hash(password, user_password)", "line_changes": {"deleted": [{"line_no": 2, "char_start": 56, "char_end": 133, "line": "                query = \"SELECT Pass FROM user WHERE Email = '\" + email +\"'\"\n"}, {"line_no": 3, "char_start": 133, "char_end": 176, "line": "                self.cursor.execute(query)\n"}], "added": [{"line_no": 3, "char_start": 134, "char_end": 199, "line": "                query = \"SELECT Pass FROM user WHERE Email = %s\"\n"}, {"line_no": 4, "char_start": 199, "char_end": 253, "line": "                self.cursor.execute(query, (email, ))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 72, "char_end": 73, "chars": "#"}, {"char_start": 134, "char_end": 199, "chars": "                query = \"SELECT Pass FROM user WHERE Email = %s\"\n"}, {"char_start": 240, "char_end": 251, "chars": ", (email, )"}]}, "commit_link": "github.com/ZerolinK/NewDepartmentNotifier/commit/3369ddfdb0590292537c3ac375252771c7bb287e", "file_name": "databaseConnectivity/databaseController.py", "vul_type": "cwe-089"}
{"func_name": "set_report", "func_src_before": "        def set_report(self, reportID, userID, summary, description):\n                query = \"INSERT INTO `testdb`.`report` (`Report_ID`, `User_ID`, `Summary`, `Description`, `Votes`, `Is_Resolved`) VALUES ('\" + reportID + \"', '\" + userID + \"', '\" + summary + \"', '\" + description + \"', '0', '0')\"\n                self.cursor.execute(query)\n                self.connection.commit()", "func_src_after": "        def set_report(self, reportID, userID, summary, description):\n                #query = \"INSERT INTO `testdb`.`report` (`Report_ID`, `User_ID`, `Summary`, `Description`, `Votes`, `Is_Resolved`) VALUES ('\" + reportID + \"', '\" + userID + \"', '\" + summary + \"', '\" + description + \"', '0', '0')\"\n                query = \"INSERT INTO `testdb`.`report` (`Report_ID`, `User_ID`, `Summary`, `Description`, `Votes`, `Is_Resolved`) VALUES (%S, %s, %s, %s, '0', '0')\"\n                self.cursor.execute(query, (reportID, userID, summary, description))\n                self.connection.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 70, "char_end": 299, "line": "                query = \"INSERT INTO `testdb`.`report` (`Report_ID`, `User_ID`, `Summary`, `Description`, `Votes`, `Is_Resolved`) VALUES ('\" + reportID + \"', '\" + userID + \"', '\" + summary + \"', '\" + description + \"', '0', '0')\"\n"}, {"line_no": 3, "char_start": 299, "char_end": 342, "line": "                self.cursor.execute(query)\n"}], "added": [{"line_no": 3, "char_start": 300, "char_end": 465, "line": "                query = \"INSERT INTO `testdb`.`report` (`Report_ID`, `User_ID`, `Summary`, `Description`, `Votes`, `Is_Resolved`) VALUES (%S, %s, %s, %s, '0', '0')\"\n"}, {"line_no": 4, "char_start": 465, "char_end": 550, "line": "                self.cursor.execute(query, (reportID, userID, summary, description))\n"}]}, "char_changes": {"deleted": [{"char_start": 315, "char_end": 340, "chars": "self.cursor.execute(query"}], "added": [{"char_start": 86, "char_end": 87, "chars": "#"}, {"char_start": 316, "char_end": 548, "chars": "query = \"INSERT INTO `testdb`.`report` (`Report_ID`, `User_ID`, `Summary`, `Description`, `Votes`, `Is_Resolved`) VALUES (%S, %s, %s, %s, '0', '0')\"\n                self.cursor.execute(query, (reportID, userID, summary, description)"}]}, "commit_link": "github.com/ZerolinK/NewDepartmentNotifier/commit/3369ddfdb0590292537c3ac375252771c7bb287e", "file_name": "databaseConnectivity/databaseController.py", "vul_type": "cwe-089"}
{"func_name": "increment_vote", "func_src_before": "        def increment_vote(self, reportID):\n                query1 = \"SELECT Votes FROM report WHERE Report_ID = '\" + reportID +\"'\"\n                self.cursor.execute(query1)\n                fetch = self.cursor.fetchone()\n                curVote = \" \".join(map(str, fetch))\n                intVote = int(curVote)\n                intVote = intVote + 1\n                query2 = \"UPDATE `testdb`.`report` SET `Votes` = '\" + str(intVote) + \"' WHERE `report`.`Report_ID` = \" + reportID\n                self.cursor.execute(query2)\n                self.connection.commit()", "func_src_after": "        def increment_vote(self, reportID):\n                #query1 = \"SELECT Votes FROM report WHERE Report_ID = '\" + reportID +\"'\"\n                query1 = \"SELECT Votes FROM report WHERE Report_ID = %s\"\n                self.cursor.execute(query1, (reportID, ))\n                fetch = self.cursor.fetchone()\n                curVote = \" \".join(map(str, fetch))\n                intVote = int(curVote)\n                intVote = intVote + 1\n                #query2 = \"UPDATE `testdb`.`report` SET `Votes` = '\" + str(intVote) + \"' WHERE `report`.`Report_ID` = \" + reportID\n                query2 = \"UPDATE `testdb`.`report` SET `Votes` = '\" + str(intVote) + \"' WHERE `report`.`Report_ID` = %s\"\n                self.cursor.execute(query2, (reportID, ))\n                self.connection.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 44, "char_end": 132, "line": "                query1 = \"SELECT Votes FROM report WHERE Report_ID = '\" + reportID +\"'\"\n"}, {"line_no": 3, "char_start": 132, "char_end": 176, "line": "                self.cursor.execute(query1)\n"}, {"line_no": 8, "char_start": 352, "char_end": 482, "line": "                query2 = \"UPDATE `testdb`.`report` SET `Votes` = '\" + str(intVote) + \"' WHERE `report`.`Report_ID` = \" + reportID\n"}, {"line_no": 9, "char_start": 482, "char_end": 526, "line": "                self.cursor.execute(query2)\n"}], "added": [{"line_no": 3, "char_start": 133, "char_end": 206, "line": "                query1 = \"SELECT Votes FROM report WHERE Report_ID = %s\"\n"}, {"line_no": 4, "char_start": 206, "char_end": 264, "line": "                self.cursor.execute(query1, (reportID, ))\n"}, {"line_no": 10, "char_start": 571, "char_end": 692, "line": "                query2 = \"UPDATE `testdb`.`report` SET `Votes` = '\" + str(intVote) + \"' WHERE `report`.`Report_ID` = %s\"\n"}, {"line_no": 11, "char_start": 692, "char_end": 750, "line": "                self.cursor.execute(query2, (reportID, ))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 60, "char_end": 61, "chars": "#"}, {"char_start": 133, "char_end": 206, "chars": "                query1 = \"SELECT Votes FROM report WHERE Report_ID = %s\"\n"}, {"char_start": 248, "char_end": 262, "chars": ", (reportID, )"}, {"char_start": 456, "char_end": 457, "chars": "#"}, {"char_start": 571, "char_end": 692, "chars": "                query2 = \"UPDATE `testdb`.`report` SET `Votes` = '\" + str(intVote) + \"' WHERE `report`.`Report_ID` = %s\"\n"}, {"char_start": 734, "char_end": 748, "chars": ", (reportID, )"}]}, "commit_link": "github.com/ZerolinK/NewDepartmentNotifier/commit/3369ddfdb0590292537c3ac375252771c7bb287e", "file_name": "databaseConnectivity/databaseController.py", "vul_type": "cwe-089"}
{"func_name": "get_vote", "func_src_before": "        def get_vote(self, reportID):\n                query1 = \"SELECT Votes FROM report WHERE Report_ID = '\" + reportID +\"'\"\n                self.cursor.execute(query1)\n                fetch = self.cursor.fetchone()\n                curVote = \" \".join(map(str, fetch))\n                intVote = int(curVote)\n                return intVote", "func_src_after": "        def get_vote(self, reportID):\n                #query1 = \"SELECT Votes FROM report WHERE Report_ID = '\" + reportID +\"'\"\n                query1 = \"SELECT Votes FROM report WHERE Report_ID = %s\"\n                self.cursor.execute(query1, (reportID, ))\n                fetch = self.cursor.fetchone()\n                curVote = \" \".join(map(str, fetch))\n                intVote = int(curVote)\n                return intVote", "line_changes": {"deleted": [{"line_no": 2, "char_start": 38, "char_end": 126, "line": "                query1 = \"SELECT Votes FROM report WHERE Report_ID = '\" + reportID +\"'\"\n"}, {"line_no": 3, "char_start": 126, "char_end": 170, "line": "                self.cursor.execute(query1)\n"}], "added": [{"line_no": 3, "char_start": 127, "char_end": 200, "line": "                query1 = \"SELECT Votes FROM report WHERE Report_ID = %s\"\n"}, {"line_no": 4, "char_start": 200, "char_end": 258, "line": "                self.cursor.execute(query1, (reportID, ))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 54, "char_end": 55, "chars": "#"}, {"char_start": 127, "char_end": 200, "chars": "                query1 = \"SELECT Votes FROM report WHERE Report_ID = %s\"\n"}, {"char_start": 242, "char_end": 256, "chars": ", (reportID, )"}]}, "commit_link": "github.com/ZerolinK/NewDepartmentNotifier/commit/3369ddfdb0590292537c3ac375252771c7bb287e", "file_name": "databaseConnectivity/databaseController.py", "vul_type": "cwe-089"}
{"func_name": "resolve_issue", "func_src_before": "        def resolve_issue(self, reportID):\n                query = \"UPDATE `testdb`.`report` SET `Is_Resolved` = '1' WHERE `report`.`Report_ID` = \" + reportID\n                self.cursor.execute(query)\n                self.connection.commit()", "func_src_after": "        def resolve_issue(self, reportID):\n                #query = \"UPDATE `testdb`.`report` SET `Is_Resolved` = '1' WHERE `report`.`Report_ID` = \" + reportID\n                query = \"UPDATE `testdb`.`report` SET `Is_Resolved` = '1' WHERE `report`.`Report_ID` = %s\"\n                self.cursor.execute(query, (reportID, ))\n                self.connection.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 43, "char_end": 159, "line": "                query = \"UPDATE `testdb`.`report` SET `Is_Resolved` = '1' WHERE `report`.`Report_ID` = \" + reportID\n"}, {"line_no": 3, "char_start": 159, "char_end": 202, "line": "                self.cursor.execute(query)\n"}], "added": [{"line_no": 3, "char_start": 160, "char_end": 267, "line": "                query = \"UPDATE `testdb`.`report` SET `Is_Resolved` = '1' WHERE `report`.`Report_ID` = %s\"\n"}, {"line_no": 4, "char_start": 267, "char_end": 324, "line": "                self.cursor.execute(query, (reportID, ))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 59, "char_end": 60, "chars": "#"}, {"char_start": 160, "char_end": 267, "chars": "                query = \"UPDATE `testdb`.`report` SET `Is_Resolved` = '1' WHERE `report`.`Report_ID` = %s\"\n"}, {"char_start": 308, "char_end": 322, "chars": ", (reportID, )"}]}, "commit_link": "github.com/ZerolinK/NewDepartmentNotifier/commit/3369ddfdb0590292537c3ac375252771c7bb287e", "file_name": "databaseConnectivity/databaseController.py", "vul_type": "cwe-089"}
{"func_name": "get_report", "func_src_before": "        def get_report(self, reportID):\n                query = \"SELECT * FROM report WHERE Report_ID = \" + reportID \n                self.cursor.execute(query)\n                self.connection.commit()\n                fetch = self.cursor.fetchone()\n                report = \" \".join(map(str, fetch))\n                return report", "func_src_after": "        def get_report(self, reportID):\n                #query = \"SELECT * FROM report WHERE Report_ID = \" + reportID \n                query = \"SELECT * FROM report WHERE Report_ID = %s\"\n                self.cursor.execute(query, (reportID, ))\n                self.connection.commit()\n                fetch = self.cursor.fetchone()\n                report = \" \".join(map(str, fetch))\n                return report", "line_changes": {"deleted": [{"line_no": 2, "char_start": 40, "char_end": 118, "line": "                query = \"SELECT * FROM report WHERE Report_ID = \" + reportID \n"}, {"line_no": 3, "char_start": 118, "char_end": 161, "line": "                self.cursor.execute(query)\n"}], "added": [{"line_no": 3, "char_start": 119, "char_end": 187, "line": "                query = \"SELECT * FROM report WHERE Report_ID = %s\"\n"}, {"line_no": 4, "char_start": 187, "char_end": 244, "line": "                self.cursor.execute(query, (reportID, ))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 56, "char_end": 57, "chars": "#"}, {"char_start": 119, "char_end": 187, "chars": "                query = \"SELECT * FROM report WHERE Report_ID = %s\"\n"}, {"char_start": 228, "char_end": 242, "chars": ", (reportID, )"}]}, "commit_link": "github.com/ZerolinK/NewDepartmentNotifier/commit/3369ddfdb0590292537c3ac375252771c7bb287e", "file_name": "databaseConnectivity/databaseController.py", "vul_type": "cwe-089"}
{"func_name": "create_basic_user", "func_src_before": "        def create_basic_user(self, userID, fName, lName, email, password):\n                password2 = generate_password_hash(password)\n                query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES ('\" + userID + \"', '\" + fName + \"', '\" + lName + \"', '\" + email +\"', '\" + password2 + \"', '0')\"\n                self.cursor.execute(query)\n                self.connection.commit()", "func_src_after": "        def create_basic_user(self, userID, fName, lName, email, password):\n                password2 = generate_password_hash(password)\n                #query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES ('\" + userID + \"', '\" + fName + \"', '\" + lName + \"', '\" + email +\"', '\" + password2 + \"', '0')\"\n                query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES (%s, %s, %s, %s, %s, '0')\"\n                self.cursor.execute(query, (userID, fName, lName, email, password2))\n                self.connection.commit()", "line_changes": {"deleted": [{"line_no": 3, "char_start": 137, "char_end": 343, "line": "                query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES ('\" + userID + \"', '\" + fName + \"', '\" + lName + \"', '\" + email +\"', '\" + password2 + \"', '0')\"\n"}, {"line_no": 4, "char_start": 343, "char_end": 386, "line": "                self.cursor.execute(query)\n"}], "added": [{"line_no": 4, "char_start": 344, "char_end": 481, "line": "                query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES (%s, %s, %s, %s, %s, '0')\"\n"}, {"line_no": 5, "char_start": 481, "char_end": 566, "line": "                self.cursor.execute(query, (userID, fName, lName, email, password2))\n"}]}, "char_changes": {"deleted": [{"char_start": 359, "char_end": 384, "chars": "self.cursor.execute(query"}], "added": [{"char_start": 153, "char_end": 154, "chars": "#"}, {"char_start": 360, "char_end": 564, "chars": "query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES (%s, %s, %s, %s, %s, '0')\"\n                self.cursor.execute(query, (userID, fName, lName, email, password2)"}]}, "commit_link": "github.com/ZerolinK/NewDepartmentNotifier/commit/3369ddfdb0590292537c3ac375252771c7bb287e", "file_name": "databaseConnectivity/databaseController.py", "vul_type": "cwe-089"}
{"func_name": "create_faculty_user", "func_src_before": "        def create_faculty_user(self, userID, fName, lName, email, password):\n                password2 = generate_password_hash(password)\n                query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES ('\" + userID + \"', '\" + fName + \"', '\" + lName + \"', '\" + email +\"', '\" + password2 + \"', '1')\"\n                self.cursor.execute(query)\n                self.connection.commit()", "func_src_after": "        def create_faculty_user(self, userID, fName, lName, email, password):\n                password2 = generate_password_hash(password)\n                #query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES ('\" + userID + \"', '\" + fName + \"', '\" + lName + \"', '\" + email +\"', '\" + password2 + \"', '1')\"\n                query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES (%s, %s, %s, %s, %S, '1')\"\n                self.cursor.execute(query, (userID, fName, lName, email, password2))\n                self.connection.commit()", "line_changes": {"deleted": [{"line_no": 3, "char_start": 139, "char_end": 345, "line": "                query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES ('\" + userID + \"', '\" + fName + \"', '\" + lName + \"', '\" + email +\"', '\" + password2 + \"', '1')\"\n"}, {"line_no": 4, "char_start": 345, "char_end": 388, "line": "                self.cursor.execute(query)\n"}], "added": [{"line_no": 4, "char_start": 346, "char_end": 483, "line": "                query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES (%s, %s, %s, %s, %S, '1')\"\n"}, {"line_no": 5, "char_start": 483, "char_end": 568, "line": "                self.cursor.execute(query, (userID, fName, lName, email, password2))\n"}]}, "char_changes": {"deleted": [{"char_start": 361, "char_end": 386, "chars": "self.cursor.execute(query"}], "added": [{"char_start": 155, "char_end": 156, "chars": "#"}, {"char_start": 362, "char_end": 566, "chars": "query = \"INSERT INTO `testdb`.`user` (`ID`, `FName`, `LName`, `Email`, `Pass`, `Role`) VALUES (%s, %s, %s, %s, %S, '1')\"\n                self.cursor.execute(query, (userID, fName, lName, email, password2)"}]}, "commit_link": "github.com/ZerolinK/NewDepartmentNotifier/commit/3369ddfdb0590292537c3ac375252771c7bb287e", "file_name": "databaseConnectivity/databaseController.py", "vul_type": "cwe-089"}
{"func_name": "launch", "func_src_before": "def launch():\n    server_settings = {\"static_path\": os.path.join(os.path.dirname(__file__), \"./static\"), \n    \"template_path\": \"./server/templates\", \n    \"login_url\": \"/login\", \n    \"cookie_secret\": os.urandom(24), \n    \"xsrf_cookies\": True}\n\n    handlers = [ (r'/', IndexController),\n        (r'/report', ReportController),\n        (r'/create', ReportController.NewReportController), \n        (r'/login', LoginController), \n        (r'/logout', LoginController.LogoutController) ]\n    \n    application = tornado.web.Application(handlers, **server_settings)\n    http_server = tornado.httpserver.HTTPServer(application)\n    http_server.listen(options.port)\n    tornado.ioloop.IOLoop.instance().start()", "func_src_after": "def launch():\n    server_settings = {\"static_path\": os.path.join(os.path.dirname(__file__), \"./static\"), \n    \"template_path\": \"./server/templates\", \n    \"login_url\": \"/login\", \n    \"cookie_secret\": os.urandom(24)}\n\n    handlers = [ (r'/', IndexController),\n        (r'/report', ReportController),\n        (r'/create', ReportController.NewReportController), \n        (r'/login', LoginController), \n        (r'/logout', LoginController.LogoutController) ]\n\n    global databaseControl\n    databaseControl = databaseController.DatabaseController('localhost', 3306, 'testuser', 'test623', 'testdb')\n\n    #databaseControl.create_basic_user(\"6003091\", \"David\", \"Vizcaino\", \"dvizc001@fiu.edu\", \"dpnet\")\n\n    application = tornado.web.Application(handlers, **server_settings)\n    http_server = tornado.httpserver.HTTPServer(application)\n    http_server.listen(options.port)\n    tornado.ioloop.IOLoop.instance().start()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 178, "char_end": 216, "line": "    \"cookie_secret\": os.urandom(24), \n"}, {"line_no": 6, "char_start": 216, "char_end": 242, "line": "    \"xsrf_cookies\": True}\n"}, {"line_no": 13, "char_start": 482, "char_end": 487, "line": "    \n"}], "added": [{"line_no": 5, "char_start": 178, "char_end": 215, "line": "    \"cookie_secret\": os.urandom(24)}\n"}, {"line_no": 12, "char_start": 455, "char_end": 456, "line": "\n"}, {"line_no": 13, "char_start": 456, "char_end": 483, "line": "    global databaseControl\n"}, {"line_no": 14, "char_start": 483, "char_end": 595, "line": "    databaseControl = databaseController.DatabaseController('localhost', 3306, 'testuser', 'test623', 'testdb')\n"}, {"line_no": 15, "char_start": 595, "char_end": 596, "line": "\n"}, {"line_no": 17, "char_start": 696, "char_end": 697, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 213, "char_end": 240, "chars": ", \n    \"xsrf_cookies\": True"}], "added": [{"char_start": 455, "char_end": 456, "chars": "\n"}, {"char_start": 460, "char_end": 696, "chars": "global databaseControl\n    databaseControl = databaseController.DatabaseController('localhost', 3306, 'testuser', 'test623', 'testdb')\n\n    #databaseControl.create_basic_user(\"6003091\", \"David\", \"Vizcaino\", \"dvizc001@fiu.edu\", \"dpnet\")\n"}]}, "commit_link": "github.com/ZerolinK/NewDepartmentNotifier/commit/3369ddfdb0590292537c3ac375252771c7bb287e", "file_name": "server/mainController.py", "vul_type": "cwe-089"}
{"func_name": "get_user", "func_src_before": "    def get_user(self):\n        if not hasattr(self, '_user'):\n            qs = \"select * from account_access where access_token = '%s'\" % self.access_token\n            result = self.db.get(qs)\n            if result:\n                self._user = result\n            else:\n                self._user = None\n        \n        return self._user", "func_src_after": "    def get_user(self):\n        if not hasattr(self, '_user'):\n            qs = \"select * from account_access where access_token = %s\"\n            result = self.db.get(qs, self.access_token)\n            if result:\n                self._user = result\n            else:\n                self._user = None\n        \n        return self._user", "line_changes": {"deleted": [{"line_no": 3, "char_start": 63, "char_end": 157, "line": "            qs = \"select * from account_access where access_token = '%s'\" % self.access_token\n"}, {"line_no": 4, "char_start": 157, "char_end": 194, "line": "            result = self.db.get(qs)\n"}], "added": [{"line_no": 3, "char_start": 63, "char_end": 135, "line": "            qs = \"select * from account_access where access_token = %s\"\n"}, {"line_no": 4, "char_start": 135, "char_end": 191, "line": "            result = self.db.get(qs, self.access_token)\n"}]}, "char_changes": {"deleted": [{"char_start": 131, "char_end": 132, "chars": "'"}, {"char_start": 134, "char_end": 156, "chars": "'\" % self.access_token"}], "added": [{"char_start": 133, "char_end": 134, "chars": "\""}, {"char_start": 170, "char_end": 189, "chars": ", self.access_token"}]}, "commit_link": "github.com/bonbondirac/tsunami/commit/396cc394bd6daaf0ee9c16b1b55a4082eeaac208", "file_name": "src/auth.py", "vul_type": "cwe-089"}
{"func_name": "_addColumn", "func_src_before": "\tdef _addColumn(self, column, init_data):\n\t\t\"\"\"\n\t\tAdds a column to the table, if it doesn't exist\n\t\t:param column: name of the new column\n\t\t:param init_data: data to be put in that column. Used to determine the type\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"ALTER TABLE \" + TABLE_NAME + \" ADD COLUMN \" + str(column) + \" \" + getSQLiteType(init_data)\n\t\ttry:\n\t\t\tself._run_command(command)\n\t\texcept sqlite3.OperationalError:\n\t\t\tprint(\"Column \" + str(column) + \" already exists!\")", "func_src_after": "\tdef _addColumn(self, column, init_data):\n\t\t\"\"\"\n\t\tAdds a column to the table, if it doesn't exist\n\t\t:param column: name of the new column\n\t\t:param init_data: data to be put in that column. Used to determine the type\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"ALTER TABLE {0} ADD COLUMN {1} {2};\".format(TABLE_NAME, str(column), getSQLiteType(init_data))\n\t\ttry:\n\t\t\tself._run_command(command)\n\t\texcept sqlite3.OperationalError:\n\t\t\tpass\n\t\t\tprint(\"Column \" + str(column) + \" already exists!\")", "line_changes": {"deleted": [{"line_no": 8, "char_start": 233, "char_end": 337, "line": "\t\tcommand = \"ALTER TABLE \" + TABLE_NAME + \" ADD COLUMN \" + str(column) + \" \" + getSQLiteType(init_data)\n"}], "added": [{"line_no": 8, "char_start": 233, "char_end": 341, "line": "\t\tcommand = \"ALTER TABLE {0} ADD COLUMN {1} {2};\".format(TABLE_NAME, str(column), getSQLiteType(init_data))\n"}, {"line_no": 12, "char_start": 413, "char_end": 421, "line": "\t\t\tpass\n"}]}, "char_changes": {"deleted": [{"char_start": 258, "char_end": 291, "chars": "\" + TABLE_NAME + \" ADD COLUMN \" +"}, {"char_start": 303, "char_end": 311, "chars": " + \" \" +"}], "added": [{"char_start": 258, "char_end": 301, "chars": "{0} ADD COLUMN {1} {2};\".format(TABLE_NAME,"}, {"char_start": 313, "char_end": 314, "chars": ","}, {"char_start": 339, "char_end": 340, "chars": ")"}, {"char_start": 413, "char_end": 421, "chars": "\t\t\tpass\n"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "getIDbyPath", "func_src_before": "\tdef getIDbyPath(self, pth):\n\t\t\"\"\"\n\t\tReturns the DB ID by a path field\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\n\t\tcommand = \"SELECT ID FROM {0} WHERE path='{1}';\".format(TABLE_NAME,pth)\n\t\tdata = self._run_command(command)\n\n\t\ttry:\n\t\t\tresult = data[0][0]\n\t\texcept IndexError:\n\t\t\tresult = None\n\n\t\treturn result", "func_src_after": "\tdef getIDbyPath(self, pth):\n\t\t\"\"\"\n\t\tReturns the DB ID by a path field\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\n\t\tcommand = \"SELECT ID FROM {0} WHERE path=?;\".format(TABLE_NAME)\n\t\tparams = (pth,)\n\t\tdata = self._run_command(command, params)\n\n\t\ttry:\n\t\t\tresult = data[0][0]\n\t\texcept IndexError:\n\t\t\tresult = None\n\n\t\treturn result", "line_changes": {"deleted": [{"line_no": 8, "char_start": 103, "char_end": 177, "line": "\t\tcommand = \"SELECT ID FROM {0} WHERE path='{1}';\".format(TABLE_NAME,pth)\n"}, {"line_no": 9, "char_start": 177, "char_end": 213, "line": "\t\tdata = self._run_command(command)\n"}], "added": [{"line_no": 8, "char_start": 103, "char_end": 169, "line": "\t\tcommand = \"SELECT ID FROM {0} WHERE path=?;\".format(TABLE_NAME)\n"}, {"line_no": 9, "char_start": 169, "char_end": 187, "line": "\t\tparams = (pth,)\n"}, {"line_no": 10, "char_start": 187, "char_end": 231, "line": "\t\tdata = self._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 146, "char_end": 151, "chars": "'{1}'"}, {"char_start": 171, "char_end": 172, "chars": ","}], "added": [{"char_start": 146, "char_end": 147, "chars": "?"}, {"char_start": 167, "char_end": 181, "chars": ")\n\t\tparams = ("}, {"char_start": 184, "char_end": 185, "chars": ","}, {"char_start": 221, "char_end": 229, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "addFile", "func_src_before": "\tdef addFile(self, pth, mod_time=None):\n\t\t\"\"\"\n\t\tAdds a file with a given path. Doesn't, if the file with given path already exists in DB.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tif not self.fileExists(pth):\n\t\t\tif not mod_time:\n\t\t\t\tmod_time = utils.FileUtils.getModificationTimeUnix(pth)\n\n\t\t\tcommand = \"INSERT INTO {0} (type, path, mod_time) VALUES (0, '{1}', {2});\".format(TABLE_NAME, pth, mod_time)\n\n\t\t\tself._run_command(command)\n\t\telse:\n\t\t\tprint(\"addFile: File already exists!\")#debug", "func_src_after": "\tdef addFile(self, pth, mod_time=None):\n\t\t\"\"\"\n\t\tAdds a file with a given path. Doesn't, if the file with given path already exists in DB.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tif not self.fileExists(pth):\n\t\t\tif not mod_time:\n\t\t\t\tmod_time = utils.FileUtils.getModificationTimeUnix(pth)\n\n\t\t\tcommand = \"INSERT INTO {0} (type, path, mod_time) VALUES (0, ?, ?);\".format(TABLE_NAME)\n\t\t\tparams = (pth, mod_time,)\n\n\t\t\tself._run_command(command, params)\n\t\telse:\n\t\t\tprint(\"addFile: File already exists!\")#debug", "line_changes": {"deleted": [{"line_no": 11, "char_start": 281, "char_end": 393, "line": "\t\t\tcommand = \"INSERT INTO {0} (type, path, mod_time) VALUES (0, '{1}', {2});\".format(TABLE_NAME, pth, mod_time)\n"}, {"line_no": 13, "char_start": 394, "char_end": 424, "line": "\t\t\tself._run_command(command)\n"}], "added": [{"line_no": 11, "char_start": 281, "char_end": 372, "line": "\t\t\tcommand = \"INSERT INTO {0} (type, path, mod_time) VALUES (0, ?, ?);\".format(TABLE_NAME)\n"}, {"line_no": 12, "char_start": 372, "char_end": 401, "line": "\t\t\tparams = (pth, mod_time,)\n"}, {"line_no": 14, "char_start": 402, "char_end": 440, "line": "\t\t\tself._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 345, "char_end": 355, "chars": "'{1}', {2}"}, {"char_start": 376, "char_end": 378, "chars": ", "}], "added": [{"char_start": 345, "char_end": 349, "chars": "?, ?"}, {"char_start": 370, "char_end": 385, "chars": ")\n\t\t\tparams = ("}, {"char_start": 398, "char_end": 399, "chars": ","}, {"char_start": 430, "char_end": 438, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "getModTime", "func_src_before": "\tdef getModTime(self, pth):\n\t\t\"\"\"\n\t\tGets the modification time of a file in DB\n\t\t:param pth:\n\t\t:return: integer or None\n\t\t\"\"\"\n\t\tif self.fileExists(pth):\n\t\t\tcommand = \"SELECT mod_time FROM {0} WHERE path='{1}';\".format(TABLE_NAME, pth)\n\t\t\tresult = self._run_command(command)\n\t\t\ttry:\n\t\t\t\tresult = result[0][0]\n\t\t\texcept IndexError:\n\t\t\t\tresult = None\n\t\telse:\n\t\t\tprint(\"getModTime: File doesn't exist\")\n\t\t\tresult = None\n\n\t\treturn result", "func_src_after": "\tdef getModTime(self, pth):\n\t\t\"\"\"\n\t\tGets the modification time of a file in DB\n\t\t:param pth:\n\t\t:return: integer or None\n\t\t\"\"\"\n\t\tif self.fileExists(pth):\n\t\t\tcommand = \"SELECT mod_time FROM {0} WHERE path=?;\".format(TABLE_NAME)\n\t\t\tparams = (pth,)\n\t\t\tresult = self._run_command(command, params)\n\t\t\ttry:\n\t\t\t\tresult = result[0][0]\n\t\t\texcept IndexError:\n\t\t\t\tresult = None\n\t\telse:\n\t\t\tprint(\"getModTime: File doesn't exist\")\n\t\t\tresult = None\n\n\t\treturn result", "line_changes": {"deleted": [{"line_no": 8, "char_start": 153, "char_end": 235, "line": "\t\t\tcommand = \"SELECT mod_time FROM {0} WHERE path='{1}';\".format(TABLE_NAME, pth)\n"}, {"line_no": 9, "char_start": 235, "char_end": 274, "line": "\t\t\tresult = self._run_command(command)\n"}], "added": [{"line_no": 8, "char_start": 153, "char_end": 226, "line": "\t\t\tcommand = \"SELECT mod_time FROM {0} WHERE path=?;\".format(TABLE_NAME)\n"}, {"line_no": 9, "char_start": 226, "char_end": 245, "line": "\t\t\tparams = (pth,)\n"}, {"line_no": 10, "char_start": 245, "char_end": 292, "line": "\t\t\tresult = self._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 203, "char_end": 208, "chars": "'{1}'"}, {"char_start": 228, "char_end": 230, "chars": ", "}], "added": [{"char_start": 203, "char_end": 204, "chars": "?"}, {"char_start": 224, "char_end": 239, "chars": ")\n\t\t\tparams = ("}, {"char_start": 242, "char_end": 243, "chars": ","}, {"char_start": 282, "char_end": 290, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "updateModTime", "func_src_before": "\tdef updateModTime(self, pth, mod_time):\n\t\t\"\"\"\n\t\tUpdates the modification time of a file in the DB\n\t\t:param pth: file in DB to assign this to\n\t\t:param mod_time: new modification time to assign\n\t\t:return:\n\t\t\"\"\"\n\t\tif self.fileExists(pth):\n\t\t\tcommand = \"UPDATE {0} SET mod_time={1} WHERE path='{2}';\".format(TABLE_NAME, mod_time, pth)\n\t\t\tself._run_command(command)\n\t\telse:\n\t\t\tprint(\"updateModTime: file doesn't exist!\")", "func_src_after": "\tdef updateModTime(self, pth, mod_time):\n\t\t\"\"\"\n\t\tUpdates the modification time of a file in the DB\n\t\t:param pth: file in DB to assign this to\n\t\t:param mod_time: new modification time to assign\n\t\t:return:\n\t\t\"\"\"\n\t\tif self.fileExists(pth):\n\t\t\tcommand = \"UPDATE {0} SET mod_time=? WHERE path=?;\".format(TABLE_NAME)\n\t\t\tparams = (mod_time, pth,)\n\t\t\tself._run_command(command, params)\n\t\telse:\n\t\t\tprint(\"updateModTime: file doesn't exist!\")", "line_changes": {"deleted": [{"line_no": 9, "char_start": 237, "char_end": 332, "line": "\t\t\tcommand = \"UPDATE {0} SET mod_time={1} WHERE path='{2}';\".format(TABLE_NAME, mod_time, pth)\n"}, {"line_no": 10, "char_start": 332, "char_end": 362, "line": "\t\t\tself._run_command(command)\n"}], "added": [{"line_no": 9, "char_start": 237, "char_end": 311, "line": "\t\t\tcommand = \"UPDATE {0} SET mod_time=? WHERE path=?;\".format(TABLE_NAME)\n"}, {"line_no": 10, "char_start": 311, "char_end": 340, "line": "\t\t\tparams = (mod_time, pth,)\n"}, {"line_no": 11, "char_start": 340, "char_end": 378, "line": "\t\t\tself._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 275, "char_end": 278, "chars": "{1}"}, {"char_start": 290, "char_end": 295, "chars": "'{2}'"}, {"char_start": 315, "char_end": 317, "chars": ", "}], "added": [{"char_start": 275, "char_end": 276, "chars": "?"}, {"char_start": 288, "char_end": 289, "chars": "?"}, {"char_start": 309, "char_end": 324, "chars": ")\n\t\t\tparams = ("}, {"char_start": 337, "char_end": 338, "chars": ","}, {"char_start": 368, "char_end": 376, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "addMetafile", "func_src_before": "\tdef addMetafile(self, pth, metadata, mod_time):\n\t\t\"\"\"\n\t\tAdds metadata entry\n\t\t:param pth: path to a metadata file\n\t\t:param metadata:\n\t\t:return:\n\t\t\"\"\"\n\n\t\tif not self.fileExists(pth):\n\t\t\tcommand = \"INSERT INTO {0} (type, path, meta, mod_time) VALUES (1, '{1}', '{2}', '{3}');\".format(TABLE_NAME,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpth,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tutils.SQLiteUtils.escapeText(metadata),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmod_time\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n\t\t\tself._run_command(command)\n\t\telse:\n\t\t\tprint(\"addMetafile: Meta File already exists!\")#debug", "func_src_after": "\tdef addMetafile(self, pth, metadata, mod_time):\n\t\t\"\"\"\n\t\tAdds metadata entry\n\t\t:param pth: path to a metadata file\n\t\t:param metadata:\n\t\t:return:\n\t\t\"\"\"\n\n\t\tif not self.fileExists(pth):\n\t\t\tcommand = \"INSERT INTO {0} (type, path, meta, mod_time) VALUES (1, ?, ?, ?);\".format(TABLE_NAME)\n\t\t\tparams = (pth, metadata, mod_time)\n\t\t\tself._run_command(command, params)\n\t\telse:\n\t\t\tprint(\"addMetafile: Meta File already exists!\")#debug", "line_changes": {"deleted": [{"line_no": 10, "char_start": 183, "char_end": 295, "line": "\t\t\tcommand = \"INSERT INTO {0} (type, path, meta, mod_time) VALUES (1, '{1}', '{2}', '{3}');\".format(TABLE_NAME,\n"}, {"line_no": 11, "char_start": 295, "char_end": 319, "line": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpth,\n"}, {"line_no": 12, "char_start": 319, "char_end": 378, "line": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tutils.SQLiteUtils.escapeText(metadata),\n"}, {"line_no": 13, "char_start": 378, "char_end": 406, "line": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmod_time\n"}, {"line_no": 14, "char_start": 406, "char_end": 427, "line": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n"}, {"line_no": 15, "char_start": 427, "char_end": 457, "line": "\t\t\tself._run_command(command)\n"}], "added": [{"line_no": 10, "char_start": 183, "char_end": 283, "line": "\t\t\tcommand = \"INSERT INTO {0} (type, path, meta, mod_time) VALUES (1, ?, ?, ?);\".format(TABLE_NAME)\n"}, {"line_no": 11, "char_start": 283, "char_end": 321, "line": "\t\t\tparams = (pth, metadata, mod_time)\n"}, {"line_no": 12, "char_start": 321, "char_end": 359, "line": "\t\t\tself._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 253, "char_end": 272, "chars": "'{1}', '{2}', '{3}'"}, {"char_start": 293, "char_end": 294, "chars": ","}, {"char_start": 298, "char_end": 425, "chars": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpth,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tutils.SQLiteUtils.escapeText(metadata),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmod_time\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t"}], "added": [{"char_start": 253, "char_end": 260, "chars": "?, ?, ?"}, {"char_start": 281, "char_end": 282, "chars": ")"}, {"char_start": 286, "char_end": 319, "chars": "params = (pth, metadata, mod_time"}, {"char_start": 349, "char_end": 357, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "updateMetadata", "func_src_before": "\tdef updateMetadata(self, pth, metadata, mod_time):\n\t\t\"\"\"\n\t\tUpdates metadata for a folder\n\t\t:param pth: path to a metadata file\n\t\t:param metadata: new metadata\n\t\t:return:\n\t\t\"\"\"\n\t\tif self.fileExists(pth):\n\t\t\tcommand = \"UPDATE {0} SET meta='{1}', mod_time='{3}' WHERE path='{2}';\".format(TABLE_NAME,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tutils.SQLiteUtils.escapeText(metadata),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpth,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmod_time)\n\t\t\tself._run_command(command)\n\t\telse:\n\t\t\tprint(\"updateMetadata: file doesn't exist!\")#debug", "func_src_after": "\tdef updateMetadata(self, pth, metadata, mod_time):\n\t\t\"\"\"\n\t\tUpdates metadata for a folder\n\t\t:param pth: path to a metadata file\n\t\t:param metadata: new metadata\n\t\t:return:\n\t\t\"\"\"\n\t\tif self.fileExists(pth):\n\t\t\tcommand = \"UPDATE {0} SET meta=?, mod_time=? WHERE path=?;\".format(TABLE_NAME)\n\t\t\tparams = (metadata, mod_time, pth)\n\t\t\tself._run_command(command, params)\n\t\telse:\n\t\t\tprint(\"updateMetadata: file doesn't exist!\")#debug", "line_changes": {"deleted": [{"line_no": 9, "char_start": 204, "char_end": 298, "line": "\t\t\tcommand = \"UPDATE {0} SET meta='{1}', mod_time='{3}' WHERE path='{2}';\".format(TABLE_NAME,\n"}, {"line_no": 10, "char_start": 298, "char_end": 356, "line": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tutils.SQLiteUtils.escapeText(metadata),\n"}, {"line_no": 11, "char_start": 356, "char_end": 379, "line": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpth,\n"}, {"line_no": 12, "char_start": 379, "char_end": 407, "line": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmod_time)\n"}, {"line_no": 13, "char_start": 407, "char_end": 437, "line": "\t\t\tself._run_command(command)\n"}], "added": [{"line_no": 9, "char_start": 204, "char_end": 286, "line": "\t\t\tcommand = \"UPDATE {0} SET meta=?, mod_time=? WHERE path=?;\".format(TABLE_NAME)\n"}, {"line_no": 10, "char_start": 286, "char_end": 324, "line": "\t\t\tparams = (metadata, mod_time, pth)\n"}, {"line_no": 11, "char_start": 324, "char_end": 362, "line": "\t\t\tself._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 238, "char_end": 243, "chars": "'{1}'"}, {"char_start": 254, "char_end": 259, "chars": "'{3}'"}, {"char_start": 271, "char_end": 276, "chars": "'{2}'"}, {"char_start": 296, "char_end": 297, "chars": ","}, {"char_start": 301, "char_end": 397, "chars": "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tutils.SQLiteUtils.escapeText(metadata),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpth,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t"}], "added": [{"char_start": 238, "char_end": 239, "chars": "?"}, {"char_start": 250, "char_end": 251, "chars": "?"}, {"char_start": 263, "char_end": 264, "chars": "?"}, {"char_start": 284, "char_end": 309, "chars": ")\n\t\t\tparams = (metadata, "}, {"char_start": 317, "char_end": 322, "chars": ", pth"}, {"char_start": 352, "char_end": 360, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "getMetadata", "func_src_before": "\tdef getMetadata(self, pth):\n\t\t\"\"\"\n\t\tGets metadata for a file in DB\n\t\t:param pth: path to a metadata file\n\t\t:return: string\n\t\t\"\"\"\n\t\tif self.fileExists(pth):\n\t\t\tcommand = \"SELECT meta FROM {0} where path='{1}';\".format(TABLE_NAME, pth)\n\t\t\tdata = self._run_command(command)\n\t\t\ttry:\n\t\t\t\tdata = data[0][0]\n\t\t\texcept IndexError:\n\t\t\t\tdata = None\n\t\telse:\n\t\t\tprint(\"getMetadata: file doesn't exist!\")#debug\n\t\t\tdata = None\n\n\t\treturn data", "func_src_after": "\tdef getMetadata(self, pth):\n\t\t\"\"\"\n\t\tGets metadata for a file in DB\n\t\t:param pth: path to a metadata file\n\t\t:return: string\n\t\t\"\"\"\n\t\tif self.fileExists(pth):\n\t\t\tcommand = \"SELECT meta FROM {0} where path=?;\".format(TABLE_NAME)\n\t\t\tparams = (pth,)\n\t\t\tdata = self._run_command(command, params)\n\t\t\ttry:\n\t\t\t\tdata = data[0][0]\n\t\t\texcept IndexError:\n\t\t\t\tdata = None\n\t\telse:\n\t\t\tprint(\"getMetadata: file doesn't exist!\")#debug\n\t\t\tdata = None\n\n\t\treturn data", "line_changes": {"deleted": [{"line_no": 8, "char_start": 157, "char_end": 235, "line": "\t\t\tcommand = \"SELECT meta FROM {0} where path='{1}';\".format(TABLE_NAME, pth)\n"}, {"line_no": 9, "char_start": 235, "char_end": 272, "line": "\t\t\tdata = self._run_command(command)\n"}], "added": [{"line_no": 8, "char_start": 157, "char_end": 226, "line": "\t\t\tcommand = \"SELECT meta FROM {0} where path=?;\".format(TABLE_NAME)\n"}, {"line_no": 9, "char_start": 226, "char_end": 245, "line": "\t\t\tparams = (pth,)\n"}, {"line_no": 10, "char_start": 245, "char_end": 290, "line": "\t\t\tdata = self._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 203, "char_end": 208, "chars": "'{1}'"}, {"char_start": 228, "char_end": 230, "chars": ", "}], "added": [{"char_start": 203, "char_end": 204, "chars": "?"}, {"char_start": 224, "char_end": 239, "chars": ")\n\t\t\tparams = ("}, {"char_start": 242, "char_end": 243, "chars": ","}, {"char_start": 280, "char_end": 288, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "deleteFile", "func_src_before": "\tdef deleteFile(self, pth):\n\t\t\"\"\"\n\t\tDeletes file with a given path from the DB. If it doesn't exist, ignores.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"DELETE FROM {0} WHERE path='{1}';\".format(TABLE_NAME, pth)\n\t\tself._run_command(command)", "func_src_after": "\tdef deleteFile(self, pth):\n\t\t\"\"\"\n\t\tDeletes file with a given path from the DB. If it doesn't exist, ignores.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"DELETE FROM {0} WHERE path=?;\".format(TABLE_NAME)\n\t\tparams = (pth,)\n\t\tself._run_command(command, params)", "line_changes": {"deleted": [{"line_no": 7, "char_start": 141, "char_end": 213, "line": "\t\tcommand = \"DELETE FROM {0} WHERE path='{1}';\".format(TABLE_NAME, pth)\n"}, {"line_no": 8, "char_start": 213, "char_end": 241, "line": "\t\tself._run_command(command)\n"}], "added": [{"line_no": 7, "char_start": 141, "char_end": 204, "line": "\t\tcommand = \"DELETE FROM {0} WHERE path=?;\".format(TABLE_NAME)\n"}, {"line_no": 8, "char_start": 204, "char_end": 222, "line": "\t\tparams = (pth,)\n"}, {"line_no": 9, "char_start": 222, "char_end": 258, "line": "\t\tself._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 181, "char_end": 186, "chars": "'{1}'"}, {"char_start": 206, "char_end": 208, "chars": ", "}], "added": [{"char_start": 181, "char_end": 182, "chars": "?"}, {"char_start": 202, "char_end": 216, "chars": ")\n\t\tparams = ("}, {"char_start": 219, "char_end": 220, "chars": ","}, {"char_start": 249, "char_end": 257, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "updateCacheID", "func_src_before": "\tdef updateCacheID(self, pth, cacheID):\n\t\t\"\"\"\n\t\tUpdates the file_id field to a given value\n\t\t:param pth:\n\t\t:param cacheID:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"UPDATE {0} SET file_id='{1}' WHERE path='{2}'\".format(TABLE_NAME, cacheID, pth)\n\t\tself._run_command(command)", "func_src_after": "\tdef updateCacheID(self, pth, cacheID):\n\t\t\"\"\"\n\t\tUpdates the file_id field to a given value\n\t\t:param pth:\n\t\t:param cacheID:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"UPDATE {0} SET file_id=? WHERE path=?;\".format(TABLE_NAME)\n\t\tparams = (cacheID, pth)\n\t\tself._run_command(command, params)", "line_changes": {"deleted": [{"line_no": 8, "char_start": 140, "char_end": 233, "line": "\t\tcommand = \"UPDATE {0} SET file_id='{1}' WHERE path='{2}'\".format(TABLE_NAME, cacheID, pth)\n"}, {"line_no": 9, "char_start": 233, "char_end": 261, "line": "\t\tself._run_command(command)\n"}], "added": [{"line_no": 8, "char_start": 140, "char_end": 212, "line": "\t\tcommand = \"UPDATE {0} SET file_id=? WHERE path=?;\".format(TABLE_NAME)\n"}, {"line_no": 9, "char_start": 212, "char_end": 238, "line": "\t\tparams = (cacheID, pth)\n"}, {"line_no": 10, "char_start": 238, "char_end": 274, "line": "\t\tself._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 176, "char_end": 181, "chars": "'{1}'"}, {"char_start": 193, "char_end": 198, "chars": "'{2}'"}, {"char_start": 217, "char_end": 219, "chars": ", "}], "added": [{"char_start": 176, "char_end": 177, "chars": "?"}, {"char_start": 189, "char_end": 191, "chars": "?;"}, {"char_start": 210, "char_end": 224, "chars": ")\n\t\tparams = ("}, {"char_start": 265, "char_end": 273, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "getFileCacheID", "func_src_before": "\tdef getFileCacheID(self, pth):\n\t\t\"\"\"\n\t\tReturns ID of a cached file on Telegram from DB. None if file doesn't exist or has no cached ID.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"SELECT file_id FROM {0} WHERE path='{1}'\".format(TABLE_NAME, pth)\n\t\tdata = self._run_command(command)\n\n\t\ttry:\n\t\t\tdata = data[0][0]\n\t\texcept IndexError:\n\t\t\tdata = None\n\n\t\treturn data", "func_src_after": "\tdef getFileCacheID(self, pth):\n\t\t\"\"\"\n\t\tReturns ID of a cached file on Telegram from DB. None if file doesn't exist or has no cached ID.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"SELECT file_id FROM {0} WHERE path=?;\".format(TABLE_NAME)\n\t\tparams = (pth,)\n\t\tdata = self._run_command(command, params)\n\n\t\ttry:\n\t\t\tdata = data[0][0]\n\t\texcept IndexError:\n\t\t\tdata = None\n\n\t\treturn data", "line_changes": {"deleted": [{"line_no": 7, "char_start": 168, "char_end": 247, "line": "\t\tcommand = \"SELECT file_id FROM {0} WHERE path='{1}'\".format(TABLE_NAME, pth)\n"}, {"line_no": 8, "char_start": 247, "char_end": 283, "line": "\t\tdata = self._run_command(command)\n"}], "added": [{"line_no": 7, "char_start": 168, "char_end": 239, "line": "\t\tcommand = \"SELECT file_id FROM {0} WHERE path=?;\".format(TABLE_NAME)\n"}, {"line_no": 8, "char_start": 239, "char_end": 257, "line": "\t\tparams = (pth,)\n"}, {"line_no": 9, "char_start": 257, "char_end": 301, "line": "\t\tdata = self._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 216, "char_end": 221, "chars": "'{1}'"}, {"char_start": 240, "char_end": 242, "chars": ", "}], "added": [{"char_start": 216, "char_end": 218, "chars": "?;"}, {"char_start": 237, "char_end": 251, "chars": ")\n\t\tparams = ("}, {"char_start": 254, "char_end": 255, "chars": ","}, {"char_start": 291, "char_end": 299, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "invalidateCached", "func_src_before": "\tdef invalidateCached(self, pth):\n\t\t\"\"\"\n\t\tSet cache to NULL in DB for a given file\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"UPDATE {0} SET file_id=NULL WHERE path='{1}'\".format(TABLE_NAME, pth)\n\t\tself._run_command(command)", "func_src_after": "\tdef invalidateCached(self, pth):\n\t\t\"\"\"\n\t\tSet cache to NULL in DB for a given file\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"UPDATE {0} SET file_id=NULL WHERE path=?\".format(TABLE_NAME)\n\t\tparams = (pth,)\n\t\tself._run_command(command, params)", "line_changes": {"deleted": [{"line_no": 7, "char_start": 114, "char_end": 197, "line": "\t\tcommand = \"UPDATE {0} SET file_id=NULL WHERE path='{1}'\".format(TABLE_NAME, pth)\n"}, {"line_no": 8, "char_start": 197, "char_end": 225, "line": "\t\tself._run_command(command)\n"}], "added": [{"line_no": 7, "char_start": 114, "char_end": 188, "line": "\t\tcommand = \"UPDATE {0} SET file_id=NULL WHERE path=?\".format(TABLE_NAME)\n"}, {"line_no": 8, "char_start": 188, "char_end": 206, "line": "\t\tparams = (pth,)\n"}, {"line_no": 9, "char_start": 206, "char_end": 242, "line": "\t\tself._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 166, "char_end": 171, "chars": "'{1}'"}, {"char_start": 190, "char_end": 192, "chars": ", "}], "added": [{"char_start": 166, "char_end": 167, "chars": "?"}, {"char_start": 186, "char_end": 200, "chars": ")\n\t\tparams = ("}, {"char_start": 203, "char_end": 204, "chars": ","}, {"char_start": 233, "char_end": 241, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "getCaption", "func_src_before": "\tdef getCaption(self, pth):\n\t\t\"\"\"\n\t\tReturns a metadata for a given metadata file from DB.\n\t\t:param pth: path to a *metadata* file\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"SELECT meta FROM {0} WHERE path='{1}';\".format(TABLE_NAME,pth)\n\t\tdata = \tself._run_command(command)\n\n\t\ttry:\n\t\t\tdata = data[0][0]\n\t\texcept IndexError:\n\t\t\tdata = None\n\n\t\treturn data", "func_src_after": "\tdef getCaption(self, pth):\n\t\t\"\"\"\n\t\tReturns a metadata for a given metadata file from DB.\n\t\t:param pth: path to a *metadata* file\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"SELECT meta FROM {0} WHERE path=?;\".format(TABLE_NAME)\n\t\tparams = (pth,)\n\t\tdata = self._run_command(command, params)\n\n\t\ttry:\n\t\t\tdata = data[0][0]\n\t\texcept IndexError:\n\t\t\tdata = None\n\n\t\treturn data", "line_changes": {"deleted": [{"line_no": 7, "char_start": 147, "char_end": 223, "line": "\t\tcommand = \"SELECT meta FROM {0} WHERE path='{1}';\".format(TABLE_NAME,pth)\n"}, {"line_no": 8, "char_start": 223, "char_end": 260, "line": "\t\tdata = \tself._run_command(command)\n"}], "added": [{"line_no": 7, "char_start": 147, "char_end": 215, "line": "\t\tcommand = \"SELECT meta FROM {0} WHERE path=?;\".format(TABLE_NAME)\n"}, {"line_no": 8, "char_start": 215, "char_end": 233, "line": "\t\tparams = (pth,)\n"}, {"line_no": 9, "char_start": 233, "char_end": 277, "line": "\t\tdata = self._run_command(command, params)\n"}]}, "char_changes": {"deleted": [{"char_start": 192, "char_end": 197, "chars": "'{1}'"}, {"char_start": 217, "char_end": 218, "chars": ","}, {"char_start": 232, "char_end": 233, "chars": "\t"}], "added": [{"char_start": 192, "char_end": 193, "chars": "?"}, {"char_start": 213, "char_end": 227, "chars": ")\n\t\tparams = ("}, {"char_start": 230, "char_end": 231, "chars": ","}, {"char_start": 267, "char_end": 275, "chars": ", params"}]}, "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089"}
{"func_name": "get_home_screen_data", "func_src_before": "  @staticmethod\n  def get_home_screen_data():\n    sql = \"SELECT jdk_entries.id, jdk_entries.title \" + \\\n      \"FROM jdk_entries \" + \\\n      \"ORDER BY date_last_modified DESC \" + \\\n      \"LIMIT 30;\" \n\n    return db_execute(sql, True)", "func_src_after": "  @staticmethod\n  def get_home_screen_data():\n    quote_tuple = ()\n    sql = \"SELECT jdk_entries.id, jdk_entries.title \" + \\\n      \"FROM jdk_entries \" + \\\n      \"ORDER BY date_last_modified DESC \" + \\\n      \"LIMIT 30;\" \n\n    return db_execute(sql, quote_tuple, True)", "line_changes": {"deleted": [{"line_no": 8, "char_start": 200, "char_end": 232, "line": "    return db_execute(sql, True)\n"}], "added": [{"line_no": 3, "char_start": 46, "char_end": 67, "line": "    quote_tuple = ()\n"}, {"line_no": 9, "char_start": 221, "char_end": 266, "line": "    return db_execute(sql, quote_tuple, True)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 46, "char_end": 67, "chars": "    quote_tuple = ()\n"}, {"char_start": 247, "char_end": 260, "chars": " quote_tuple,"}]}, "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089"}
{"func_name": "search_existing_entries", "func_src_before": "  @staticmethod\n  def search_existing_entries(keyword=None, from_date=None, to_date=None):\n    total_parameters = 0\n\n    if (keyword):\n      keyword_string = \"(jdk_entries.title LIKE '%\" + keyword + \"%' OR \" + \\\n        \"jdk_entries.body LIKE '%\" + keyword + \"%') \"\n      total_parameters += 1\n    else:\n      keyword_string = \"\"  \n  \n    if (from_date):\n      from_date_string = \"jdk_entries.date_last_modified >= '\" + from_date + \"' \"\n      total_parameters += 1\n    else:\n      from_date_string = \"\"\n\n    if (to_date):\n      to_date_string = \"jdk_entries.date_last_modified <= '\" + to_date + \"' \"\n      total_parameters += 1\n    else:\n      to_date_string = \"\"\n\n    sql = \"SELECT jdk_entries.id, jdk_entries.title \" + \\\n      \"FROM jdk_entries \" + \\\n      \"WHERE \" + \\\n      keyword_string + \\\n      (\"AND \" if (keyword_string and (from_date or to_date)) else \"\") + \\\n      from_date_string + \\\n      (\"AND \" if (from_date and to_date) else \"\") + \\\n      to_date_string + \\\n      \"LIMIT 30;\"\n\n    return db_execute(sql, True)", "func_src_after": "  @staticmethod\n  def search_existing_entries(keyword=None, from_date=None, to_date=None):\n    total_parameters = 0\n    quote_tuple = ()\n\n    if (keyword):\n      keyword_string = '(jdk_entries.title LIKE ? OR ' + \\\n        'jdk_entries.body LIKE ?) '\n      total_parameters += 1\n      keyword = '%' + keyword + '%'\n      quote_tuple += keyword, keyword\n    else:\n      keyword_string = \"\"  \n  \n    if (from_date):\n      from_date_string = \"jdk_entries.date_last_modified >= ? \"\n      total_parameters += 1\n      quote_tuple += from_date,\n    else:\n      from_date_string = \"\"\n\n    if (to_date):\n      to_date_string = \"jdk_entries.date_last_modified <= ? \"\n      total_parameters += 1\n      quote_tuple += to_date,\n    else:\n      to_date_string = \"\"\n\n    sql = \"SELECT jdk_entries.id, jdk_entries.title \" + \\\n      \"FROM jdk_entries \" + \\\n      \"WHERE \" + \\\n      keyword_string + \\\n      (\"AND \" if (keyword_string and (from_date or to_date)) else \"\") + \\\n      from_date_string + \\\n      (\"AND \" if (from_date and to_date) else \"\") + \\\n      to_date_string + \\\n      \"LIMIT 30;\"\n\n    return db_execute(sql, quote_tuple, True)", "line_changes": {"deleted": [{"line_no": 6, "char_start": 135, "char_end": 212, "line": "      keyword_string = \"(jdk_entries.title LIKE '%\" + keyword + \"%' OR \" + \\\n"}, {"line_no": 7, "char_start": 212, "char_end": 266, "line": "        \"jdk_entries.body LIKE '%\" + keyword + \"%') \"\n"}, {"line_no": 13, "char_start": 355, "char_end": 437, "line": "      from_date_string = \"jdk_entries.date_last_modified >= '\" + from_date + \"' \"\n"}, {"line_no": 19, "char_start": 522, "char_end": 600, "line": "      to_date_string = \"jdk_entries.date_last_modified <= '\" + to_date + \"' \"\n"}, {"line_no": 34, "char_start": 996, "char_end": 1028, "line": "    return db_execute(sql, True)\n"}], "added": [{"line_no": 4, "char_start": 116, "char_end": 137, "line": "    quote_tuple = ()\n"}, {"line_no": 7, "char_start": 156, "char_end": 215, "line": "      keyword_string = '(jdk_entries.title LIKE ? OR ' + \\\n"}, {"line_no": 8, "char_start": 215, "char_end": 251, "line": "        'jdk_entries.body LIKE ?) '\n"}, {"line_no": 10, "char_start": 279, "char_end": 315, "line": "      keyword = '%' + keyword + '%'\n"}, {"line_no": 11, "char_start": 315, "char_end": 353, "line": "      quote_tuple += keyword, keyword\n"}, {"line_no": 16, "char_start": 414, "char_end": 478, "line": "      from_date_string = \"jdk_entries.date_last_modified >= ? \"\n"}, {"line_no": 18, "char_start": 506, "char_end": 538, "line": "      quote_tuple += from_date,\n"}, {"line_no": 23, "char_start": 595, "char_end": 657, "line": "      to_date_string = \"jdk_entries.date_last_modified <= ? \"\n"}, {"line_no": 25, "char_start": 685, "char_end": 715, "line": "      quote_tuple += to_date,\n"}, {"line_no": 39, "char_start": 1083, "char_end": 1128, "line": "    return db_execute(sql, quote_tuple, True)\n"}]}, "char_changes": {"deleted": [{"char_start": 158, "char_end": 159, "chars": "\""}, {"char_start": 183, "char_end": 202, "chars": "'%\" + keyword + \"%'"}, {"char_start": 206, "char_end": 207, "chars": "\""}, {"char_start": 220, "char_end": 221, "chars": "\""}, {"char_start": 245, "char_end": 246, "chars": "\""}, {"char_start": 259, "char_end": 260, "chars": "\""}, {"char_start": 262, "char_end": 265, "chars": ") \""}, {"char_start": 272, "char_end": 293, "chars": "total_parameters += 1"}, {"char_start": 415, "char_end": 434, "chars": "'\" + from_date + \"'"}, {"char_start": 580, "char_end": 597, "chars": "'\" + to_date + \"'"}], "added": [{"char_start": 115, "char_end": 136, "chars": "\n    quote_tuple = ()"}, {"char_start": 179, "char_end": 180, "chars": "'"}, {"char_start": 204, "char_end": 205, "chars": "?"}, {"char_start": 209, "char_end": 210, "chars": "'"}, {"char_start": 223, "char_end": 224, "chars": "'"}, {"char_start": 245, "char_end": 294, "chars": " ?) '\n      total_parameters += 1\n      keyword ="}, {"char_start": 297, "char_end": 298, "chars": "'"}, {"char_start": 311, "char_end": 312, "chars": "'"}, {"char_start": 321, "char_end": 352, "chars": "quote_tuple += keyword, keyword"}, {"char_start": 474, "char_end": 475, "chars": "?"}, {"char_start": 506, "char_end": 538, "chars": "      quote_tuple += from_date,\n"}, {"char_start": 653, "char_end": 654, "chars": "?"}, {"char_start": 685, "char_end": 715, "chars": "      quote_tuple += to_date,\n"}, {"char_start": 1109, "char_end": 1122, "chars": " quote_tuple,"}]}, "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089"}
{"func_name": "populate_entry_data", "func_src_before": "  def populate_entry_data(self):\n    sql = \"SELECT jdk_entries.title, jdk_entries.body \" + \\\n      \"FROM jdk_entries \" + \\\n      \"WHERE jdk_entries.id = \" + self.entry_id + \";\" \n\n    self.title, self.body = db_execute(sql, True)[0] # returns array\n    \n    return None", "func_src_after": "  def populate_entry_data(self):\n    quote_tuple = self.entry_id,\n\n    sql = \"SELECT jdk_entries.title, jdk_entries.body \" + \\\n      \"FROM jdk_entries \" + \\\n      \"WHERE jdk_entries.id = ?;\" \n\n    self.title, self.body = db_execute(sql, quote_tuple, True)[0] # returns array\n    \n    return None", "line_changes": {"deleted": [{"line_no": 4, "char_start": 123, "char_end": 178, "line": "      \"WHERE jdk_entries.id = \" + self.entry_id + \";\" \n"}, {"line_no": 6, "char_start": 179, "char_end": 248, "line": "    self.title, self.body = db_execute(sql, True)[0] # returns array\n"}], "added": [{"line_no": 2, "char_start": 33, "char_end": 66, "line": "    quote_tuple = self.entry_id,\n"}, {"line_no": 3, "char_start": 66, "char_end": 67, "line": "\n"}, {"line_no": 6, "char_start": 157, "char_end": 192, "line": "      \"WHERE jdk_entries.id = ?;\" \n"}, {"line_no": 8, "char_start": 193, "char_end": 275, "line": "    self.title, self.body = db_execute(sql, quote_tuple, True)[0] # returns array\n"}]}, "char_changes": {"deleted": [{"char_start": 153, "char_end": 174, "chars": "\" + self.entry_id + \""}], "added": [{"char_start": 33, "char_end": 67, "chars": "    quote_tuple = self.entry_id,\n\n"}, {"char_start": 187, "char_end": 188, "chars": "?"}, {"char_start": 236, "char_end": 249, "chars": " quote_tuple,"}]}, "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089"}
{"func_name": "create_entry", "func_src_before": "  def create_entry(self):\n    sql = \"INSERT INTO jdk_entries \" + \\\n      \"(title, body,  date_created, date_last_modified)\" + \\\n      \"VALUES ('', '', \" + CURRENT_DATESTAMP + \\\n      \", \" + CURRENT_DATESTAMP + \");\"\n\n    db_execute(sql)\n\n    return None", "func_src_after": "  def create_entry(self):\n    quote_tuple = CURRENT_DATESTAMP, CURRENT_DATESTAMP\n\n    sql = \"INSERT INTO jdk_entries \" + \\\n      \"(title, body,  date_created, date_last_modified)\" + \\\n      \"VALUES ('', '', ?, ?);\"\n\n    db_execute(sql, quote_tuple)\n\n    return None", "line_changes": {"deleted": [{"line_no": 4, "char_start": 128, "char_end": 177, "line": "      \"VALUES ('', '', \" + CURRENT_DATESTAMP + \\\n"}, {"line_no": 5, "char_start": 177, "char_end": 215, "line": "      \", \" + CURRENT_DATESTAMP + \");\"\n"}, {"line_no": 7, "char_start": 216, "char_end": 236, "line": "    db_execute(sql)\n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 81, "line": "    quote_tuple = CURRENT_DATESTAMP, CURRENT_DATESTAMP\n"}, {"line_no": 3, "char_start": 81, "char_end": 82, "line": "\n"}, {"line_no": 6, "char_start": 184, "char_end": 215, "line": "      \"VALUES ('', '', ?, ?);\"\n"}, {"line_no": 8, "char_start": 216, "char_end": 249, "line": "    db_execute(sql, quote_tuple)\n"}]}, "char_changes": {"deleted": [{"char_start": 151, "char_end": 211, "chars": "\" + CURRENT_DATESTAMP + \\\n      \", \" + CURRENT_DATESTAMP + \""}], "added": [{"char_start": 26, "char_end": 82, "chars": "    quote_tuple = CURRENT_DATESTAMP, CURRENT_DATESTAMP\n\n"}, {"char_start": 207, "char_end": 211, "chars": "?, ?"}, {"char_start": 234, "char_end": 247, "chars": ", quote_tuple"}]}, "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089"}
{"func_name": "set_entry_id", "func_src_before": "  def set_entry_id(self):\n    sql = \"SELECT MAX(id) FROM jdk_entries;\"\n\n    # returns a nested list, need to get at it with array syntax\n    self.entry_id = str(db_execute(sql, True)[0][0]);     \n\n    return None", "func_src_after": "  def set_entry_id(self):\n    quote_tuple = ()\n    \n    sql = \"SELECT MAX(id) FROM jdk_entries;\"\n\n    # returns a nested list, need to get at it with array syntax\n    self.entry_id = str(db_execute(sql, quote_tuple, True)[0][0]);     \n\n    return None", "line_changes": {"deleted": [{"line_no": 5, "char_start": 137, "char_end": 196, "line": "    self.entry_id = str(db_execute(sql, True)[0][0]);     \n"}], "added": [{"line_no": 2, "char_start": 26, "char_end": 47, "line": "    quote_tuple = ()\n"}, {"line_no": 3, "char_start": 47, "char_end": 52, "line": "    \n"}, {"line_no": 7, "char_start": 163, "char_end": 235, "line": "    self.entry_id = str(db_execute(sql, quote_tuple, True)[0][0]);     \n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 26, "char_end": 52, "chars": "    quote_tuple = ()\n    \n"}, {"char_start": 202, "char_end": 215, "chars": " quote_tuple,"}]}, "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089"}
{"func_name": "update_title", "func_src_before": "  def update_title(self, title = None):\n    if (not self.title):\n      self.title = title\n\n    # This will fall to a sql injection \n    sql = \"UPDATE jdk_entries SET title = '\" + self.title + \"'\" + \\\n          \"WHERE jdk_entries.id = '\" + self.entry_id + \"';\" \n\n    db_execute(sql)\n    \n    self.update_date_modified()\n\n    return None", "func_src_after": "  def update_title(self, title = None):\n    if (not self.title):\n      self.title = title\n\n    quote_tuple = self.title, self.entry_id\n\n    # This will fall to a sql injection \n    sql = \"UPDATE jdk_entries SET title = ?\" + \\\n          \"WHERE jdk_entries.id = ?;\" \n\n    db_execute(sql, quote_tuple)\n    \n    self.update_date_modified()\n\n    return None", "line_changes": {"deleted": [{"line_no": 6, "char_start": 132, "char_end": 200, "line": "    sql = \"UPDATE jdk_entries SET title = '\" + self.title + \"'\" + \\\n"}, {"line_no": 7, "char_start": 200, "char_end": 261, "line": "          \"WHERE jdk_entries.id = '\" + self.entry_id + \"';\" \n"}, {"line_no": 9, "char_start": 262, "char_end": 282, "line": "    db_execute(sql)\n"}], "added": [{"line_no": 5, "char_start": 91, "char_end": 135, "line": "    quote_tuple = self.title, self.entry_id\n"}, {"line_no": 6, "char_start": 135, "char_end": 136, "line": "\n"}, {"line_no": 8, "char_start": 177, "char_end": 226, "line": "    sql = \"UPDATE jdk_entries SET title = ?\" + \\\n"}, {"line_no": 9, "char_start": 226, "char_end": 265, "line": "          \"WHERE jdk_entries.id = ?;\" \n"}, {"line_no": 11, "char_start": 266, "char_end": 299, "line": "    db_execute(sql, quote_tuple)\n"}]}, "char_changes": {"deleted": [{"char_start": 174, "char_end": 194, "chars": "'\" + self.title + \"'"}, {"char_start": 234, "char_end": 257, "chars": "'\" + self.entry_id + \"'"}], "added": [{"char_start": 91, "char_end": 136, "chars": "    quote_tuple = self.title, self.entry_id\n\n"}, {"char_start": 219, "char_end": 220, "chars": "?"}, {"char_start": 260, "char_end": 261, "chars": "?"}, {"char_start": 284, "char_end": 297, "chars": ", quote_tuple"}]}, "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089"}
{"func_name": "update_date_modified", "func_src_before": "  def update_date_modified(self):\n    sql = \"UPDATE jdk_entries \" + \\\n      \"SET date_last_modified = \" + CURRENT_DATESTAMP + \" \" + \\\n      \"WHERE jdk_entries.id = '\" + self.entry_id + \"';\"\n    \n    db_execute(sql)\n\n    return None", "func_src_after": "  def update_date_modified(self):\n    quote_tuple = CURRENT_DATESTAMP, self.entry_id\n\n    sql = \"UPDATE jdk_entries \" + \\\n      \"SET date_last_modified = ? \" + \\\n      \"WHERE jdk_entries.id = ?;\"\n    \n    db_execute(sql, quote_tuple)\n\n    return None", "line_changes": {"deleted": [{"line_no": 3, "char_start": 70, "char_end": 134, "line": "      \"SET date_last_modified = \" + CURRENT_DATESTAMP + \" \" + \\\n"}, {"line_no": 4, "char_start": 134, "char_end": 190, "line": "      \"WHERE jdk_entries.id = '\" + self.entry_id + \"';\"\n"}, {"line_no": 6, "char_start": 195, "char_end": 215, "line": "    db_execute(sql)\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 85, "line": "    quote_tuple = CURRENT_DATESTAMP, self.entry_id\n"}, {"line_no": 3, "char_start": 85, "char_end": 86, "line": "\n"}, {"line_no": 5, "char_start": 122, "char_end": 162, "line": "      \"SET date_last_modified = ? \" + \\\n"}, {"line_no": 6, "char_start": 162, "char_end": 196, "line": "      \"WHERE jdk_entries.id = ?;\"\n"}, {"line_no": 8, "char_start": 201, "char_end": 234, "line": "    db_execute(sql, quote_tuple)\n"}]}, "char_changes": {"deleted": [{"char_start": 102, "char_end": 127, "chars": "\" + CURRENT_DATESTAMP + \""}, {"char_start": 164, "char_end": 187, "chars": "'\" + self.entry_id + \"'"}], "added": [{"char_start": 34, "char_end": 86, "chars": "    quote_tuple = CURRENT_DATESTAMP, self.entry_id\n\n"}, {"char_start": 154, "char_end": 155, "chars": "?"}, {"char_start": 192, "char_end": 193, "chars": "?"}, {"char_start": 219, "char_end": 232, "chars": ", quote_tuple"}]}, "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089"}
{"func_name": "edit_entry", "func_src_before": "  def edit_entry(self):\n    self.create_temp_file()\n    if (self.body is not None):\n      self.write_body_to_temp_file() \n    \n    self.open_temp_file() # opens vim here\n    \n    body_new = self.get_temp_file_data()\n  \n    if (body_new != self.body):\n      self.body = body_new \n    \n      sql = \"UPDATE jdk_entries \" + \\\n        \"SET body = '\" + self.body + \"' \" + \\\n        \"WHERE jdk_entries.id = '\" + self.entry_id + \"';\"\n\n      db_execute(sql)\n      self.update_date_modified()\n    \n    self.remove_temp_file()\n    \n    return None", "func_src_after": "  def edit_entry(self):\n    self.create_temp_file()\n    if (self.body is not None):\n      self.write_body_to_temp_file() \n    \n    self.open_temp_file() # opens vim here\n    \n    body_new = self.get_temp_file_data()\n  \n    if (body_new != self.body):\n      self.body = body_new \n    \n      quote_tuple = self.body, self.entry_id\n\n      sql = \"UPDATE jdk_entries SET body = ? \" + \\\n        \"WHERE jdk_entries.id = ?;\"\n\n      db_execute(sql, quote_tuple)\n      self.update_date_modified()\n    \n    self.remove_temp_file()\n    \n    return None", "line_changes": {"deleted": [{"line_no": 13, "char_start": 284, "char_end": 322, "line": "      sql = \"UPDATE jdk_entries \" + \\\n"}, {"line_no": 14, "char_start": 322, "char_end": 368, "line": "        \"SET body = '\" + self.body + \"' \" + \\\n"}, {"line_no": 15, "char_start": 368, "char_end": 426, "line": "        \"WHERE jdk_entries.id = '\" + self.entry_id + \"';\"\n"}, {"line_no": 17, "char_start": 427, "char_end": 449, "line": "      db_execute(sql)\n"}], "added": [{"line_no": 13, "char_start": 284, "char_end": 329, "line": "      quote_tuple = self.body, self.entry_id\n"}, {"line_no": 14, "char_start": 329, "char_end": 330, "line": "\n"}, {"line_no": 15, "char_start": 330, "char_end": 381, "line": "      sql = \"UPDATE jdk_entries SET body = ? \" + \\\n"}, {"line_no": 16, "char_start": 381, "char_end": 417, "line": "        \"WHERE jdk_entries.id = ?;\"\n"}, {"line_no": 18, "char_start": 418, "char_end": 453, "line": "      db_execute(sql, quote_tuple)\n"}]}, "char_changes": {"deleted": [{"char_start": 290, "char_end": 361, "chars": "sql = \"UPDATE jdk_entries \" + \\\n        \"SET body = '\" + self.body + \"'"}, {"char_start": 400, "char_end": 423, "chars": "'\" + self.entry_id + \"'"}], "added": [{"char_start": 290, "char_end": 374, "chars": "quote_tuple = self.body, self.entry_id\n\n      sql = \"UPDATE jdk_entries SET body = ?"}, {"char_start": 413, "char_end": 414, "chars": "?"}, {"char_start": 438, "char_end": 451, "chars": ", quote_tuple"}]}, "commit_link": "github.com/peterlebrun/jdk/commit/000238566fbe55ba09676c3d57af04ae207235ae", "file_name": "entry.py", "vul_type": "cwe-089"}
{"func_name": "jobs", "func_src_before": "def jobs(table=JOBS_TABLE):\n    \"\"\"Return list of projects.\"\"\"\n    query = 'select job from %s group by job' %table\n    df = model.sql.frame_query(query, db)\n    return json.dumps(df.job.values.tolist())", "func_src_after": "def jobs(table=JOBS_TABLE):\n    \"\"\"Return list of projects.\"\"\"\n    query = 'select job from %s group by job' %table\n    df = model.sql.read_frame(query, db)\n    return json.dumps(df.job.values.tolist())", "line_changes": {"deleted": [{"line_no": 4, "char_start": 116, "char_end": 158, "line": "    df = model.sql.frame_query(query, db)\n"}], "added": [{"line_no": 4, "char_start": 116, "char_end": 157, "line": "    df = model.sql.read_frame(query, db)\n"}]}, "char_changes": {"deleted": [{"char_start": 140, "char_end": 146, "chars": "_query"}], "added": [{"char_start": 135, "char_end": 140, "chars": "read_"}]}, "commit_link": "github.com/rpinho/happy.li/commit/67adb6701eb3b6c0e9cacf5f7ef99a1945374e56", "file_name": "myapp.py", "vul_type": "cwe-089"}
{"func_name": "media_list", "func_src_before": "@api_view(['GET'])\ndef media_list(request, repository, mucua, args=None, format=None):\n    \"\"\"\n    List all medias, or search by terms\n    \"\"\"\n\n    if request.method == 'GET':\n        \"\"\"\n        list medias\n        \"\"\"\n\n        # pegando sessao por url\n        redirect_page = False\n\n        # REPOSITORIO: verifica se existe no banco, senao pega a default\n        if mucua == 'rede':\n            # get actual mucua for excluding it\n            this_mucua = Mucua.objects.get(description=DEFAULT_MUCUA)\n        else:\n            try:\n                mucua = Mucua.objects.get(description=mucua)\n            except Mucua.DoesNotExist:\n                mucua = Mucua.objects.get(description=DEFAULT_MUCUA)\n                redirect_page = True\n\n        try:\n            repository = Repository.objects.get(name=repository)\n        except Repository.DoesNotExist:\n            repository = Repository.objects.get(name=DEFAULT_REPOSITORY)\n            redirect_page = True\n\n        # redirect\n        if redirect_page:\n            return HttpResponseRedirect(redirect_base_url + repository.name +\n                                        '/' + mucua.description +\n                                        '/bbx/search/')\n\n        \"\"\"\n        ====================\n        SEARCH ENGINE\n        \n        -------------\n        Sample urls\n        \n        Valid with the following types of url (TODO: create tests):\n        \n        [repository]/[mucua]/search/video/quilombo/limit/5\n        [repository]/[mucua]/search/orderby/note/limit/10\n        [repository]/[mucua]/search/video/quilombo/orderby/title/limit/5\n        [repository]/[mucua]/search/video/quilombo/orderby/type/desc/name/asc/limit/5\n        [repository]/[mucua]/search/video/quilombo/orderby/author/desc\n\n        TODO: still failling when receives incomplete urls. i.e.:\n        [repository]/[mucua]/search/video/quilombo/orderby/title/limit/5\n        \"\"\"\n        \n        \"\"\"  if passed, get limiting rules \"\"\"\n\n        \"\"\" TODO: move default_limit to configurable place \"\"\"\n        default_limit = 20\n        if (args.find('limit') != -1):\n            limiting_str = int(args.split('limit/')[1])\n            args = args.split('limit/')[0]\n        else:\n            limiting_str = default_limit\n        \n        \"\"\" if passed, get ordering rules \"\"\"\n        ordering_str = ''\n        if (args.find('orderby/') != -1):\n            ordering_terms = args.split('orderby/')[1].split('/')\n            ordering_list = []\n            counting = 0\n            for term in ordering_terms:\n                if ((term == 'asc') | (term == 'desc')):\n                    if counting == 0:\n                        continue\n                    ordering_list[-1] += ' ' + term + ' '\n                else:\n                    if (term != ''):\n                        ordering_list.append(term)                               \n                counting += 1\n        \n            ordering_str = ','.join(ordering_list)\n            \n            args = args.split('orderby/')[0]\n        else:\n            ordering_str = 'm.name'\n        \n        \"\"\" compose query string for terms \"\"\"\n        term_str = \"\"\n        args = args.rstrip('/')\n        if args != '':\n            term_index = 0\n            for term in args.split('/'):\n                term = str(term)\n                if (term in [key for (key, type_choice) in getTypeChoices() if\n                            term == type_choice]):\n                    term_str += ' type LIKE \"%' + term + '%\"'\n                elif term in [key for\n                             (key, format_choice) in getFormatChoices() if\n                             term == format_choice]:\n                    term_str += ' format LIKE \"%' + term + '\"%\"'\n                else:\n                    if (term_index > 0):\n                        term_str += 'AND' \n                    \n                    term_str += '( t.name LIKE \"%' + term + '%\"'\n                    term_str += ' OR m.name LIKE \"%' + term + '%\"'\n                    term_str += ' OR m.note LIKE \"%' + term + '%\")'\n                    term_index += 1\n                    \n                    \n        if (len(term_str) > 0):\n            term_str = ' AND (' + term_str + ')'\n        \n        \"\"\" exclude the content of own mucua on the network\n        TODO: maybe create also an option for including or not the own mucua data \"\"\"\n        if (mucua == 'rede'):\n            origin_str = \"origin_id!=\" + str(this_mucua.id)\n        else:\n            origin_str = \"origin_id=\" + str(mucua.id)\n        \n        sql ='SELECT DISTINCT m.* FROM media_media m LEFT JOIN media_media_tags mt ON m.id = mt.media_id LEFT JOIN tag_tag t ON mt.tag_id = t.id  WHERE (%s AND repository_id = %d) %s ORDER BY %s LIMIT %s' % (origin_str, repository.id, term_str, ordering_str, limiting_str)\n        \n        medias = Media.objects.raw(sql)\n        \n        \"\"\" sql log\n        logger.info('sql: ' + sql)\n        \"\"\"\n        \n        # serializa e da saida\n        serializer = MediaSerializer(medias, many=True)\n        return Response(serializer.data)", "func_src_after": "@api_view(['GET'])\ndef media_list(request, repository, mucua, args=None, format=None):\n    \"\"\"\n    List all medias, or search by terms\n    \"\"\"\n\n    if request.method == 'GET':\n        \"\"\"\n        list medias\n        \"\"\"\n\n        # pegando sessao por url\n        redirect_page = False\n\n        # REPOSITORIO: verifica se existe no banco, senao pega a default\n        if mucua == 'rede':\n            # get actual mucua for excluding it\n            this_mucua = Mucua.objects.get(description=DEFAULT_MUCUA)\n        else:\n            try:\n                mucua = Mucua.objects.get(description=mucua)\n            except Mucua.DoesNotExist:\n                mucua = Mucua.objects.get(description=DEFAULT_MUCUA)\n                redirect_page = True\n\n        try:\n            repository = Repository.objects.get(name=repository)\n        except Repository.DoesNotExist:\n            repository = Repository.objects.get(name=DEFAULT_REPOSITORY)\n            redirect_page = True\n\n        # redirect\n        if redirect_page:\n            return HttpResponseRedirect(redirect_base_url + repository.name +\n                                        '/' + mucua.description +\n                                        '/bbx/search/')\n\n        \"\"\"\n        ====================\n        SEARCH ENGINE\n        \n        -------------\n        Sample urls\n        \n        Valid with the following types of url (TODO: create tests):\n        \n        [repository]/[mucua]/search/video/quilombo/limit/5\n        [repository]/[mucua]/search/orderby/note/limit/10\n        [repository]/[mucua]/search/video/quilombo/orderby/title/limit/5\n        [repository]/[mucua]/search/video/quilombo/orderby/type/desc/name/asc/limit/5\n        [repository]/[mucua]/search/video/quilombo/orderby/author/desc\n\n        TODO: still failling when receives incomplete urls. i.e.:\n        [repository]/[mucua]/search/video/quilombo/orderby/title/limit/5\n        \"\"\"\n        \n        \"\"\"  if passed, get limiting rules \"\"\"\n\n        \"\"\" TODO: move default_limit to configurable place \"\"\"\n        params = []\n        \n        default_limit = 20\n        limiting_params = []\n        if (args.find('limit') != -1):\n            limiting_params.append(str(args.split('limit/')[1]))\n            args = args.split('limit/')[0]\n        else:\n            limiting_params.append(str(default_limit))\n        \n        \"\"\" if passed, get ordering rules \"\"\"\n        ordering_sql = ''\n        ordering_params = []\n        if (args.find('orderby/') != -1):\n            ordering_terms = args.split('orderby/')[1].split('/')\n            ordering_list = []\n            counting = 0\n            for term in ordering_terms:\n                if ((term == 'asc') | (term == 'desc')):\n                    if counting == 0:\n                        continue\n                    ordering_list[-1] += ' ' + term + ' '\n                else:\n                    if (term != ''):\n                        ordering_list.append(term)                               \n                counting += 1\n                \n            for ordering in ordering_list:\n                ordering_sql += '%s,'\n                ordering_params.append(ordering)\n            \n            # remove last char if it's a comma / ','\n            if ordering_sql[:-1] == ',':\n                ordering_sql = ordering_sql[:-1]\n            \n            args = args.split('orderby/')[0]\n        else:\n            ordering_sql = 'm.name'\n        \n        \"\"\" exclude the content of own mucua on the network\n        TODO: maybe create also an option for including or not the own mucua data \"\"\"\n        if (mucua == 'rede'):\n            origin_sql = \"origin_id!=?  \"\n            params.append(this_mucua.id)\n            \n        else:\n            origin_sql = \"origin_id=?  \"\n            params.append(mucua.id)\n        \n        \"\"\" appends repository id \"\"\"\n        params.append(repository.id)\n\n        \"\"\" compose query string for terms \"\"\"\n        term_sql = \"\"\n        args = args.rstrip('/')\n        if args != '':\n            term_index = 0\n            for term in args.split('/'):\n                term = str(term.encode('utf-8'))\n                if (term in [key for (key, type_choice) in getTypeChoices() if\n                            term == type_choice]):\n                    term_sql += \" type LIKE ? \"\n                    params.append(\"%\" + term + \"%\")\n                    \n                elif term in [key for\n                             (key, format_choice) in getFormatChoices() if\n                             term == format_choice]:\n                    term_sql += \" format LIKE ? \"\n                    params.append(\"%\" + term + \"%\")\n                else:\n                    if (term_index > 0):\n                        term_sql += \" AND \" \n                    \n                    term_sql += \"( t.name LIKE ? \"\n                    term_sql += \" OR m.name LIKE ?\"\n                    term_sql += \" OR m.note LIKE ? )\"\n                    params.append(\"%\" + term + \"%\")\n                    params.append(\"%\" + term + \"%\")\n                    params.append(\"%\" + term + \"%\")\n                    \n                    term_index += 1\n                    \n                    \n        if (len(term_sql) > 0):\n            term_sql = ' AND (' + term_sql + ')'\n                            \n        logger.info(params)\n        sql = \"SELECT DISTINCT m.* FROM media_media m LEFT JOIN media_media_tags mt ON m.id = mt.media_id LEFT JOIN tag_tag t ON mt.tag_id = t.id  WHERE (\" + origin_sql + \" AND repository_id = ? ) \" + term_sql + \" ORDER BY \" + ordering_sql + \" LIMIT ? \"\n        sql = sql.decode('utf-8')\n        \n        params.extend(ordering_params)\n        params.extend(limiting_params)\n        \n        medias = Media.objects.raw(sql, params)\n        \n        \"\"\" sql log\n        logger.info('sql: ' + sql)\n        \"\"\"\n        \n        # serializa e da saida\n        serializer = MediaSerializer(medias, many=True)\n        logger.info(serializer.data)\n                \n        return Response(serializer.data)", "line_changes": {"deleted": [{"line_no": 62, "char_start": 2098, "char_end": 2154, "line": "            limiting_str = int(args.split('limit/')[1])\n"}, {"line_no": 65, "char_start": 2211, "char_end": 2252, "line": "            limiting_str = default_limit\n"}, {"line_no": 68, "char_start": 2307, "char_end": 2333, "line": "        ordering_str = ''\n"}, {"line_no": 82, "char_start": 2894, "char_end": 2903, "line": "        \n"}, {"line_no": 83, "char_start": 2903, "char_end": 2954, "line": "            ordering_str = ','.join(ordering_list)\n"}, {"line_no": 87, "char_start": 3026, "char_end": 3062, "line": "            ordering_str = 'm.name'\n"}, {"line_no": 90, "char_start": 3118, "char_end": 3140, "line": "        term_str = \"\"\n"}, {"line_no": 95, "char_start": 3263, "char_end": 3296, "line": "                term = str(term)\n"}, {"line_no": 98, "char_start": 3426, "char_end": 3488, "line": "                    term_str += ' type LIKE \"%' + term + '%\"'\n"}, {"line_no": 102, "char_start": 3654, "char_end": 3719, "line": "                    term_str += ' format LIKE \"%' + term + '\"%\"'\n"}, {"line_no": 105, "char_start": 3782, "char_end": 3825, "line": "                        term_str += 'AND' \n"}, {"line_no": 107, "char_start": 3846, "char_end": 3911, "line": "                    term_str += '( t.name LIKE \"%' + term + '%\"'\n"}, {"line_no": 108, "char_start": 3911, "char_end": 3978, "line": "                    term_str += ' OR m.name LIKE \"%' + term + '%\"'\n"}, {"line_no": 109, "char_start": 3978, "char_end": 4046, "line": "                    term_str += ' OR m.note LIKE \"%' + term + '%\")'\n"}, {"line_no": 113, "char_start": 4124, "char_end": 4156, "line": "        if (len(term_str) > 0):\n"}, {"line_no": 114, "char_start": 4156, "char_end": 4205, "line": "            term_str = ' AND (' + term_str + ')'\n"}, {"line_no": 115, "char_start": 4205, "char_end": 4214, "line": "        \n"}, {"line_no": 116, "char_start": 4214, "char_end": 4274, "line": "        \"\"\" exclude the content of own mucua on the network\n"}, {"line_no": 117, "char_start": 4274, "char_end": 4360, "line": "        TODO: maybe create also an option for including or not the own mucua data \"\"\"\n"}, {"line_no": 118, "char_start": 4360, "char_end": 4390, "line": "        if (mucua == 'rede'):\n"}, {"line_no": 119, "char_start": 4390, "char_end": 4450, "line": "            origin_str = \"origin_id!=\" + str(this_mucua.id)\n"}, {"line_no": 120, "char_start": 4450, "char_end": 4464, "line": "        else:\n"}, {"line_no": 121, "char_start": 4464, "char_end": 4518, "line": "            origin_str = \"origin_id=\" + str(mucua.id)\n"}, {"line_no": 123, "char_start": 4527, "char_end": 4800, "line": "        sql ='SELECT DISTINCT m.* FROM media_media m LEFT JOIN media_media_tags mt ON m.id = mt.media_id LEFT JOIN tag_tag t ON mt.tag_id = t.id  WHERE (%s AND repository_id = %d) %s ORDER BY %s LIMIT %s' % (origin_str, repository.id, term_str, ordering_str, limiting_str)\n"}, {"line_no": 125, "char_start": 4809, "char_end": 4849, "line": "        medias = Media.objects.raw(sql)\n"}], "added": [{"line_no": 60, "char_start": 2032, "char_end": 2052, "line": "        params = []\n"}, {"line_no": 61, "char_start": 2052, "char_end": 2061, "line": "        \n"}, {"line_no": 63, "char_start": 2088, "char_end": 2117, "line": "        limiting_params = []\n"}, {"line_no": 65, "char_start": 2156, "char_end": 2221, "line": "            limiting_params.append(str(args.split('limit/')[1]))\n"}, {"line_no": 68, "char_start": 2278, "char_end": 2333, "line": "            limiting_params.append(str(default_limit))\n"}, {"line_no": 71, "char_start": 2388, "char_end": 2414, "line": "        ordering_sql = ''\n"}, {"line_no": 72, "char_start": 2414, "char_end": 2443, "line": "        ordering_params = []\n"}, {"line_no": 86, "char_start": 3004, "char_end": 3021, "line": "                \n"}, {"line_no": 87, "char_start": 3021, "char_end": 3064, "line": "            for ordering in ordering_list:\n"}, {"line_no": 88, "char_start": 3064, "char_end": 3102, "line": "                ordering_sql += '%s,'\n"}, {"line_no": 89, "char_start": 3102, "char_end": 3151, "line": "                ordering_params.append(ordering)\n"}, {"line_no": 90, "char_start": 3151, "char_end": 3164, "line": "            \n"}, {"line_no": 92, "char_start": 3217, "char_end": 3258, "line": "            if ordering_sql[:-1] == ',':\n"}, {"line_no": 93, "char_start": 3258, "char_end": 3307, "line": "                ordering_sql = ordering_sql[:-1]\n"}, {"line_no": 97, "char_start": 3379, "char_end": 3415, "line": "            ordering_sql = 'm.name'\n"}, {"line_no": 98, "char_start": 3415, "char_end": 3424, "line": "        \n"}, {"line_no": 99, "char_start": 3424, "char_end": 3484, "line": "        \"\"\" exclude the content of own mucua on the network\n"}, {"line_no": 100, "char_start": 3484, "char_end": 3570, "line": "        TODO: maybe create also an option for including or not the own mucua data \"\"\"\n"}, {"line_no": 101, "char_start": 3570, "char_end": 3600, "line": "        if (mucua == 'rede'):\n"}, {"line_no": 102, "char_start": 3600, "char_end": 3642, "line": "            origin_sql = \"origin_id!=?  \"\n"}, {"line_no": 103, "char_start": 3642, "char_end": 3683, "line": "            params.append(this_mucua.id)\n"}, {"line_no": 104, "char_start": 3683, "char_end": 3696, "line": "            \n"}, {"line_no": 105, "char_start": 3696, "char_end": 3710, "line": "        else:\n"}, {"line_no": 106, "char_start": 3710, "char_end": 3751, "line": "            origin_sql = \"origin_id=?  \"\n"}, {"line_no": 107, "char_start": 3751, "char_end": 3787, "line": "            params.append(mucua.id)\n"}, {"line_no": 109, "char_start": 3796, "char_end": 3834, "line": "        \"\"\" appends repository id \"\"\"\n"}, {"line_no": 110, "char_start": 3834, "char_end": 3871, "line": "        params.append(repository.id)\n"}, {"line_no": 111, "char_start": 3871, "char_end": 3872, "line": "\n"}, {"line_no": 113, "char_start": 3919, "char_end": 3941, "line": "        term_sql = \"\"\n"}, {"line_no": 118, "char_start": 4064, "char_end": 4113, "line": "                term = str(term.encode('utf-8'))\n"}, {"line_no": 121, "char_start": 4243, "char_end": 4291, "line": "                    term_sql += \" type LIKE ? \"\n"}, {"line_no": 122, "char_start": 4291, "char_end": 4343, "line": "                    params.append(\"%\" + term + \"%\")\n"}, {"line_no": 123, "char_start": 4343, "char_end": 4364, "line": "                    \n"}, {"line_no": 127, "char_start": 4530, "char_end": 4580, "line": "                    term_sql += \" format LIKE ? \"\n"}, {"line_no": 128, "char_start": 4580, "char_end": 4632, "line": "                    params.append(\"%\" + term + \"%\")\n"}, {"line_no": 131, "char_start": 4695, "char_end": 4740, "line": "                        term_sql += \" AND \" \n"}, {"line_no": 132, "char_start": 4740, "char_end": 4761, "line": "                    \n"}, {"line_no": 133, "char_start": 4761, "char_end": 4812, "line": "                    term_sql += \"( t.name LIKE ? \"\n"}, {"line_no": 134, "char_start": 4812, "char_end": 4864, "line": "                    term_sql += \" OR m.name LIKE ?\"\n"}, {"line_no": 135, "char_start": 4864, "char_end": 4918, "line": "                    term_sql += \" OR m.note LIKE ? )\"\n"}, {"line_no": 136, "char_start": 4918, "char_end": 4970, "line": "                    params.append(\"%\" + term + \"%\")\n"}, {"line_no": 137, "char_start": 4970, "char_end": 5022, "line": "                    params.append(\"%\" + term + \"%\")\n"}, {"line_no": 138, "char_start": 5022, "char_end": 5074, "line": "                    params.append(\"%\" + term + \"%\")\n"}, {"line_no": 143, "char_start": 5173, "char_end": 5205, "line": "        if (len(term_sql) > 0):\n"}, {"line_no": 144, "char_start": 5205, "char_end": 5254, "line": "            term_sql = ' AND (' + term_sql + ')'\n"}, {"line_no": 145, "char_start": 5254, "char_end": 5283, "line": "                            \n"}, {"line_no": 146, "char_start": 5283, "char_end": 5311, "line": "        logger.info(params)\n"}, {"line_no": 147, "char_start": 5311, "char_end": 5565, "line": "        sql = \"SELECT DISTINCT m.* FROM media_media m LEFT JOIN media_media_tags mt ON m.id = mt.media_id LEFT JOIN tag_tag t ON mt.tag_id = t.id  WHERE (\" + origin_sql + \" AND repository_id = ? ) \" + term_sql + \" ORDER BY \" + ordering_sql + \" LIMIT ? \"\n"}, {"line_no": 148, "char_start": 5565, "char_end": 5599, "line": "        sql = sql.decode('utf-8')\n"}, {"line_no": 150, "char_start": 5608, "char_end": 5647, "line": "        params.extend(ordering_params)\n"}, {"line_no": 151, "char_start": 5647, "char_end": 5686, "line": "        params.extend(limiting_params)\n"}, {"line_no": 153, "char_start": 5695, "char_end": 5743, "line": "        medias = Media.objects.raw(sql, params)\n"}, {"line_no": 161, "char_start": 5915, "char_end": 5952, "line": "        logger.info(serializer.data)\n"}, {"line_no": 162, "char_start": 5952, "char_end": 5969, "line": "                \n"}]}, "char_changes": {"deleted": [{"char_start": 2040, "char_end": 2058, "chars": "default_limit = 20"}, {"char_start": 2119, "char_end": 2128, "chars": "str = int"}, {"char_start": 2232, "char_end": 2238, "chars": "str = "}, {"char_start": 2325, "char_end": 2327, "chars": "tr"}, {"char_start": 2915, "char_end": 3070, "chars": "ordering_str = ','.join(ordering_list)\n            \n            args = args.split('orderby/')[0]\n        else:\n            ordering_str = 'm.name'\n        "}, {"char_start": 3132, "char_end": 3134, "chars": "tr"}, {"char_start": 3452, "char_end": 3454, "chars": "tr"}, {"char_start": 3458, "char_end": 3459, "chars": "'"}, {"char_start": 3472, "char_end": 3473, "chars": "'"}, {"char_start": 3483, "char_end": 3484, "chars": "'"}, {"char_start": 3486, "char_end": 3487, "chars": "'"}, {"char_start": 3680, "char_end": 3682, "chars": "tr"}, {"char_start": 3686, "char_end": 3687, "chars": "'"}, {"char_start": 3702, "char_end": 3703, "chars": "'"}, {"char_start": 3713, "char_end": 3714, "chars": "'"}, {"char_start": 3717, "char_end": 3718, "chars": "'"}, {"char_start": 3812, "char_end": 3814, "chars": "tr"}, {"char_start": 3818, "char_end": 3819, "chars": "'"}, {"char_start": 3822, "char_end": 3823, "chars": "'"}, {"char_start": 3872, "char_end": 3874, "chars": "tr"}, {"char_start": 3878, "char_end": 3879, "chars": "'"}, {"char_start": 3893, "char_end": 3910, "chars": "\"%' + term + '%\"'"}, {"char_start": 3937, "char_end": 3939, "chars": "tr"}, {"char_start": 3943, "char_end": 3944, "chars": "'"}, {"char_start": 3961, "char_end": 3977, "chars": "%' + term + '%\"'"}, {"char_start": 4004, "char_end": 4006, "chars": "tr"}, {"char_start": 4010, "char_end": 4011, "chars": "'"}, {"char_start": 4029, "char_end": 4030, "chars": "'"}, {"char_start": 4040, "char_end": 4041, "chars": "'"}, {"char_start": 4044, "char_end": 4045, "chars": "'"}, {"char_start": 4066, "char_end": 4204, "chars": "term_index += 1\n                    \n                    \n        if (len(term_str) > 0):\n            term_str = ' AND (' + term_str + ')'"}, {"char_start": 4213, "char_end": 4214, "chars": "\n"}, {"char_start": 4222, "char_end": 4449, "chars": "\"\"\" exclude the content of own mucua on the network\n        TODO: maybe create also an option for including or not the own mucua data \"\"\"\n        if (mucua == 'rede'):\n            origin_str = \"origin_id!=\" + str(this_mucua.id)"}, {"char_start": 4458, "char_end": 4464, "chars": "else:\n"}, {"char_start": 4476, "char_end": 4526, "chars": "origin_str = \"origin_id=\" + str(mucua.id)\n        "}, {"char_start": 4540, "char_end": 4541, "chars": "'"}, {"char_start": 4680, "char_end": 4682, "chars": "%s"}, {"char_start": 4703, "char_end": 4786, "chars": "%d) %s ORDER BY %s LIMIT %s' % (origin_str, repository.id, term_str, ordering_str, "}, {"char_start": 4795, "char_end": 4798, "chars": "str"}], "added": [{"char_start": 2040, "char_end": 2116, "chars": "params = []\n        \n        default_limit = 20\n        limiting_params = []"}, {"char_start": 2177, "char_end": 2194, "chars": "params.append(str"}, {"char_start": 2219, "char_end": 2220, "chars": ")"}, {"char_start": 2299, "char_end": 2317, "chars": "params.append(str("}, {"char_start": 2330, "char_end": 2332, "chars": "))"}, {"char_start": 2406, "char_end": 2408, "chars": "ql"}, {"char_start": 2414, "char_end": 2443, "chars": "        ordering_params = []\n"}, {"char_start": 3012, "char_end": 3020, "chars": "        "}, {"char_start": 3033, "char_end": 3871, "chars": "for ordering in ordering_list:\n                ordering_sql += '%s,'\n                ordering_params.append(ordering)\n            \n            # remove last char if it's a comma / ','\n            if ordering_sql[:-1] == ',':\n                ordering_sql = ordering_sql[:-1]\n            \n            args = args.split('orderby/')[0]\n        else:\n            ordering_sql = 'm.name'\n        \n        \"\"\" exclude the content of own mucua on the network\n        TODO: maybe create also an option for including or not the own mucua data \"\"\"\n        if (mucua == 'rede'):\n            origin_sql = \"origin_id!=?  \"\n            params.append(this_mucua.id)\n            \n        else:\n            origin_sql = \"origin_id=?  \"\n            params.append(mucua.id)\n        \n        \"\"\" appends repository id \"\"\"\n        params.append(repository.id)\n"}, {"char_start": 3933, "char_end": 3935, "chars": "ql"}, {"char_start": 4095, "char_end": 4111, "chars": ".encode('utf-8')"}, {"char_start": 4269, "char_end": 4271, "chars": "ql"}, {"char_start": 4275, "char_end": 4276, "chars": "\""}, {"char_start": 4287, "char_end": 4325, "chars": "? \"\n                    params.append("}, {"char_start": 4327, "char_end": 4328, "chars": "\""}, {"char_start": 4338, "char_end": 4339, "chars": "\""}, {"char_start": 4341, "char_end": 4363, "chars": ")\n                    "}, {"char_start": 4556, "char_end": 4558, "chars": "ql"}, {"char_start": 4562, "char_end": 4563, "chars": "\""}, {"char_start": 4576, "char_end": 4614, "chars": "? \"\n                    params.append("}, {"char_start": 4616, "char_end": 4617, "chars": "\""}, {"char_start": 4630, "char_end": 4631, "chars": ")"}, {"char_start": 4725, "char_end": 4727, "chars": "ql"}, {"char_start": 4731, "char_end": 4733, "chars": "\" "}, {"char_start": 4736, "char_end": 4738, "chars": " \""}, {"char_start": 4787, "char_end": 4789, "chars": "ql"}, {"char_start": 4793, "char_end": 4794, "chars": "\""}, {"char_start": 4808, "char_end": 4811, "chars": "? \""}, {"char_start": 4838, "char_end": 4840, "chars": "ql"}, {"char_start": 4844, "char_end": 4845, "chars": "\""}, {"char_start": 4861, "char_end": 4862, "chars": "?"}, {"char_start": 4890, "char_end": 4892, "chars": "ql"}, {"char_start": 4896, "char_end": 4897, "chars": "\""}, {"char_start": 4913, "char_end": 4952, "chars": "? )\"\n                    params.append("}, {"char_start": 4954, "char_end": 4955, "chars": "\""}, {"char_start": 4965, "char_end": 4966, "chars": "\""}, {"char_start": 4990, "char_end": 5074, "chars": "params.append(\"%\" + term + \"%\")\n                    params.append(\"%\" + term + \"%\")\n"}, {"char_start": 5093, "char_end": 5130, "chars": " \n                    term_index += 1"}, {"char_start": 5147, "char_end": 5253, "chars": "    \n                    \n        if (len(term_sql) > 0):\n            term_sql = ' AND (' + term_sql + ')'"}, {"char_start": 5262, "char_end": 5266, "chars": "    "}, {"char_start": 5278, "char_end": 5310, "chars": "    \n        logger.info(params)"}, {"char_start": 5324, "char_end": 5326, "chars": " \""}, {"char_start": 5465, "char_end": 5483, "chars": "\" + origin_sql + \""}, {"char_start": 5504, "char_end": 5669, "chars": "? ) \" + term_sql + \" ORDER BY \" + ordering_sql + \" LIMIT ? \"\n        sql = sql.decode('utf-8')\n        \n        params.extend(ordering_params)\n        params.extend("}, {"char_start": 5678, "char_end": 5684, "chars": "params"}, {"char_start": 5733, "char_end": 5741, "chars": ", params"}, {"char_start": 5915, "char_end": 5969, "chars": "        logger.info(serializer.data)\n                \n"}]}, "commit_link": "github.com/RedeMocambos/baobaxia/commit/593ae99b691cd948f621656d2f5735045a6b0afc", "file_name": "app/django-bbx/media/views.py", "vul_type": "cwe-089"}
{"func_name": "find_rides", "func_src_before": "    def find_rides(self, driver):\n        query = '''\n        SELECT r.rno, r.price, r.rdate, r.seats, r.lugDesc, r.src, r.dst, r.driver, r.cno, r.seats-COUNT(b.bno) \n        FROM rides r, bookings b\n        WHERE driver = '{driver}'\n        AND r.rno = b.bno \n        GROUP BY r.rno, r.price, r.rdate, r.seats, r.lugDesc, r.src, r.dst, r.driver, r.cno\n        '''.format(driver = driver)\n\n        self.cursor.execute(query)\n        self.rides = self.cursor.fetchall()", "func_src_after": "    def find_rides(self, driver):\n        self.cursor.execute('''\n        SELECT r.rno, r.price, r.rdate, r.seats, r.lugDesc, r.src, r.dst, r.driver, r.cno, r.seats-COUNT(b.bno) \n        FROM rides r, bookings b\n        WHERE driver = ':driver'\n        AND r.rno = b.bno \n        GROUP BY r.rno, r.price, r.rdate, r.seats, r.lugDesc, r.src, r.dst, r.driver, r.cno\n        ''', {'driver': driver})\n        self.rides = self.cursor.fetchall()\n\n        # create rides dictionary for quick access \n        for ride in self.rides:\n            self.rides_dict[ride[0]] = self.rides[1:]", "line_changes": {"deleted": [{"line_no": 2, "char_start": 34, "char_end": 54, "line": "        query = '''\n"}, {"line_no": 5, "char_start": 200, "char_end": 234, "line": "        WHERE driver = '{driver}'\n"}, {"line_no": 8, "char_start": 353, "char_end": 389, "line": "        '''.format(driver = driver)\n"}, {"line_no": 9, "char_start": 389, "char_end": 390, "line": "\n"}, {"line_no": 10, "char_start": 390, "char_end": 425, "line": "        self.cursor.execute(query)\n"}], "added": [{"line_no": 2, "char_start": 34, "char_end": 66, "line": "        self.cursor.execute('''\n"}, {"line_no": 5, "char_start": 212, "char_end": 245, "line": "        WHERE driver = ':driver'\n"}, {"line_no": 8, "char_start": 364, "char_end": 397, "line": "        ''', {'driver': driver})\n"}]}, "char_changes": {"deleted": [{"char_start": 42, "char_end": 50, "chars": "query = "}, {"char_start": 224, "char_end": 225, "chars": "{"}, {"char_start": 231, "char_end": 232, "chars": "}"}, {"char_start": 364, "char_end": 372, "chars": ".format("}, {"char_start": 378, "char_end": 380, "chars": " ="}, {"char_start": 388, "char_end": 389, "chars": "\n"}, {"char_start": 403, "char_end": 468, "chars": "cursor.execute(query)\n        self.rides = self.cursor.fetchall()"}], "added": [{"char_start": 42, "char_end": 62, "chars": "self.cursor.execute("}, {"char_start": 236, "char_end": 237, "chars": ":"}, {"char_start": 375, "char_end": 379, "chars": ", {'"}, {"char_start": 385, "char_end": 387, "chars": "':"}, {"char_start": 394, "char_end": 395, "chars": "}"}, {"char_start": 410, "char_end": 579, "chars": "rides = self.cursor.fetchall()\n\n        # create rides dictionary for quick access \n        for ride in self.rides:\n            self.rides_dict[ride[0]] = self.rides[1:]"}]}, "commit_link": "github.com/kenboo98/291-Mini-Project-I/commit/3080ccb687c79c83954ce703faee8fcceec8c9eb", "file_name": "book_rides/book_rides.py", "vul_type": "cwe-089"}
{"func_name": "verify_email", "func_src_before": "    def verify_email(self, member):\n        query = \"SELECT COUNT(email) FROM members WHERE email = '{email}'\".format(email = member)\n        self.cursor.execute(query)\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "func_src_after": "    def verify_email(self, member):\n        self.cursor.execute(\"SELECT COUNT(email) FROM members WHERE email = ':email'\", {'email':member})\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "line_changes": {"deleted": [{"line_no": 2, "char_start": 36, "char_end": 134, "line": "        query = \"SELECT COUNT(email) FROM members WHERE email = '{email}'\".format(email = member)\n"}, {"line_no": 3, "char_start": 134, "char_end": 169, "line": "        self.cursor.execute(query)\n"}], "added": [{"line_no": 2, "char_start": 36, "char_end": 141, "line": "        self.cursor.execute(\"SELECT COUNT(email) FROM members WHERE email = ':email'\", {'email':member})\n"}]}, "char_changes": {"deleted": [{"char_start": 44, "char_end": 52, "chars": "query = "}, {"char_start": 101, "char_end": 102, "chars": "{"}, {"char_start": 107, "char_end": 108, "chars": "}"}, {"char_start": 110, "char_end": 118, "chars": ".format("}, {"char_start": 123, "char_end": 126, "chars": " = "}, {"char_start": 132, "char_end": 167, "chars": ")\n        self.cursor.execute(query"}], "added": [{"char_start": 44, "char_end": 64, "chars": "self.cursor.execute("}, {"char_start": 113, "char_end": 114, "chars": ":"}, {"char_start": 121, "char_end": 125, "chars": ", {'"}, {"char_start": 130, "char_end": 132, "chars": "':"}, {"char_start": 138, "char_end": 139, "chars": "}"}]}, "commit_link": "github.com/kenboo98/291-Mini-Project-I/commit/3080ccb687c79c83954ce703faee8fcceec8c9eb", "file_name": "book_rides/book_rides.py", "vul_type": "cwe-089"}
{"func_name": "verify_rno", "func_src_before": "    def verify_rno(self, rno):\n        query = \"SELECT COUNT(rno) FROM rides WHERE rno = {rno}\".format(rno = rno)\n        self.cursor.execute(query)\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "func_src_after": "    def verify_rno(self, rno):\n        self.cursor.execute(\"SELECT COUNT(rno) FROM rides WHERE rno = :rno\", {'rno': rno})\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 114, "line": "        query = \"SELECT COUNT(rno) FROM rides WHERE rno = {rno}\".format(rno = rno)\n"}, {"line_no": 3, "char_start": 114, "char_end": 149, "line": "        self.cursor.execute(query)\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 122, "line": "        self.cursor.execute(\"SELECT COUNT(rno) FROM rides WHERE rno = :rno\", {'rno': rno})\n"}]}, "char_changes": {"deleted": [{"char_start": 39, "char_end": 47, "chars": "query = "}, {"char_start": 89, "char_end": 90, "chars": "{"}, {"char_start": 93, "char_end": 103, "chars": "}\".format("}, {"char_start": 106, "char_end": 108, "chars": " ="}, {"char_start": 112, "char_end": 147, "chars": ")\n        self.cursor.execute(query"}], "added": [{"char_start": 39, "char_end": 59, "chars": "self.cursor.execute("}, {"char_start": 101, "char_end": 102, "chars": ":"}, {"char_start": 105, "char_end": 120, "chars": "\", {'rno': rno}"}]}, "commit_link": "github.com/kenboo98/291-Mini-Project-I/commit/3080ccb687c79c83954ce703faee8fcceec8c9eb", "file_name": "book_rides/book_rides.py", "vul_type": "cwe-089"}
{"func_name": "book_ride", "func_src_before": "    def book_ride(self):\n\n        try:\n            rno = input(\"Please enter a rno: \")\n            \n            if (not self.verify_rno(rno)):\n                raise InvalidRNOError\n\n            member = input(\"Please enter the email of the member you want to book on the ride: \")\n\n            if (not self.verify_email(member)):\n                raise InvalidMemberError\n\n            pickup = input(\"Please enter pick up location code: \")\n            dropoff = input(\"Please enter pick up location code: \")\n\n            if (not self.verify_location(pickup) or not self.verify_location(dropoff)):\n                raise InvalidLocationError\n\n            if (not self.verify_email(member)):\n                raise InvalidMemberError\n\n            cost = input(\"Please enter the cost for ride: \")\n\n            seats = input(\"Please enter the number of seats for ride: \")\n\n            #if (int(seats) > self.rides[rno]\n\n            #get unique booking number\n            bno = self.generate_bno()\n            \n\n            query = '''INSERT INTO bookings VALUES ({bno}, {member}, {rno}, {cost}, {seats}, {pickup}, {dropoff})\n                    '''.format(bno = bno, member = member, rno = rno, cost = cost, seats = seats, pickup = pickup, dropoff = dropoff)\n            \n            print(query)\n\n        except InvalidRNOError:\n            print(\"Please enter a valid rno\") \n            self.display_rides(1)\n        except InvalidMemberError:\n            print(\"Please enter a valid member email\")\n            self.display_rides(1)\n        except InvalidLocationError:\n            print(\"Please enter a valid pickup and dropoff location code\")\n            self.display_rides(1)", "func_src_after": "    def book_ride(self):\n\n        try:\n            rno = input(\"Please enter a rno: \")\n            \n            if (not self.verify_rno(rno)):\n                raise InvalidRNOError\n\n            member = input(\"Please enter the email of the member you want to book on the ride: \")\n\n            if (not self.verify_email(member)):\n                raise InvalidMemberError\n\n            pickup = input(\"Please enter pick up location code: \")\n            dropoff = input(\"Please enter pick up location code: \")\n\n            if (not self.verify_location(pickup) or not self.verify_location(dropoff)):\n                raise InvalidLocationError\n\n            if (not self.verify_email(member)):\n                raise InvalidMemberError\n\n            cost = input(\"Please enter the cost for ride: \")\n\n            seats = input(\"Please enter the number of seats for ride: \")\n\n            if (int(seats) > self.rides_dict[rno][-1]):\n                overbook = input(\"Warning: the ride is being over booked, are you sure you want to continue (y/n)\")\n                if overbook == 'n':\n                    raise OverbookError\n                else:\n                    pass\n\n            #get unique booking number\n            bno = self.generate_bno()\n\n            query = '''INSERT INTO bookings VALUES ({bno}, {member}, {rno}, {cost}, {seats}, {pickup}, {dropoff})\n                    '''.format(bno = bno, member = member, rno = rno, cost = cost, seats = seats, pickup = pickup, dropoff = dropoff)\n            \n            print(query)\n\n        except InvalidRNOError:\n            print(\"Please enter a valid rno\") \n            self.display_rides(1)\n        except InvalidMemberError:\n            print(\"Please enter a valid member email\")\n            self.display_rides(1)\n        except InvalidLocationError:\n            print(\"Please enter a valid pickup and dropoff location code\")\n            self.display_rides(1)\n        except OverbookError:\n            print(\"Please select a fewer number of seats\")\n            self.display_rides(1)", "line_changes": {"deleted": [{"line_no": 31, "char_start": 989, "char_end": 1002, "line": "            \n"}], "added": [{"line_no": 27, "char_start": 865, "char_end": 921, "line": "            if (int(seats) > self.rides_dict[rno][-1]):\n"}, {"line_no": 28, "char_start": 921, "char_end": 1037, "line": "                overbook = input(\"Warning: the ride is being over booked, are you sure you want to continue (y/n)\")\n"}, {"line_no": 29, "char_start": 1037, "char_end": 1073, "line": "                if overbook == 'n':\n"}, {"line_no": 30, "char_start": 1073, "char_end": 1113, "line": "                    raise OverbookError\n"}, {"line_no": 31, "char_start": 1113, "char_end": 1135, "line": "                else:\n"}, {"line_no": 32, "char_start": 1135, "char_end": 1160, "line": "                    pass\n"}, {"line_no": 51, "char_start": 1909, "char_end": 1939, "line": "        except OverbookError:\n"}, {"line_no": 52, "char_start": 1939, "char_end": 1998, "line": "            print(\"Please select a fewer number of seats\")\n"}, {"line_no": 53, "char_start": 1998, "char_end": 2031, "line": "            self.display_rides(1)\n"}]}, "char_changes": {"deleted": [{"char_start": 877, "char_end": 878, "chars": "#"}, {"char_start": 905, "char_end": 910, "chars": "[rno]"}, {"char_start": 988, "char_end": 1001, "chars": "\n            "}], "added": [{"char_start": 904, "char_end": 1159, "chars": "_dict[rno][-1]):\n                overbook = input(\"Warning: the ride is being over booked, are you sure you want to continue (y/n)\")\n                if overbook == 'n':\n                    raise OverbookError\n                else:\n                    pass"}, {"char_start": 1908, "char_end": 2031, "chars": "\n        except OverbookError:\n            print(\"Please select a fewer number of seats\")\n            self.display_rides(1)"}]}, "commit_link": "github.com/kenboo98/291-Mini-Project-I/commit/3080ccb687c79c83954ce703faee8fcceec8c9eb", "file_name": "book_rides/book_rides.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self,data):\n        connection = self.connect()\n        try:\n            # The following is a flaw\n            query = \"INSERT INTO crimes(description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self,data):\n        connection = self.connect()\n        try:\n            # The following is a flaw\n            query = \"INSERT INTO crimes(description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 117, "char_end": 199, "line": "            query = \"INSERT INTO crimes(description) VALUES ('{}');\".format(data)\n"}, {"line_no": 7, "char_start": 247, "char_end": 285, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 5, "char_start": 117, "char_end": 184, "line": "            query = \"INSERT INTO crimes(description) VALUES (%s);\"\n"}, {"line_no": 7, "char_start": 232, "char_end": 276, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 178, "char_end": 198, "chars": "'{}');\".format(data)"}], "added": [{"char_start": 178, "char_end": 183, "chars": "%s);\""}, {"char_start": 268, "char_end": 274, "chars": ", data"}]}, "commit_link": "github.com/amrishc/crimemap/commit/51b3d51aa031d7c285295de36f5464d43debf6de", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "do_HEAD", "func_src_before": "    def do_HEAD(self):\n        conn = sqlite3.connect(config)\n        # this will be where response will be figured out based on database query\n        c = conn.cursor()\n        # vars\n        dte = self.date_time_string()\n        cladd = '%s' % self.address_string()\n        cmd = '%s' % self.command\n        path = '%s' % self.path\n        UserAgentString = '%s' % str(self.headers['user-agent'])\n        rvers = '%s' % self.request_version\n        c.execute(\"INSERT INTO requests VALUES('\"+dte+\"','\"+cladd+\"','\"+cmd+\"','\"+path+\"','\"+UserAgentString+\"','\"+rvers+\"')\") # logging\n        try:\n            c.execute(\"INSERT INTO useragents VALUES(NULL,NULL,'\"+UserAgentString+\"')\") # trying to find all the new useragentstrings\n        except sqlite3.IntegrityError:\n            RefID = c.execute(\"SELECT RefID FROM useragents WHERE useragent='\"+UserAgentString+\"'\").fetchone() #get RefID if there is one - should be set in Backend\n            #print(str(RefID[0]))\n            if str(RefID[0]) != \"None\":\n                Resp = c.execute(\"SELECT * FROM responses WHERE RID=\"+str(RefID[0])+\"\").fetchall()\n                #self.send_response(200)\n                #print(Resp[1][3])\n                for i in Resp:\n                    self.send_header(i[2], i[3])\n                #self.send_header(Resp[1][2], Resp[1][3])\n                self.send_header('Date', self.date_time_string(time.time())) # can potentially have multiple if not careful\n                self.end_headers() #iterates through DB - need to make sure vuln pages and this are synced.\n            else:\n                print(\"Useragent: '\"+UserAgentString+\"' needs a custom response.\")  #get RefID if there is one - should be set in Backend\n        except:\n            self.send_response(200)\n            self.end_headers()\n        finally:\n            conn.commit()", "func_src_after": "    def do_HEAD(self):\n        conn = sqlite3.connect(config)\n        # this will be where response will be figured out based on database query\n        c = conn.cursor()\n        # vars\n        dte = self.date_time_string()\n        cladd = '%s' % self.address_string()\n        cmd = '%s' % self.command\n        path = '%s' % self.path\n        UserAgentString = '%s' % str(self.headers['user-agent'])\n        rvers = '%s' % self.request_version\n        c.execute(\"\"\"INSERT INTO requests (date, address, cmd, path, useragent, vers) VALUES (?,?,?,?,?,?)\"\"\",(dte,cladd,cmd,path,UserAgentString,rvers)) # logging\n        try:\n            c.execute(\"\"\"INSERT INTO useragents (useragent) VALUES (?)\"\"\",(UserAgentString)) # trying to find all the new useragentstrings\n        except sqlite3.IntegrityError:\n            RefID = c.execute(\"\"\"SELECT RefID FROM useragents WHERE useragent=?\"\"\",(UserAgentString)).fetchone() #get RefID if there is one - should be set in Backend\n            #print(str(RefID[0]))\n            if str(RefID[0]) != \"None\":\n                Resp = c.execute(\"\"\"SELECT * FROM responses WHERE RID=?\"\"\",(RefID[0])).fetchall()\n                #self.send_response(200)\n                #print(Resp[1][3])\n                for i in Resp:\n                    self.send_header(i[2], i[3])\n                #self.send_header(Resp[1][2], Resp[1][3])\n                self.send_header('Date', self.date_time_string(time.time())) # can potentially have multiple if not careful\n                self.end_headers() #iterates through DB - need to make sure vuln pages and this are synced.\n            else:\n                print(\"Useragent: '\"+UserAgentString+\"' needs a custom response.\")  #get RefID if there is one - should be set in Backend\n        except:\n            self.send_response(200)\n            self.end_headers()\n        finally:\n            conn.commit()", "line_changes": {"deleted": [{"line_no": 12, "char_start": 443, "char_end": 580, "line": "        c.execute(\"INSERT INTO requests VALUES('\"+dte+\"','\"+cladd+\"','\"+cmd+\"','\"+path+\"','\"+UserAgentString+\"','\"+rvers+\"')\") # logging\n"}, {"line_no": 14, "char_start": 593, "char_end": 727, "line": "            c.execute(\"INSERT INTO useragents VALUES(NULL,NULL,'\"+UserAgentString+\"')\") # trying to find all the new useragentstrings\n"}, {"line_no": 16, "char_start": 766, "char_end": 931, "line": "            RefID = c.execute(\"SELECT RefID FROM useragents WHERE useragent='\"+UserAgentString+\"'\").fetchone() #get RefID if there is one - should be set in Backend\n"}, {"line_no": 19, "char_start": 1005, "char_end": 1104, "line": "                Resp = c.execute(\"SELECT * FROM responses WHERE RID=\"+str(RefID[0])+\"\").fetchall()\n"}], "added": [{"line_no": 12, "char_start": 443, "char_end": 607, "line": "        c.execute(\"\"\"INSERT INTO requests (date, address, cmd, path, useragent, vers) VALUES (?,?,?,?,?,?)\"\"\",(dte,cladd,cmd,path,UserAgentString,rvers)) # logging\n"}, {"line_no": 14, "char_start": 620, "char_end": 759, "line": "            c.execute(\"\"\"INSERT INTO useragents (useragent) VALUES (?)\"\"\",(UserAgentString)) # trying to find all the new useragentstrings\n"}, {"line_no": 16, "char_start": 798, "char_end": 965, "line": "            RefID = c.execute(\"\"\"SELECT RefID FROM useragents WHERE useragent=?\"\"\",(UserAgentString)).fetchone() #get RefID if there is one - should be set in Backend\n"}, {"line_no": 19, "char_start": 1039, "char_end": 1137, "line": "                Resp = c.execute(\"\"\"SELECT * FROM responses WHERE RID=?\"\"\",(RefID[0])).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 483, "char_end": 568, "chars": "VALUES('\"+dte+\"','\"+cladd+\"','\"+cmd+\"','\"+path+\"','\"+UserAgentString+\"','\"+rvers+\"')\""}, {"char_start": 639, "char_end": 659, "chars": "VALUES(NULL,NULL,'\"+"}, {"char_start": 674, "char_end": 679, "chars": "+\"')\""}, {"char_start": 842, "char_end": 845, "chars": "'\"+"}, {"char_start": 860, "char_end": 864, "chars": "+\"'\""}, {"char_start": 1073, "char_end": 1078, "chars": "\"+str"}, {"char_start": 1088, "char_end": 1091, "chars": "+\"\""}], "added": [{"char_start": 462, "char_end": 464, "chars": "\"\""}, {"char_start": 485, "char_end": 595, "chars": "(date, address, cmd, path, useragent, vers) VALUES (?,?,?,?,?,?)\"\"\",(dte,cladd,cmd,path,UserAgentString,rvers)"}, {"char_start": 643, "char_end": 645, "chars": "\"\""}, {"char_start": 668, "char_end": 695, "chars": "(useragent) VALUES (?)\"\"\",("}, {"char_start": 710, "char_end": 711, "chars": ")"}, {"char_start": 829, "char_end": 831, "chars": "\"\""}, {"char_start": 876, "char_end": 882, "chars": "?\"\"\",("}, {"char_start": 897, "char_end": 898, "chars": ")"}, {"char_start": 1073, "char_end": 1075, "chars": "\"\""}, {"char_start": 1109, "char_end": 1114, "chars": "?\"\"\","}]}, "commit_link": "github.com/DShield-ISC/dshield/commit/aa907a12123031ba9f6491e307d4ae76fe6fa2fe", "file_name": "bin/web.py", "vul_type": "cwe-089"}
{"func_name": "fetch_product", "func_src_before": "\tdef fetch_product(self):\n\n\t\tconn = sql.connect(self.dbStr)\n\n\t\tc = conn.cursor()\n\n\t\tc.execute(\"SELECT * FROM {tn} WHERE {upc}={my_upc}\".\\\n\t        format(tn=self.table_name, cn=self.column_2, \n\t        \tupc=self.column_2, my_upc=self.some_upc))\n\t\t\n\t\tresult = c.fetchone()\n\n\t\treturn result", "func_src_after": "\tdef fetch_product(self):\n\n\t\tconn = sql.connect(self.dbStr)\n\n\t\tc = conn.cursor()\n\n\t\tmy_upc = self.some_upc\n\n\t\tc.execute(\"SELECT * FROM products WHERE upc='%s'\" % my_upc)\n\t\t\n\t\tresult = c.fetchone()\n\n\t\treturn result", "line_changes": {"deleted": [{"line_no": 7, "char_start": 82, "char_end": 138, "line": "\t\tc.execute(\"SELECT * FROM {tn} WHERE {upc}={my_upc}\".\\\n"}, {"line_no": 8, "char_start": 138, "char_end": 193, "line": "\t        format(tn=self.table_name, cn=self.column_2, \n"}, {"line_no": 9, "char_start": 193, "char_end": 245, "line": "\t        \tupc=self.column_2, my_upc=self.some_upc))\n"}], "added": [{"line_no": 7, "char_start": 82, "char_end": 107, "line": "\t\tmy_upc = self.some_upc\n"}, {"line_no": 8, "char_start": 107, "char_end": 108, "line": "\n"}, {"line_no": 9, "char_start": 108, "char_end": 170, "line": "\t\tc.execute(\"SELECT * FROM products WHERE upc='%s'\" % my_upc)\n"}]}, "char_changes": {"deleted": [{"char_start": 109, "char_end": 113, "chars": "{tn}"}, {"char_start": 120, "char_end": 121, "chars": "{"}, {"char_start": 124, "char_end": 243, "chars": "}={my_upc}\".\\\n\t        format(tn=self.table_name, cn=self.column_2, \n\t        \tupc=self.column_2, my_upc=self.some_upc)"}], "added": [{"char_start": 82, "char_end": 108, "chars": "\t\tmy_upc = self.some_upc\n\n"}, {"char_start": 135, "char_end": 143, "chars": "products"}, {"char_start": 153, "char_end": 168, "chars": "='%s'\" % my_upc"}]}, "commit_link": "github.com/kmangame0/raspi-telxon/commit/1904cdb2598236a0de3ac4af382fafea813c7a49", "file_name": "Scripts/Controller.py", "vul_type": "cwe-089"}
{"func_name": "post", "func_src_before": "    def post(self):\n        print(request.json)\n        Name = request.json['Name']\n        Password = request.json['Password']\n        query = conn.execute(\"INSERT INTO USERS(NAME, PASSWORD) VALUES ('\"+Name+\"', '\"+Password+\"')\");\n        conn.commit()\n        return {'status': 'success'}", "func_src_after": "    def post(self):\n        print(request.json)\n        Name = request.json['Name']\n        Password = request.json['Password']\n        query = conn.executes(\"INSERT INTO USERS(NAME, PASSWORD) VALUES ('\"+Name+\"', '\"+Password+\"')\");\n        conn.commit()\n        return {'status': 'success'}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 128, "char_end": 231, "line": "        query = conn.execute(\"INSERT INTO USERS(NAME, PASSWORD) VALUES ('\"+Name+\"', '\"+Password+\"')\");\n"}], "added": [{"line_no": 5, "char_start": 128, "char_end": 232, "line": "        query = conn.executes(\"INSERT INTO USERS(NAME, PASSWORD) VALUES ('\"+Name+\"', '\"+Password+\"')\");\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 156, "char_end": 157, "chars": "s"}]}, "commit_link": "github.com/antoinevdm/scalable-architecture/commit/a0f66ede93bf4524161b281f6fbc9fa6abd98c4c", "file_name": "src/user.py", "vul_type": "cwe-089"}
{"func_name": "show_entries", "func_src_before": "@app.route('/')\ndef show_entries():\n    if not session.get('logged_in'):\n        return redirect(url_for('users.login'))\n    user_id = session['logged_id']\n    sql = 'SELECT * FROM message where user_id = %d ORDER BY c_time DESC' \\\n        % (user_id)\n    cursor.execute(sql)\n    m = cursor.fetchall()\n    messages = list(m)\n    for i, message in enumerate(messages):\n        message = list(message)\n        user_id = message[1]\n        sql = 'SELECT nickname FROM users where user_id = %d' % user_id\n        cursor.execute(sql)\n        u = cursor.fetchone()\n        message.append(u[0])\n        sql = \"SELECT * FROM like_msg where msg_id = %d AND user_id = %d\" \\\n            % (message[0], user_id)\n        cursor.execute(sql)\n        like = cursor.fetchone()\n        if like is not None:\n            like_flag = 1\n        else:\n            like_flag = 0\n        message.append(like_flag)\n        messages[i] = message\n\n    return render_template('show_entries.html', entries=messages)", "func_src_after": "@app.route('/')\ndef show_entries():\n    if not session.get('logged_in'):\n        return redirect(url_for('users.login'))\n    user_id = session['logged_id']\n    cursor.execute(\"SELECT * FROM message where user_id = %s ORDER BY c_time DESC\", (user_id,))\n    m = cursor.fetchall()\n    messages = list(m)\n    for i, message in enumerate(messages):\n        message = list(message)\n        user_id = message[1]\n        cursor.execute(\"SELECT nickname FROM users where user_id = %s\", (user_id,))\n        u = cursor.fetchone()\n        message.append(u[0])\n        cursor.execute(\"SELECT * FROM like_msg where msg_id = %s AND user_id = %s\", (message[0], user_id))\n        like = cursor.fetchone()\n        if like is not None:\n            like_flag = 1\n        else:\n            like_flag = 0\n        message.append(like_flag)\n        messages[i] = message\n\n    return render_template('show_entries.html', entries=messages)", "line_changes": {"deleted": [{"line_no": 6, "char_start": 156, "char_end": 232, "line": "    sql = 'SELECT * FROM message where user_id = %d ORDER BY c_time DESC' \\\n"}, {"line_no": 7, "char_start": 232, "char_end": 252, "line": "        % (user_id)\n"}, {"line_no": 8, "char_start": 252, "char_end": 276, "line": "    cursor.execute(sql)\n"}, {"line_no": 14, "char_start": 429, "char_end": 501, "line": "        sql = 'SELECT nickname FROM users where user_id = %d' % user_id\n"}, {"line_no": 15, "char_start": 501, "char_end": 529, "line": "        cursor.execute(sql)\n"}, {"line_no": 18, "char_start": 588, "char_end": 664, "line": "        sql = \"SELECT * FROM like_msg where msg_id = %d AND user_id = %d\" \\\n"}, {"line_no": 19, "char_start": 664, "char_end": 700, "line": "            % (message[0], user_id)\n"}, {"line_no": 20, "char_start": 700, "char_end": 728, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 6, "char_start": 156, "char_end": 252, "line": "    cursor.execute(\"SELECT * FROM message where user_id = %s ORDER BY c_time DESC\", (user_id,))\n"}, {"line_no": 12, "char_start": 405, "char_end": 489, "line": "        cursor.execute(\"SELECT nickname FROM users where user_id = %s\", (user_id,))\n"}, {"line_no": 15, "char_start": 548, "char_end": 655, "line": "        cursor.execute(\"SELECT * FROM like_msg where msg_id = %s AND user_id = %s\", (message[0], user_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 160, "char_end": 167, "chars": "sql = '"}, {"char_start": 206, "char_end": 207, "chars": "d"}, {"char_start": 228, "char_end": 274, "chars": "' \\\n        % (user_id)\n    cursor.execute(sql"}, {"char_start": 437, "char_end": 444, "chars": "sql = '"}, {"char_start": 488, "char_end": 493, "chars": "d' % "}, {"char_start": 500, "char_end": 527, "chars": "\n        cursor.execute(sql"}, {"char_start": 596, "char_end": 602, "chars": "sql = "}, {"char_start": 642, "char_end": 643, "chars": "d"}, {"char_start": 659, "char_end": 677, "chars": "d\" \\\n            %"}, {"char_start": 699, "char_end": 726, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 160, "char_end": 176, "chars": "cursor.execute(\""}, {"char_start": 215, "char_end": 216, "chars": "s"}, {"char_start": 237, "char_end": 250, "chars": "\", (user_id,)"}, {"char_start": 413, "char_end": 429, "chars": "cursor.execute(\""}, {"char_start": 473, "char_end": 478, "chars": "s\", ("}, {"char_start": 485, "char_end": 487, "chars": ",)"}, {"char_start": 556, "char_end": 571, "chars": "cursor.execute("}, {"char_start": 611, "char_end": 612, "chars": "s"}, {"char_start": 628, "char_end": 631, "chars": "s\","}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/flaskr2.py", "vul_type": "cwe-089"}
{"func_name": "show", "func_src_before": "@mod.route('/show/<int:msg_id>', methods=['GET', 'POST'])\ndef show(msg_id):\n    user_id = session['logged_id']\n    if request.method == 'GET':\n        sql = \"SELECT * FROM message where msg_id = %d;\" % (msg_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        sql = \"SELECT * FROM comment where msg_id = %d;\" % (msg_id)\n        cursor.execute(sql)\n        cs = cursor.fetchall()\n        if cs is None:\n            cs = ()\n        cs = list(cs)\n        for i, comment in enumerate(cs):\n            comment = list(comment)\n            sql = \"SELECT nickname FROM users where user_id = %d\" % user_id\n            cursor.execute(sql)\n            u = cursor.fetchone()\n            comment.append(u[0])\n            sql = \"SELECT * FROM like_cmt where cmt_id = %d AND user_id = %d\" \\\n                % (comment[0], user_id)\n            cursor.execute(sql)\n            like = cursor.fetchone()\n            if like is not None:\n                like_flag = 1\n            else:\n                like_flag = 0\n            comment.append(like_flag)\n            cs[i] = comment\n    return render_template('comment/show.html', m=m, cs=cs)", "func_src_after": "@mod.route('/show/<int:msg_id>', methods=['GET', 'POST'])\ndef show(msg_id):\n    user_id = session['logged_id']\n    if request.method == 'GET':\n        cursor.execute(\"SELECT * FROM message where msg_id = %s;\", (msg_id,))\n        m = cursor.fetchone()\n        cursor.execute(\"SELECT * FROM comment where msg_id = %s;\", (msg_id,))\n        cs = cursor.fetchall()\n        if cs is None:\n            cs = ()\n        cs = list(cs)\n        for i, comment in enumerate(cs):\n            comment = list(comment)\n            cursor.execute(\"SELECT nickname FROM users where user_id = %s\", (user_id,))\n            u = cursor.fetchone()\n            comment.append(u[0])\n            cursor.execute(\"SELECT * FROM like_cmt where cmt_id = %s AND user_id = %s\", (comment[0], user_id))\n            like = cursor.fetchone()\n            if like is not None:\n                like_flag = 1\n            else:\n                like_flag = 0\n            comment.append(like_flag)\n            cs[i] = comment\n    return render_template('comment/show.html', m=m, cs=cs)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 143, "char_end": 211, "line": "        sql = \"SELECT * FROM message where msg_id = %d;\" % (msg_id)\n"}, {"line_no": 6, "char_start": 211, "char_end": 239, "line": "        cursor.execute(sql)\n"}, {"line_no": 8, "char_start": 269, "char_end": 337, "line": "        sql = \"SELECT * FROM comment where msg_id = %d;\" % (msg_id)\n"}, {"line_no": 9, "char_start": 337, "char_end": 365, "line": "        cursor.execute(sql)\n"}, {"line_no": 16, "char_start": 538, "char_end": 614, "line": "            sql = \"SELECT nickname FROM users where user_id = %d\" % user_id\n"}, {"line_no": 17, "char_start": 614, "char_end": 646, "line": "            cursor.execute(sql)\n"}, {"line_no": 20, "char_start": 713, "char_end": 793, "line": "            sql = \"SELECT * FROM like_cmt where cmt_id = %d AND user_id = %d\" \\\n"}, {"line_no": 21, "char_start": 793, "char_end": 833, "line": "                % (comment[0], user_id)\n"}, {"line_no": 22, "char_start": 833, "char_end": 865, "line": "            cursor.execute(sql)\n"}], "added": [{"line_no": 5, "char_start": 143, "char_end": 221, "line": "        cursor.execute(\"SELECT * FROM message where msg_id = %s;\", (msg_id,))\n"}, {"line_no": 7, "char_start": 251, "char_end": 329, "line": "        cursor.execute(\"SELECT * FROM comment where msg_id = %s;\", (msg_id,))\n"}, {"line_no": 14, "char_start": 502, "char_end": 590, "line": "            cursor.execute(\"SELECT nickname FROM users where user_id = %s\", (user_id,))\n"}, {"line_no": 17, "char_start": 657, "char_end": 768, "line": "            cursor.execute(\"SELECT * FROM like_cmt where cmt_id = %s AND user_id = %s\", (comment[0], user_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 151, "char_end": 157, "chars": "sql = "}, {"char_start": 196, "char_end": 197, "chars": "d"}, {"char_start": 199, "char_end": 201, "chars": " %"}, {"char_start": 226, "char_end": 237, "chars": "execute(sql"}, {"char_start": 246, "char_end": 250, "chars": " m ="}, {"char_start": 258, "char_end": 283, "chars": "fetchone()\n        sql = "}, {"char_start": 322, "char_end": 323, "chars": "d"}, {"char_start": 325, "char_end": 327, "chars": " %"}, {"char_start": 336, "char_end": 363, "chars": "\n        cursor.execute(sql"}, {"char_start": 550, "char_end": 556, "chars": "sql = "}, {"char_start": 601, "char_end": 606, "chars": "d\" % "}, {"char_start": 613, "char_end": 644, "chars": "\n            cursor.execute(sql"}, {"char_start": 725, "char_end": 731, "chars": "sql = "}, {"char_start": 771, "char_end": 772, "chars": "d"}, {"char_start": 788, "char_end": 863, "chars": "d\" \\\n                % (comment[0], user_id)\n            cursor.execute(sql"}], "added": [{"char_start": 151, "char_end": 166, "chars": "cursor.execute("}, {"char_start": 205, "char_end": 206, "chars": "s"}, {"char_start": 208, "char_end": 209, "chars": ","}, {"char_start": 217, "char_end": 218, "chars": ","}, {"char_start": 259, "char_end": 274, "chars": "cursor.execute("}, {"char_start": 313, "char_end": 314, "chars": "s"}, {"char_start": 316, "char_end": 317, "chars": ","}, {"char_start": 325, "char_end": 326, "chars": ","}, {"char_start": 514, "char_end": 529, "chars": "cursor.execute("}, {"char_start": 574, "char_end": 579, "chars": "s\", ("}, {"char_start": 586, "char_end": 588, "chars": ",)"}, {"char_start": 669, "char_end": 684, "chars": "cursor.execute("}, {"char_start": 724, "char_end": 725, "chars": "s"}, {"char_start": 741, "char_end": 766, "chars": "s\", (comment[0], user_id)"}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089"}
{"func_name": "add", "func_src_before": "@mod.route('/add', methods=['GET', 'POST'])\ndef add():\n    if request.method == 'POST':\n        msg_id = int(request.form['msg_id'])\n        user_id = session['logged_id']\n        content = request.form['content']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        sql = \"INSERT INTO comment(msg_id,user_id,content,c_time) \" + \\\n                \"VALUES(%d,%d,'%s','%s');\" % (msg_id, user_id, content, c_time)\n        cursor.execute(sql)\n        conn.commit()\n    return redirect(url_for('comment.show', msg_id=msg_id))", "func_src_after": "@mod.route('/add', methods=['GET', 'POST'])\ndef add():\n    if request.method == 'POST':\n        msg_id = int(request.form['msg_id'])\n        user_id = session['logged_id']\n        content = request.form['content']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        cursor.execute(\"INSERT INTO comment(msg_id,user_id,content,c_time) VALUES(%s,%s,%s,%s);\", (msg_id, user_id, content, c_time))\n        conn.commit()\n    return redirect(url_for('comment.show', msg_id=msg_id))", "line_changes": {"deleted": [{"line_no": 8, "char_start": 276, "char_end": 348, "line": "        sql = \"INSERT INTO comment(msg_id,user_id,content,c_time) \" + \\\n"}, {"line_no": 9, "char_start": 348, "char_end": 428, "line": "                \"VALUES(%d,%d,'%s','%s');\" % (msg_id, user_id, content, c_time)\n"}, {"line_no": 10, "char_start": 428, "char_end": 456, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 8, "char_start": 276, "char_end": 410, "line": "        cursor.execute(\"INSERT INTO comment(msg_id,user_id,content,c_time) VALUES(%s,%s,%s,%s);\", (msg_id, user_id, content, c_time))\n"}]}, "char_changes": {"deleted": [{"char_start": 284, "char_end": 290, "chars": "sql = "}, {"char_start": 342, "char_end": 365, "chars": "\" + \\\n                \""}, {"char_start": 373, "char_end": 374, "chars": "d"}, {"char_start": 376, "char_end": 384, "chars": "d,'%s','"}, {"char_start": 386, "char_end": 387, "chars": "'"}, {"char_start": 390, "char_end": 392, "chars": " %"}, {"char_start": 427, "char_end": 454, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 284, "char_end": 299, "chars": "cursor.execute("}, {"char_start": 359, "char_end": 360, "chars": "s"}, {"char_start": 362, "char_end": 367, "chars": "s,%s,"}, {"char_start": 372, "char_end": 373, "chars": ","}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089"}
{"func_name": "edit", "func_src_before": "@mod.route('/edit/<int:cmt_id>', methods=['GET', 'POST'])\ndef edit(cmt_id):\n    m = None\n    if request.method == 'GET':\n        sql = \"SELECT * FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        return render_template('comment/edit.html', m=m, cmt_id=cmt_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        sql = \"UPDATE comment SET content = '%s' where cmt_id = '%d';\" \\\n            % (content, cmt_id)\n        cursor.execute(sql)\n        conn.commit()\n        sql = \"SELECT msg_id FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        flash('Edit Success!')\n        return redirect(url_for('comment.show', msg_id=m[0]))\n\n    return render_template('comment/edit.html', m=m, cmt_id=cmt_id)", "func_src_after": "@mod.route('/edit/<int:cmt_id>', methods=['GET', 'POST'])\ndef edit(cmt_id):\n    m = None\n    if request.method == 'GET':\n        cursor.execute(\"SELECT * FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        return render_template('comment/edit.html', m=m, cmt_id=cmt_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        cursor.execute(\"UPDATE comment SET content = %s where cmt_id = %s;\", (content, cmt_id))\n        conn.commit()\n        cursor.execute(\"SELECT msg_id FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        flash('Edit Success!')\n        return redirect(url_for('comment.show', msg_id=m[0]))\n\n    return render_template('comment/edit.html', m=m, cmt_id=cmt_id)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 121, "char_end": 189, "line": "        sql = \"SELECT * FROM comment where cmt_id = %d;\" % (cmt_id)\n"}, {"line_no": 6, "char_start": 189, "char_end": 217, "line": "        cursor.execute(sql)\n"}, {"line_no": 12, "char_start": 395, "char_end": 468, "line": "        sql = \"UPDATE comment SET content = '%s' where cmt_id = '%d';\" \\\n"}, {"line_no": 13, "char_start": 468, "char_end": 500, "line": "            % (content, cmt_id)\n"}, {"line_no": 14, "char_start": 500, "char_end": 528, "line": "        cursor.execute(sql)\n"}, {"line_no": 16, "char_start": 550, "char_end": 623, "line": "        sql = \"SELECT msg_id FROM comment where cmt_id = %d;\" % (cmt_id)\n"}, {"line_no": 17, "char_start": 623, "char_end": 651, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 5, "char_start": 121, "char_end": 199, "line": "        cursor.execute(\"SELECT * FROM comment where cmt_id = %s;\", (cmt_id,))\n"}, {"line_no": 11, "char_start": 377, "char_end": 473, "line": "        cursor.execute(\"UPDATE comment SET content = %s where cmt_id = %s;\", (content, cmt_id))\n"}, {"line_no": 13, "char_start": 495, "char_end": 578, "line": "        cursor.execute(\"SELECT msg_id FROM comment where cmt_id = %s;\", (cmt_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 129, "char_end": 135, "chars": "sql = "}, {"char_start": 174, "char_end": 175, "chars": "d"}, {"char_start": 177, "char_end": 179, "chars": " %"}, {"char_start": 188, "char_end": 215, "chars": "\n        cursor.execute(sql"}, {"char_start": 403, "char_end": 409, "chars": "sql = "}, {"char_start": 439, "char_end": 440, "chars": "'"}, {"char_start": 442, "char_end": 443, "chars": "'"}, {"char_start": 459, "char_end": 526, "chars": "'%d';\" \\\n            % (content, cmt_id)\n        cursor.execute(sql"}, {"char_start": 558, "char_end": 564, "chars": "sql = "}, {"char_start": 608, "char_end": 609, "chars": "d"}, {"char_start": 611, "char_end": 613, "chars": " %"}, {"char_start": 622, "char_end": 649, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 129, "char_end": 144, "chars": "cursor.execute("}, {"char_start": 183, "char_end": 184, "chars": "s"}, {"char_start": 186, "char_end": 187, "chars": ","}, {"char_start": 195, "char_end": 196, "chars": ","}, {"char_start": 385, "char_end": 400, "chars": "cursor.execute("}, {"char_start": 448, "char_end": 471, "chars": "%s;\", (content, cmt_id)"}, {"char_start": 503, "char_end": 518, "chars": "cursor.execute("}, {"char_start": 562, "char_end": 563, "chars": "s"}, {"char_start": 565, "char_end": 566, "chars": ","}, {"char_start": 574, "char_end": 575, "chars": ","}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089"}
{"func_name": "delete", "func_src_before": "@mod.route('/delete/<int:cmt_id>', methods=['GET', 'POST'])\ndef delete(cmt_id):\n    if request.method == 'GET':\n        sql = \"SELECT msg_id FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        sql = \"DELETE FROM comment where cmt_id = '%d';\" % (cmt_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('comment.show', msg_id=m[0]))", "func_src_after": "@mod.route('/delete/<int:cmt_id>', methods=['GET', 'POST'])\ndef delete(cmt_id):\n    if request.method == 'GET':\n        cursor.execute(\"SELECT msg_id FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        cursor.execute(\"DELETE FROM comment where cmt_id = %s;\", (cmt_id,))\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('comment.show', msg_id=m[0]))", "line_changes": {"deleted": [{"line_no": 4, "char_start": 112, "char_end": 185, "line": "        sql = \"SELECT msg_id FROM comment where cmt_id = %d;\" % (cmt_id)\n"}, {"line_no": 5, "char_start": 185, "char_end": 213, "line": "        cursor.execute(sql)\n"}, {"line_no": 7, "char_start": 243, "char_end": 311, "line": "        sql = \"DELETE FROM comment where cmt_id = '%d';\" % (cmt_id)\n"}, {"line_no": 8, "char_start": 311, "char_end": 339, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 4, "char_start": 112, "char_end": 195, "line": "        cursor.execute(\"SELECT msg_id FROM comment where cmt_id = %s;\", (cmt_id,))\n"}, {"line_no": 6, "char_start": 225, "char_end": 301, "line": "        cursor.execute(\"DELETE FROM comment where cmt_id = %s;\", (cmt_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 120, "char_end": 126, "chars": "sql = "}, {"char_start": 170, "char_end": 171, "chars": "d"}, {"char_start": 173, "char_end": 175, "chars": " %"}, {"char_start": 184, "char_end": 211, "chars": "\n        cursor.execute(sql"}, {"char_start": 251, "char_end": 257, "chars": "sql = "}, {"char_start": 293, "char_end": 337, "chars": "'%d';\" % (cmt_id)\n        cursor.execute(sql"}], "added": [{"char_start": 120, "char_end": 135, "chars": "cursor.execute("}, {"char_start": 179, "char_end": 180, "chars": "s"}, {"char_start": 182, "char_end": 183, "chars": ","}, {"char_start": 191, "char_end": 193, "chars": ",)"}, {"char_start": 202, "char_end": 206, "chars": " m ="}, {"char_start": 214, "char_end": 223, "chars": "fetchone("}, {"char_start": 240, "char_end": 248, "chars": "execute("}, {"char_start": 284, "char_end": 299, "chars": "%s;\", (cmt_id,)"}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089"}
{"func_name": "like", "func_src_before": "@mod.route('/like/<int:cmt_id>', methods=['GET', 'POST'])\ndef like(cmt_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        sql = \"INSERT INTO like_cmt(cmt_id, user_id,c_time) \" + \\\n                \"VALUES(%d,'%s','%s');\" % (cmt_id, user_id, c_time)\n        cursor.execute(sql)\n        conn.commit()\n        sql = \"SELECT msg_id FROM comment WHERE cmt_id = %d\" % cmt_id\n        cursor.execute(sql)\n        c = cursor.fetchone()\n    return redirect(url_for('comment.show', msg_id=c[0]))", "func_src_after": "@mod.route('/like/<int:cmt_id>', methods=['GET', 'POST'])\ndef like(cmt_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        cursor.execute(\"INSERT INTO like_cmt(cmt_id, user_id,c_time) VALUES(%s,%s,%s);\", (cmt_id, user_id, c_time))\n        conn.commit()\n        cursor.execute(\"SELECT msg_id FROM comment WHERE cmt_id = %s\", (cmt_id,))\n        c = cursor.fetchone()\n    return redirect(url_for('comment.show', msg_id=c[0]))", "line_changes": {"deleted": [{"line_no": 6, "char_start": 209, "char_end": 275, "line": "        sql = \"INSERT INTO like_cmt(cmt_id, user_id,c_time) \" + \\\n"}, {"line_no": 7, "char_start": 275, "char_end": 343, "line": "                \"VALUES(%d,'%s','%s');\" % (cmt_id, user_id, c_time)\n"}, {"line_no": 8, "char_start": 343, "char_end": 371, "line": "        cursor.execute(sql)\n"}, {"line_no": 10, "char_start": 393, "char_end": 463, "line": "        sql = \"SELECT msg_id FROM comment WHERE cmt_id = %d\" % cmt_id\n"}, {"line_no": 11, "char_start": 463, "char_end": 491, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 6, "char_start": 209, "char_end": 325, "line": "        cursor.execute(\"INSERT INTO like_cmt(cmt_id, user_id,c_time) VALUES(%s,%s,%s);\", (cmt_id, user_id, c_time))\n"}, {"line_no": 8, "char_start": 347, "char_end": 429, "line": "        cursor.execute(\"SELECT msg_id FROM comment WHERE cmt_id = %s\", (cmt_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 217, "char_end": 223, "chars": "sql = "}, {"char_start": 269, "char_end": 308, "chars": "\" + \\\n                \"VALUES(%d,'%s','"}, {"char_start": 310, "char_end": 311, "chars": "'"}, {"char_start": 314, "char_end": 316, "chars": " %"}, {"char_start": 342, "char_end": 369, "chars": "\n        cursor.execute(sql"}, {"char_start": 401, "char_end": 407, "chars": "sql = "}, {"char_start": 451, "char_end": 456, "chars": "d\" % "}, {"char_start": 462, "char_end": 489, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 217, "char_end": 232, "chars": "cursor.execute("}, {"char_start": 278, "char_end": 291, "chars": "VALUES(%s,%s,"}, {"char_start": 296, "char_end": 297, "chars": ","}, {"char_start": 355, "char_end": 370, "chars": "cursor.execute("}, {"char_start": 414, "char_end": 419, "chars": "s\", ("}, {"char_start": 425, "char_end": 427, "chars": ",)"}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/like_cmt.py", "vul_type": "cwe-089"}
{"func_name": "unlike", "func_src_before": "@mod.route('/unlike/<int:cmt_id>', methods=['GET', 'POST'])\ndef unlike(cmt_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        sql = \"DELETE FROM like_cmt where cmt_id = '%d' AND user_id = %d;\" \\\n            % (cmt_id, user_id)\n        cursor.execute(sql)\n        conn.commit()\n        sql = \"SELECT msg_id FROM comment WHERE cmt_id = %d\" % cmt_id\n        cursor.execute(sql)\n        c = cursor.fetchone()\n    return redirect(url_for('comment.show', msg_id=c[0]))", "func_src_after": "@mod.route('/unlike/<int:cmt_id>', methods=['GET', 'POST'])\ndef unlike(cmt_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        cursor.execute(\"DELETE FROM like_cmt where cmt_id = %s AND user_id = %s;\", (cmt_id, user_id))\n        conn.commit()\n        cursor.execute(\"SELECT msg_id FROM comment WHERE cmt_id = %s\", (cmt_id,))\n        c = cursor.fetchone()\n    return redirect(url_for('comment.show', msg_id=c[0]))", "line_changes": {"deleted": [{"line_no": 5, "char_start": 151, "char_end": 228, "line": "        sql = \"DELETE FROM like_cmt where cmt_id = '%d' AND user_id = %d;\" \\\n"}, {"line_no": 6, "char_start": 228, "char_end": 260, "line": "            % (cmt_id, user_id)\n"}, {"line_no": 7, "char_start": 260, "char_end": 288, "line": "        cursor.execute(sql)\n"}, {"line_no": 9, "char_start": 310, "char_end": 380, "line": "        sql = \"SELECT msg_id FROM comment WHERE cmt_id = %d\" % cmt_id\n"}, {"line_no": 10, "char_start": 380, "char_end": 408, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 5, "char_start": 151, "char_end": 253, "line": "        cursor.execute(\"DELETE FROM like_cmt where cmt_id = %s AND user_id = %s;\", (cmt_id, user_id))\n"}, {"line_no": 7, "char_start": 275, "char_end": 357, "line": "        cursor.execute(\"SELECT msg_id FROM comment WHERE cmt_id = %s\", (cmt_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 159, "char_end": 165, "chars": "sql = "}, {"char_start": 202, "char_end": 206, "chars": "'%d'"}, {"char_start": 222, "char_end": 223, "chars": "d"}, {"char_start": 225, "char_end": 241, "chars": " \\\n            %"}, {"char_start": 259, "char_end": 286, "chars": "\n        cursor.execute(sql"}, {"char_start": 318, "char_end": 324, "chars": "sql = "}, {"char_start": 368, "char_end": 373, "chars": "d\" % "}, {"char_start": 379, "char_end": 406, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 159, "char_end": 174, "chars": "cursor.execute("}, {"char_start": 211, "char_end": 213, "chars": "%s"}, {"char_start": 229, "char_end": 230, "chars": "s"}, {"char_start": 232, "char_end": 233, "chars": ","}, {"char_start": 283, "char_end": 298, "chars": "cursor.execute("}, {"char_start": 342, "char_end": 347, "chars": "s\", ("}, {"char_start": 353, "char_end": 355, "chars": ",)"}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/like_cmt.py", "vul_type": "cwe-089"}
{"func_name": "like", "func_src_before": "@mod.route('/like/<int:msg_id>', methods=['GET', 'POST'])\ndef like(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        sql = \"INSERT INTO like_msg(msg_id, user_id,c_time) \" + \\\n                \"VALUES(%d,'%s','%s');\" % (msg_id, user_id, c_time)\n        cursor.execute(sql)\n        conn.commit()\n    return redirect(url_for('show_entries'))", "func_src_after": "@mod.route('/like/<int:msg_id>', methods=['GET', 'POST'])\ndef like(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        cursor.execute(\"INSERT INTO like_msg(msg_id, user_id,c_time) VALUES(%s,%s,%s);\", (msg_id, user_id, c_time))\n        conn.commit()\n    return redirect(url_for('show_entries'))", "line_changes": {"deleted": [{"line_no": 6, "char_start": 209, "char_end": 275, "line": "        sql = \"INSERT INTO like_msg(msg_id, user_id,c_time) \" + \\\n"}, {"line_no": 7, "char_start": 275, "char_end": 343, "line": "                \"VALUES(%d,'%s','%s');\" % (msg_id, user_id, c_time)\n"}, {"line_no": 8, "char_start": 343, "char_end": 371, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 6, "char_start": 209, "char_end": 325, "line": "        cursor.execute(\"INSERT INTO like_msg(msg_id, user_id,c_time) VALUES(%s,%s,%s);\", (msg_id, user_id, c_time))\n"}]}, "char_changes": {"deleted": [{"char_start": 217, "char_end": 223, "chars": "sql = "}, {"char_start": 269, "char_end": 308, "chars": "\" + \\\n                \"VALUES(%d,'%s','"}, {"char_start": 310, "char_end": 311, "chars": "'"}, {"char_start": 314, "char_end": 316, "chars": " %"}, {"char_start": 342, "char_end": 369, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 217, "char_end": 232, "chars": "cursor.execute("}, {"char_start": 278, "char_end": 291, "chars": "VALUES(%s,%s,"}, {"char_start": 296, "char_end": 297, "chars": ","}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/like_msg.py", "vul_type": "cwe-089"}
{"func_name": "unlike", "func_src_before": "@mod.route('/unlike/<int:msg_id>', methods=['GET', 'POST'])\ndef unlike(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        sql = \"DELETE FROM like_msg where msg_id = '%d' AND user_id = %d;\" \\\n            % (msg_id, user_id)\n        cursor.execute(sql)\n        conn.commit()\n    return redirect(url_for('show_entries'))", "func_src_after": "@mod.route('/unlike/<int:msg_id>', methods=['GET', 'POST'])\ndef unlike(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        cursor.execute(\"DELETE FROM like_msg where msg_id = %s AND user_id = %s;\", (msg_id, user_id))\n        conn.commit()\n    return redirect(url_for('show_entries'))", "line_changes": {"deleted": [{"line_no": 5, "char_start": 151, "char_end": 228, "line": "        sql = \"DELETE FROM like_msg where msg_id = '%d' AND user_id = %d;\" \\\n"}, {"line_no": 6, "char_start": 228, "char_end": 260, "line": "            % (msg_id, user_id)\n"}, {"line_no": 7, "char_start": 260, "char_end": 288, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 5, "char_start": 151, "char_end": 253, "line": "        cursor.execute(\"DELETE FROM like_msg where msg_id = %s AND user_id = %s;\", (msg_id, user_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 159, "char_end": 165, "chars": "sql = "}, {"char_start": 202, "char_end": 206, "chars": "'%d'"}, {"char_start": 222, "char_end": 223, "chars": "d"}, {"char_start": 225, "char_end": 241, "chars": " \\\n            %"}, {"char_start": 259, "char_end": 286, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 159, "char_end": 174, "chars": "cursor.execute("}, {"char_start": 211, "char_end": 213, "chars": "%s"}, {"char_start": 229, "char_end": 230, "chars": "s"}, {"char_start": 232, "char_end": 233, "chars": ","}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/like_msg.py", "vul_type": "cwe-089"}
{"func_name": "add", "func_src_before": "@mod.route('/add', methods=['GET', 'POST'])\ndef add():\n    if request.method == 'POST':\n        user_id = session['logged_id']\n        content = request.form['content']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        sql = \"INSERT INTO message(user_id,content,c_time) \" + \\\n                \"VALUES(%d,'%s','%s');\" % (user_id, content, c_time)\n        cursor.execute(sql)\n        conn.commit()\n    return redirect(url_for('show_entries'))", "func_src_after": "@mod.route('/add', methods=['GET', 'POST'])\ndef add():\n    if request.method == 'POST':\n        user_id = session['logged_id']\n        content = request.form['content']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        cursor.execute(\"INSERT INTO message(user_id,content,c_time) VALUES(%s,%s,%s);\", (user_id, content, c_time))\n        conn.commit()\n    return redirect(url_for('show_entries'))", "line_changes": {"deleted": [{"line_no": 7, "char_start": 231, "char_end": 296, "line": "        sql = \"INSERT INTO message(user_id,content,c_time) \" + \\\n"}, {"line_no": 8, "char_start": 296, "char_end": 365, "line": "                \"VALUES(%d,'%s','%s');\" % (user_id, content, c_time)\n"}, {"line_no": 9, "char_start": 365, "char_end": 393, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 7, "char_start": 231, "char_end": 347, "line": "        cursor.execute(\"INSERT INTO message(user_id,content,c_time) VALUES(%s,%s,%s);\", (user_id, content, c_time))\n"}]}, "char_changes": {"deleted": [{"char_start": 239, "char_end": 245, "chars": "sql = "}, {"char_start": 290, "char_end": 329, "chars": "\" + \\\n                \"VALUES(%d,'%s','"}, {"char_start": 331, "char_end": 332, "chars": "'"}, {"char_start": 335, "char_end": 337, "chars": " %"}, {"char_start": 364, "char_end": 391, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 239, "char_end": 254, "chars": "cursor.execute("}, {"char_start": 299, "char_end": 312, "chars": "VALUES(%s,%s,"}, {"char_start": 317, "char_end": 318, "chars": ","}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089"}
{"func_name": "edit", "func_src_before": "@mod.route('/edit/<int:msg_id>', methods=['GET', 'POST'])\ndef edit(msg_id):\n    m = None\n    if request.method == 'GET':\n        sql = \"SELECT * FROM message where msg_id = %d;\" % (msg_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        return render_template('message/edit.html', m=m, msg_id=msg_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        sql = \"UPDATE message SET content = '%s' where msg_id = '%d';\" \\\n            % (content, msg_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Edit Success!')\n        return redirect(url_for('show_entries'))\n\n    return render_template('message/edit.html', m=m, msg_id=msg_id)", "func_src_after": "@mod.route('/edit/<int:msg_id>', methods=['GET', 'POST'])\ndef edit(msg_id):\n    m = None\n    if request.method == 'GET':\n        cursor.execute(\"SELECT * FROM message where msg_id = %s;\", (msg_id,))\n        m = cursor.fetchone()\n        return render_template('message/edit.html', m=m, msg_id=msg_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        cursor.execute(\"UPDATE message SET content = %s where msg_id = %s;\", (content, msg_id))\n        conn.commit()\n        flash('Edit Success!')\n        return redirect(url_for('show_entries'))\n\n    return render_template('message/edit.html', m=m, msg_id=msg_id)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 121, "char_end": 189, "line": "        sql = \"SELECT * FROM message where msg_id = %d;\" % (msg_id)\n"}, {"line_no": 6, "char_start": 189, "char_end": 217, "line": "        cursor.execute(sql)\n"}, {"line_no": 12, "char_start": 395, "char_end": 468, "line": "        sql = \"UPDATE message SET content = '%s' where msg_id = '%d';\" \\\n"}, {"line_no": 13, "char_start": 468, "char_end": 500, "line": "            % (content, msg_id)\n"}, {"line_no": 14, "char_start": 500, "char_end": 528, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 5, "char_start": 121, "char_end": 199, "line": "        cursor.execute(\"SELECT * FROM message where msg_id = %s;\", (msg_id,))\n"}, {"line_no": 11, "char_start": 377, "char_end": 473, "line": "        cursor.execute(\"UPDATE message SET content = %s where msg_id = %s;\", (content, msg_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 129, "char_end": 135, "chars": "sql = "}, {"char_start": 174, "char_end": 175, "chars": "d"}, {"char_start": 177, "char_end": 179, "chars": " %"}, {"char_start": 188, "char_end": 215, "chars": "\n        cursor.execute(sql"}, {"char_start": 403, "char_end": 409, "chars": "sql = "}, {"char_start": 439, "char_end": 440, "chars": "'"}, {"char_start": 442, "char_end": 443, "chars": "'"}, {"char_start": 459, "char_end": 526, "chars": "'%d';\" \\\n            % (content, msg_id)\n        cursor.execute(sql"}], "added": [{"char_start": 129, "char_end": 144, "chars": "cursor.execute("}, {"char_start": 183, "char_end": 184, "chars": "s"}, {"char_start": 186, "char_end": 187, "chars": ","}, {"char_start": 195, "char_end": 196, "chars": ","}, {"char_start": 385, "char_end": 400, "chars": "cursor.execute("}, {"char_start": 448, "char_end": 471, "chars": "%s;\", (content, msg_id)"}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089"}
{"func_name": "delete", "func_src_before": "@mod.route('/delete/<int:msg_id>', methods=['GET', 'POST'])\ndef delete(msg_id):\n    if request.method == 'GET':\n        sql = \"DELETE FROM message where msg_id = '%d';\" % (msg_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('show_entries'))", "func_src_after": "@mod.route('/delete/<int:msg_id>', methods=['GET', 'POST'])\ndef delete(msg_id):\n    if request.method == 'GET':\n        cursor.execute(\"DELETE FROM message where msg_id = %s;\", (msg_id,))\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('show_entries'))", "line_changes": {"deleted": [{"line_no": 4, "char_start": 112, "char_end": 180, "line": "        sql = \"DELETE FROM message where msg_id = '%d';\" % (msg_id)\n"}, {"line_no": 5, "char_start": 180, "char_end": 208, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 4, "char_start": 112, "char_end": 188, "line": "        cursor.execute(\"DELETE FROM message where msg_id = %s;\", (msg_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 120, "char_end": 126, "chars": "sql = "}, {"char_start": 162, "char_end": 206, "chars": "'%d';\" % (msg_id)\n        cursor.execute(sql"}], "added": [{"char_start": 120, "char_end": 135, "chars": "cursor.execute("}, {"char_start": 171, "char_end": 186, "chars": "%s;\", (msg_id,)"}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089"}
{"func_name": "test", "func_src_before": "@mod.route('/test', methods=['GET', 'POST'])\ndef test():\n    user_id = session['logged_id']\n    sql = 'SELECT * FROM message where user_id = %d ORDER BY c_time DESC' \\\n        % (user_id)\n    cursor.execute(sql)\n    m = cursor.fetchall()\n    print(m)", "func_src_after": "@mod.route('/test', methods=['GET', 'POST'])\ndef test():\n    user_id = session['logged_id']\n    cursor.execute('SELECT * FROM message where user_id = %s ORDER BY c_time DESC', (user_id,))\n    m = cursor.fetchall()\n    print(m)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 92, "char_end": 168, "line": "    sql = 'SELECT * FROM message where user_id = %d ORDER BY c_time DESC' \\\n"}, {"line_no": 5, "char_start": 168, "char_end": 188, "line": "        % (user_id)\n"}, {"line_no": 6, "char_start": 188, "char_end": 212, "line": "    cursor.execute(sql)\n"}], "added": [{"line_no": 4, "char_start": 92, "char_end": 188, "line": "    cursor.execute('SELECT * FROM message where user_id = %s ORDER BY c_time DESC', (user_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 96, "char_end": 102, "chars": "sql = "}, {"char_start": 142, "char_end": 143, "chars": "d"}, {"char_start": 165, "char_end": 210, "chars": " \\\n        % (user_id)\n    cursor.execute(sql"}], "added": [{"char_start": 96, "char_end": 111, "chars": "cursor.execute("}, {"char_start": 151, "char_end": 152, "chars": "s"}, {"char_start": 174, "char_end": 186, "chars": ", (user_id,)"}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089"}
{"func_name": "register", "func_src_before": "@mod.route('/register', methods=['GET', 'POST'])\ndef register():\n    if request.method == 'POST':\n        error = None\n        email = request.form['email'].strip()\n        nickname = request.form['nickname'].strip()\n        password = request.form['password'].strip()\n        password2 = request.form['password2'].strip()\n\n        email = email.lower()\n\n        if email == \"\" or nickname == \"\" or password == \"\" or password2 == \"\":\n            error = 'Please input all the information'\n        elif password2 != password:\n            error = 'The password is not repeated correctly'\n        elif len(password) < 6:\n            error = 'The password has at least 6 characters'\n        elif not re.match(r'^[0-9a-zA-Z_]{0,19}@' +\n                          '[0-9a-zA-Z]{1,15}\\.[com,cn,net]', email):\n            error = 'Please input the right email'\n\n        sql = \"SELECT * FROM users where email = '%s';\" % (email)\n        cursor.execute(sql)\n        u = cursor.fetchone()\n\n        if u is not None:\n            error = 'The email has already exsit'\n\n        if error is not None:\n            return render_template('register.html', error=error)\n        else:\n            password = bcrypt.generate_password_hash(password)\n            cursor.execute(\"INSERT INTO users(email,nickname,password) VALUES(%s,%s,%s);\", (email, nickname, password))\n            conn.commit()\n            flash('Register Success!')\n            return redirect(url_for('users.login'))\n\n    return render_template('register.html')", "func_src_after": "@mod.route('/register', methods=['GET', 'POST'])\ndef register():\n    if request.method == 'POST':\n        error = None\n        email = request.form['email'].strip()\n        nickname = request.form['nickname'].strip()\n        password = request.form['password'].strip()\n        password2 = request.form['password2'].strip()\n\n        email = email.lower()\n\n        if email == \"\" or nickname == \"\" or password == \"\" or password2 == \"\":\n            error = 'Please input all the information'\n        elif password2 != password:\n            error = 'The password is not repeated correctly'\n        elif len(password) < 6:\n            error = 'The password has at least 6 characters'\n        elif not re.match(r'^[0-9a-zA-Z_]{0,19}@' +\n                          '[0-9a-zA-Z]{1,15}\\.[com,cn,net]', email):\n            error = 'Please input the right email'\n\n        cursor.execute(\"SELECT * FROM users where email = %s;\", (email,))\n        u = cursor.fetchone()\n\n        if u is not None:\n            error = 'The email has already exsit'\n\n        if error is not None:\n            return render_template('register.html', error=error)\n        else:\n            password = bcrypt.generate_password_hash(password)\n            cursor.execute(\"INSERT INTO users(email,nickname,password) VALUES(%s,%s,%s);\", (email, nickname, password))\n            conn.commit()\n            flash('Register Success!')\n            return redirect(url_for('users.login'))\n\n    return render_template('register.html')", "line_changes": {"deleted": [{"line_no": 22, "char_start": 852, "char_end": 918, "line": "        sql = \"SELECT * FROM users where email = '%s';\" % (email)\n"}, {"line_no": 23, "char_start": 918, "char_end": 946, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 22, "char_start": 852, "char_end": 926, "line": "        cursor.execute(\"SELECT * FROM users where email = %s;\", (email,))\n"}]}, "char_changes": {"deleted": [{"char_start": 860, "char_end": 866, "chars": "sql = "}, {"char_start": 901, "char_end": 902, "chars": "'"}, {"char_start": 904, "char_end": 905, "chars": "'"}, {"char_start": 907, "char_end": 909, "chars": " %"}, {"char_start": 917, "char_end": 944, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 860, "char_end": 875, "chars": "cursor.execute("}, {"char_start": 914, "char_end": 915, "chars": ","}, {"char_start": 922, "char_end": 923, "chars": ","}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/users.py", "vul_type": "cwe-089"}
{"func_name": "login", "func_src_before": "@mod.route('/login', methods=['GET', 'POST'])\ndef login():\n    error = None\n    if session.get('logged_in'):\n        return redirect(url_for('show_entries'))\n    if request.method == 'POST':\n        email = request.form['email'].strip()\n        password = request.form['password'].strip()\n\n        email = email.lower()\n\n        sql = \"SELECT password,user_id FROM users where email = '%s';\" % (email)\n        cursor.execute(sql)\n        u = cursor.fetchone()\n\n        if u is None:\n            error = \"The user doesn\\'t exsit.Please register first.\"\n        elif bcrypt.check_password_hash(u[0].encode('utf-8'), password):\n            session['logged_in'] = True\n            session['logged_email'] = email\n            session['logged_id'] = u[1]\n            return redirect(url_for('show_entries'))\n        else:\n            error = \"Your password is wrong.Try it again.\"\n\n    return render_template('login.html', error=error)", "func_src_after": "@mod.route('/login', methods=['GET', 'POST'])\ndef login():\n    error = None\n    if session.get('logged_in'):\n        return redirect(url_for('show_entries'))\n    if request.method == 'POST':\n        email = request.form['email'].strip()\n        password = request.form['password'].strip()\n\n        email = email.lower()\n\n        cursor.execute(\"SELECT password,user_id FROM users where email = %s;\", (email,))\n        u = cursor.fetchone()\n\n        if u is None:\n            error = \"The user doesn\\'t exsit.Please register first.\"\n        elif bcrypt.check_password_hash(u[0], password):\n            session['logged_in'] = True\n            session['logged_email'] = email\n            session['logged_id'] = u[1]\n            return redirect(url_for('show_entries'))\n        else:\n            error = \"Your password is wrong.Try it again.\"\n\n    return render_template('login.html', error=error)", "line_changes": {"deleted": [{"line_no": 12, "char_start": 321, "char_end": 402, "line": "        sql = \"SELECT password,user_id FROM users where email = '%s';\" % (email)\n"}, {"line_no": 13, "char_start": 402, "char_end": 430, "line": "        cursor.execute(sql)\n"}, {"line_no": 18, "char_start": 552, "char_end": 625, "line": "        elif bcrypt.check_password_hash(u[0].encode('utf-8'), password):\n"}], "added": [{"line_no": 12, "char_start": 321, "char_end": 410, "line": "        cursor.execute(\"SELECT password,user_id FROM users where email = %s;\", (email,))\n"}, {"line_no": 17, "char_start": 532, "char_end": 589, "line": "        elif bcrypt.check_password_hash(u[0], password):\n"}]}, "char_changes": {"deleted": [{"char_start": 329, "char_end": 335, "chars": "sql = "}, {"char_start": 385, "char_end": 386, "chars": "'"}, {"char_start": 388, "char_end": 389, "chars": "'"}, {"char_start": 391, "char_end": 393, "chars": " %"}, {"char_start": 401, "char_end": 428, "chars": "\n        cursor.execute(sql"}, {"char_start": 596, "char_end": 612, "chars": ".encode('utf-8')"}], "added": [{"char_start": 329, "char_end": 344, "chars": "cursor.execute("}, {"char_start": 398, "char_end": 399, "chars": ","}, {"char_start": 406, "char_end": 407, "chars": ","}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/users.py", "vul_type": "cwe-089"}
{"func_name": "edit", "func_src_before": "@mod.route('/edit', methods=['GET', 'POST'])\ndef edit():\n    sql = \"SELECT * FROM users where email = '%s';\" % (session['logged_email'])\n    cursor.execute(sql)\n    u = cursor.fetchone()\n    if request.method == 'POST':\n        sql = \"UPDATE users SET nickname = '%s' where email = '%s'\" \\\n        % (request.form['nickname'], session['logged_email'])\n        cursor.execute(sql)\n        sql = \"SELECT * FROM users where email = '%s';\" \\\n            % (session['logged_email'])\n        cursor.execute(sql)\n        u = cursor.fetchone()\n        conn.commit()\n        flash('Edit Nickname Success!')\n    return render_template('users/edit.html', u=u)", "func_src_after": "@mod.route('/edit', methods=['GET', 'POST'])\ndef edit():\n    cursor.execute(\"SELECT * FROM users where email = %s;\", (session['logged_email'],))\n    u = cursor.fetchone()\n    if request.method == 'POST':\n        cursor.execute(\"UPDATE users SET nickname = %s where email = %s\", (request.form['nickname'], session['logged_email']))\n        cursor.execute(\"SELECT * FROM users where email = %s;\", (session['logged_email'],))\n        u = cursor.fetchone()\n        conn.commit()\n        flash('Edit Nickname Success!')\n    return render_template('users/edit.html', u=u)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 57, "char_end": 137, "line": "    sql = \"SELECT * FROM users where email = '%s';\" % (session['logged_email'])\n"}, {"line_no": 4, "char_start": 137, "char_end": 161, "line": "    cursor.execute(sql)\n"}, {"line_no": 7, "char_start": 220, "char_end": 290, "line": "        sql = \"UPDATE users SET nickname = '%s' where email = '%s'\" \\\n"}, {"line_no": 8, "char_start": 290, "char_end": 352, "line": "        % (request.form['nickname'], session['logged_email'])\n"}, {"line_no": 9, "char_start": 352, "char_end": 380, "line": "        cursor.execute(sql)\n"}, {"line_no": 10, "char_start": 380, "char_end": 438, "line": "        sql = \"SELECT * FROM users where email = '%s';\" \\\n"}, {"line_no": 11, "char_start": 438, "char_end": 478, "line": "            % (session['logged_email'])\n"}, {"line_no": 12, "char_start": 478, "char_end": 506, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 3, "char_start": 57, "char_end": 145, "line": "    cursor.execute(\"SELECT * FROM users where email = %s;\", (session['logged_email'],))\n"}, {"line_no": 6, "char_start": 204, "char_end": 331, "line": "        cursor.execute(\"UPDATE users SET nickname = %s where email = %s\", (request.form['nickname'], session['logged_email']))\n"}, {"line_no": 7, "char_start": 331, "char_end": 423, "line": "        cursor.execute(\"SELECT * FROM users where email = %s;\", (session['logged_email'],))\n"}]}, "char_changes": {"deleted": [{"char_start": 61, "char_end": 67, "chars": "sql = "}, {"char_start": 102, "char_end": 103, "chars": "'"}, {"char_start": 105, "char_end": 106, "chars": "'"}, {"char_start": 108, "char_end": 110, "chars": " %"}, {"char_start": 136, "char_end": 159, "chars": "\n    cursor.execute(sql"}, {"char_start": 228, "char_end": 234, "chars": "sql = "}, {"char_start": 263, "char_end": 264, "chars": "'"}, {"char_start": 266, "char_end": 267, "chars": "'"}, {"char_start": 282, "char_end": 283, "chars": "'"}, {"char_start": 285, "char_end": 299, "chars": "'\" \\\n        %"}, {"char_start": 375, "char_end": 394, "chars": "sql)\n        sql = "}, {"char_start": 429, "char_end": 430, "chars": "'"}, {"char_start": 432, "char_end": 433, "chars": "'"}, {"char_start": 435, "char_end": 451, "chars": " \\\n            %"}, {"char_start": 477, "char_end": 504, "chars": "\n        cursor.execute(sql"}], "added": [{"char_start": 61, "char_end": 76, "chars": "cursor.execute("}, {"char_start": 115, "char_end": 116, "chars": ","}, {"char_start": 141, "char_end": 142, "chars": ","}, {"char_start": 212, "char_end": 227, "chars": "cursor.execute("}, {"char_start": 275, "char_end": 277, "chars": "\","}, {"char_start": 329, "char_end": 330, "chars": ")"}, {"char_start": 393, "char_end": 394, "chars": ","}, {"char_start": 419, "char_end": 420, "chars": ","}]}, "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/users.py", "vul_type": "cwe-089"}
{"func_name": "to_sql", "func_src_before": "    def to_sql(self):\n        self.do_pre_sql_check()\n        sql = 'SELECT '\n        if self.aggregations:\n            i = 0\n            for agg_op, column in self.aggregations:\n                sql += ('' if i == 0 else ', ') + agg_op + '(' + column + ')'\n                i += 1\n        elif self.output_format in ['graph', 'png']:\n            if self.graphtype == 'line':\n                sql += \"date_trunc('{}', {}), count(*)\".format(self.graphbucket, self.graphkey)\n            else:\n                sql += \"{}, count(*)\".format(self.graphkey)\n        else:\n            sql += ', '.join(self.column_names)\n\n        sql += ' FROM ' + self.table\n        if self.filters:\n            sql += ' WHERE '\n            i = 0\n            for fcol, fop, fval in self.filters:\n                col_full_name = self.object_cache.get_column_single(self.db_uniq, self.table, fcol)\n                if not col_full_name:\n                    raise Exception('Column {} not found! Known columns: {}'.format(fcol, self.column_names))\n                sql += '{}{} {} {}'.format((' AND ' if i > 0 else ''), col_full_name, fop.upper(), fval)\n                i += 1\n\n        if self.graphkey:\n            if self.graphtype == 'line':\n                sql += ' GROUP BY 1 ORDER BY 1'\n            elif self.graphtype == 'pie':\n                sql += ' GROUP BY 1 ORDER BY 2 DESC'    # LIMIT {}'.format(self.limit)\n        elif not self.aggregations:\n            if self.order_by_columns:\n                if isinstance(self.order_by_columns, list):\n                    sql += ' ORDER BY '\n                    order_bys = []\n                    for col in self.order_by_columns:\n                        order_bys.append('{} {}'.format(col, self.order_by_direction.upper()))\n                    sql += ', '.join(order_bys)\n                else:\n                    sql += ' ORDER BY {} {}'.format(self.order_by_columns, self.order_by_direction.upper())\n            sql += ' LIMIT {}'.format(self.limit)\n        return sql", "func_src_after": "    def to_sql(self):\n        self.do_pre_sql_check()\n        params = []\n        sql = 'SELECT '\n        if self.aggregations:\n            i = 0\n            for agg_op, column in self.aggregations:\n                sql += ('' if i == 0 else ', ') + agg_op + '(' + column + ')'\n                i += 1\n        elif self.output_format in ['graph', 'png']:\n            if self.graphtype == 'line':\n                sql += \"date_trunc('{}', {}), count(*)\".format(self.graphbucket, self.graphkey)\n            else:\n                sql += \"{}, count(*)\".format(self.graphkey)\n        else:\n            sql += ', '.join(self.column_names)\n\n        sql += ' FROM ' + self.table\n        if self.filters:\n            sql += ' WHERE '\n            i = 0\n            for fcol, fop, fval in self.filters:\n                col_full_name = self.object_cache.get_column_single(self.db_uniq, self.table, fcol)\n                if not col_full_name:\n                    raise Exception('Column {} not found! Known columns: {}'.format(fcol, self.column_names))\n                and_prefix = ' AND ' if i > 0 else ''\n                if fop == 'ANY':\n                    sql += \"{}{} = ANY('{{{}}}')\".format(and_prefix, col_full_name, fval)\n                else:\n                    sql += '{}{} {} %s'.format(and_prefix, col_full_name, fop.upper())\n                    params.append(fval)\n                i += 1\n\n        if self.graphkey:\n            if self.graphtype == 'line':\n                sql += ' GROUP BY 1 ORDER BY 1'\n            elif self.graphtype == 'pie':\n                sql += ' GROUP BY 1 ORDER BY 2 DESC'    # LIMIT {}'.format(self.limit)\n        elif not self.aggregations:\n            if self.order_by_columns:\n                if isinstance(self.order_by_columns, list):\n                    sql += ' ORDER BY '\n                    order_bys = []\n                    for col in self.order_by_columns:\n                        order_bys.append('{} {} NULLS LAST'.format(col, self.order_by_direction.upper()))\n                    sql += ', '.join(order_bys)\n                else:\n                    sql += ' ORDER BY {} {}  NULLS LAST'.format(self.order_by_columns, self.order_by_direction.upper())\n            sql += ' LIMIT {}'.format(self.limit)\n        return sql, params", "line_changes": {"deleted": [{"line_no": 25, "char_start": 1017, "char_end": 1122, "line": "                sql += '{}{} {} {}'.format((' AND ' if i > 0 else ''), col_full_name, fop.upper(), fval)\n"}, {"line_no": 39, "char_start": 1653, "char_end": 1748, "line": "                        order_bys.append('{} {}'.format(col, self.order_by_direction.upper()))\n"}, {"line_no": 42, "char_start": 1818, "char_end": 1926, "line": "                    sql += ' ORDER BY {} {}'.format(self.order_by_columns, self.order_by_direction.upper())\n"}, {"line_no": 44, "char_start": 1976, "char_end": 1994, "line": "        return sql\n"}], "added": [{"line_no": 3, "char_start": 54, "char_end": 74, "line": "        params = []\n"}, {"line_no": 26, "char_start": 1037, "char_end": 1091, "line": "                and_prefix = ' AND ' if i > 0 else ''\n"}, {"line_no": 27, "char_start": 1091, "char_end": 1124, "line": "                if fop == 'ANY':\n"}, {"line_no": 28, "char_start": 1124, "char_end": 1214, "line": "                    sql += \"{}{} = ANY('{{{}}}')\".format(and_prefix, col_full_name, fval)\n"}, {"line_no": 29, "char_start": 1214, "char_end": 1236, "line": "                else:\n"}, {"line_no": 30, "char_start": 1236, "char_end": 1323, "line": "                    sql += '{}{} {} %s'.format(and_prefix, col_full_name, fop.upper())\n"}, {"line_no": 31, "char_start": 1323, "char_end": 1363, "line": "                    params.append(fval)\n"}, {"line_no": 45, "char_start": 1894, "char_end": 2000, "line": "                        order_bys.append('{} {} NULLS LAST'.format(col, self.order_by_direction.upper()))\n"}, {"line_no": 48, "char_start": 2070, "char_end": 2190, "line": "                    sql += ' ORDER BY {} {}  NULLS LAST'.format(self.order_by_columns, self.order_by_direction.upper())\n"}, {"line_no": 50, "char_start": 2240, "char_end": 2266, "line": "        return sql, params\n"}]}, "char_changes": {"deleted": [{"char_start": 1040, "char_end": 1041, "chars": "'"}, {"char_start": 1046, "char_end": 1116, "chars": "{} {}'.format((' AND ' if i > 0 else ''), col_full_name, fop.upper(), "}], "added": [{"char_start": 54, "char_end": 74, "chars": "        params = []\n"}, {"char_start": 1037, "char_end": 1128, "chars": "                and_prefix = ' AND ' if i > 0 else ''\n                if fop == 'ANY':\n    "}, {"char_start": 1151, "char_end": 1152, "chars": "\""}, {"char_start": 1157, "char_end": 1357, "chars": "= ANY('{{{}}}')\".format(and_prefix, col_full_name, fval)\n                else:\n                    sql += '{}{} {} %s'.format(and_prefix, col_full_name, fop.upper())\n                    params.append("}, {"char_start": 1941, "char_end": 1952, "chars": " NULLS LAST"}, {"char_start": 2113, "char_end": 2125, "chars": "  NULLS LAST"}, {"char_start": 2258, "char_end": 2266, "chars": ", params"}]}, "commit_link": "github.com/kmoppel/pgzebra/commit/bb5e064b3d13ec733abd0e126ebba1aee383b354", "file_name": "src/urlparams.py", "vul_type": "cwe-089"}
{"func_name": "getPlayer", "func_src_before": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = '%s' COLLATE NOCASE\" % player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "func_src_after": "def getPlayer(player):\n\tdb.execute(\"SELECT * FROM players WHERE Name = ? COLLATE NOCASE\", player)\n\tplayerstats = dict(db.fetchone())\n\treturn playerstats", "line_changes": {"deleted": [{"line_no": 2, "char_start": 23, "char_end": 102, "line": "\tdb.execute(\"SELECT * FROM players WHERE Name = '%s' COLLATE NOCASE\" % player)\n"}], "added": [{"line_no": 2, "char_start": 23, "char_end": 98, "line": "\tdb.execute(\"SELECT * FROM players WHERE Name = ? COLLATE NOCASE\", player)\n"}]}, "char_changes": {"deleted": [{"char_start": 71, "char_end": 75, "chars": "'%s'"}, {"char_start": 91, "char_end": 93, "chars": " %"}], "added": [{"char_start": 71, "char_end": 72, "chars": "?"}, {"char_start": 88, "char_end": 89, "chars": ","}]}, "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089"}
{"func_name": "ratingChange", "func_src_before": "def ratingChange(Name, ELO, Played, W, L):\n\tdb.execute(\"UPDATE players SET ELO = %i, Played = %i, W = %i, L = %i WHERE Name = '%s' COLLATE NOCASE\" % (ELO, Played, W, L, Name))\n\tdatabase.commit()", "func_src_after": "def ratingChange(Name, ELO, Played, W, L):\n\tdb.execute(\"UPDATE players SET ELO = ?, Played = ?, W = ?, L = ? WHERE Name = ? COLLATE NOCASE\", ELO, Played, W, L, Name)\n\tdatabase.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 43, "char_end": 176, "line": "\tdb.execute(\"UPDATE players SET ELO = %i, Played = %i, W = %i, L = %i WHERE Name = '%s' COLLATE NOCASE\" % (ELO, Played, W, L, Name))\n"}], "added": [{"line_no": 2, "char_start": 43, "char_end": 166, "line": "\tdb.execute(\"UPDATE players SET ELO = ?, Played = ?, W = ?, L = ? WHERE Name = ? COLLATE NOCASE\", ELO, Played, W, L, Name)\n"}]}, "char_changes": {"deleted": [{"char_start": 81, "char_end": 83, "chars": "%i"}, {"char_start": 94, "char_end": 96, "chars": "%i"}, {"char_start": 102, "char_end": 104, "chars": "%i"}, {"char_start": 110, "char_end": 112, "chars": "%i"}, {"char_start": 126, "char_end": 130, "chars": "'%s'"}, {"char_start": 147, "char_end": 150, "chars": "% ("}, {"char_start": 174, "char_end": 175, "chars": ")"}], "added": [{"char_start": 81, "char_end": 82, "chars": "?"}, {"char_start": 93, "char_end": 94, "chars": "?"}, {"char_start": 100, "char_end": 101, "chars": "?"}, {"char_start": 107, "char_end": 108, "chars": "?"}, {"char_start": 122, "char_end": 123, "chars": "?"}, {"char_start": 139, "char_end": 140, "chars": ","}]}, "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089"}
{"func_name": "makeJudge", "func_src_before": "def makeJudge(judge):\n\tdb.execute(\"UPDATE players SET Judge = 1 WHERE Name = '%s' COLLATE NOCASE\" % (judge)) \n\tdatabase.commit()", "func_src_after": "def makeJudge(judge):\n\tdb.execute(\"UPDATE players SET Judge = 1 WHERE Name = ? COLLATE NOCASE\", judge) \n\tdatabase.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 22, "char_end": 110, "line": "\tdb.execute(\"UPDATE players SET Judge = 1 WHERE Name = '%s' COLLATE NOCASE\" % (judge)) \n"}], "added": [{"line_no": 2, "char_start": 22, "char_end": 104, "line": "\tdb.execute(\"UPDATE players SET Judge = 1 WHERE Name = ? COLLATE NOCASE\", judge) \n"}]}, "char_changes": {"deleted": [{"char_start": 77, "char_end": 81, "chars": "'%s'"}, {"char_start": 98, "char_end": 101, "chars": "% ("}, {"char_start": 107, "char_end": 108, "chars": ")"}], "added": [{"char_start": 77, "char_end": 78, "chars": "?"}, {"char_start": 94, "char_end": 95, "chars": ","}]}, "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089"}
{"func_name": "GameNewPlayed", "func_src_before": "def GameNewPlayed(Played, ID):\n\tdb.execute(\"UPDATE games set GamesPlayed = %i WHERE ID = %i\" % (Played, ID))\n\tdatabase.commit()", "func_src_after": "def GameNewPlayed(Played, ID):\n\tdb.execute(\"UPDATE games set GamesPlayed = ? WHERE ID = ?\", Played, ID)\n\tdatabase.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 31, "char_end": 109, "line": "\tdb.execute(\"UPDATE games set GamesPlayed = %i WHERE ID = %i\" % (Played, ID))\n"}], "added": [{"line_no": 2, "char_start": 31, "char_end": 104, "line": "\tdb.execute(\"UPDATE games set GamesPlayed = ? WHERE ID = ?\", Played, ID)\n"}]}, "char_changes": {"deleted": [{"char_start": 75, "char_end": 77, "chars": "%i"}, {"char_start": 89, "char_end": 96, "chars": "%i\" % ("}, {"char_start": 107, "char_end": 108, "chars": ")"}], "added": [{"char_start": 75, "char_end": 76, "chars": "?"}, {"char_start": 88, "char_end": 92, "chars": "?\", "}]}, "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089"}
{"func_name": "closeGame", "func_src_before": "def closeGame(ID):\n\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = %i\" % ID)\n\tdatabase.commit()", "func_src_after": "def closeGame(ID):\n\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = ?\", ID)\n\tdatabase.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 19, "char_end": 85, "line": "\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = %i\" % ID)\n"}], "added": [{"line_no": 2, "char_start": 19, "char_end": 83, "line": "\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = ?\", ID)\n"}]}, "char_changes": {"deleted": [{"char_start": 75, "char_end": 80, "chars": "%i\" %"}], "added": [{"char_start": 75, "char_end": 78, "chars": "?\","}]}, "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089"}
{"func_name": "getGameID", "func_src_before": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = %i\" % ID)\n\tID = db.fetchone()\n\treturn ID", "func_src_after": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = ?\", ID)\n\tID = db.fetchone()\n\treturn ID", "line_changes": {"deleted": [{"line_no": 2, "char_start": 19, "char_end": 73, "line": "\tdb.execute(\"SELECT * FROM games WHERE ID = %i\" % ID)\n"}], "added": [{"line_no": 2, "char_start": 19, "char_end": 71, "line": "\tdb.execute(\"SELECT * FROM games WHERE ID = ?\", ID)\n"}]}, "char_changes": {"deleted": [{"char_start": 63, "char_end": 68, "chars": "%i\" %"}], "added": [{"char_start": 63, "char_end": 66, "chars": "?\","}]}, "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089"}
{"func_name": "create_table", "func_src_before": "def create_table(table_name, arg_count, arg_values):\n    '''Takes a table name, a number of arguments count, and argument values.\n    Argument values are used for the individual table columns.'''\n    con = sqlite3.connect(\"something.db\")\n    con.isolation_level = None\n    cur = con.cursor()\n    buffer = \"\"\n    #Create the table.\n    arg_string = \" (\"\n    for i in range (0, arg_count):\n        #We have to process it as a string first.\n        if(i != arg_count):\n            #If it is not the last argument in the string, insert a comma.\n            arg_string += (arg_values[i] + \", \")\n        elif(i == arg_count):\n            #If it is the last argument in the string, insert a closing parentheses and semicolon.\n            arg_string += (arg_values[i] + \");\")\n    cur.execute(\"CREATE TABLE \" + table_name + arg_string)", "func_src_after": "def create_table(table_name, arg_count, arg_values):\n    '''Takes a table name, a number of arguments count, and argument values.\n    Argument values are used for the individual table columns.'''\n\n    #Create the table.\n    arg_string = \" (\"\n    for i in range (0, arg_count):\n        #We have to process it as a string first.\n        if i != (arg_count - 1):\n            #If it is not the last argument in the string, insert a comma.\n            arg_string += (arg_values[i] + \", \")\n        elif i == (arg_count - 1):\n            #If it is the last argument in the string, insert a closing parentheses and semicolon.\n            arg_string += (arg_values[i] + \") \")\n    cur.execute(\"CREATE TABLE \" + table_name + arg_string)\n    con.commit() #Commit changes", "line_changes": {"deleted": [{"line_no": 4, "char_start": 196, "char_end": 238, "line": "    con = sqlite3.connect(\"something.db\")\n"}, {"line_no": 5, "char_start": 238, "char_end": 269, "line": "    con.isolation_level = None\n"}, {"line_no": 6, "char_start": 269, "char_end": 292, "line": "    cur = con.cursor()\n"}, {"line_no": 7, "char_start": 292, "char_end": 308, "line": "    buffer = \"\"\n"}, {"line_no": 12, "char_start": 438, "char_end": 466, "line": "        if(i != arg_count):\n"}, {"line_no": 15, "char_start": 590, "char_end": 620, "line": "        elif(i == arg_count):\n"}, {"line_no": 17, "char_start": 719, "char_end": 768, "line": "            arg_string += (arg_values[i] + \");\")\n"}], "added": [{"line_no": 4, "char_start": 196, "char_end": 197, "line": "\n"}, {"line_no": 9, "char_start": 327, "char_end": 360, "line": "        if i != (arg_count - 1):\n"}, {"line_no": 12, "char_start": 484, "char_end": 519, "line": "        elif i == (arg_count - 1):\n"}, {"line_no": 14, "char_start": 618, "char_end": 667, "line": "            arg_string += (arg_values[i] + \") \")\n"}, {"line_no": 16, "char_start": 726, "char_end": 758, "line": "    con.commit() #Commit changes\n"}]}, "char_changes": {"deleted": [{"char_start": 196, "char_end": 307, "chars": "    con = sqlite3.connect(\"something.db\")\n    con.isolation_level = None\n    cur = con.cursor()\n    buffer = \"\""}, {"char_start": 448, "char_end": 449, "chars": "("}, {"char_start": 602, "char_end": 603, "chars": "("}, {"char_start": 764, "char_end": 765, "chars": ";"}], "added": [{"char_start": 197, "char_end": 197, "chars": ""}, {"char_start": 337, "char_end": 338, "chars": " "}, {"char_start": 343, "char_end": 344, "chars": "("}, {"char_start": 353, "char_end": 357, "chars": " - 1"}, {"char_start": 496, "char_end": 497, "chars": " "}, {"char_start": 502, "char_end": 503, "chars": "("}, {"char_start": 512, "char_end": 516, "chars": " - 1"}, {"char_start": 663, "char_end": 664, "chars": " "}, {"char_start": 725, "char_end": 758, "chars": "\n    con.commit() #Commit changes"}]}, "commit_link": "github.com/trungnt6669/blockchain-voting/commit/4c9ae4d0ea34174e778c549a0b144034d102bfff", "file_name": "SQLTest.py", "vul_type": "cwe-089"}
{"func_name": "copy", "func_src_before": "    def copy(self, cr, uid, id, default={},context={}):\n        proj = self.browse(cr, uid, id, context=context)\n        default = default or {}\n        context['active_test'] = False\n        default['state'] = 'open'\n        if not default.get('name', False):\n            default['name'] = proj.name+_(' (copy)')\n        res = super(project, self).copy(cr, uid, id, default, context)\n        ids = self.search(cr, uid, [('parent_id','child_of', [res])])\n        cr.execute('update project_task set active=True where project_id in %s', (tuple(ids,)))\n        return res", "func_src_after": "    def copy(self, cr, uid, id, default={},context={}):\n        proj = self.browse(cr, uid, id, context=context)\n        default = default or {}\n        context['active_test'] = False\n        default['state'] = 'open'\n        if not default.get('name', False):\n            default['name'] = proj.name+_(' (copy)')\n        res = super(project, self).copy(cr, uid, id, default, context)\n        ids = self.search(cr, uid, [('parent_id','child_of', [res])])\n        cr.execute('update project_task set active=True where project_id in %s', (tuple(ids),))\n        return res", "line_changes": {"deleted": [{"line_no": 10, "char_start": 455, "char_end": 551, "line": "        cr.execute('update project_task set active=True where project_id in %s', (tuple(ids,)))\n"}], "added": [{"line_no": 10, "char_start": 455, "char_end": 551, "line": "        cr.execute('update project_task set active=True where project_id in %s', (tuple(ids),))\n"}]}, "char_changes": {"deleted": [{"char_start": 546, "char_end": 547, "chars": ","}], "added": [{"char_start": 546, "char_end": 547, "chars": ")"}]}, "commit_link": "github.com/xrg/OpenERP-addons/commit/4a6bbaef7c713a6c2309336c118960fabe810499", "file_name": "project/project.py", "vul_type": "cwe-089"}
{"func_name": "update_find_by", "func_src_before": "    def update_find_by(self, key, value,id):\n        \"\"\" Find object from table and return \"\"\"\n\n        query = \"SELECT * FROM {} WHERE {} = '{}' AND id != {}\".format(\n            self.table_name, key, self.escapedString(value),id)\n\n        data = self.get_one(query)\n        if data:\n            data[key] = value\n        return data", "func_src_after": "    def update_find_by(self, key, value,id):\n        \"\"\" Find object from table and return \"\"\"\n\n        query = \"SELECT * FROM {} WHERE {} = '{}' AND id != {}\"\n        query=query.format(self.table_name, key, self.escapedString(value),id)\n    \n        data = self.get_one(query)\n        if data:\n            data[key] = value\n        return data", "line_changes": {"deleted": [{"line_no": 4, "char_start": 96, "char_end": 168, "line": "        query = \"SELECT * FROM {} WHERE {} = '{}' AND id != {}\".format(\n"}, {"line_no": 5, "char_start": 168, "char_end": 232, "line": "            self.table_name, key, self.escapedString(value),id)\n"}, {"line_no": 6, "char_start": 232, "char_end": 233, "line": "\n"}], "added": [{"line_no": 4, "char_start": 96, "char_end": 160, "line": "        query = \"SELECT * FROM {} WHERE {} = '{}' AND id != {}\"\n"}, {"line_no": 5, "char_start": 160, "char_end": 239, "line": "        query=query.format(self.table_name, key, self.escapedString(value),id)\n"}, {"line_no": 6, "char_start": 239, "char_end": 244, "line": "    \n"}]}, "char_changes": {"deleted": [{"char_start": 159, "char_end": 167, "chars": ".format("}, {"char_start": 176, "char_end": 180, "chars": "    "}], "added": [{"char_start": 168, "char_end": 187, "chars": "query=query.format("}, {"char_start": 239, "char_end": 243, "chars": "    "}]}, "commit_link": "github.com/martinMutuma/def-politico/commit/3acae8df24e250ece085dfa3ff9213c494a1f007", "file_name": "app/v2/models/base_model.py", "vul_type": "cwe-089"}
{"func_name": "update_find_by", "func_src_before": "    def update_find_by(self, key, value,id):\n        \"\"\" Find object from table and return \"\"\"\n\n        query = \"SELECT * FROM {} WHERE {} = '{}' AND id != {}\"\n        query=query.format(self.table_name, key, self.escapedString(value),id)\n    \n        data = self.get_one(query)\n        if data:\n            data[key] = value\n        return data", "func_src_after": "    def update_find_by(self, key, value,value_id):\n        \"\"\" Find object from table and return \"\"\"\n\n        query = \"SELECT * FROM {} WHERE {} = '{}' AND id != {}\"\n        query=query.format(self.table_name, key, self.escapedString(value),value_id)\n        data = self.get_one(query)\n        if data:\n            data[key] = value\n        return data", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 45, "line": "    def update_find_by(self, key, value,id):\n"}, {"line_no": 5, "char_start": 160, "char_end": 239, "line": "        query=query.format(self.table_name, key, self.escapedString(value),id)\n"}, {"line_no": 6, "char_start": 239, "char_end": 244, "line": "    \n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 51, "line": "    def update_find_by(self, key, value,value_id):\n"}, {"line_no": 5, "char_start": 166, "char_end": 251, "line": "        query=query.format(self.table_name, key, self.escapedString(value),value_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 235, "char_end": 243, "chars": "id)\n    "}], "added": [{"char_start": 40, "char_end": 46, "chars": "value_"}, {"char_start": 241, "char_end": 250, "chars": "value_id)"}]}, "commit_link": "github.com/martinMutuma/def-politico/commit/0794d1d552ef666c2bc9bf255294f98b73823644", "file_name": "app/v2/models/base_model.py", "vul_type": "cwe-089"}
{"func_name": "get_requested_day", "func_src_before": "    def get_requested_day(self, date):\n\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, SUM(Power) AS Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN %s AND %s \n            GROUP BY TimeStamp;\n        '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (day_start, day_end)):\n            data['data'].append({ 'time': row[0], 'power': row[1] })\n\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT SUM(EToday) as EToday\n                FROM Inverters;\n                '''\n        else:\n            query = '''\n                SELECT SUM(DayYield) AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN %s AND %s\n                GROUP BY TimeStamp\n                ''' % (day_start, day_end)\n        self.c.execute(query)\n        row = self.c.fetchone()\n        if row and row[0]: data['total'] = row[0]\n        else: data['total'] = 0\n\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data):  data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        #print(json.dumps(data, indent=4))\n        return data", "func_src_after": "    def get_requested_day(self, date):\n\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, SUM(Power) AS Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN ? AND ?\n            GROUP BY TimeStamp;\n        '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (day_start, day_end)):\n            data['data'].append({ 'time': row[0], 'power': row[1] })\n\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT SUM(EToday) as EToday\n                FROM Inverters;\n                '''\n            self.c.execute(query)\n        else:\n            query = '''\n                SELECT SUM(DayYield) AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN ? AND ?\n                GROUP BY TimeStamp;\n                '''\n            self.c.execute(query, (day_start, day_end))\n\n        row = self.c.fetchone()\n        if row and row[0]: data['total'] = row[0]\n        else: data['total'] = 0\n\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data):  data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        #print(json.dumps(data, indent=4))\n        return data", "line_changes": {"deleted": [{"line_no": 11, "char_start": 379, "char_end": 426, "line": "            WHERE TimeStamp BETWEEN %s AND %s \n"}, {"line_no": 16, "char_start": 501, "char_end": 566, "line": "        for row in self.c.execute(query % (day_start, day_end)):\n"}, {"line_no": 29, "char_start": 945, "char_end": 995, "line": "                WHERE TimeStamp BETWEEN %s AND %s\n"}, {"line_no": 30, "char_start": 995, "char_end": 1030, "line": "                GROUP BY TimeStamp\n"}, {"line_no": 31, "char_start": 1030, "char_end": 1073, "line": "                ''' % (day_start, day_end)\n"}, {"line_no": 32, "char_start": 1073, "char_end": 1103, "line": "        self.c.execute(query)\n"}], "added": [{"line_no": 11, "char_start": 379, "char_end": 423, "line": "            WHERE TimeStamp BETWEEN ? AND ?\n"}, {"line_no": 16, "char_start": 498, "char_end": 562, "line": "        for row in self.c.execute(query, (day_start, day_end)):\n"}, {"line_no": 25, "char_start": 824, "char_end": 858, "line": "            self.c.execute(query)\n"}, {"line_no": 30, "char_start": 975, "char_end": 1023, "line": "                WHERE TimeStamp BETWEEN ? AND ?\n"}, {"line_no": 31, "char_start": 1023, "char_end": 1059, "line": "                GROUP BY TimeStamp;\n"}, {"line_no": 32, "char_start": 1059, "char_end": 1079, "line": "                '''\n"}, {"line_no": 33, "char_start": 1079, "char_end": 1135, "line": "            self.c.execute(query, (day_start, day_end))\n"}, {"line_no": 34, "char_start": 1135, "char_end": 1136, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 415, "char_end": 417, "chars": "%s"}, {"char_start": 422, "char_end": 425, "chars": "%s "}, {"char_start": 540, "char_end": 542, "chars": " %"}, {"char_start": 985, "char_end": 987, "chars": "%s"}, {"char_start": 992, "char_end": 994, "chars": "%s"}, {"char_start": 1049, "char_end": 1073, "chars": " % (day_start, day_end)\n"}, {"char_start": 1101, "char_end": 1102, "chars": ")"}], "added": [{"char_start": 415, "char_end": 416, "chars": "?"}, {"char_start": 421, "char_end": 422, "chars": "?"}, {"char_start": 537, "char_end": 538, "chars": ","}, {"char_start": 824, "char_end": 858, "chars": "            self.c.execute(query)\n"}, {"char_start": 1015, "char_end": 1016, "chars": "?"}, {"char_start": 1021, "char_end": 1022, "chars": "?"}, {"char_start": 1057, "char_end": 1058, "chars": ";"}, {"char_start": 1078, "char_end": 1083, "chars": "\n    "}, {"char_start": 1111, "char_end": 1135, "chars": ", (day_start, day_end))\n"}]}, "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "get_requested_day_for_inverter", "func_src_before": "    def get_requested_day_for_inverter(self, inverter_serial, date):\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN %s AND %s AND Serial = %s;\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (day_start, day_end, inverter_serial)):\n            data['data'].append({'time': row[0], 'power': row[1]})\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT EToday\n                FROM Inverters\n                WHERE Serial = %s;\n                ''' % inverter_serial\n        else:\n            query = '''\n                SELECT DayYield AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN %s AND %s AND Serial = %s\n                ''' % (day_start, day_end, inverter_serial)\n        self.c.execute(query)\n        res = self.c.fetchone()\n        if res and res[0]:\n            data['total'] = res[0]\n        else:\n            data['total'] = 0\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData WHERE Serial = %s );\n            ''' % inverter_serial\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data): data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        # print(json.dumps(data, indent=4))\n        return data", "func_src_after": "    def get_requested_day_for_inverter(self, inverter_serial, date):\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN ? AND ? AND Serial=?;\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (day_start, day_end, inverter_serial)):\n            data['data'].append({'time': row[0], 'power': row[1]})\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT EToday\n                FROM Inverters\n                WHERE Serial=?;\n                '''\n            self.c.execute(query, (inverter_serial,))\n        else:\n            query = '''\n                SELECT DayYield AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN ? AND ? AND Serial=?;\n                '''\n            self.c.execute(query, (day_start, day_end, inverter_serial))\n\n        res = self.c.fetchone()\n        if res and res[0]:\n            data['total'] = res[0]\n        else:\n            data['total'] = 0\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData WHERE Serial=? );\n            '''\n\n        self.c.execute(query, (inverter_serial,))\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data): data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        # print(json.dumps(data, indent=4))\n        return data", "line_changes": {"deleted": [{"line_no": 10, "char_start": 394, "char_end": 457, "line": "            WHERE TimeStamp BETWEEN %s AND %s AND Serial = %s;\n"}, {"line_no": 14, "char_start": 504, "char_end": 586, "line": "        for row in self.c.execute(query % (day_start, day_end, inverter_serial)):\n"}, {"line_no": 21, "char_start": 809, "char_end": 844, "line": "                WHERE Serial = %s;\n"}, {"line_no": 22, "char_start": 844, "char_end": 882, "line": "                ''' % inverter_serial\n"}, {"line_no": 27, "char_start": 994, "char_end": 1060, "line": "                WHERE TimeStamp BETWEEN %s AND %s AND Serial = %s\n"}, {"line_no": 28, "char_start": 1060, "char_end": 1120, "line": "                ''' % (day_start, day_end, inverter_serial)\n"}, {"line_no": 29, "char_start": 1120, "char_end": 1150, "line": "        self.c.execute(query)\n"}, {"line_no": 38, "char_start": 1374, "char_end": 1444, "line": "            FROM ( SELECT TimeStamp FROM DayData WHERE Serial = %s );\n"}, {"line_no": 39, "char_start": 1444, "char_end": 1478, "line": "            ''' % inverter_serial\n"}, {"line_no": 41, "char_start": 1479, "char_end": 1509, "line": "        self.c.execute(query)\n"}], "added": [{"line_no": 10, "char_start": 394, "char_end": 452, "line": "            WHERE TimeStamp BETWEEN ? AND ? AND Serial=?;\n"}, {"line_no": 14, "char_start": 499, "char_end": 580, "line": "        for row in self.c.execute(query, (day_start, day_end, inverter_serial)):\n"}, {"line_no": 21, "char_start": 803, "char_end": 835, "line": "                WHERE Serial=?;\n"}, {"line_no": 22, "char_start": 835, "char_end": 855, "line": "                '''\n"}, {"line_no": 23, "char_start": 855, "char_end": 909, "line": "            self.c.execute(query, (inverter_serial,))\n"}, {"line_no": 28, "char_start": 1021, "char_end": 1083, "line": "                WHERE TimeStamp BETWEEN ? AND ? AND Serial=?;\n"}, {"line_no": 29, "char_start": 1083, "char_end": 1103, "line": "                '''\n"}, {"line_no": 30, "char_start": 1103, "char_end": 1176, "line": "            self.c.execute(query, (day_start, day_end, inverter_serial))\n"}, {"line_no": 31, "char_start": 1176, "char_end": 1177, "line": "\n"}, {"line_no": 40, "char_start": 1401, "char_end": 1468, "line": "            FROM ( SELECT TimeStamp FROM DayData WHERE Serial=? );\n"}, {"line_no": 41, "char_start": 1468, "char_end": 1484, "line": "            '''\n"}, {"line_no": 43, "char_start": 1485, "char_end": 1535, "line": "        self.c.execute(query, (inverter_serial,))\n"}]}, "char_changes": {"deleted": [{"char_start": 430, "char_end": 432, "chars": "%s"}, {"char_start": 437, "char_end": 439, "chars": "%s"}, {"char_start": 450, "char_end": 455, "chars": " = %s"}, {"char_start": 543, "char_end": 545, "chars": " %"}, {"char_start": 837, "char_end": 842, "chars": " = %s"}, {"char_start": 863, "char_end": 866, "chars": " % "}, {"char_start": 1034, "char_end": 1036, "chars": "%s"}, {"char_start": 1041, "char_end": 1043, "chars": "%s"}, {"char_start": 1054, "char_end": 1059, "chars": " = %s"}, {"char_start": 1079, "char_end": 1081, "chars": " %"}, {"char_start": 1119, "char_end": 1148, "chars": "\n        self.c.execute(query"}, {"char_start": 1435, "char_end": 1440, "chars": " = %s"}, {"char_start": 1459, "char_end": 1477, "chars": " % inverter_serial"}], "added": [{"char_start": 430, "char_end": 431, "chars": "?"}, {"char_start": 436, "char_end": 437, "chars": "?"}, {"char_start": 448, "char_end": 450, "chars": "=?"}, {"char_start": 538, "char_end": 539, "chars": ","}, {"char_start": 831, "char_end": 833, "chars": "=?"}, {"char_start": 854, "char_end": 890, "chars": "\n            self.c.execute(query, ("}, {"char_start": 905, "char_end": 908, "chars": ",))"}, {"char_start": 1061, "char_end": 1062, "chars": "?"}, {"char_start": 1067, "char_end": 1068, "chars": "?"}, {"char_start": 1079, "char_end": 1082, "chars": "=?;"}, {"char_start": 1102, "char_end": 1136, "chars": "\n            self.c.execute(query,"}, {"char_start": 1174, "char_end": 1175, "chars": ")"}, {"char_start": 1462, "char_end": 1464, "chars": "=?"}, {"char_start": 1513, "char_end": 1533, "chars": ", (inverter_serial,)"}]}, "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "get_requested_month", "func_src_before": "    def get_requested_month(self, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, SUM(DayYield) AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN %s AND %s\n            GROUP BY TimeStamp\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (month_start, month_end)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM MonthData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "func_src_after": "    def get_requested_month(self, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, SUM(DayYield) AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN ? AND ?\n            GROUP BY TimeStamp;\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (month_start, month_end)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM MonthData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "line_changes": {"deleted": [{"line_no": 11, "char_start": 419, "char_end": 465, "line": "            WHERE TimeStamp BETWEEN %s AND %s\n"}, {"line_no": 12, "char_start": 465, "char_end": 496, "line": "            GROUP BY TimeStamp\n"}, {"line_no": 16, "char_start": 543, "char_end": 612, "line": "        for row in self.c.execute(query % (month_start, month_end)):\n"}], "added": [{"line_no": 11, "char_start": 419, "char_end": 463, "line": "            WHERE TimeStamp BETWEEN ? AND ?\n"}, {"line_no": 12, "char_start": 463, "char_end": 495, "line": "            GROUP BY TimeStamp;\n"}, {"line_no": 16, "char_start": 542, "char_end": 610, "line": "        for row in self.c.execute(query, (month_start, month_end)):\n"}]}, "char_changes": {"deleted": [{"char_start": 455, "char_end": 457, "chars": "%s"}, {"char_start": 462, "char_end": 464, "chars": "%s"}, {"char_start": 582, "char_end": 584, "chars": " %"}], "added": [{"char_start": 455, "char_end": 456, "chars": "?"}, {"char_start": 461, "char_end": 462, "chars": "?"}, {"char_start": 493, "char_end": 494, "chars": ";"}, {"char_start": 581, "char_end": 582, "chars": ","}]}, "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "get_requested_month_for_inverter", "func_src_before": "    def get_requested_month_for_inverter(self, inverter_serial, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, DayYield AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN %s AND %s AND Serial = %s\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (month_start, month_end, inverter_serial)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM MonthData \n            WHERE Serial = %s;\n            ''' % inverter_serial\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "func_src_after": "    def get_requested_month_for_inverter(self, inverter_serial, date):\n        data = dict()\n\n        month_start, month_end = self.get_epoch_month(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(month_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(month_end, self.local_timezone)}\n        month_total = 0\n\n        query = '''\n            SELECT TimeStamp, DayYield AS Power \n            FROM MonthData \n            WHERE TimeStamp BETWEEN ? AND ? AND Serial=?;\n            '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (month_start, month_end, inverter_serial)):\n            data['data'].append({'time': self.convert_local_ts_to_utc(row[0], self.local_timezone), 'power': row[1]})\n            month_total += row[1]\n\n        data['total'] = month_total\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM MonthData \n            WHERE Serial=?;\n            '''\n\n        self.c.execute(query, (inverter_serial,))\n        first_data, last_data = self.c.fetchone()\n\n        if first_data: data['hasPrevious'] = (first_data < month_start)\n        else: data['hasPrevious'] = False\n        if last_data: data['hasNext'] = (last_data > month_end)\n        else: data['hasNext'] = False\n\n        return data", "line_changes": {"deleted": [{"line_no": 11, "char_start": 444, "char_end": 506, "line": "            WHERE TimeStamp BETWEEN %s AND %s AND Serial = %s\n"}, {"line_no": 15, "char_start": 553, "char_end": 639, "line": "        for row in self.c.execute(query % (month_start, month_end, inverter_serial)):\n"}, {"line_no": 24, "char_start": 942, "char_end": 973, "line": "            WHERE Serial = %s;\n"}, {"line_no": 25, "char_start": 973, "char_end": 1007, "line": "            ''' % inverter_serial\n"}, {"line_no": 27, "char_start": 1008, "char_end": 1038, "line": "        self.c.execute(query)\n"}], "added": [{"line_no": 11, "char_start": 444, "char_end": 502, "line": "            WHERE TimeStamp BETWEEN ? AND ? AND Serial=?;\n"}, {"line_no": 15, "char_start": 549, "char_end": 634, "line": "        for row in self.c.execute(query, (month_start, month_end, inverter_serial)):\n"}, {"line_no": 24, "char_start": 937, "char_end": 965, "line": "            WHERE Serial=?;\n"}, {"line_no": 25, "char_start": 965, "char_end": 981, "line": "            '''\n"}, {"line_no": 27, "char_start": 982, "char_end": 1032, "line": "        self.c.execute(query, (inverter_serial,))\n"}]}, "char_changes": {"deleted": [{"char_start": 480, "char_end": 482, "chars": "%s"}, {"char_start": 487, "char_end": 489, "chars": "%s"}, {"char_start": 500, "char_end": 505, "chars": " = %s"}, {"char_start": 592, "char_end": 594, "chars": " %"}, {"char_start": 966, "char_end": 971, "chars": " = %s"}, {"char_start": 988, "char_end": 1006, "chars": " % inverter_serial"}], "added": [{"char_start": 480, "char_end": 481, "chars": "?"}, {"char_start": 486, "char_end": 487, "chars": "?"}, {"char_start": 498, "char_end": 501, "chars": "=?;"}, {"char_start": 588, "char_end": 589, "chars": ","}, {"char_start": 961, "char_end": 963, "chars": "=?"}, {"char_start": 1010, "char_end": 1030, "chars": ", (inverter_serial,)"}]}, "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089"}
{"func_name": "get_posts", "func_src_before": "def get_posts():\n  \"\"\"Return all posts from the 'database', most recent first.\"\"\"\n  return reversed(POSTS)", "func_src_after": "def get_posts():\n  \"\"\"Return all posts from the 'database', most recent first.\"\"\"\n  # conn = psycopg2.connect(\"dbname=forum\")\n  conn = psycopg2.connect(database=DBNAME)\n  cursor = conn.cursor()\n  cursor.execute(\"select content,time from posts order by time desc\")\n  results = cursor.fetchall()\n  # bleach.clean all the results\n  clean_results = list(map(lambda x: (bleach.clean(x[0]), x[1]), results )) #clean the text in the database, so when it gets displayed on the browser, it doesn't get interpreted as code\n  conn.close()\n  # return results\n  return clean_results", "line_changes": {"deleted": [{"line_no": 3, "char_start": 82, "char_end": 106, "line": "  return reversed(POSTS)\n"}], "added": [{"line_no": 4, "char_start": 126, "char_end": 169, "line": "  conn = psycopg2.connect(database=DBNAME)\n"}, {"line_no": 5, "char_start": 169, "char_end": 194, "line": "  cursor = conn.cursor()\n"}, {"line_no": 6, "char_start": 194, "char_end": 264, "line": "  cursor.execute(\"select content,time from posts order by time desc\")\n"}, {"line_no": 7, "char_start": 264, "char_end": 294, "line": "  results = cursor.fetchall()\n"}, {"line_no": 9, "char_start": 327, "char_end": 513, "line": "  clean_results = list(map(lambda x: (bleach.clean(x[0]), x[1]), results )) #clean the text in the database, so when it gets displayed on the browser, it doesn't get interpreted as code\n"}, {"line_no": 10, "char_start": 513, "char_end": 528, "line": "  conn.close()\n"}, {"line_no": 12, "char_start": 547, "char_end": 569, "line": "  return clean_results\n"}]}, "char_changes": {"deleted": [{"char_start": 84, "char_end": 106, "chars": "return reversed(POSTS)"}], "added": [{"char_start": 84, "char_end": 569, "chars": "# conn = psycopg2.connect(\"dbname=forum\")\n  conn = psycopg2.connect(database=DBNAME)\n  cursor = conn.cursor()\n  cursor.execute(\"select content,time from posts order by time desc\")\n  results = cursor.fetchall()\n  # bleach.clean all the results\n  clean_results = list(map(lambda x: (bleach.clean(x[0]), x[1]), results )) #clean the text in the database, so when it gets displayed on the browser, it doesn't get interpreted as code\n  conn.close()\n  # return results\n  return clean_results"}]}, "commit_link": "github.com/lzhengem/fullstack-nanodegree-vm/commit/71aaaab9467abfb6c3edd2e7a365a242b5d15a9b", "file_name": "vagrant/forum/forumdb.py", "vul_type": "cwe-089"}
{"func_name": "get_one_user", "func_src_before": "def get_one_user(user_id):\n    \"\"\" \u83b7\u53d6\u5355\u4e2a\u7528\u6237\uff0c\u6d4b\u8bd5sql \u6ce8\u5165\"\"\"\n    conn = sqlite3.connect(DB_FILE)\n\n    sql = 'select * from home_user WHERE id={};'.format(user_id)\n    print('sql', sql)\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    res = cursor.fetchall()\n    return res", "func_src_after": "def get_one_user(user_id):\n    \"\"\" \u83b7\u53d6\u5355\u4e2a\u7528\u6237\uff0c\u6d4b\u8bd5sql \u6ce8\u5165\"\"\"\n\n    # \u9632\u6b62Sql\u6ce8\u5165\u7684sql\u6267\u884c\u65b9\u5f0f\n    # sql2 = \"select * from home_user WHERE id=%s\"\n    # with connection.cursor() as cursor:\n    #     cursor.execute(sql2, [user_id])\n    #     res = cursor.fetchall()\n\n    sql = 'select * from home_user WHERE id={};'.format(user_id)\n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    res = cursor.fetchall()\n    return res", "line_changes": {"deleted": [{"line_no": 3, "char_start": 54, "char_end": 90, "line": "    conn = sqlite3.connect(DB_FILE)\n"}, {"line_no": 6, "char_start": 156, "char_end": 178, "line": "    print('sql', sql)\n"}, {"line_no": 10, "char_start": 257, "char_end": 271, "line": "    return res\n"}], "added": [{"line_no": 3, "char_start": 54, "char_end": 55, "line": "\n"}, {"line_no": 11, "char_start": 312, "char_end": 348, "line": "    conn = sqlite3.connect(DB_FILE)\n"}]}, "char_changes": {"deleted": [{"char_start": 58, "char_end": 88, "chars": "conn = sqlite3.connect(DB_FILE"}, {"char_start": 160, "char_end": 176, "chars": "print('sql', sql"}], "added": [{"char_start": 54, "char_end": 244, "chars": "\n    # \u9632\u6b62Sql\u6ce8\u5165\u7684sql\u6267\u884c\u65b9\u5f0f\n    # sql2 = \"select * from home_user WHERE id=%s\"\n    # with connection.cursor() as cursor:\n    #     cursor.execute(sql2, [user_id])\n    #     res = cursor.fetchall("}, {"char_start": 316, "char_end": 346, "chars": "conn = sqlite3.connect(DB_FILE"}]}, "commit_link": "github.com/Briskwind/Collector/commit/d577060cef1df621c02b14c335ca6786fb984ba0", "file_name": "server/extensions/sqlite_conn.py", "vul_type": "cwe-089"}
{"func_name": "get_top_popular", "func_src_before": "def get_top_popular(top_num):\r\n    \"\"\" query the top(top_num) popular articles\r\n        top_num => list of [title, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT title, views FROM articles\r\n             INNER JOIN (\r\n             SELECT path, count(path) AS views\r\n             FROM log GROUP BY log.path\r\n             ) AS log\r\n             ON log.path = '/article/' || articles.slug\r\n             ORDER BY views DESC\r\n             LIMIT {}\"\"\".format(top_num)\r\n    return execute_query(cmd)", "func_src_after": "def get_top_popular(top_num):\r\n    \"\"\" query the top(top_num) popular articles\r\n        top_num => list of [title, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT title, views FROM articles\r\n             INNER JOIN (\r\n             SELECT path, count(path) AS views\r\n             FROM log GROUP BY log.path\r\n             ) AS log\r\n             ON log.path = '/article/' || articles.slug\r\n             ORDER BY views DESC\r\n             LIMIT %s\"\"\"\r\n    data = [top_num, ]\r\n    return execute_query(cmd, data)", "line_changes": {"deleted": [{"line_no": 12, "char_start": 410, "char_end": 452, "line": "             LIMIT {}\"\"\".format(top_num)\r\n"}, {"line_no": 13, "char_start": 452, "char_end": 481, "line": "    return execute_query(cmd)\r\n"}], "added": [{"line_no": 12, "char_start": 410, "char_end": 436, "line": "             LIMIT %s\"\"\"\r\n"}, {"line_no": 13, "char_start": 436, "char_end": 460, "line": "    data = [top_num, ]\r\n"}, {"line_no": 14, "char_start": 460, "char_end": 495, "line": "    return execute_query(cmd, data)\r\n"}]}, "char_changes": {"deleted": [{"char_start": 429, "char_end": 431, "chars": "{}"}, {"char_start": 434, "char_end": 442, "chars": ".format("}, {"char_start": 449, "char_end": 450, "chars": ")"}], "added": [{"char_start": 429, "char_end": 431, "chars": "%s"}, {"char_start": 434, "char_end": 448, "chars": "\r\n    data = ["}, {"char_start": 455, "char_end": 458, "chars": ", ]"}, {"char_start": 488, "char_end": 494, "chars": ", data"}]}, "commit_link": "github.com/thugasin/udacity-homework-logAnalyzer/commit/506f25f9a1caee7f17034adf7c75e0efbc88082b", "file_name": "logAnalyzerDb.py", "vul_type": "cwe-089"}
{"func_name": "get_top_author", "func_src_before": "def get_top_author(top_num):\r\n    \"\"\" query the top(top_num) popular author\r\n        top_num => list of [author, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT authors.name,author_result.num\r\n                    FROM authors JOIN\r\n                    (SELECT SUM(article_result.num) as num,\r\n                    article_result.author\r\n                    from (SELECT articles.title, articles.author,\r\n                    SUM(log.views) AS num\r\n                    FROM articles\r\n                    INNER JOIN (\r\n                    SELECT path, count(path) AS views\r\n                    FROM log GROUP BY log.path\r\n                    ) AS log ON log.path = '/article/'\r\n                    || articles.slug\r\n                    GROUP BY articles.title, articles.author)\r\n                    AS article_result\r\n                    GROUP BY article_result.author) as author_result\r\n                    ON authors.id = author_result.author\r\n                    ORDER BY num DESC LIMIT {}\"\"\".format(top_num)\r\n    return execute_query(cmd)", "func_src_after": "def get_top_author(top_num):\r\n    \"\"\" query the top(top_num) popular author\r\n        top_num => list of [author, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT authors.name,author_result.num\r\n                    FROM authors JOIN\r\n                    (SELECT SUM(article_result.num) as num,\r\n                    article_result.author\r\n                    from (SELECT articles.title, articles.author,\r\n                    SUM(log.views) AS num\r\n                    FROM articles\r\n                    INNER JOIN (\r\n                    SELECT path, count(path) AS views\r\n                    FROM log GROUP BY log.path\r\n                    ) AS log ON log.path = '/article/'\r\n                    || articles.slug\r\n                    GROUP BY articles.title, articles.author)\r\n                    AS article_result\r\n                    GROUP BY article_result.author) as author_result\r\n                    ON authors.id = author_result.author\r\n                    ORDER BY num DESC LIMIT %s\"\"\"\r\n    data = [top_num, ]\r\n    return execute_query(cmd, data)", "line_changes": {"deleted": [{"line_no": 21, "char_start": 931, "char_end": 998, "line": "                    ORDER BY num DESC LIMIT {}\"\"\".format(top_num)\r\n"}, {"line_no": 22, "char_start": 998, "char_end": 1027, "line": "    return execute_query(cmd)\r\n"}], "added": [{"line_no": 21, "char_start": 931, "char_end": 982, "line": "                    ORDER BY num DESC LIMIT %s\"\"\"\r\n"}, {"line_no": 22, "char_start": 982, "char_end": 1006, "line": "    data = [top_num, ]\r\n"}, {"line_no": 23, "char_start": 1006, "char_end": 1041, "line": "    return execute_query(cmd, data)\r\n"}]}, "char_changes": {"deleted": [{"char_start": 975, "char_end": 977, "chars": "{}"}, {"char_start": 980, "char_end": 988, "chars": ".format("}, {"char_start": 995, "char_end": 996, "chars": ")"}], "added": [{"char_start": 975, "char_end": 977, "chars": "%s"}, {"char_start": 980, "char_end": 994, "chars": "\r\n    data = ["}, {"char_start": 1001, "char_end": 1004, "chars": ", ]"}, {"char_start": 1034, "char_end": 1040, "chars": ", data"}]}, "commit_link": "github.com/thugasin/udacity-homework-logAnalyzer/commit/506f25f9a1caee7f17034adf7c75e0efbc88082b", "file_name": "logAnalyzerDb.py", "vul_type": "cwe-089"}
{"func_name": "__init__", "func_src_before": "    def __init__(self, parent, controller):\n        Frame.__init__(self, parent)\n\n        viewRecipeFrame = Frame(self, bg=\"#f8f8f8\")\n        menuFrame = Frame(self, bg=\"#e7e7e7\")\n\n        frame = Frame(self, bg=\"#f8f8f8\")\n        frame.pack(expand=True, fill='both')\n\n        Label(frame, text=\"Trisha's Meal Planner\", font=LARGE_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(fill='both', pady=20)\n\n        load = Image.open(\"recipe_card.jpg\")\n        render = ImageTk.PhotoImage(load)\n        img = Label(frame, image = render, bg=\"#f8f8f8\")\n        img.image = render\n        img.pack(fill='both', pady=40)\n\n        Button(frame, text=\"Add A Recipe\", highlightbackground=\"#f8f8f8\", command=lambda: controller.show_frame(AddARecipe)).pack(fill=Y)\n        Button(frame, text=\"Make a Meal Plan\", highlightbackground=\"#f8f8f8\", command=lambda: controller.show_frame(MakeMealPlan)).pack(fill=Y)\n        Button(frame, text=\"View Recipes\", highlightbackground=\"#f8f8f8\", command=lambda: view_recipes()).pack(fill=Y)\n\n        def view_recipes():\n            frame.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n\n            database_file = \"meal_planner.db\"\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe\"\"\")\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        recipeNames.append(name)\n            conn.close()\n            for i in range(len(recipeNames)):\n                label = Label(viewRecipeFrame, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\", text=recipeNames[i])\n                label.pack()\n                label.bind(\"<Button-1>\", lambda  event, x=recipeNames[i]: [callback(x), viewRecipeFrame.pack_forget()])\n\n\n        def callback(recipeName):\n                viewRecipeFrame.pack_forget()\n                database_file = \"meal_planner.db\"\n\n                menuFrame.pack(fill='both')\n                load = Image.open(\"home.jpg\")\n                render = ImageTk.PhotoImage(load)\n                img = Button(menuFrame, image=render, borderwidth=0, highlightthickness=0,\n                             highlightbackground=\"#e7e7e7\",\n                             command=lambda: [frame.pack(expand=True, fill='both'), menuFrame.pack_forget(), viewDetailsFrame.pack_forget()])\n                img.image = render\n                img.pack(side=LEFT)\n                label = Label(menuFrame, text=\"View Recipe\", font=LARGE_FONT, bg=\"#e7e7e7\", fg=\"#272822\")\n                label.pack(side=LEFT, padx=300)\n\n                viewDetailsFrame = Frame(self, bg=\"#f8f8f8\")\n                viewDetailsFrame.pack(expand=True, fill='both')\n                with sqlite3.connect(database_file) as conn:\n                    cursor = conn.cursor()\n                    selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\" )\n                    for result in [selection]:\n                        for row in result.fetchall():\n                            name = row[0]\n                            time = row[1]\n                            servings = row[2]\n                            favorite = row[3]\n                            ingredients = row[4]\n                            directions = row[5]\n                    string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n Ingredients: {} \\n Directions: {}\".format(name, time, servings, ingredients, directions))\n                    Label(viewDetailsFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=LEFT)\n                conn.close()\n\n                Button(menuFrame, text=\"Delete\", highlightbackground=\"#e7e7e7\",\n                       command=lambda: delete_recipe(name)).pack(side=RIGHT)\n\n        def delete_recipe(recipeName):\n            database_file = \"meal_planner.db\"\n\n            now = datetime.datetime.now()\n            dt = datetime.date(now.year, now.month, now.day)\n            weekNumber = dt.isocalendar()[1]\n\n            tableName = \"recipes_\" + str(weekNumber)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                cursor.execute(\"\"\"SELECT recipe FROM \"\"\" + tableName + \"\"\" WHERE recipe = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n                returnObject = cursor.fetchone()\n                if returnObject:\n                    print(returnObject[0])\n                    messagebox.showerror(\"Cannot Delete\",\n                                         \"Cannot delete recipe when it's used in the current week's menu.\")\n                    # conn.close()\n                else:\n                    # conn.close()\n                    actually_delete(recipeName)\n\n        def actually_delete(recipeName):\n            queryString = \"\\\"\" + recipeName + \"\\\"\"\n            with sqlite3.connect(\"meal_planner.db\") as conn:\n                cursor = conn.cursor()\n                cursor.execute(\"\"\"DELETE FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n                print(cursor.rowcount)\n                if cursor.rowcount == 1:\n                    messagebox.showinfo(\"Success\", \"Recipe Deleted.\")\n                    menuFrame.pack_forget()\n                    viewRecipeFrame.pack(expand=True, fill='both')\n                elif cursor.rowcount == 0:\n                    messagebox.showerror(\"Cannot Delete\",\n                                         \"Cannot delete recipe, please try again.\")\n            conn.close()", "func_src_after": "    def __init__(self, parent, controller):\n        Frame.__init__(self, parent)\n\n        viewRecipeFrame = Frame(self, bg=\"#f8f8f8\")\n        menuFrame = Frame(self, bg=\"#e7e7e7\")\n        viewDetailsFrame = Frame(self, bg=\"#f8f8f8\")\n\n        frame = Frame(self, bg=\"#f8f8f8\")\n        frame.pack(expand=True, fill='both')\n\n        Label(frame, text=\"Trisha's Meal Planner\", font=LARGE_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(fill='both', pady=20)\n\n        load = Image.open(\"recipe_card.jpg\")\n        render = ImageTk.PhotoImage(load)\n        img = Label(frame, image = render, bg=\"#f8f8f8\")\n        img.image = render\n        img.pack(fill='both', pady=40)\n\n        Button(frame, text=\"Add A Recipe\", highlightbackground=\"#f8f8f8\", command=lambda: controller.show_frame(AddARecipe)).pack(fill=Y)\n        Button(frame, text=\"Make a Meal Plan\", highlightbackground=\"#f8f8f8\", command=lambda: controller.show_frame(MakeMealPlan)).pack(fill=Y)\n        Button(frame, text=\"View Recipes\", highlightbackground=\"#f8f8f8\", command=lambda: view_recipes()).pack(fill=Y)\n\n        def view_recipes():\n            frame.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n\n            database_file = \"meal_planner.db\"\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe\"\"\")\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        recipeNames.append(name)\n            conn.close()\n            for i in range(len(recipeNames)):\n                label = Label(viewRecipeFrame, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\", text=recipeNames[i])\n                label.pack()\n                label.bind(\"<Button-1>\", lambda  event, x=recipeNames[i]: [callback(x), viewRecipeFrame.pack_forget()])\n\n\n        def callback(recipeName):\n                viewRecipeFrame.pack_forget()\n                database_file = \"meal_planner.db\"\n\n                menuFrame.pack(fill='both')\n                load = Image.open(\"home.jpg\")\n                render = ImageTk.PhotoImage(load)\n                img = Button(menuFrame, image=render, borderwidth=0, highlightthickness=0,\n                             highlightbackground=\"#e7e7e7\",\n                             command=lambda: [frame.pack(expand=True, fill='both'), menuFrame.pack_forget(), viewDetailsFrame.pack_forget()])\n                img.image = render\n                img.pack(side=LEFT)\n                label = Label(menuFrame, text=\"View Recipe\", font=LARGE_FONT, bg=\"#e7e7e7\", fg=\"#272822\")\n                label.pack(side=LEFT, padx=300)\n\n                viewDetailsFrame.pack(expand=True, fill='both')\n                with sqlite3.connect(database_file) as conn:\n                    cursor = conn.cursor()\n                    selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n                    for result in [selection]:\n                        for row in result.fetchall():\n                            name = row[0]\n                            time = row[1]\n                            servings = row[2]\n                            favorite = row[3]\n                            ingredients = row[4]\n                            directions = row[5]\n                    string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n Ingredients: {} \\n Directions: {}\".format(name, time, servings, ingredients, directions))\n                    Label(viewDetailsFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=LEFT)\n                conn.close()\n\n                Button(menuFrame, text=\"Delete\", highlightbackground=\"#e7e7e7\",\n                       command=lambda: delete_recipe(name)).pack(side=RIGHT)\n\n        def delete_recipe(recipeName):\n            database_file = \"meal_planner.db\"\n\n            now = datetime.datetime.now()\n            dt = datetime.date(now.year, now.month, now.day)\n            weekNumber = dt.isocalendar()[1]\n\n            tableName = \"recipes_\" + str(weekNumber)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                cursor.execute(\"\"\"SELECT count(*) FROM \"\"\" + tableName + \"\"\" WHERE recipe = ?;\"\"\", (recipeName, ))\n                returnObject = cursor.fetchone()[0]\n                if returnObject == 0:\n                    actually_delete(recipeName)\n                    print(\"there is no component named {}\".format(recipeName))\n                else:\n                    print(\"component {} found\".format(recipeName))\n                    messagebox.showerror(\"Cannot Delete\",\n                                         \"Cannot delete recipe when it's used in the current week's menu.\")\n\n\n        def actually_delete(recipeName):\n            with sqlite3.connect(\"meal_planner.db\") as conn:\n                cursor = conn.cursor()\n                cursor.execute(\"\"\"DELETE FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n                if cursor.rowcount == 1:\n                    messagebox.showinfo(\"Success\", \"Recipe Deleted.\")\n                    menuFrame.pack_forget()\n                    viewDetailsFrame.pack_forget()\n                    viewRecipeFrame.pack_forget()\n                    frame.pack(expand=True, fill='both')\n                elif cursor.rowcount == 0:\n                    messagebox.showerror(\"Cannot Delete\", \"Error.\")\n            conn.close()", "line_changes": {"deleted": [{"line_no": 56, "char_start": 2645, "char_end": 2706, "line": "                viewDetailsFrame = Frame(self, bg=\"#f8f8f8\")\n"}, {"line_no": 60, "char_start": 2874, "char_end": 2991, "line": "                    selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\" )\n"}, {"line_no": 86, "char_start": 4232, "char_end": 4354, "line": "                cursor.execute(\"\"\"SELECT recipe FROM \"\"\" + tableName + \"\"\" WHERE recipe = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n"}, {"line_no": 87, "char_start": 4354, "char_end": 4403, "line": "                returnObject = cursor.fetchone()\n"}, {"line_no": 88, "char_start": 4403, "char_end": 4436, "line": "                if returnObject:\n"}, {"line_no": 89, "char_start": 4436, "char_end": 4479, "line": "                    print(returnObject[0])\n"}, {"line_no": 93, "char_start": 4680, "char_end": 4702, "line": "                else:\n"}, {"line_no": 95, "char_start": 4737, "char_end": 4785, "line": "                    actually_delete(recipeName)\n"}, {"line_no": 98, "char_start": 4827, "char_end": 4878, "line": "            queryString = \"\\\"\" + recipeName + \"\\\"\"\n"}, {"line_no": 101, "char_start": 4978, "char_end": 5076, "line": "                cursor.execute(\"\"\"DELETE FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n"}, {"line_no": 102, "char_start": 5076, "char_end": 5115, "line": "                print(cursor.rowcount)\n"}, {"line_no": 106, "char_start": 5270, "char_end": 5337, "line": "                    viewRecipeFrame.pack(expand=True, fill='both')\n"}, {"line_no": 108, "char_start": 5380, "char_end": 5438, "line": "                    messagebox.showerror(\"Cannot Delete\",\n"}, {"line_no": 109, "char_start": 5438, "char_end": 5522, "line": "                                         \"Cannot delete recipe, please try again.\")\n"}], "added": [{"line_no": 6, "char_start": 180, "char_end": 233, "line": "        viewDetailsFrame = Frame(self, bg=\"#f8f8f8\")\n"}, {"line_no": 60, "char_start": 2866, "char_end": 2973, "line": "                    selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n"}, {"line_no": 86, "char_start": 4214, "char_end": 4329, "line": "                cursor.execute(\"\"\"SELECT count(*) FROM \"\"\" + tableName + \"\"\" WHERE recipe = ?;\"\"\", (recipeName, ))\n"}, {"line_no": 87, "char_start": 4329, "char_end": 4381, "line": "                returnObject = cursor.fetchone()[0]\n"}, {"line_no": 88, "char_start": 4381, "char_end": 4419, "line": "                if returnObject == 0:\n"}, {"line_no": 89, "char_start": 4419, "char_end": 4467, "line": "                    actually_delete(recipeName)\n"}, {"line_no": 90, "char_start": 4467, "char_end": 4546, "line": "                    print(\"there is no component named {}\".format(recipeName))\n"}, {"line_no": 91, "char_start": 4546, "char_end": 4568, "line": "                else:\n"}, {"line_no": 92, "char_start": 4568, "char_end": 4635, "line": "                    print(\"component {} found\".format(recipeName))\n"}, {"line_no": 95, "char_start": 4801, "char_end": 4802, "line": "\n"}, {"line_no": 100, "char_start": 4944, "char_end": 5033, "line": "                cursor.execute(\"\"\"DELETE FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n"}, {"line_no": 104, "char_start": 5188, "char_end": 5239, "line": "                    viewDetailsFrame.pack_forget()\n"}, {"line_no": 105, "char_start": 5239, "char_end": 5289, "line": "                    viewRecipeFrame.pack_forget()\n"}, {"line_no": 106, "char_start": 5289, "char_end": 5346, "line": "                    frame.pack(expand=True, fill='both')\n"}, {"line_no": 108, "char_start": 5389, "char_end": 5457, "line": "                    messagebox.showerror(\"Cannot Delete\", \"Error.\")\n"}]}, "char_changes": {"deleted": [{"char_start": 2645, "char_end": 2706, "chars": "                viewDetailsFrame = Frame(self, bg=\"#f8f8f8\")\n"}, {"char_start": 2958, "char_end": 2971, "chars": "\"\"\" + \"\\\"\" + "}, {"char_start": 2981, "char_end": 2989, "chars": " + \"\\\"\" "}, {"char_start": 4273, "char_end": 4279, "chars": "recipe"}, {"char_start": 4325, "char_end": 4335, "chars": " + \"\\\"\" + "}, {"char_start": 4345, "char_end": 4352, "chars": " + \"\\\"\""}, {"char_start": 4456, "char_end": 4542, "chars": "print(returnObject[0])\n                    messagebox.showerror(\"Cannot Delete\",\n     "}, {"char_start": 4578, "char_end": 4701, "chars": "\"Cannot delete recipe when it's used in the current week's menu.\")\n                    # conn.close()\n                else:"}, {"char_start": 4722, "char_end": 4737, "chars": "# conn.close()\n"}, {"char_start": 4757, "char_end": 4766, "chars": "actually_"}, {"char_start": 4772, "char_end": 4773, "chars": "("}, {"char_start": 4779, "char_end": 4784, "chars": "Name)"}, {"char_start": 4827, "char_end": 4878, "chars": "            queryString = \"\\\"\" + recipeName + \"\\\"\"\n"}, {"char_start": 5044, "char_end": 5113, "chars": "\"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n                print(cursor.rowcount"}, {"char_start": 5294, "char_end": 5301, "chars": "RecipeF"}, {"char_start": 5437, "char_end": 5518, "chars": "\n                                         \"Cannot delete recipe, please try again"}], "added": [{"char_start": 179, "char_end": 232, "chars": "\n        viewDetailsFrame = Frame(self, bg=\"#f8f8f8\")"}, {"char_start": 2950, "char_end": 2958, "chars": "?;\"\"\", ("}, {"char_start": 2968, "char_end": 2971, "chars": ", )"}, {"char_start": 4255, "char_end": 4263, "chars": "count(*)"}, {"char_start": 4306, "char_end": 4314, "chars": "?;\"\"\", ("}, {"char_start": 4324, "char_end": 4327, "chars": ", )"}, {"char_start": 4377, "char_end": 4380, "chars": "[0]"}, {"char_start": 4412, "char_end": 4417, "chars": " == 0"}, {"char_start": 4439, "char_end": 4545, "chars": "actually_delete(recipeName)\n                    print(\"there is no component named {}\".format(recipeName))"}, {"char_start": 4562, "char_end": 4568, "chars": "else:\n"}, {"char_start": 4588, "char_end": 4692, "chars": "print(\"component {} found\".format(recipeName))\n                    messagebox.showerror(\"Cannot Delete\","}, {"char_start": 4713, "char_end": 4714, "chars": " "}, {"char_start": 4734, "char_end": 4742, "chars": "\"Cannot "}, {"char_start": 4748, "char_end": 4749, "chars": " "}, {"char_start": 4755, "char_end": 4801, "chars": " when it's used in the current week's menu.\")\n"}, {"char_start": 5010, "char_end": 5012, "chars": "?;"}, {"char_start": 5015, "char_end": 5031, "chars": ", (recipeName, )"}, {"char_start": 5212, "char_end": 5310, "chars": "DetailsFrame.pack_forget()\n                    viewRecipeFrame.pack_forget()\n                    f"}, {"char_start": 5446, "char_end": 5453, "chars": " \"Error"}]}, "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "landingpage.py", "vul_type": "cwe-089"}
{"func_name": "__init__.callback", "func_src_before": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "line_changes": {"deleted": [{"line_no": 9, "char_start": 336, "char_end": 448, "line": "                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n"}], "added": [{"line_no": 9, "char_start": 336, "char_end": 439, "line": "                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 419, "char_end": 429, "chars": " + \"\\\"\" + "}, {"char_start": 439, "char_end": 446, "chars": " + \"\\\"\""}], "added": [{"char_start": 416, "char_end": 424, "chars": "?;\"\"\", ("}, {"char_start": 434, "char_end": 437, "chars": ", )"}]}, "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089"}
{"func_name": "__init__.view_grocery_list", "func_src_before": "        def view_grocery_list():\n            print(\"grocery== list\")\n            groceryListFrame = Frame(self)\n            groceryListFrame.rowconfigure(0, weight=1)\n            groceryListFrame.columnconfigure(0, weight=1)\n            groceryListFrame.rowconfigure(1, weight=3)\n            groceryListFrame.columnconfigure(1, weight=3)\n            groceryListFrame.pack()\n\n            menu.pack_forget()\n            groceryButton.pack_forget()\n            label.configure(text=\"Grocery List\")\n\n            i = 0\n            database_file = \"meal_planner.db\"\n            item_array = []\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                tableName = \"ingredients_\" + str(weekNumber)\n                selection = cursor.execute(\"\"\"SELECT * FROM \"\"\" + tableName)\n                for result in [selection]:\n                    for row in result.fetchall():\n                        print(row)\n                        for ingredient in row:\n                            print(ingredient)\n                            item_array.append(str(ingredient).split())\n                        i = i +1\n                        Label(groceryListFrame, text=ingredient, font=MEDIUM_FONT, justify=LEFT).grid(row=i, column=0, sticky=\"w\")\n            \n\n            j = 0\n            for item in item_array:\n                print(item)\n\n\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [groceryListFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def view_grocery_list():\n            print(\"grocery== list\")\n            groceryListFrame = Frame(self)\n            groceryListFrame.rowconfigure(0, weight=1)\n            groceryListFrame.columnconfigure(0, weight=1)\n            groceryListFrame.rowconfigure(1, weight=3)\n            groceryListFrame.columnconfigure(1, weight=3)\n            groceryListFrame.pack()\n\n            menu.pack_forget()\n            groceryButton.pack_forget()\n            label.configure(text=\"Grocery List\")\n\n            i = 0\n            database_file = \"meal_planner.db\"\n            item_array = []\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                tableName = \"ingredients_\" + str(weekNumber)\n                selection = cursor.execute(\"\"\"SELECT * FROM ?;\"\"\", (tableName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        print(row)\n                        for ingredient in row:\n                            print(ingredient)\n                            item_array.append(str(ingredient).split())\n                        i = i +1\n                        Label(groceryListFrame, text=ingredient, font=MEDIUM_FONT, justify=LEFT).grid(row=i, column=0, sticky=\"w\")\n            \n\n            j = 0\n            for item in item_array:\n                print(item)\n\n\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [groceryListFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "line_changes": {"deleted": [{"line_no": 20, "char_start": 745, "char_end": 822, "line": "                selection = cursor.execute(\"\"\"SELECT * FROM \"\"\" + tableName)\n"}], "added": [{"line_no": 20, "char_start": 745, "char_end": 827, "line": "                selection = cursor.execute(\"\"\"SELECT * FROM ?;\"\"\", (tableName, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 808, "char_end": 811, "chars": " + "}], "added": [{"char_start": 805, "char_end": 807, "chars": "?;"}, {"char_start": 810, "char_end": 813, "chars": ", ("}, {"char_start": 822, "char_end": 825, "chars": ", )"}]}, "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089"}
{"func_name": "get_top_articles", "func_src_before": "def get_top_articles(list_count):\n    \"\"\"Return article and number of times viewed with most viewed first.\"\"\"\n    query = (\n        'select a.title, count(alv.article) as views from articles a, '\n        ' article_log_view alv where a.slug = alv.article '\n        ' group by a.title '\n        ' order by count(alv.article) desc limit %d;' % list_count)\n    db = psycopg2.connect(database=DBNAME)\n    c = db.cursor()\n    c.execute(query)\n    rows = c.fetchall()\n    db.close()\n    return rows", "func_src_after": "def get_top_articles(list_count):\n    \"\"\"Return article and number of times viewed with most viewed first.\"\"\"\n    query = \"\"\"\n        select a.title, sum(alv.views) as views from articles a,\n         article_log_view alv where a.slug = alv.article\n         group by a.title\n         order by sum(alv.views) desc limit %s;\"\"\"\n    db = psycopg2.connect(database=DBNAME)\n    c = db.cursor()\n    c.execute(query, (list_count,))\n    rows = c.fetchall()\n    db.close()\n    return rows", "line_changes": {"deleted": [{"line_no": 3, "char_start": 110, "char_end": 124, "line": "    query = (\n"}, {"line_no": 4, "char_start": 124, "char_end": 196, "line": "        'select a.title, count(alv.article) as views from articles a, '\n"}, {"line_no": 5, "char_start": 196, "char_end": 256, "line": "        ' article_log_view alv where a.slug = alv.article '\n"}, {"line_no": 6, "char_start": 256, "char_end": 285, "line": "        ' group by a.title '\n"}, {"line_no": 7, "char_start": 285, "char_end": 353, "line": "        ' order by count(alv.article) desc limit %d;' % list_count)\n"}, {"line_no": 10, "char_start": 416, "char_end": 437, "line": "    c.execute(query)\n"}], "added": [{"line_no": 3, "char_start": 110, "char_end": 126, "line": "    query = \"\"\"\n"}, {"line_no": 4, "char_start": 126, "char_end": 191, "line": "        select a.title, sum(alv.views) as views from articles a,\n"}, {"line_no": 5, "char_start": 191, "char_end": 248, "line": "         article_log_view alv where a.slug = alv.article\n"}, {"line_no": 6, "char_start": 248, "char_end": 274, "line": "         group by a.title\n"}, {"line_no": 7, "char_start": 274, "char_end": 325, "line": "         order by sum(alv.views) desc limit %s;\"\"\"\n"}, {"line_no": 10, "char_start": 388, "char_end": 424, "line": "    c.execute(query, (list_count,))\n"}]}, "char_changes": {"deleted": [{"char_start": 122, "char_end": 123, "chars": "("}, {"char_start": 132, "char_end": 133, "chars": "'"}, {"char_start": 149, "char_end": 166, "chars": "count(alv.article"}, {"char_start": 193, "char_end": 195, "chars": " '"}, {"char_start": 204, "char_end": 205, "chars": "'"}, {"char_start": 253, "char_end": 255, "chars": " '"}, {"char_start": 264, "char_end": 265, "chars": "'"}, {"char_start": 282, "char_end": 284, "chars": " '"}, {"char_start": 293, "char_end": 294, "chars": "'"}, {"char_start": 304, "char_end": 352, "chars": "count(alv.article) desc limit %d;' % list_count)"}, {"char_start": 416, "char_end": 416, "chars": ""}], "added": [{"char_start": 122, "char_end": 125, "chars": "\"\"\""}, {"char_start": 150, "char_end": 163, "chars": "sum(alv.views"}, {"char_start": 292, "char_end": 324, "chars": "sum(alv.views) desc limit %s;\"\"\""}, {"char_start": 407, "char_end": 422, "chars": ", (list_count,)"}]}, "commit_link": "github.com/evelozud2017/log-analysis/commit/4ddd07ebef947573cefe9d88d9edc7c475875570", "file_name": "report.py", "vul_type": "cwe-089"}
{"func_name": "get_top_authors", "func_src_before": "def get_top_authors():\n    \"\"\"Return author and number of views with most viewed first.\"\"\"\n    query = (\n        'select au.name, count(alv.article) as views '\n        ' from articles a inner join article_log_view alv '\n        ' on a.slug = alv.article '\n        ' inner join authors au '\n        ' on a.author = au.id '\n        ' group by au.name '\n        ' order by count(alv.article) desc;')\n    db = psycopg2.connect(database=DBNAME)\n    c = db.cursor()\n    c.execute(query)\n    rows = c.fetchall()\n    db.close()\n    return rows", "func_src_after": "def get_top_authors():\n    \"\"\"Return author and number of views with most viewed first.\"\"\"\n    query = \"\"\"\n        select au.name, sum(alv.views) as views\n         from articles a inner join article_log_view alv\n         on a.slug = alv.article\n         inner join authors au\n         on a.author = au.id\n         group by au.name\n         order by sum(alv.views) desc;\"\"\"\n    db = psycopg2.connect(database=DBNAME)\n    c = db.cursor()\n    c.execute(query)\n    rows = c.fetchall()\n    db.close()\n    return rows", "line_changes": {"deleted": [{"line_no": 3, "char_start": 91, "char_end": 105, "line": "    query = (\n"}, {"line_no": 4, "char_start": 105, "char_end": 160, "line": "        'select au.name, count(alv.article) as views '\n"}, {"line_no": 5, "char_start": 160, "char_end": 220, "line": "        ' from articles a inner join article_log_view alv '\n"}, {"line_no": 6, "char_start": 220, "char_end": 256, "line": "        ' on a.slug = alv.article '\n"}, {"line_no": 7, "char_start": 256, "char_end": 290, "line": "        ' inner join authors au '\n"}, {"line_no": 8, "char_start": 290, "char_end": 322, "line": "        ' on a.author = au.id '\n"}, {"line_no": 9, "char_start": 322, "char_end": 351, "line": "        ' group by au.name '\n"}, {"line_no": 10, "char_start": 351, "char_end": 397, "line": "        ' order by count(alv.article) desc;')\n"}], "added": [{"line_no": 3, "char_start": 91, "char_end": 107, "line": "    query = \"\"\"\n"}, {"line_no": 4, "char_start": 107, "char_end": 155, "line": "        select au.name, sum(alv.views) as views\n"}, {"line_no": 5, "char_start": 155, "char_end": 212, "line": "         from articles a inner join article_log_view alv\n"}, {"line_no": 6, "char_start": 212, "char_end": 245, "line": "         on a.slug = alv.article\n"}, {"line_no": 7, "char_start": 245, "char_end": 276, "line": "         inner join authors au\n"}, {"line_no": 8, "char_start": 276, "char_end": 305, "line": "         on a.author = au.id\n"}, {"line_no": 9, "char_start": 305, "char_end": 331, "line": "         group by au.name\n"}, {"line_no": 10, "char_start": 331, "char_end": 373, "line": "         order by sum(alv.views) desc;\"\"\"\n"}]}, "char_changes": {"deleted": [{"char_start": 103, "char_end": 104, "chars": "("}, {"char_start": 113, "char_end": 114, "chars": "'"}, {"char_start": 130, "char_end": 147, "chars": "count(alv.article"}, {"char_start": 157, "char_end": 159, "chars": " '"}, {"char_start": 168, "char_end": 169, "chars": "'"}, {"char_start": 217, "char_end": 219, "chars": " '"}, {"char_start": 228, "char_end": 229, "chars": "'"}, {"char_start": 253, "char_end": 255, "chars": " '"}, {"char_start": 264, "char_end": 265, "chars": "'"}, {"char_start": 287, "char_end": 289, "chars": " '"}, {"char_start": 298, "char_end": 299, "chars": "'"}, {"char_start": 319, "char_end": 321, "chars": " '"}, {"char_start": 330, "char_end": 331, "chars": "'"}, {"char_start": 348, "char_end": 350, "chars": " '"}, {"char_start": 359, "char_end": 360, "chars": "'"}, {"char_start": 370, "char_end": 387, "chars": "count(alv.article"}, {"char_start": 394, "char_end": 396, "chars": "')"}], "added": [{"char_start": 103, "char_end": 106, "chars": "\"\"\""}, {"char_start": 131, "char_end": 144, "chars": "sum(alv.views"}, {"char_start": 349, "char_end": 362, "chars": "sum(alv.views"}, {"char_start": 369, "char_end": 372, "chars": "\"\"\""}]}, "commit_link": "github.com/evelozud2017/log-analysis/commit/4ddd07ebef947573cefe9d88d9edc7c475875570", "file_name": "report.py", "vul_type": "cwe-089"}
{"func_name": "get_most_error_day", "func_src_before": "def get_most_error_day():\n    \"\"\"Return day with errors > 1%.\"\"\"\n    query = (\n        'select tot.logdate, '\n        ' round(((err.errors_count::decimal/tot.requests_count)*100),2) '\n        ' as err_pct '\n        ' from '\n        ' ( select to_char(time, \\'FMMonth DD, YYYY\\') as logdate, '\n        ' count(*) as requests_count '\n        ' from log '\n        ' group by to_char(time, \\'FMMonth DD, YYYY\\') ) tot, '\n        '( select to_char(time, \\'FMMonth DD, YYYY\\') as logdate,  '\n        ' count(*) as errors_count '\n        ' from log '\n        ' where status <> \\'200 OK\\' '\n        ' group by to_char(time, \\'FMMonth DD, YYYY\\') ) err '\n        ' where '\n        ' tot.logdate = err.logdate '\n        ' and (err.errors_count::decimal/tot.requests_count) > .01; ')\n    db = psycopg2.connect(database=DBNAME)\n    c = db.cursor()\n    c.execute(query)\n    rows = c.fetchall()\n    db.close()\n    return rows", "func_src_after": "def get_most_error_day():\n    \"\"\"Return day with errors > 1%.\"\"\"\n    query = \"\"\"\n        select to_char(tot.logdate, 'FMMonth DD, YYYY') as logdate,\n         round(((err.errors_count::decimal/tot.requests_count)*100),2)\n         as err_pct\n         from\n         ( select date(time) as logdate,\n         count(*) as requests_count\n         from log\n         group by date(time) ) tot,\n        ( select date(time) as logdate,\n         count(*) as errors_count\n         from log\n         where status <> '200 OK'\n         group by date(time) ) err\n         where\n         tot.logdate = err.logdate\n         and (err.errors_count::decimal/tot.requests_count) > .01;\"\"\"\n    db = psycopg2.connect(database=DBNAME)\n    c = db.cursor()\n    c.execute(query)\n    rows = c.fetchall()\n    db.close()\n    return rows", "line_changes": {"deleted": [{"line_no": 3, "char_start": 65, "char_end": 79, "line": "    query = (\n"}, {"line_no": 4, "char_start": 79, "char_end": 110, "line": "        'select tot.logdate, '\n"}, {"line_no": 5, "char_start": 110, "char_end": 184, "line": "        ' round(((err.errors_count::decimal/tot.requests_count)*100),2) '\n"}, {"line_no": 6, "char_start": 184, "char_end": 207, "line": "        ' as err_pct '\n"}, {"line_no": 7, "char_start": 207, "char_end": 224, "line": "        ' from '\n"}, {"line_no": 8, "char_start": 224, "char_end": 293, "line": "        ' ( select to_char(time, \\'FMMonth DD, YYYY\\') as logdate, '\n"}, {"line_no": 9, "char_start": 293, "char_end": 332, "line": "        ' count(*) as requests_count '\n"}, {"line_no": 10, "char_start": 332, "char_end": 353, "line": "        ' from log '\n"}, {"line_no": 11, "char_start": 353, "char_end": 417, "line": "        ' group by to_char(time, \\'FMMonth DD, YYYY\\') ) tot, '\n"}, {"line_no": 12, "char_start": 417, "char_end": 486, "line": "        '( select to_char(time, \\'FMMonth DD, YYYY\\') as logdate,  '\n"}, {"line_no": 13, "char_start": 486, "char_end": 523, "line": "        ' count(*) as errors_count '\n"}, {"line_no": 14, "char_start": 523, "char_end": 544, "line": "        ' from log '\n"}, {"line_no": 15, "char_start": 544, "char_end": 583, "line": "        ' where status <> \\'200 OK\\' '\n"}, {"line_no": 16, "char_start": 583, "char_end": 646, "line": "        ' group by to_char(time, \\'FMMonth DD, YYYY\\') ) err '\n"}, {"line_no": 17, "char_start": 646, "char_end": 664, "line": "        ' where '\n"}, {"line_no": 18, "char_start": 664, "char_end": 702, "line": "        ' tot.logdate = err.logdate '\n"}, {"line_no": 19, "char_start": 702, "char_end": 773, "line": "        ' and (err.errors_count::decimal/tot.requests_count) > .01; ')\n"}], "added": [{"line_no": 3, "char_start": 65, "char_end": 81, "line": "    query = \"\"\"\n"}, {"line_no": 4, "char_start": 81, "char_end": 149, "line": "        select to_char(tot.logdate, 'FMMonth DD, YYYY') as logdate,\n"}, {"line_no": 5, "char_start": 149, "char_end": 220, "line": "         round(((err.errors_count::decimal/tot.requests_count)*100),2)\n"}, {"line_no": 6, "char_start": 220, "char_end": 240, "line": "         as err_pct\n"}, {"line_no": 7, "char_start": 240, "char_end": 254, "line": "         from\n"}, {"line_no": 8, "char_start": 254, "char_end": 295, "line": "         ( select date(time) as logdate,\n"}, {"line_no": 9, "char_start": 295, "char_end": 331, "line": "         count(*) as requests_count\n"}, {"line_no": 10, "char_start": 331, "char_end": 349, "line": "         from log\n"}, {"line_no": 11, "char_start": 349, "char_end": 385, "line": "         group by date(time) ) tot,\n"}, {"line_no": 12, "char_start": 385, "char_end": 425, "line": "        ( select date(time) as logdate,\n"}, {"line_no": 13, "char_start": 425, "char_end": 459, "line": "         count(*) as errors_count\n"}, {"line_no": 14, "char_start": 459, "char_end": 477, "line": "         from log\n"}, {"line_no": 15, "char_start": 477, "char_end": 511, "line": "         where status <> '200 OK'\n"}, {"line_no": 16, "char_start": 511, "char_end": 546, "line": "         group by date(time) ) err\n"}, {"line_no": 17, "char_start": 546, "char_end": 561, "line": "         where\n"}, {"line_no": 18, "char_start": 561, "char_end": 596, "line": "         tot.logdate = err.logdate\n"}, {"line_no": 19, "char_start": 596, "char_end": 666, "line": "         and (err.errors_count::decimal/tot.requests_count) > .01;\"\"\"\n"}]}, "char_changes": {"deleted": [{"char_start": 77, "char_end": 78, "chars": "("}, {"char_start": 87, "char_end": 88, "chars": "'"}, {"char_start": 118, "char_end": 119, "chars": "'"}, {"char_start": 181, "char_end": 183, "chars": " '"}, {"char_start": 192, "char_end": 193, "chars": "'"}, {"char_start": 204, "char_end": 206, "chars": " '"}, {"char_start": 215, "char_end": 216, "chars": "'"}, {"char_start": 221, "char_end": 223, "chars": " '"}, {"char_start": 232, "char_end": 233, "chars": "'"}, {"char_start": 243, "char_end": 277, "chars": "to_char(time, \\'FMMonth DD, YYYY\\'"}, {"char_start": 290, "char_end": 292, "chars": " '"}, {"char_start": 301, "char_end": 302, "chars": "'"}, {"char_start": 329, "char_end": 331, "chars": " '"}, {"char_start": 340, "char_end": 341, "chars": "'"}, {"char_start": 350, "char_end": 352, "chars": " '"}, {"char_start": 361, "char_end": 362, "chars": "'"}, {"char_start": 372, "char_end": 406, "chars": "to_char(time, \\'FMMonth DD, YYYY\\'"}, {"char_start": 414, "char_end": 416, "chars": " '"}, {"char_start": 425, "char_end": 426, "chars": "'"}, {"char_start": 435, "char_end": 469, "chars": "to_char(time, \\'FMMonth DD, YYYY\\'"}, {"char_start": 482, "char_end": 485, "chars": "  '"}, {"char_start": 494, "char_end": 495, "chars": "'"}, {"char_start": 520, "char_end": 522, "chars": " '"}, {"char_start": 531, "char_end": 532, "chars": "'"}, {"char_start": 541, "char_end": 543, "chars": " '"}, {"char_start": 552, "char_end": 553, "chars": "'"}, {"char_start": 570, "char_end": 571, "chars": "\\"}, {"char_start": 578, "char_end": 581, "chars": "\\' "}, {"char_start": 591, "char_end": 592, "chars": "'"}, {"char_start": 602, "char_end": 636, "chars": "to_char(time, \\'FMMonth DD, YYYY\\'"}, {"char_start": 643, "char_end": 645, "chars": " '"}, {"char_start": 654, "char_end": 655, "chars": "'"}, {"char_start": 661, "char_end": 663, "chars": " '"}, {"char_start": 672, "char_end": 673, "chars": "'"}, {"char_start": 699, "char_end": 701, "chars": " '"}, {"char_start": 710, "char_end": 711, "chars": "'"}, {"char_start": 769, "char_end": 772, "chars": " ')"}], "added": [{"char_start": 77, "char_end": 80, "chars": "\"\"\""}, {"char_start": 96, "char_end": 104, "chars": "to_char("}, {"char_start": 118, "char_end": 148, "chars": "FMMonth DD, YYYY') as logdate,"}, {"char_start": 272, "char_end": 281, "chars": "date(time"}, {"char_start": 367, "char_end": 376, "chars": "date(time"}, {"char_start": 402, "char_end": 411, "chars": "date(time"}, {"char_start": 529, "char_end": 538, "chars": "date(time"}, {"char_start": 662, "char_end": 665, "chars": "\"\"\""}]}, "commit_link": "github.com/evelozud2017/log-analysis/commit/4ddd07ebef947573cefe9d88d9edc7c475875570", "file_name": "report.py", "vul_type": "cwe-089"}
{"func_name": "insert", "func_src_before": "def insert(key, value):\n    connection = psycopg2.connect(host=config['HOST'], port=config['PORT'], database=config['NAME'], user=config['USER'], password=config['PASSWORD'])\n    cur = connection.cursor()\n    try:\n        cur.execute(\"insert into reply_map values('{}', '{}')\".format(key, value))\n        connection.commit()\n    except:\n        pass", "func_src_after": "def insert(key, value):\n    connection = psycopg2.connect(host=config['HOST'], port=config['PORT'], database=config['NAME'], user=config['USER'], password=config['PASSWORD'])\n    cur = connection.cursor()\n    try:\n        cur.execute(\"insert into reply_map values(?, ?)\", (key, value))\n        connection.commit()\n    except:\n        pass", "line_changes": {"deleted": [{"line_no": 5, "char_start": 214, "char_end": 297, "line": "        cur.execute(\"insert into reply_map values('{}', '{}')\".format(key, value))\n"}], "added": [{"line_no": 5, "char_start": 214, "char_end": 286, "line": "        cur.execute(\"insert into reply_map values(?, ?)\", (key, value))\n"}]}, "char_changes": {"deleted": [{"char_start": 264, "char_end": 283, "chars": "'{}', '{}')\".format"}], "added": [{"char_start": 264, "char_end": 272, "chars": "?, ?)\", "}]}, "commit_link": "github.com/tadaren/reply_bot/commit/5aeafa7e9597a766992af9ff8189e1f050b6579b", "file_name": "db.py", "vul_type": "cwe-089"}
{"func_name": "update_user_tasks", "func_src_before": "def update_user_tasks(verified_user, all_tasks):\n    \"\"\"\n    updates user task information\n    \"\"\"\n    user_id = verified_user.id\n    db_user_tasks = verified_user.tasks\n    db_user_task_ids = set([task.id for task in db_user_tasks])\n    for task_id, task in all_tasks.items():\n        if task_id in db_user_task_ids:\n            print(db_user_task_ids)\n            db_user_task_ids.remove(task_id)\n            verified_user.bm_update(task)\n        else:\n            task['user_id'] = user_id\n            new_task = Task(**task)\n            new_task.save()\n    if len(db_user_task_ids) > 0:\n        for task_id in db_user_task_ids:\n            task_to_delete = storage.get(\"Task\", task_id)\n            task_to_delete.delete()\n            print('deleted task')\n    return \"new tasks updated & created\"", "func_src_after": "def update_user_tasks(verified_user, all_tasks):\n    \"\"\"\n    updates user task information\n    \"\"\"\n    user_id = verified_user.id\n    db_user_tasks = verified_user.tasks\n    db_user_task_ids = set([task.id for task in db_user_tasks])\n    for task_id, task in all_tasks.items():\n        if task_id in db_user_task_ids:\n            db_user_task_ids.remove(task_id)\n            verified_user.bm_update(task)\n        else:\n            task['user_id'] = user_id\n            new_task = Task(**task)\n            new_task.save()\n    if len(db_user_task_ids) > 0:\n        for task_id in db_user_task_ids:\n            task_to_delete = storage.get(\"Task\", task_id)\n            key = \"{}.{}\".format(\"Task\", task_id)\n            value = task_to_delete.get(key)\n            value.delete()\n    return \"new tasks updated & created\"", "line_changes": {"deleted": [{"line_no": 10, "char_start": 318, "char_end": 354, "line": "            print(db_user_task_ids)\n"}, {"line_no": 20, "char_start": 690, "char_end": 726, "line": "            task_to_delete.delete()\n"}, {"line_no": 21, "char_start": 726, "char_end": 760, "line": "            print('deleted task')\n"}], "added": [{"line_no": 19, "char_start": 654, "char_end": 704, "line": "            key = \"{}.{}\".format(\"Task\", task_id)\n"}, {"line_no": 20, "char_start": 704, "char_end": 748, "line": "            value = task_to_delete.get(key)\n"}, {"line_no": 21, "char_start": 748, "char_end": 775, "line": "            value.delete()\n"}]}, "char_changes": {"deleted": [{"char_start": 318, "char_end": 354, "chars": "            print(db_user_task_ids)\n"}, {"char_start": 717, "char_end": 724, "chars": "delete("}, {"char_start": 738, "char_end": 758, "chars": "print('deleted task'"}], "added": [{"char_start": 665, "char_end": 723, "chars": " key = \"{}.{}\".format(\"Task\", task_id)\n            value ="}, {"char_start": 739, "char_end": 746, "chars": "get(key"}, {"char_start": 760, "char_end": 773, "chars": "value.delete("}]}, "commit_link": "github.com/johncoleman83/todo-list/commit/01ef753795c213b61c230bb2b54c4e4dd17111f9", "file_name": "web_app/app.py", "vul_type": "cwe-089"}
{"func_name": "deleteMatches", "func_src_before": "def deleteMatches():\n    \"\"\"Remove all the match records from the database.\"\"\"\n    conn = connect()\n    c = conn.cursor()\n    table = \"matches\"\n    playerTable = \"players\"\n    c.execute(\"DELETE FROM %s;\" % (table,))\n    # UPDATE statement is to reset all values to default after deleting all\n    # rows from matches table\n    c.execute(\"\"\"UPDATE %s SET wins = 0, \n        loss = 0, matchesPlayed = 0\"\"\" % (playerTable,))\n    conn.commit()\n    conn.close()", "func_src_after": "def deleteMatches():\n    \"\"\"Remove all the match records from the database.\"\"\"\n    conn = connect()\n    c = conn.cursor()\n    table = \"matches\"\n    queryMatches = \"DELETE FROM %s\" % (table, )\n    playerTable = \"players\"\n    queryPlayer = \"\"\"UPDATE %s SET wins = 0,\n                    loss = 0, matchesPlayed = 0\"\"\" % (playerTable,)\n    c.execute(queryMatches)\n    # UPDATE statement is to reset all values to default after deleting all\n    # rows from matches table\n    c.execute(queryPlayer)\n    conn.commit()\n    conn.close()", "line_changes": {"deleted": [{"line_no": 7, "char_start": 172, "char_end": 216, "line": "    c.execute(\"DELETE FROM %s;\" % (table,))\n"}, {"line_no": 10, "char_start": 322, "char_end": 364, "line": "    c.execute(\"\"\"UPDATE %s SET wins = 0, \n"}, {"line_no": 11, "char_start": 364, "char_end": 421, "line": "        loss = 0, matchesPlayed = 0\"\"\" % (playerTable,))\n"}], "added": [{"line_no": 6, "char_start": 144, "char_end": 192, "line": "    queryMatches = \"DELETE FROM %s\" % (table, )\n"}, {"line_no": 8, "char_start": 220, "char_end": 265, "line": "    queryPlayer = \"\"\"UPDATE %s SET wins = 0,\n"}, {"line_no": 9, "char_start": 265, "char_end": 333, "line": "                    loss = 0, matchesPlayed = 0\"\"\" % (playerTable,)\n"}, {"line_no": 10, "char_start": 333, "char_end": 361, "line": "    c.execute(queryMatches)\n"}, {"line_no": 13, "char_start": 467, "char_end": 494, "line": "    c.execute(queryPlayer)\n"}]}, "char_changes": {"deleted": [{"char_start": 148, "char_end": 214, "chars": "playerTable = \"players\"\n    c.execute(\"DELETE FROM %s;\" % (table,)"}, {"char_start": 336, "char_end": 419, "chars": "\"\"\"UPDATE %s SET wins = 0, \n        loss = 0, matchesPlayed = 0\"\"\" % (playerTable,)"}], "added": [{"char_start": 148, "char_end": 359, "chars": "queryMatches = \"DELETE FROM %s\" % (table, )\n    playerTable = \"players\"\n    queryPlayer = \"\"\"UPDATE %s SET wins = 0,\n                    loss = 0, matchesPlayed = 0\"\"\" % (playerTable,)\n    c.execute(queryMatches"}, {"char_start": 481, "char_end": 492, "chars": "queryPlayer"}]}, "commit_link": "github.com/bryancresswell/tournamentResults/commit/10270b5e80a8ca91be043e5323fb41091070b6bb", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "deletePlayers", "func_src_before": "def deletePlayers():\n    \"\"\"Remove all the player records from the database.\"\"\"\n    conn = connect()\n    table = \"players\"\n    c = conn.cursor()\n    c.execute(\"DELETE FROM %s;\" % (table,))\n    conn.commit()\n    conn.close()", "func_src_after": "def deletePlayers():\n    \"\"\"Remove all the player records from the database.\"\"\"\n    conn = connect()\n    table = \"players\"\n    c = conn.cursor()\n    queryDelete = \"DELETE FROM %s;\" % (table,)\n    c.execute(queryDelete)\n    conn.commit()\n    conn.close()", "line_changes": {"deleted": [{"line_no": 6, "char_start": 145, "char_end": 189, "line": "    c.execute(\"DELETE FROM %s;\" % (table,))\n"}], "added": [{"line_no": 6, "char_start": 145, "char_end": 192, "line": "    queryDelete = \"DELETE FROM %s;\" % (table,)\n"}, {"line_no": 7, "char_start": 192, "char_end": 219, "line": "    c.execute(queryDelete)\n"}]}, "char_changes": {"deleted": [{"char_start": 149, "char_end": 159, "chars": "c.execute("}], "added": [{"char_start": 149, "char_end": 163, "chars": "queryDelete = "}, {"char_start": 191, "char_end": 217, "chars": "\n    c.execute(queryDelete"}]}, "commit_link": "github.com/bryancresswell/tournamentResults/commit/10270b5e80a8ca91be043e5323fb41091070b6bb", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "countPlayers", "func_src_before": "def countPlayers():\n    \"\"\"Returns the number of players currently registered.\"\"\"\n    conn = connect()\n    table = \"players\"\n    c = conn.cursor()\n    c.execute(\"SELECT COUNT(playerID) FROM %s;\" % (table,))\n    result = c.fetchone()[0]\n    conn.commit()\n    conn.close()\n    return result", "func_src_after": "def countPlayers():\n    \"\"\"Returns the number of players currently registered.\"\"\"\n    conn = connect()\n    table = \"players\"\n    c = conn.cursor()\n    queryCount = \"SELECT COUNT(playerID) FROM %s;\" % (table,)\n    c.execute(queryCount)\n    result = c.fetchone()[0]\n    conn.commit()\n    conn.close()\n    return result", "line_changes": {"deleted": [{"line_no": 6, "char_start": 147, "char_end": 207, "line": "    c.execute(\"SELECT COUNT(playerID) FROM %s;\" % (table,))\n"}], "added": [{"line_no": 6, "char_start": 147, "char_end": 209, "line": "    queryCount = \"SELECT COUNT(playerID) FROM %s;\" % (table,)\n"}, {"line_no": 7, "char_start": 209, "char_end": 235, "line": "    c.execute(queryCount)\n"}]}, "char_changes": {"deleted": [{"char_start": 151, "char_end": 161, "chars": "c.execute("}], "added": [{"char_start": 151, "char_end": 164, "chars": "queryCount = "}, {"char_start": 208, "char_end": 233, "chars": "\n    c.execute(queryCount"}]}, "commit_link": "github.com/bryancresswell/tournamentResults/commit/10270b5e80a8ca91be043e5323fb41091070b6bb", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "registerPlayer", "func_src_before": "def registerPlayer(name):                                                                   \n    \"\"\"Adds a player to the tournament database.                                            \n    The database assigns a unique serial id number for the player.  (This                   \n    should be handled by your SQL database schema, not in your Python code.)                \n                                                                                            \n    Args:                                                                                   \n      name: the player's full name (need not be unique).                                    \n    \"\"\"                                                                                     \n    conn = connect()                                                                        \n    c = conn.cursor()                                                                       \n    # Regex is used here for instances where we might have apostrophes in one's             \n    # name                                                                                  \n    c.execute(\"INSERT INTO players (playerName) VALUES ('{}')\".format(                      \n        re.sub(r'\\'', '', name)));                                                          \n    conn.commit()                                                                           \n    conn.close()", "func_src_after": "def registerPlayer(name):                                                                   \n    \"\"\"Adds a player to the tournament database.                                            \n    The database assigns a unique serial id number for the player.  (This                   \n    should be handled by your SQL database schema, not in your Python code.)                \n                                                                                            \n    Args:                                                                                   \n      name: the player's full name (need not be unique).                                    \n    \"\"\"                                                                                     \n    conn = connect()                                                                        \n    c = conn.cursor()                                                                       \n    # Regex is used here for instances where we might have apostrophes in one's             \n    # name      \n    queryRegister = \"INSERT INTO players (playerName) VALUES ('{}')\".format(\n        re.sub(r'\\'', '', name))                                                                            \n    c.execute(queryRegister)                                                          \n    conn.commit()                                                                           \n    conn.close()", "line_changes": {"deleted": [{"line_no": 13, "char_start": 1116, "char_end": 1209, "line": "    c.execute(\"INSERT INTO players (playerName) VALUES ('{}')\".format(                      \n"}, {"line_no": 14, "char_start": 1209, "char_end": 1302, "line": "        re.sub(r'\\'', '', name)));                                                          \n"}], "added": [{"line_no": 13, "char_start": 1040, "char_end": 1117, "line": "    queryRegister = \"INSERT INTO players (playerName) VALUES ('{}')\".format(\n"}, {"line_no": 14, "char_start": 1117, "char_end": 1226, "line": "        re.sub(r'\\'', '', name))                                                                            \n"}, {"line_no": 15, "char_start": 1226, "char_end": 1313, "line": "    c.execute(queryRegister)                                                          \n"}]}, "char_changes": {"deleted": [{"char_start": 1043, "char_end": 1243, "chars": "                                                                        \n    c.execute(\"INSERT INTO players (playerName) VALUES ('{}')\".format(                      \n        re.sub(r'\\'', '', name)));"}], "added": [{"char_start": 1039, "char_end": 1040, "chars": "\n"}, {"char_start": 1044, "char_end": 1254, "chars": "queryRegister = \"INSERT INTO players (playerName) VALUES ('{}')\".format(\n        re.sub(r'\\'', '', name))                                                                            \n    c.execute(queryRegister)"}]}, "commit_link": "github.com/bryancresswell/tournamentResults/commit/10270b5e80a8ca91be043e5323fb41091070b6bb", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "playerStandings", "func_src_before": "def playerStandings():                                                                      \n    \"\"\"Returns a list of the players and their win records, sorted by wins.                 \n                                                                                            \n    The first entry in the list should be the player in first place, or a player            \n    tied for first place if there is currently a tie.                                       \n                                                                                            \n    Returns:                                                                                \n      A list of tuples, each of which contains (id, name, wins, matches):                   \n        id: the player's unique id (assigned by the database)                               \n        name: the player's full name (as registered)                                        \n        wins: the number of matches the player has won                                      \n        matches: the number of matches the player has played                                \n    \"\"\"                                                                                     \n    conn = connect()                                                                        \n    c = conn.cursor()                                                                       \n    table = \"players\"                                                                       \n    c.execute(\"\"\"SELECT playerID,                                                           \n        playerName,                                                                         \n        wins,                                                                               \n        matchesPlayed FROM %s ORDER BY wins DESC;\"\"\" % (table,))                            \n    result = c.fetchall()                                                                   \n    conn.commit()                                                                           \n    conn.close()                                                                            \n    return result", "func_src_after": "def playerStandings():                                                                      \n    \"\"\"Returns a list of the players and their win records, sorted by wins.                 \n                                                                                            \n    The first entry in the list should be the player in first place, or a player            \n    tied for first place if there is currently a tie.                                       \n                                                                                            \n    Returns:                                                                                \n      A list of tuples, each of which contains (id, name, wins, matches):                   \n        id: the player's unique id (assigned by the database)                               \n        name: the player's full name (as registered)                                        \n        wins: the number of matches the player has won                                      \n        matches: the number of matches the player has played                                \n    \"\"\"                                                                                     \n    conn = connect()                                                                        \n    c = conn.cursor()                                                                       \n    table = \"players\"  \n    queryStandings = \"\"\"SELECT playerID,                                                           \n        playerName,                                                                         \n        wins,                                                                               \n        matchesPlayed FROM %s ORDER BY wins DESC;\"\"\" % (table,)                                                                     \n    c.execute(queryStandings)                            \n    result = c.fetchall()                                                                   \n    conn.commit()                                                                           \n    conn.close()                                                                            \n    return result", "line_changes": {"deleted": [{"line_no": 16, "char_start": 1395, "char_end": 1488, "line": "    table = \"players\"                                                                       \n"}, {"line_no": 17, "char_start": 1488, "char_end": 1581, "line": "    c.execute(\"\"\"SELECT playerID,                                                           \n"}, {"line_no": 20, "char_start": 1767, "char_end": 1860, "line": "        matchesPlayed FROM %s ORDER BY wins DESC;\"\"\" % (table,))                            \n"}], "added": [{"line_no": 16, "char_start": 1395, "char_end": 1419, "line": "    table = \"players\"  \n"}, {"line_no": 17, "char_start": 1419, "char_end": 1519, "line": "    queryStandings = \"\"\"SELECT playerID,                                                           \n"}, {"line_no": 20, "char_start": 1705, "char_end": 1838, "line": "        matchesPlayed FROM %s ORDER BY wins DESC;\"\"\" % (table,)                                                                     \n"}, {"line_no": 21, "char_start": 1838, "char_end": 1896, "line": "    c.execute(queryStandings)                            \n"}]}, "char_changes": {"deleted": [{"char_start": 1418, "char_end": 1502, "chars": "                                                                     \n    c.execute("}], "added": [{"char_start": 1418, "char_end": 1440, "chars": "\n    queryStandings = "}, {"char_start": 1768, "char_end": 1866, "chars": "                                                                     \n    c.execute(queryStandings"}]}, "commit_link": "github.com/bryancresswell/tournamentResults/commit/10270b5e80a8ca91be043e5323fb41091070b6bb", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "reportMatch", "func_src_before": "def reportMatch(winner, loser):                                                             \n    \"\"\"Records the outcome of a single match between two players.                           \n                                                                                            \n    Args:                                                                                   \n      winner:  the id number of the player who won                                          \n      loser:  the id number of the player who lost                                          \n    \"\"\"                                                                                     \n    conn = connect()                                                                        \n    c = conn.cursor()                                                                       \n    # Inserts a row into the matches table, and updates subsequent data                     \n    c.execute(\"\"\"INSERT INTO matches (winner, loser)                                        \n        VALUES ('%i', '%i')\"\"\" % (winner, loser))                                           \n    c.execute(\"\"\"UPDATE players SET wins = wins + 1,                                        \n        matchesPlayed = matchesPlayed + 1                                                   \n        WHERE playerID = %s\"\"\" % (winner,))                                                 \n    c.execute(\"\"\"UPDATE players SET loss = loss + 1,                                        \n        matchesPlayed = matchesPlayed + 1                                                   \n        WHERE playerID = %s\"\"\" % (loser,))                                                  \n    conn.commit()                                                                           \n    conn.close()", "func_src_after": "def reportMatch(winner, loser):                                                             \n    \"\"\"Records the outcome of a single match between two players.                           \n                                                                                            \n    Args:                                                                                   \n      winner:  the id number of the player who won                                          \n      loser:  the id number of the player who lost                                          \n    \"\"\"                                                                                     \n    conn = connect()                                                                        \n    c = conn.cursor()                                                                       \n    # Inserts a row into the matches table, and updates subsequent data \n    queryReportInsert = \"\"\"INSERT INTO matches (winner, loser)                                        \n        VALUES ('%i', '%i')\"\"\" % (winner, loser)                    \n    c.execute(queryReportInsert)\n    queryReportUpdate = \"\"\"UPDATE players SET wins = wins + 1,                                        \n        matchesPlayed = matchesPlayed + 1                                                   \n        WHERE playerID = %s\"\"\" % (winner,)                                          \n    c.execute(queryReportUpdate)  \n    queryReportUpdate1 = \"\"\"UPDATE players SET loss = loss + 1,                                        \n        matchesPlayed = matchesPlayed + 1                                                   \n        WHERE playerID = %s\"\"\" % (loser,)                                               \n    c.execute(queryReportUpdate1)                                                  \n    conn.commit()                                                                           \n    conn.close()", "line_changes": {"deleted": [{"line_no": 11, "char_start": 930, "char_end": 1023, "line": "    c.execute(\"\"\"INSERT INTO matches (winner, loser)                                        \n"}, {"line_no": 12, "char_start": 1023, "char_end": 1116, "line": "        VALUES ('%i', '%i')\"\"\" % (winner, loser))                                           \n"}, {"line_no": 13, "char_start": 1116, "char_end": 1209, "line": "    c.execute(\"\"\"UPDATE players SET wins = wins + 1,                                        \n"}, {"line_no": 15, "char_start": 1302, "char_end": 1395, "line": "        WHERE playerID = %s\"\"\" % (winner,))                                                 \n"}, {"line_no": 16, "char_start": 1395, "char_end": 1488, "line": "    c.execute(\"\"\"UPDATE players SET loss = loss + 1,                                        \n"}, {"line_no": 18, "char_start": 1581, "char_end": 1674, "line": "        WHERE playerID = %s\"\"\" % (loser,))                                                  \n"}], "added": [{"line_no": 11, "char_start": 910, "char_end": 1013, "line": "    queryReportInsert = \"\"\"INSERT INTO matches (winner, loser)                                        \n"}, {"line_no": 12, "char_start": 1013, "char_end": 1082, "line": "        VALUES ('%i', '%i')\"\"\" % (winner, loser)                    \n"}, {"line_no": 13, "char_start": 1082, "char_end": 1115, "line": "    c.execute(queryReportInsert)\n"}, {"line_no": 14, "char_start": 1115, "char_end": 1218, "line": "    queryReportUpdate = \"\"\"UPDATE players SET wins = wins + 1,                                        \n"}, {"line_no": 16, "char_start": 1311, "char_end": 1396, "line": "        WHERE playerID = %s\"\"\" % (winner,)                                          \n"}, {"line_no": 17, "char_start": 1396, "char_end": 1431, "line": "    c.execute(queryReportUpdate)  \n"}, {"line_no": 18, "char_start": 1431, "char_end": 1535, "line": "    queryReportUpdate1 = \"\"\"UPDATE players SET loss = loss + 1,                                        \n"}, {"line_no": 20, "char_start": 1628, "char_end": 1717, "line": "        WHERE playerID = %s\"\"\" % (loser,)                                               \n"}, {"line_no": 21, "char_start": 1717, "char_end": 1801, "line": "    c.execute(queryReportUpdate1)                                                  \n"}]}, "char_changes": {"deleted": [{"char_start": 909, "char_end": 944, "chars": "                    \n    c.execute("}, {"char_start": 1071, "char_end": 1090, "chars": ")                  "}, {"char_start": 1110, "char_end": 1115, "chars": "     "}, {"char_start": 1344, "char_end": 1345, "chars": ")"}, {"char_start": 1391, "char_end": 1399, "chars": "   \n    "}], "added": [{"char_start": 909, "char_end": 934, "chars": "\n    queryReportInsert = "}, {"char_start": 1096, "char_end": 1139, "chars": "queryReportInsert)\n    queryReportUpdate = "}, {"char_start": 1410, "char_end": 1456, "chars": "queryReportUpdate)  \n    queryReportUpdate1 = "}, {"char_start": 1669, "char_end": 1749, "chars": "                                               \n    c.execute(queryReportUpdate1"}]}, "commit_link": "github.com/bryancresswell/tournamentResults/commit/10270b5e80a8ca91be043e5323fb41091070b6bb", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "swissPairings", "func_src_before": "def swissPairings():                                                                        \n    \"\"\"Returns a list of pairs of players for the next round of a match.                    \n                                                                                            \n    Assuming that there are an even number of players registered, each player               \n    appears exactly once in the pairings.  Each player is paired with another               \n    player with an equal or nearly-equal win record, that is, a player adjacent             \n    to him or her in the standings.                                                         \n                                                                                            \n    Returns:                                                                                \n      A list of tuples, each of which contains (id1, name1, id2, name2)                     \n        id1: the first player's unique id                                                   \n        name1: the first player's name                                                      \n        id2: the second player's unique id                                                  \n        name2: the second player's name                                                     \n    \"\"\"                                                                                     \n    conn = connect()                                                                        \n    c = conn.cursor()                                                                       \n    table = \"players\"                                                                       \n    c.execute(\"\"\"SELECT playerID,                                                           \n        playerName FROM %s ORDER BY wins DESC;\"\"\" % (table,))                               \n    result = c.fetchall()\n    pairings = list()\n    if (result % 2 != 0):\n        return None\n    else:                                                                   \n    # For loop to simply pair up adjacent players based on                                  \n    # already sorted value from the playerStandings() method                                \n        for i in range(0, len(result), 2):                                                      \n            tmpList = result[i:i+2]                                                             \n            temp1 = tmpList[0]                                                                  \n            temp2 = tmpList[1]                                                                  \n            pairings.append((temp1[0], temp1[1], temp2[0], temp2[1]))                           \n        return pairings   \n    return None", "func_src_after": "def swissPairings():                                                                        \n    \"\"\"Returns a list of pairs of players for the next round of a match.                    \n                                                                                            \n    Assuming that there are an even number of players registered, each player               \n    appears exactly once in the pairings.  Each player is paired with another               \n    player with an equal or nearly-equal win record, that is, a player adjacent             \n    to him or her in the standings.                                                         \n                                                                                            \n    Returns:                                                                                \n      A list of tuples, each of which contains (id1, name1, id2, name2)                     \n        id1: the first player's unique id                                                   \n        name1: the first player's name                                                      \n        id2: the second player's unique id                                                  \n        name2: the second player's name                                                     \n    \"\"\"                                                                                     \n    conn = connect()                                                                        \n    c = conn.cursor()                                                                       \n    table = \"players\" \n    querySwiss = \"\"\"SELECT playerID,                                                           \n        playerName FROM %s ORDER BY wins DESC;\"\"\" % (table,)                                                                       \n    c.execute(querySwiss)                               \n    result = c.fetchall()\n    pairings = list()\n    if (result % 2 != 0):\n        return None\n    else:                                                                   \n    # For loop to simply pair up adjacent players based on                                  \n    # already sorted value from the playerStandings() method                                \n        for i in range(0, len(result), 2):                                                      \n            tmpList = result[i:i+2]                                                             \n            temp1 = tmpList[0]                                                                  \n            temp2 = tmpList[1]                                                                  \n            pairings.append((temp1[0], temp1[1], temp2[0], temp2[1]))                           \n        return pairings   \n    return None", "line_changes": {"deleted": [{"line_no": 18, "char_start": 1581, "char_end": 1674, "line": "    table = \"players\"                                                                       \n"}, {"line_no": 19, "char_start": 1674, "char_end": 1767, "line": "    c.execute(\"\"\"SELECT playerID,                                                           \n"}, {"line_no": 20, "char_start": 1767, "char_end": 1860, "line": "        playerName FROM %s ORDER BY wins DESC;\"\"\" % (table,))                               \n"}, {"line_no": 34, "char_start": 2729, "char_end": 2744, "line": "    return None \n"}], "added": [{"line_no": 18, "char_start": 1581, "char_end": 1604, "line": "    table = \"players\" \n"}, {"line_no": 19, "char_start": 1604, "char_end": 1700, "line": "    querySwiss = \"\"\"SELECT playerID,                                                           \n"}, {"line_no": 20, "char_start": 1700, "char_end": 1832, "line": "        playerName FROM %s ORDER BY wins DESC;\"\"\" % (table,)                                                                       \n"}, {"line_no": 21, "char_start": 1832, "char_end": 1889, "line": "    c.execute(querySwiss)                               \n"}]}, "char_changes": {"deleted": [{"char_start": 1603, "char_end": 1688, "chars": "                                                                      \n    c.execute("}], "added": [{"char_start": 1603, "char_end": 1621, "chars": "\n    querySwiss = "}, {"char_start": 1760, "char_end": 1856, "chars": "                                                                       \n    c.execute(querySwiss"}]}, "commit_link": "github.com/bryancresswell/tournamentResults/commit/10270b5e80a8ca91be043e5323fb41091070b6bb", "file_name": "tournament.py", "vul_type": "cwe-089"}
{"func_name": "print_states_N", "func_src_before": "def print_states_N(db):\n    \"\"\"prints all states with first initial 'N' from input DB\"\"\"\n    cur = db.cursor()\n    cur.execute(\"SELECT * FROM states \"\n                \"WHERE name LIKE BINARY 'N%' \"\n                \"ORDER BY states.id ASC\")\n    rows = cur.fetchall()\n    for row in rows:\n        print(row)\n    cur.close()\n    db.close()", "func_src_after": "def print_states_N(db):\n    \"\"\"prints all states with first initial 'N' from input DB\"\"\"\n    cur = db.cursor()\n    cur.execute(\"SELECT * FROM states \"\n                \"WHERE name LIKE BINARY 'N%' \"\n                \"ORDER BY states.id ASC\")\n    for row in cur.fetchall():\n        print(row)\n    cur.close()\n    db.close()", "line_changes": {"deleted": [{"line_no": 7, "char_start": 240, "char_end": 266, "line": "    rows = cur.fetchall()\n"}, {"line_no": 8, "char_start": 266, "char_end": 287, "line": "    for row in rows:\n"}], "added": [{"line_no": 7, "char_start": 240, "char_end": 271, "line": "    for row in cur.fetchall():\n"}]}, "char_changes": {"deleted": [{"char_start": 244, "char_end": 250, "chars": "rows ="}, {"char_start": 265, "char_end": 285, "chars": "\n    for row in rows"}], "added": [{"char_start": 244, "char_end": 254, "chars": "for row in"}]}, "commit_link": "github.com/johncoleman83/holbertonschool-higher_level_programming/commit/2c15fab9d5ad7a3435eb7aef6eae78e38312f24a", "file_name": "0x0F-python-object_relational_mapping/1-filter_states.py", "vul_type": "cwe-089"}
{"func_name": "run", "func_src_before": "def run(config, instrum, wait,\n        output=False, sql=False, header=True, quiet=False, debug=False):\n    \"\"\" start the emonitor server and output to sqlite database.\n    \"\"\"\n    tty = sys.stdout.isatty()\n    settings = parse_settings(config, instrum)\n    columns = get_columns(settings)\n    if debug and tty:\n        print(\"DEBUG enabled\")\n    try:\n        device = get_device(settings, instrum, debug=debug)\n        # sqlite output\n        db = None\n        if output:\n            db = get_sqlite(settings, columns)\n        # sql output\n        sql_conn = None\n        if sql:\n            sql_conn = get_sql(settings)\n        # header\n        if tty:\n            if not quiet:\n                print(\"Starting emonitor. Use Ctrl-C to stop. \\n\")\n                if header:\n                    test = tuple(device.read_data())\n                    if debug:\n                        print(test)\n                    str_width = len(str(test[0]))\n                    print(columns[0].rjust(19) + \" \\t\",\n                          \"\\t \".join([col.rjust(str_width) for col in columns[1:]]))\n        elif header:\n            print(\",\".join(columns))\n        # start server\n        while True:\n            ## read data\n            values = tuple(device.read_data())\n            is_null = all([isinstance(v, str) and v.upper() == \"NULL\" for v in values])\n            ## output\n            if not is_null:\n                values = (time.strftime(\"%Y-%m-%d %H:%M:%S\"), ) + values\n                if tty:\n                    if not quiet:\n                        print(\"\\t \".join(values))\n                else:\n                    print(\",\".join(values))\n                if output:\n                    db_insert(db, TABLE, columns, values, debug=debug)\n                if sql:\n                    try:\n                        if not sql_conn.open:\n                            # attempt to reconnect\n                            sql_conn.connect()\n                        db_insert(sql_conn, settings[\"sql_table\"], columns, values, debug=debug)\n                    except:\n                        warnings.warn(\"SQL connection failed\")\n            time.sleep(wait)\n    except KeyboardInterrupt:\n        if tty and not quiet:\n            print(\"\\nStopping emonitor.\")\n    finally:\n        device.close()\n        if db is not None:\n            db.close()\n        if sql_conn is not None:\n            sql_conn.close()", "func_src_after": "def run(config, instrum, wait,\n        output=False, sql=False, header=True, quiet=False, debug=False):\n    \"\"\" start the emonitor server and output to sqlite database.\n    \"\"\"\n    tty = sys.stdout.isatty()\n    settings = parse_settings(config, instrum)\n    columns = get_columns(settings)\n    if debug and tty:\n        print(\"DEBUG enabled\")\n    try:\n        device = get_device(settings, instrum, debug=debug)\n        # sqlite output\n        db = None\n        if output:\n            db = get_sqlite(settings, columns)\n        # sql output\n        sql_conn = None\n        if sql:\n            sql_conn = get_sql(settings)\n        # header\n        if tty:\n            if not quiet:\n                print(\"Starting emonitor. Use Ctrl-C to stop. \\n\")\n                if header:\n                    test = tuple(device.read_data())\n                    if debug:\n                        print(test)\n                    str_width = len(str(test[0]))\n                    print(columns[0].rjust(19) + \" \\t\",\n                          \"\\t \".join([col.rjust(str_width) for col in columns[1:]]))\n        elif header:\n            print(\",\".join(columns))\n        # start server\n        while True:\n            ## read data\n            values = tuple(device.read_data())\n            is_null = all([v is None for v in values])\n            ## output\n            if not is_null:\n                values = (time.strftime(\"%Y-%m-%d %H:%M:%S\"), ) + values\n                if tty:\n                    if not quiet:\n                        val_str = tuple(str(v).replace(\"None\", \"NULL\".rjust(str_width)) for v in values)\n                        print(\"\\t \".join(val_str))\n                else:\n                    val_str = tuple(str(v).replace(\"None\", \"NULL\") for v in values)\n                    print(\",\".join(val_str))\n                if output:\n                    db_insert(db, TABLE, columns, values, debug=debug)\n                if sql:\n                    try:\n                        if not sql_conn.open:\n                            # attempt to reconnect\n                            sql_conn.connect()\n                        sql_insert(sql_conn, settings[\"sql_table\"], columns, values, debug=debug)\n                    except:\n                        warnings.warn(\"SQL connection failed\")\n            time.sleep(wait)\n    except KeyboardInterrupt:\n        if tty and not quiet:\n            print(\"\\nStopping emonitor.\")\n    finally:\n        device.close()\n        if db is not None:\n            db.close()\n        if sql_conn is not None:\n            sql_conn.close()", "line_changes": {"deleted": [{"line_no": 37, "char_start": 1258, "char_end": 1346, "line": "            is_null = all([isinstance(v, str) and v.upper() == \"NULL\" for v in values])\n"}, {"line_no": 43, "char_start": 1527, "char_end": 1577, "line": "                        print(\"\\t \".join(values))\n"}, {"line_no": 45, "char_start": 1599, "char_end": 1643, "line": "                    print(\",\".join(values))\n"}, {"line_no": 53, "char_start": 1934, "char_end": 2031, "line": "                        db_insert(sql_conn, settings[\"sql_table\"], columns, values, debug=debug)\n"}], "added": [{"line_no": 37, "char_start": 1258, "char_end": 1313, "line": "            is_null = all([v is None for v in values])\n"}, {"line_no": 43, "char_start": 1494, "char_end": 1599, "line": "                        val_str = tuple(str(v).replace(\"None\", \"NULL\".rjust(str_width)) for v in values)\n"}, {"line_no": 44, "char_start": 1599, "char_end": 1650, "line": "                        print(\"\\t \".join(val_str))\n"}, {"line_no": 46, "char_start": 1672, "char_end": 1756, "line": "                    val_str = tuple(str(v).replace(\"None\", \"NULL\") for v in values)\n"}, {"line_no": 47, "char_start": 1756, "char_end": 1801, "line": "                    print(\",\".join(val_str))\n"}, {"line_no": 55, "char_start": 2092, "char_end": 2190, "line": "                        sql_insert(sql_conn, settings[\"sql_table\"], columns, values, debug=debug)\n"}]}, "char_changes": {"deleted": [{"char_start": 1285, "char_end": 1327, "chars": "isinstance(v, str) and v.upper() == \"NULL\""}, {"char_start": 1571, "char_end": 1574, "chars": "ues"}, {"char_start": 1637, "char_end": 1640, "chars": "ues"}, {"char_start": 1958, "char_end": 1960, "chars": "db"}], "added": [{"char_start": 1285, "char_end": 1294, "chars": "v is None"}, {"char_start": 1494, "char_end": 1599, "chars": "                        val_str = tuple(str(v).replace(\"None\", \"NULL\".rjust(str_width)) for v in values)\n"}, {"char_start": 1643, "char_end": 1647, "chars": "_str"}, {"char_start": 1672, "char_end": 1756, "chars": "                    val_str = tuple(str(v).replace(\"None\", \"NULL\") for v in values)\n"}, {"char_start": 1794, "char_end": 1798, "chars": "_str"}, {"char_start": 2116, "char_end": 2119, "chars": "sql"}]}, "commit_link": "github.com/ad3ller/emonitor/commit/16130fa7c2f53fbf4b53a8e0e0a6b51a40e6b03d", "file_name": "emonitor/run.py", "vul_type": "cwe-089"}
{"func_name": "db_insert", "func_src_before": "def db_insert(conn, table, columns, values, debug=False):\n    \"\"\" INSERT INTO {table} {columns} VALUES {values};\n    \"\"\"\n    col_str = str(columns).replace(\"'\", \"`\")\n    sql = f\"INSERT INTO {table} {col_str} VALUES {values};\"\n    if debug:\n        print(sql)\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    conn.commit()", "func_src_after": "def db_insert(conn, table, columns, values, debug=False):\n    \"\"\" INSERT INTO {table} {columns} VALUES {values};\n    \"\"\"\n    col_str = str(tuple(columns)).replace(\"'\", \"`\")\n    val_str = \", \".join(tuple('?' for c in columns))\n    sql = f\"INSERT INTO {table} {col_str} VALUES ({val_str});\"\n    if debug:\n        print(sql)\n    cursor = conn.cursor()\n    cursor.execute(sql, values)\n    conn.commit()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 121, "char_end": 166, "line": "    col_str = str(columns).replace(\"'\", \"`\")\n"}, {"line_no": 5, "char_start": 166, "char_end": 226, "line": "    sql = f\"INSERT INTO {table} {col_str} VALUES {values};\"\n"}, {"line_no": 9, "char_start": 286, "char_end": 310, "line": "    cursor.execute(sql)\n"}], "added": [{"line_no": 4, "char_start": 121, "char_end": 173, "line": "    col_str = str(tuple(columns)).replace(\"'\", \"`\")\n"}, {"line_no": 5, "char_start": 173, "char_end": 226, "line": "    val_str = \", \".join(tuple('?' for c in columns))\n"}, {"line_no": 6, "char_start": 226, "char_end": 289, "line": "    sql = f\"INSERT INTO {table} {col_str} VALUES ({val_str});\"\n"}, {"line_no": 10, "char_start": 349, "char_end": 381, "line": "    cursor.execute(sql, values)\n"}, {"line_no": 11, "char_start": 381, "char_end": 398, "line": "    conn.commit()\n"}]}, "char_changes": {"deleted": [{"char_start": 219, "char_end": 223, "chars": "ues}"}, {"char_start": 286, "char_end": 286, "chars": ""}], "added": [{"char_start": 139, "char_end": 145, "chars": "tuple("}, {"char_start": 153, "char_end": 154, "chars": ")"}, {"char_start": 173, "char_end": 226, "chars": "    val_str = \", \".join(tuple('?' for c in columns))\n"}, {"char_start": 275, "char_end": 276, "chars": "("}, {"char_start": 280, "char_end": 286, "chars": "_str})"}, {"char_start": 371, "char_end": 379, "chars": ", values"}]}, "commit_link": "github.com/ad3ller/emonitor/commit/16130fa7c2f53fbf4b53a8e0e0a6b51a40e6b03d", "file_name": "emonitor/tools.py", "vul_type": "cwe-089"}
{"func_name": "help", "func_src_before": "@bot.message_handler(commands=['help'])\ndef help(message):\n    bot.send_message(message.from_user.id, \"- Write /start to begin\\n- You can send files, images, videos, etc. and they will be stored in your current path\\n- If you write a message to the bot, it will make a directory with that name in the current path\\n- You can delete files or directories using the red cross next to them\\n- I have tried to make this bot as similar as possible to a basic file explorer\\n- You can donate using /donate\")", "func_src_after": "@bot.message_handler(commands=['help'])\ndef help(message):\n    bot.send_message(message.from_user.id, help_message)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 59, "char_end": 500, "line": "    bot.send_message(message.from_user.id, \"- Write /start to begin\\n- You can send files, images, videos, etc. and they will be stored in your current path\\n- If you write a message to the bot, it will make a directory with that name in the current path\\n- You can delete files or directories using the red cross next to them\\n- I have tried to make this bot as similar as possible to a basic file explorer\\n- You can donate using /donate\")\n"}], "added": [{"line_no": 3, "char_start": 59, "char_end": 115, "line": "    bot.send_message(message.from_user.id, help_message)\n"}]}, "char_changes": {"deleted": [{"char_start": 102, "char_end": 499, "chars": "\"- Write /start to begin\\n- You can send files, images, videos, etc. and they will be stored in your current path\\n- If you write a message to the bot, it will make a directory with that name in the current path\\n- You can delete files or directories using the red cross next to them\\n- I have tried to make this bot as similar as possible to a basic file explorer\\n- You can donate using /donate\""}], "added": [{"char_start": 102, "char_end": 114, "chars": "help_message"}]}, "commit_link": "github.com/victor141516/FileXbot-telegram/commit/7ad4112b4715d2cd46a5b5f19cb531907525024a", "file_name": "filex.py", "vul_type": "cwe-089"}
{"func_name": "start", "func_src_before": "@bot.message_handler(commands=['start'])\ndef start(message):\n    telegram_id = message.from_user.id\n\n    bot.send_message(telegram_id, \"- Write /start to begin\\n- You can send files, images, videos, etc. and they will be stored in your current path\\n- If you write a message to the bot, it will make a directory with that name in the current path\\n- I have tried to make this bot as similar as possible to a basic file explorer\\n- You can donate using /donate\")\n    db.insert('user', {'name': message.from_user.username, 'telegram_id': telegram_id}, {'telegram_id' : telegram_id})\n    user_id = db.select('user', \"telegram_id = \" + str(telegram_id))[0]['id']\n\n    db.insert('directory', {'name': '/', 'parent_directory_id': 'NULL', 'user_id': user_id})\n\n    explorers[telegram_id] = Explorer(telegram_id)\n    send_replacing_message(telegram_id, bot)", "func_src_after": "@bot.message_handler(commands=['start'])\ndef start(message):\n    telegram_id = message.from_user.id\n\n    bot.send_message(telegram_id, help_message)\n    db.insert('user', {'name': message.from_user.username, 'telegram_id': telegram_id}, {'telegram_id' : telegram_id})\n    user_id = db.select('user', \"telegram_id = \" + str(telegram_id))[0]['id']\n\n    db.insert('directory', {'name': '/', 'parent_directory_id': 'NULL', 'user_id': user_id})\n\n    get_or_create_explorer(telegram_id)\n    send_replacing_message(telegram_id, bot)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 101, "char_end": 462, "line": "    bot.send_message(telegram_id, \"- Write /start to begin\\n- You can send files, images, videos, etc. and they will be stored in your current path\\n- If you write a message to the bot, it will make a directory with that name in the current path\\n- I have tried to make this bot as similar as possible to a basic file explorer\\n- You can donate using /donate\")\n"}, {"line_no": 11, "char_start": 754, "char_end": 805, "line": "    explorers[telegram_id] = Explorer(telegram_id)\n"}], "added": [{"line_no": 5, "char_start": 101, "char_end": 149, "line": "    bot.send_message(telegram_id, help_message)\n"}, {"line_no": 11, "char_start": 441, "char_end": 481, "line": "    get_or_create_explorer(telegram_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 135, "char_end": 460, "chars": "\"- Write /start to begin\\n- You can send files, images, videos, etc. and they will be stored in your current path\\n- If you write a message to the bot, it will make a directory with that name in the current path\\n- I have tried to make this bot as similar as possible to a basic file explorer\\n- You can donate using /donate\""}, {"char_start": 758, "char_end": 784, "chars": "explorers[telegram_id] = E"}], "added": [{"char_start": 135, "char_end": 147, "chars": "help_message"}, {"char_start": 445, "char_end": 460, "chars": "get_or_create_e"}]}, "commit_link": "github.com/victor141516/FileXbot-telegram/commit/7ad4112b4715d2cd46a5b5f19cb531907525024a", "file_name": "filex.py", "vul_type": "cwe-089"}
{"func_name": "get_books_by_page", "func_src_before": "def get_books_by_page(page, pagesize, sort_col, sort_dir):\n    # q = db_session.query(Book).join(Collaborations, Collaborations.book_id==Book.id)\n    # q = q.join(Series, Series.id==Book.series_id)\n    # q = append_order_by_clause(q, sort_col, sort_dir)\n    # count = q.count();\n    # books = q.offset(page * pagesize).limit(pagesize)\n    # dict_books = books_todict(books)\n    # return {\"rows\": dict_books, \"count\": count}\n\n    # Column sorting\n    # TODO There are consistency issues. Collab records with no book or no author.\n    # We use left outer joins here to get all books regardless of collaborations status.\n    stmt = \"\"\"\n        select b.*,\n        case when length(a.FirstName) > 0\n            then (a.LastName || \", \" || a.FirstName)\n            else a.LastName\n            end as Author,\n        s.name as Series from books as b\n        left outer join collaborations as c on c.book_id=b.id\n        left outer join authors as a on a.id=c.author_id\n        left join series as s on s.id=b.series_id\n        order by {0}\n        limit :limit offset :offset\n        \"\"\".format(get_sort_clause(sort_col, sort_dir))\n    inputs = {\"limit\": pagesize, \"offset\": int(page * pagesize)}\n\n    csr = get_cursor()\n    rst = csr.execute(stmt, inputs)\n    rows = rows2list(rst)\n\n    return {\"rows\": rows, \"count\": get_all_books_count()}", "func_src_after": "def get_books_by_page(page, pagesize, sort_col, sort_dir):\n    # Column sorting\n    # TODO There are consistency issues. Collab records with no book or no author.\n    # We use left outer joins here to get all books regardless of collaborations status.\n    stmt = \"\"\"\n        select b.*,\n        case when length(a.FirstName) > 0\n            then (a.LastName || \", \" || a.FirstName)\n            else a.LastName\n            end as Author,\n        s.name as Series from books as b\n        left outer join collaborations as c on c.book_id=b.id\n        left outer join authors as a on a.id=c.author_id\n        left outer join series as s on s.id=b.series_id\n        order by {0}\n        limit :limit offset :offset\n        \"\"\".format(get_sort_clause(sort_col, sort_dir))\n    parameters = {\"limit\": pagesize, \"offset\": int(page * pagesize)}\n\n    csr = get_cursor()\n    rst = csr.execute(stmt, parameters)\n    rows = rows2list(rst)\n\n    return {\"rows\": rows, \"count\": get_filtered_books_count(None, None, None)}", "line_changes": {"deleted": [{"line_no": 9, "char_start": 424, "char_end": 425, "line": "\n"}, {"line_no": 22, "char_start": 963, "char_end": 1013, "line": "        left join series as s on s.id=b.series_id\n"}, {"line_no": 26, "char_start": 1126, "char_end": 1191, "line": "    inputs = {\"limit\": pagesize, \"offset\": int(page * pagesize)}\n"}, {"line_no": 29, "char_start": 1215, "char_end": 1251, "line": "    rst = csr.execute(stmt, inputs)\n"}, {"line_no": 32, "char_start": 1278, "char_end": 1335, "line": "    return {\"rows\": rows, \"count\": get_all_books_count()}\n"}], "added": [{"line_no": 14, "char_start": 597, "char_end": 653, "line": "        left outer join series as s on s.id=b.series_id\n"}, {"line_no": 18, "char_start": 766, "char_end": 835, "line": "    parameters = {\"limit\": pagesize, \"offset\": int(page * pagesize)}\n"}, {"line_no": 21, "char_start": 859, "char_end": 899, "line": "    rst = csr.execute(stmt, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 59, "char_end": 425, "chars": "    # q = db_session.query(Book).join(Collaborations, Collaborations.book_id==Book.id)\n    # q = q.join(Series, Series.id==Book.series_id)\n    # q = append_order_by_clause(q, sort_col, sort_dir)\n    # count = q.count();\n    # books = q.offset(page * pagesize).limit(pagesize)\n    # dict_books = books_todict(books)\n    # return {\"rows\": dict_books, \"count\": count}\n\n"}, {"char_start": 1130, "char_end": 1135, "chars": "input"}, {"char_start": 1243, "char_end": 1248, "chars": "input"}, {"char_start": 1317, "char_end": 1320, "chars": "all"}], "added": [{"char_start": 610, "char_end": 616, "chars": "outer "}, {"char_start": 770, "char_end": 779, "chars": "parameter"}, {"char_start": 887, "char_end": 896, "chars": "parameter"}, {"char_start": 965, "char_end": 973, "chars": "filtered"}, {"char_start": 986, "char_end": 1002, "chars": "None, None, None"}]}, "commit_link": "github.com/dhocker/susannas-library-frb/commit/3f0775b82a12f52cb221f1aefa03b527bf861a70", "file_name": "app/models/sql_books.py", "vul_type": "cwe-089"}
{"func_name": "search_for_books_by_page", "func_src_before": "def search_for_books_by_page(page, pagesize, author_id, series_id, search_arg, sort_col, sort_dir):\n    # q = db_session.query(Book).join(Collaborations, Collaborations.book_id==Book.id)\n    # q = q.join(Author, Author.id==Collaborations.author_id)\n    # q = q.join(Series, Series.id==Book.series_id)\n    # if author_id:\n    #     # This appears to be slow, but it works for finding an author's books\n    #     # q = q.filter(Book.authors.any(Author.id==author_id))\n    #     # This technique appears to be much faster\n    #     q = q.filter(Book.series_id==series_id)\n    # elif series_id:\n    #     q = q.filter(Book.series_id==series_id)\n    # if search_arg:\n    #     s = \"%\" + search_arg + \"%\"\n    #     q = q.filter(Book.Title.like(s))\n    #\n    # count = q.count()\n    # books = q.order_by(func.lower(Book.Title)).offset(page * page_size).limit(page_size)\n    # dict_books = books_todict(books)\n    #\n    # return {\"rows\": dict_books, \"count\": count}\n\n    # Build where clause based on filter inputs\n    inputs = {\"limit\": pagesize, \"offset\": int(page * pagesize)}\n    wh = \"\"\n    if author_id:\n        wh = \"where c.author_id=\" + str(author_id)\n    elif series_id:\n        wh = \"where b.series_id=\" + str(series_id)\n    if search_arg:\n        # Need Sql injection check on search arg\n        s = \"%\" + search_arg + \"%\"\n        inputs[\"like\"] = s\n        wh = 'where b.Title like :like'\n\n    stmt = \"\"\"\n        select b.*,\n        case when length(a.FirstName) > 0\n            then (a.LastName || \", \" || a.FirstName)\n            else a.LastName\n            end as Author,\n        s.name as Series from books as b\n        left outer join collaborations as c on c.book_id=b.id\n        left outer join authors as a on a.id=c.author_id\n        left join series as s on s.id=b.series_id\n        {1}\n        order by {0}\n        limit :limit offset :offset\n        \"\"\".format(get_sort_clause(sort_col, sort_dir), wh)\n\n    csr = get_cursor()\n    rst = csr.execute(stmt, inputs)\n    rows = rows2list(rst)\n\n    return {\"rows\": rows, \"count\": get_filtered_books_count(author_id, series_id, search_arg)}", "func_src_after": "def search_for_books_by_page(page, pagesize, author_id, series_id, search_arg, sort_col, sort_dir):\n    # Build where clause based on filter inputs\n    # We used named parameters to prevent Sql injection vulnerabilities\n    parameters = {\"limit\": pagesize, \"offset\": int(page * pagesize)}\n    wh = \"\"\n    if author_id:\n        wh = \"where c.author_id=:author_id\"\n        parameters[\"author_id\"] = str(int(author_id))\n    elif series_id:\n        wh = \"where b.series_id=:series_id\"\n        parameters[\"series_id\"] = str(int(series_id))\n    if search_arg:\n        # Sql injection prevention on search arg\n        s = \"%\" + search_arg + \"%\"\n        parameters[\"like\"] = s\n        wh = 'where b.Title like :like'\n\n    stmt = \"\"\"\n        select b.*,\n        case when length(a.FirstName) > 0\n            then (a.LastName || \", \" || a.FirstName)\n            else a.LastName\n            end as Author,\n        s.name as Series from books as b\n        left outer join collaborations as c on c.book_id=b.id\n        left outer join authors as a on a.id=c.author_id\n        left join series as s on s.id=b.series_id\n        {1}\n        order by {0}\n        limit :limit offset :offset\n        \"\"\".format(get_sort_clause(sort_col, sort_dir), wh)\n\n    csr = get_cursor()\n    rst = csr.execute(stmt, parameters)\n    rows = rows2list(rst)\n\n    return {\"rows\": rows, \"count\": get_filtered_books_count(author_id, series_id, search_arg)}", "line_changes": {"deleted": [{"line_no": 21, "char_start": 958, "char_end": 959, "line": "\n"}, {"line_no": 23, "char_start": 1007, "char_end": 1072, "line": "    inputs = {\"limit\": pagesize, \"offset\": int(page * pagesize)}\n"}, {"line_no": 26, "char_start": 1102, "char_end": 1153, "line": "        wh = \"where c.author_id=\" + str(author_id)\n"}, {"line_no": 28, "char_start": 1173, "char_end": 1224, "line": "        wh = \"where b.series_id=\" + str(series_id)\n"}, {"line_no": 32, "char_start": 1327, "char_end": 1354, "line": "        inputs[\"like\"] = s\n"}, {"line_no": 51, "char_start": 1943, "char_end": 1979, "line": "    rst = csr.execute(stmt, inputs)\n"}], "added": [{"line_no": 4, "char_start": 220, "char_end": 289, "line": "    parameters = {\"limit\": pagesize, \"offset\": int(page * pagesize)}\n"}, {"line_no": 7, "char_start": 319, "char_end": 363, "line": "        wh = \"where c.author_id=:author_id\"\n"}, {"line_no": 8, "char_start": 363, "char_end": 417, "line": "        parameters[\"author_id\"] = str(int(author_id))\n"}, {"line_no": 10, "char_start": 437, "char_end": 481, "line": "        wh = \"where b.series_id=:series_id\"\n"}, {"line_no": 11, "char_start": 481, "char_end": 535, "line": "        parameters[\"series_id\"] = str(int(series_id))\n"}, {"line_no": 15, "char_start": 638, "char_end": 669, "line": "        parameters[\"like\"] = s\n"}, {"line_no": 34, "char_start": 1258, "char_end": 1298, "line": "    rst = csr.execute(stmt, parameters)\n"}]}, "char_changes": {"deleted": [{"char_start": 106, "char_end": 1016, "chars": "q = db_session.query(Book).join(Collaborations, Collaborations.book_id==Book.id)\n    # q = q.join(Author, Author.id==Collaborations.author_id)\n    # q = q.join(Series, Series.id==Book.series_id)\n    # if author_id:\n    #     # This appears to be slow, but it works for finding an author's books\n    #     # q = q.filter(Book.authors.any(Author.id==author_id))\n    #     # This technique appears to be much faster\n    #     q = q.filter(Book.series_id==series_id)\n    # elif series_id:\n    #     q = q.filter(Book.series_id==series_id)\n    # if search_arg:\n    #     s = \"%\" + search_arg + \"%\"\n    #     q = q.filter(Book.Title.like(s))\n    #\n    # count = q.count()\n    # books = q.order_by(func.lower(Book.Title)).offset(page * page_size).limit(page_size)\n    # dict_books = books_todict(books)\n    #\n    # return {\"rows\": dict_books, \"count\": count}\n\n    # Build where clause based on filter inputs\n    input"}, {"char_start": 1134, "char_end": 1141, "chars": "\" + str"}, {"char_start": 1205, "char_end": 1212, "chars": "\" + str"}, {"char_start": 1252, "char_end": 1257, "chars": " Need"}, {"char_start": 1272, "char_end": 1277, "chars": "check"}, {"char_start": 1335, "char_end": 1340, "chars": "input"}, {"char_start": 1971, "char_end": 1976, "chars": "input"}], "added": [{"char_start": 106, "char_end": 233, "chars": "Build where clause based on filter inputs\n    # We used named parameters to prevent Sql injection vulnerabilities\n    parameter"}, {"char_start": 351, "char_end": 396, "chars": ":author_id\"\n        parameters[\"author_id\"] ="}, {"char_start": 401, "char_end": 405, "chars": "int("}, {"char_start": 415, "char_end": 416, "chars": ")"}, {"char_start": 469, "char_end": 522, "chars": ":series_id\"\n        parameters[\"series_id\"] = str(int"}, {"char_start": 533, "char_end": 534, "chars": ")"}, {"char_start": 578, "char_end": 588, "chars": "prevention"}, {"char_start": 646, "char_end": 655, "chars": "parameter"}, {"char_start": 1286, "char_end": 1295, "chars": "parameter"}]}, "commit_link": "github.com/dhocker/susannas-library-frb/commit/3f0775b82a12f52cb221f1aefa03b527bf861a70", "file_name": "app/models/sql_books.py", "vul_type": "cwe-089"}
{"func_name": "get_filtered_books_count", "func_src_before": "def get_filtered_books_count(author_id, series_id, search_arg):\n    # Build where clause based on filter inputs\n    wh = \"\"\n    parameters = ()\n    if author_id:\n        wh = \"where c.author_id=\" + str(int(author_id))\n    elif series_id:\n        wh = \"where b.series_id=\" + str(int(series_id))\n    if search_arg:\n        # Need to do Sql injection check on search arg\n        s = \"%\" + search_arg + \"%\"\n        parameters += (s.encode('utf-8'),)\n        wh = 'where b.Title like ?'\n\n    stmt = \"\"\"\n        select count(*) from books as b\n        left outer join collaborations as c on c.book_id=b.id\n        left outer join authors as a on a.id=c.author_id\n        left join series as s on s.id=b.series_id\n        {0}\n        \"\"\".format(wh)\n\n    csr = get_cursor()\n    if len(parameters) > 0:\n        count = csr.execute(stmt, parameters).fetchone()[0]\n    else:\n        count = csr.execute(stmt).fetchone()[0]\n    return count", "func_src_after": "def get_filtered_books_count(author_id, series_id, search_arg):\n    # Build where clause based on filter inputs\n    # We used named parameters to prevent Sql injection vulnerabilities\n    wh = \"\"\n    parameters = {}\n    if author_id:\n        wh = \"where c.author_id=:author_id\"\n        parameters[\"author_id\"] = str(int(author_id))\n    elif series_id:\n        wh = \"where b.series_id=:series_id\"\n        parameters[\"series_id\"] = str(int(series_id))\n    if search_arg:\n        # Sql injection prevention on search arg\n        s = \"%\" + search_arg + \"%\"\n        parameters[\"like\"] = s.encode('utf-8')\n        wh = 'where b.Title like :like'\n\n    stmt = \"\"\"\n        select count(*) from books as b\n        left outer join collaborations as c on c.book_id=b.id\n        left outer join authors as a on a.id=c.author_id\n        left join series as s on s.id=b.series_id\n        {0}\n        \"\"\".format(wh)\n\n    csr = get_cursor()\n    count = csr.execute(stmt, parameters).fetchone()[0]\n    return count", "line_changes": {"deleted": [{"line_no": 4, "char_start": 124, "char_end": 144, "line": "    parameters = ()\n"}, {"line_no": 6, "char_start": 162, "char_end": 218, "line": "        wh = \"where c.author_id=\" + str(int(author_id))\n"}, {"line_no": 8, "char_start": 238, "char_end": 294, "line": "        wh = \"where b.series_id=\" + str(int(series_id))\n"}, {"line_no": 12, "char_start": 403, "char_end": 446, "line": "        parameters += (s.encode('utf-8'),)\n"}, {"line_no": 13, "char_start": 446, "char_end": 482, "line": "        wh = 'where b.Title like ?'\n"}, {"line_no": 24, "char_start": 766, "char_end": 794, "line": "    if len(parameters) > 0:\n"}, {"line_no": 25, "char_start": 794, "char_end": 854, "line": "        count = csr.execute(stmt, parameters).fetchone()[0]\n"}, {"line_no": 26, "char_start": 854, "char_end": 864, "line": "    else:\n"}, {"line_no": 27, "char_start": 864, "char_end": 912, "line": "        count = csr.execute(stmt).fetchone()[0]\n"}], "added": [{"line_no": 5, "char_start": 196, "char_end": 216, "line": "    parameters = {}\n"}, {"line_no": 7, "char_start": 234, "char_end": 278, "line": "        wh = \"where c.author_id=:author_id\"\n"}, {"line_no": 8, "char_start": 278, "char_end": 332, "line": "        parameters[\"author_id\"] = str(int(author_id))\n"}, {"line_no": 10, "char_start": 352, "char_end": 396, "line": "        wh = \"where b.series_id=:series_id\"\n"}, {"line_no": 11, "char_start": 396, "char_end": 450, "line": "        parameters[\"series_id\"] = str(int(series_id))\n"}, {"line_no": 15, "char_start": 553, "char_end": 600, "line": "        parameters[\"like\"] = s.encode('utf-8')\n"}, {"line_no": 16, "char_start": 600, "char_end": 640, "line": "        wh = 'where b.Title like :like'\n"}, {"line_no": 27, "char_start": 924, "char_end": 980, "line": "    count = csr.execute(stmt, parameters).fetchone()[0]\n"}]}, "char_changes": {"deleted": [{"char_start": 141, "char_end": 143, "chars": "()"}, {"char_start": 194, "char_end": 197, "chars": "\" +"}, {"char_start": 270, "char_end": 273, "chars": "\" +"}, {"char_start": 322, "char_end": 333, "chars": " Need to do"}, {"char_start": 348, "char_end": 353, "chars": "check"}, {"char_start": 422, "char_end": 423, "chars": "+"}, {"char_start": 425, "char_end": 426, "chars": "("}, {"char_start": 443, "char_end": 445, "chars": ",)"}, {"char_start": 479, "char_end": 480, "chars": "?"}, {"char_start": 766, "char_end": 868, "chars": "    if len(parameters) > 0:\n        count = csr.execute(stmt, parameters).fetchone()[0]\n    else:\n    "}], "added": [{"char_start": 112, "char_end": 184, "chars": "    # We used named parameters to prevent Sql injection vulnerabilities\n"}, {"char_start": 213, "char_end": 215, "chars": "{}"}, {"char_start": 266, "char_end": 311, "chars": ":author_id\"\n        parameters[\"author_id\"] ="}, {"char_start": 384, "char_end": 429, "chars": ":series_id\"\n        parameters[\"series_id\"] ="}, {"char_start": 493, "char_end": 503, "chars": "prevention"}, {"char_start": 571, "char_end": 579, "chars": "[\"like\"]"}, {"char_start": 633, "char_end": 638, "chars": ":like"}, {"char_start": 952, "char_end": 964, "chars": ", parameters"}]}, "commit_link": "github.com/dhocker/susannas-library-frb/commit/3f0775b82a12f52cb221f1aefa03b527bf861a70", "file_name": "app/models/sql_books.py", "vul_type": "cwe-089"}
{"func_name": "add_item", "func_src_before": "    def add_item(self, item):\n        \"\"\"\"Add new item.\"\"\"\n        if self.connection:\n            self.cursor.execute('insert into item (name, shoppinglistid) values (\"%s\", \"%s\")' % (item[0], item[1]))\n            self.connection.commit()", "func_src_after": "    def add_item(self, item):\n        \"\"\"\"Add new item.\"\"\"\n        if self.connection:\n            t = (item[0], item[1], )\n            self.cursor.execute('insert into item (name, shoppinglistid) values (?, ?)', t)\n            self.connection.commit()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 87, "char_end": 203, "line": "            self.cursor.execute('insert into item (name, shoppinglistid) values (\"%s\", \"%s\")' % (item[0], item[1]))\n"}], "added": [{"line_no": 4, "char_start": 87, "char_end": 124, "line": "            t = (item[0], item[1], )\n"}, {"line_no": 5, "char_start": 124, "char_end": 216, "line": "            self.cursor.execute('insert into item (name, shoppinglistid) values (?, ?)', t)\n"}]}, "char_changes": {"deleted": [{"char_start": 168, "char_end": 201, "chars": "\"%s\", \"%s\")' % (item[0], item[1])"}], "added": [{"char_start": 87, "char_end": 124, "chars": "            t = (item[0], item[1], )\n"}, {"char_start": 205, "char_end": 214, "chars": "?, ?)', t"}]}, "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089"}
{"func_name": "add_language", "func_src_before": "    def add_language(self, language):\n        \"\"\"\"Add new language for item translations.\"\"\"\n        if self.connection:\n            self.cursor.execute('insert into itemlanguage (language) values (\"%s\")' % language[0])\n            self.connection.commit()", "func_src_after": "    def add_language(self, language):\n        \"\"\"\"Add new language for item translations.\"\"\"\n        if self.connection:\n            t = (language[0], )\n            self.cursor.execute('insert into itemlanguage (language) values (?)', t)\n            self.connection.commit()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 121, "char_end": 220, "line": "            self.cursor.execute('insert into itemlanguage (language) values (\"%s\")' % language[0])\n"}], "added": [{"line_no": 4, "char_start": 121, "char_end": 153, "line": "            t = (language[0], )\n"}, {"line_no": 5, "char_start": 153, "char_end": 238, "line": "            self.cursor.execute('insert into itemlanguage (language) values (?)', t)\n"}]}, "char_changes": {"deleted": [{"char_start": 198, "char_end": 218, "chars": "\"%s\")' % language[0]"}], "added": [{"char_start": 121, "char_end": 153, "chars": "            t = (language[0], )\n"}, {"char_start": 230, "char_end": 236, "chars": "?)', t"}]}, "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089"}
{"func_name": "add_translationname", "func_src_before": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (\"%s\", \"%s\", \"%s\")' % (item[0], trname[1], trname[2]))\n            self.connection.commit()", "func_src_after": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                t = (item[0], trname[1], trname[2], )\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (?, ?, ?)', t)\n            self.connection.commit()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 194, "char_end": 359, "line": "                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (\"%s\", \"%s\", \"%s\")' % (item[0], trname[1], trname[2]))\n"}], "added": [{"line_no": 5, "char_start": 194, "char_end": 248, "line": "                t = (item[0], trname[1], trname[2], )\n"}, {"line_no": 6, "char_start": 248, "char_end": 373, "line": "                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (?, ?, ?)', t)\n"}, {"line_no": 7, "char_start": 373, "char_end": 409, "line": "            self.connection.commit()\n"}]}, "char_changes": {"deleted": [{"char_start": 305, "char_end": 357, "chars": "\"%s\", \"%s\", \"%s\")' % (item[0], trname[1], trname[2])"}], "added": [{"char_start": 194, "char_end": 248, "chars": "                t = (item[0], trname[1], trname[2], )\n"}, {"char_start": 359, "char_end": 371, "chars": "?, ?, ?)', t"}]}, "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089"}
{"func_name": "level2Search", "func_src_before": "@app.route(\"/level-2/search\", methods=[\"POST\"])\n@login_required\ndef level2Search():\n    term = str(request.form[\"term\"])\n    conn = psycopg2.connect(\"dbname=unlock user=ubuntu\")\n    cur = conn.cursor()\n    cur.execute(\"SELECT * FROM nile_items;\")\n    res = cur.fetchall()\n    cur.close()\n    conn.close()\n    items = [dict() for x in range(len(res))]\n    for i in range(len(res)-1, -1, -1):\n        if term in res[i][0] or term in res[i][3]:\n            items[i][\"name\"] = res[i][0]\n            items[i][\"price\"] = res[i][1]\n            items[i][\"image\"] = res[i][2]\n    return str(items)", "func_src_after": "@app.route(\"/level-2/search\", methods=[\"POST\"])\n@login_required\ndef level2Search():\n    term = str(request.form[\"term\"])\n    conn = psycopg2.connect(\"dbname=nile user=ubuntu\")\n    cur = conn.cursor()\n    cur.execute(\"SELECT * FROM items WHERE tags LIKE '%\" + term + \"%';\")\n    res = cur.fetchall()\n    cur.close()\n    conn.close()\n    items = [dict() for x in range(len(res))]\n    for i in range(len(res)-1, -1, -1):\n        items[i][\"name\"] = res[i][0]\n        items[i][\"price\"] = res[i][1]\n        items[i][\"image\"] = res[i][2]\n    return str(items)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 121, "char_end": 178, "line": "    conn = psycopg2.connect(\"dbname=unlock user=ubuntu\")\n"}, {"line_no": 7, "char_start": 202, "char_end": 247, "line": "    cur.execute(\"SELECT * FROM nile_items;\")\n"}, {"line_no": 13, "char_start": 391, "char_end": 442, "line": "        if term in res[i][0] or term in res[i][3]:\n"}, {"line_no": 14, "char_start": 442, "char_end": 483, "line": "            items[i][\"name\"] = res[i][0]\n"}, {"line_no": 15, "char_start": 483, "char_end": 525, "line": "            items[i][\"price\"] = res[i][1]\n"}, {"line_no": 16, "char_start": 525, "char_end": 567, "line": "            items[i][\"image\"] = res[i][2]\n"}], "added": [{"line_no": 5, "char_start": 121, "char_end": 176, "line": "    conn = psycopg2.connect(\"dbname=nile user=ubuntu\")\n"}, {"line_no": 7, "char_start": 200, "char_end": 273, "line": "    cur.execute(\"SELECT * FROM items WHERE tags LIKE '%\" + term + \"%';\")\n"}, {"line_no": 13, "char_start": 417, "char_end": 454, "line": "        items[i][\"name\"] = res[i][0]\n"}, {"line_no": 14, "char_start": 454, "char_end": 492, "line": "        items[i][\"price\"] = res[i][1]\n"}, {"line_no": 15, "char_start": 492, "char_end": 530, "line": "        items[i][\"image\"] = res[i][2]\n"}]}, "char_changes": {"deleted": [{"char_start": 157, "char_end": 163, "chars": "unlock"}, {"char_start": 233, "char_end": 238, "chars": "nile_"}, {"char_start": 391, "char_end": 446, "chars": "        if term in res[i][0] or term in res[i][3]:\n    "}, {"char_start": 483, "char_end": 487, "chars": "    "}, {"char_start": 525, "char_end": 529, "chars": "    "}], "added": [{"char_start": 157, "char_end": 161, "chars": "nile"}, {"char_start": 236, "char_end": 269, "chars": " WHERE tags LIKE '%\" + term + \"%'"}]}, "commit_link": "github.com/brocksmith225/unlock/commit/acdbc66aa7b3cf69980d8b9dc2eeffb3ac125e1b", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "render_GET", "func_src_before": "    def render_GET(self, request):\n        \"\"\"\n        .. http:get:: /search?q=(string:query)\n\n        A GET request to this endpoint will create a search.\n\n        first and last options limit the range of the query.\n        xxx_filter option disables xxx filter\n        channel option limits search to a certain channel\n        sort_by option sorts results in forward or backward, based on column name (e.g. \"id\" vs \"-id\")\n        txt option uses FTS search on the chosen word* terms\n        type option limits query to certain metadata types (e.g. \"torrent\" or \"channel\")\n\n            **Example request**:\n\n            .. sourcecode:: none\n\n                curl -X GET 'http://localhost:8085/search?txt=ubuntu&first=0&last=30&type=torrent&sort_by=size'\n\n            **Example response**:\n\n            .. sourcecode:: javascript\n\n                {\n                   \"torrents\":[\n                      {\n                         \"commit_status\":1,\n                         \"num_leechers\":0,\n                         \"date\":\"1539867830.0\",\n                         \"relevance_score\":0,\n                         \"id\":21,\n                         \"size\":923795456,\n                         \"category\":\"unknown\",\n                         \"public_key\":\"4c69624e...\",\n                         \"name\":\"ubuntu-18.10-live-server-amd64.iso\",\n                         \"last_tracker_check\":0,\n                         \"infohash\":\"8c4adbf9ebe66f1d804fb6a4fb9b74966c3ab609\",\n                         \"num_seeders\":0,\n                         \"type\":\"torrent\"\n                      },\n                      ...\n                   ],\n                   \"chant_dirty\":false\n                }\n        \"\"\"\n\n        sanitized = SearchEndpoint.sanitize_parameters(request.args)\n\n        if not sanitized[\"query_filter\"]:\n            request.setResponseCode(http.BAD_REQUEST)\n            return json.dumps({\"error\": \"filter parameter missing\"})\n\n        if not sanitized[\"metadata_type\"]:\n            request.setResponseCode(http.BAD_REQUEST)\n            return json.dumps({\"error\": \"Trying to query for unknown type of metadata\"})\n\n        with db_session:\n            pony_query, total = self.session.lm.mds.TorrentMetadata.get_entries(**sanitized)\n            search_results = [(dict(type={REGULAR_TORRENT: 'torrent', CHANNEL_TORRENT: 'channel'}[r.metadata_type],\n                                    **(r.to_simple_dict()))) for r in pony_query]\n\n        return json.dumps({\n            \"results\": search_results,\n            \"first\": sanitized[\"first\"],\n            \"last\": sanitized[\"last\"],\n            \"sort_by\": sanitized[\"sort_by\"],\n            \"sort_asc\": sanitized[\"sort_asc\"],\n            \"total\": total\n        })", "func_src_after": "    def render_GET(self, request):\n        \"\"\"\n        .. http:get:: /search?q=(string:query)\n\n        A GET request to this endpoint will create a search.\n\n        first and last options limit the range of the query.\n        xxx_filter option disables xxx filter\n        channel option limits search to a certain channel\n        sort_by option sorts results in forward or backward, based on column name (e.g. \"id\" vs \"-id\")\n        txt option uses FTS search on the chosen word* terms\n        type option limits query to certain metadata types (e.g. \"torrent\" or \"channel\")\n\n            **Example request**:\n\n            .. sourcecode:: none\n\n                curl -X GET 'http://localhost:8085/search?txt=ubuntu&first=0&last=30&type=torrent&sort_by=size'\n\n            **Example response**:\n\n            .. sourcecode:: javascript\n\n                {\n                   \"torrents\":[\n                      {\n                         \"commit_status\":1,\n                         \"num_leechers\":0,\n                         \"date\":\"1539867830.0\",\n                         \"relevance_score\":0,\n                         \"id\":21,\n                         \"size\":923795456,\n                         \"category\":\"unknown\",\n                         \"public_key\":\"4c69624e...\",\n                         \"name\":\"ubuntu-18.10-live-server-amd64.iso\",\n                         \"last_tracker_check\":0,\n                         \"infohash\":\"8c4adbf9ebe66f1d804fb6a4fb9b74966c3ab609\",\n                         \"num_seeders\":0,\n                         \"type\":\"torrent\"\n                      },\n                      ...\n                   ],\n                   \"chant_dirty\":false\n                }\n        \"\"\"\n        sanitized = SearchEndpoint.sanitize_parameters(request.args)\n\n        if not sanitized[\"query_filter\"]:\n            request.setResponseCode(http.BAD_REQUEST)\n            return json.dumps({\"error\": \"filter parameter missing\"})\n\n        if not sanitized[\"metadata_type\"]:\n            request.setResponseCode(http.BAD_REQUEST)\n            return json.dumps({\"error\": \"Trying to query for unknown type of metadata\"})\n\n        with db_session:\n            pony_query, total = self.session.lm.mds.TorrentMetadata.get_entries(**sanitized)\n            search_results = [(dict(type={REGULAR_TORRENT: 'torrent', CHANNEL_TORRENT: 'channel'}[r.metadata_type],\n                                    **(r.to_simple_dict()))) for r in pony_query]\n\n        # Apart from the local search results, we also do remote search to get search results from peers in the\n        # Giga channel community.\n        if self.session.lm.gigachannel_community and sanitized[\"first\"] == 1:\n            raw_metadata_type = request.args['metadata_type'][0] if 'metadata_type' in request.args else ''\n            self.session.lm.gigachannel_community.send_search_request(sanitized['query_filter'],\n                                                                      metadata_type=raw_metadata_type,\n                                                                      sort_by=sanitized['sort_by'],\n                                                                      sort_asc=sanitized['sort_asc'],\n                                                                      hide_xxx=sanitized['hide_xxx'])\n\n        return json.dumps({\n            \"results\": search_results,\n            \"first\": sanitized[\"first\"],\n            \"last\": sanitized[\"last\"],\n            \"sort_by\": sanitized[\"sort_by\"],\n            \"sort_asc\": sanitized[\"sort_asc\"],\n            \"total\": total\n        })", "line_changes": {"deleted": [{"line_no": 46, "char_start": 1689, "char_end": 1690, "line": "\n"}], "added": [{"line_no": 63, "char_start": 2575, "char_end": 2653, "line": "        if self.session.lm.gigachannel_community and sanitized[\"first\"] == 1:\n"}, {"line_no": 64, "char_start": 2653, "char_end": 2761, "line": "            raw_metadata_type = request.args['metadata_type'][0] if 'metadata_type' in request.args else ''\n"}, {"line_no": 65, "char_start": 2761, "char_end": 2858, "line": "            self.session.lm.gigachannel_community.send_search_request(sanitized['query_filter'],\n"}, {"line_no": 66, "char_start": 2858, "char_end": 2961, "line": "                                                                      metadata_type=raw_metadata_type,\n"}, {"line_no": 67, "char_start": 2961, "char_end": 3061, "line": "                                                                      sort_by=sanitized['sort_by'],\n"}, {"line_no": 68, "char_start": 3061, "char_end": 3163, "line": "                                                                      sort_asc=sanitized['sort_asc'],\n"}, {"line_no": 69, "char_start": 3163, "char_end": 3265, "line": "                                                                      hide_xxx=sanitized['hide_xxx'])\n"}, {"line_no": 70, "char_start": 3265, "char_end": 3266, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 1689, "char_end": 1690, "chars": "\n"}, {"char_start": 2347, "char_end": 2347, "chars": ""}], "added": [{"char_start": 2429, "char_end": 3266, "chars": "        # Apart from the local search results, we also do remote search to get search results from peers in the\n        # Giga channel community.\n        if self.session.lm.gigachannel_community and sanitized[\"first\"] == 1:\n            raw_metadata_type = request.args['metadata_type'][0] if 'metadata_type' in request.args else ''\n            self.session.lm.gigachannel_community.send_search_request(sanitized['query_filter'],\n                                                                      metadata_type=raw_metadata_type,\n                                                                      sort_by=sanitized['sort_by'],\n                                                                      sort_asc=sanitized['sort_asc'],\n                                                                      hide_xxx=sanitized['hide_xxx'])\n\n"}]}, "commit_link": "github.com/Tribler/tribler/commit/90c44130524cf82c62689cfb03bfcbb8f9b62ad7", "file_name": "Tribler/Core/Modules/restapi/search_endpoint.py", "vul_type": "cwe-089"}
{"func_name": "update_table", "func_src_before": "    def update_table(self, listings, cat_id):\n        logger.info('Updating table c{} in the MySQL database'.format(cat_id))\n        logger.info('Requesting for MySQL connection')\n\n        db = self.get_connection()\n        cursor = db.cursor()\n\n        for l in listings:\n            if not isinstance(l, Listing):\n                logger.error('TypeError: Expected a Listing instance')\n                logger.error('Skipping this listing')\n                continue\n\n            logger.debug('Generating SQL command')\n\n            sql = self.gen_sql_insert(l, cat_id)\n            if sql == -1:\n                # Failed to generate SQL command\n                logger.error('Skipping the listing')\n                continue\n\n            try:\n                logger.debug('Executing SQL command')\n                cursor.execute(sql)\n                logger.debug('Committing changes to the database')\n                db.commit()\n                logger.info('Successfully added a listing to table c{:d}'.format(cat_id))\n            except:\n                db.rollback()\n                logger.error('Failed to add a listing to table c{:d}'.format(cat_id))\n                logger.error('Rolled back the database changes')\n        return 0", "func_src_after": "    def update_table(self, listings):\n        if not listings:\n            logger.warning('Did not update table. listings is empty.')\n            return 0\n\n        cat_id = listings[0].cat_id\n\n        logger.info('Updating table c{} in the MySQL database'.format(cat_id))\n        logger.info('Requesting for MySQL connection')\n\n        db = self.get_connection()\n        cursor = db.cursor()\n\n        for l in listings:\n            if not isinstance(l, Listing):\n                logger.error('TypeError: Expected a Listing instance')\n                logger.error('Skipping this listing')\n                continue\n\n            (sql, pars) = self._gen_sql_insert(l, cat_id)\n            if sql == -1:\n                # Failed to generate SQL command\n                logger.error('Skipping the listing')\n                continue\n\n            try:\n                logger.debug('Executing SQL command')\n                cursor.execute(sql, pars)\n                logger.debug('Committing changes to the database')\n                db.commit()\n                logger.info('Successfully added a listing to table c{:d}'.format(cat_id))\n            except:\n                db.rollback()\n                print(sql)\n                logger.exception('Exception:')\n                logger.error('Failed to add a listing to table c{:d}'.format(cat_id))\n                logger.error('Listing url: {:s}'.format(l.url))\n                logger.error('Rolled back the database changes')\n        return 0", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 46, "line": "    def update_table(self, listings, cat_id):\n"}, {"line_no": 14, "char_start": 467, "char_end": 518, "line": "            logger.debug('Generating SQL command')\n"}, {"line_no": 15, "char_start": 518, "char_end": 519, "line": "\n"}, {"line_no": 16, "char_start": 519, "char_end": 568, "line": "            sql = self.gen_sql_insert(l, cat_id)\n"}, {"line_no": 24, "char_start": 793, "char_end": 829, "line": "                cursor.execute(sql)\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 38, "line": "    def update_table(self, listings):\n"}, {"line_no": 2, "char_start": 38, "char_end": 63, "line": "        if not listings:\n"}, {"line_no": 3, "char_start": 63, "char_end": 134, "line": "            logger.warning('Did not update table. listings is empty.')\n"}, {"line_no": 4, "char_start": 134, "char_end": 155, "line": "            return 0\n"}, {"line_no": 5, "char_start": 155, "char_end": 156, "line": "\n"}, {"line_no": 6, "char_start": 156, "char_end": 192, "line": "        cat_id = listings[0].cat_id\n"}, {"line_no": 7, "char_start": 192, "char_end": 193, "line": "\n"}, {"line_no": 20, "char_start": 614, "char_end": 672, "line": "            (sql, pars) = self._gen_sql_insert(l, cat_id)\n"}, {"line_no": 28, "char_start": 897, "char_end": 939, "line": "                cursor.execute(sql, pars)\n"}, {"line_no": 34, "char_start": 1174, "char_end": 1201, "line": "                print(sql)\n"}, {"line_no": 35, "char_start": 1201, "char_end": 1248, "line": "                logger.exception('Exception:')\n"}, {"line_no": 37, "char_start": 1334, "char_end": 1398, "line": "                logger.error('Listing url: {:s}'.format(l.url))\n"}]}, "char_changes": {"deleted": [{"char_start": 35, "char_end": 45, "chars": ", cat_id):"}, {"char_start": 479, "char_end": 534, "chars": "logger.debug('Generating SQL command')\n\n            sql"}], "added": [{"char_start": 35, "char_end": 192, "chars": "):\n        if not listings:\n            logger.warning('Did not update table. listings is empty.')\n            return 0\n\n        cat_id = listings[0].cat_id\n"}, {"char_start": 626, "char_end": 637, "chars": "(sql, pars)"}, {"char_start": 645, "char_end": 646, "chars": "_"}, {"char_start": 931, "char_end": 937, "chars": ", pars"}, {"char_start": 1174, "char_end": 1248, "chars": "                print(sql)\n                logger.exception('Exception:')\n"}, {"char_start": 1334, "char_end": 1398, "chars": "                logger.error('Listing url: {:s}'.format(l.url))\n"}]}, "commit_link": "github.com/timweri/kijiji-housing-scraper/commit/1bf3a8d584935c2e34a085e9b9727a11e94ebdce", "file_name": "database/mysql.py", "vul_type": "cwe-089"}
{"func_name": "_process_parameter", "func_src_before": "    def _process_parameter(self, data_type, parameter_data):\n        assert len(data_type) > 0, 'Invalid data type'\n        assert isinstance(parameter_data, dict), 'Invalid parameter data format'\n\n        if data_type.upper() == 'FIELD':\n            field_data = self.field_mapping[parameter_data['field']]\n            return \"`{table}`.`{field}`\".format(\n                table=field_data[self.TABLE_NAME], field=field_data[self.FIELD_NAME]\n            )\n        elif data_type.upper() == 'INTEGER':\n            return int(parameter_data['value'])\n        elif data_type.upper() == 'STRING':\n            return parameter_data['value']\n        else:\n            raise AttributeError(\"Unsupported data type for parameter: {}\".format(data_type))", "func_src_after": "    def _process_parameter(self, data_type, parameter_data):\n        assert len(data_type) > 0, 'Invalid data type'\n        assert isinstance(parameter_data, dict), 'Invalid parameter data format'\n\n        if data_type.upper() == 'FIELD':\n            field_data = self.field_mapping[parameter_data['field']]\n            return \"`{table}`.`{field}`\".format(\n                table=field_data[self.TABLE_NAME], field=field_data[self.FIELD_NAME]\n            )\n        elif data_type.upper() == 'INTEGER':\n            return int(parameter_data['value'])\n        elif data_type.upper() == 'STRING':\n            return \"'{}'\".format(self._sql_injection_proof(parameter_data['value']))\n        else:\n            raise AttributeError(\"Unsupported data type for parameter: {}\".format(data_type))", "line_changes": {"deleted": [{"line_no": 13, "char_start": 593, "char_end": 636, "line": "            return parameter_data['value']\n"}], "added": [{"line_no": 13, "char_start": 593, "char_end": 678, "line": "            return \"'{}'\".format(self._sql_injection_proof(parameter_data['value']))\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 612, "char_end": 652, "chars": "\"'{}'\".format(self._sql_injection_proof("}, {"char_start": 675, "char_end": 677, "chars": "))"}]}, "commit_link": "github.com/icanbwell/JSON2SQL/commit/172c629e0414f175a99afaf9b095c380821b2c8f", "file_name": "json2sql/engine.py", "vul_type": "cwe-089"}
{"func_name": "_create_database", "func_src_before": "@pytest.fixture(scope='session', autouse=True)\ndef _create_database(request, _system_engine):\n    test_db_name = _get_test_db_name()\n    # TODO(aershov182): use sqlalchemy for query generation\n    with _system_engine.connect().execution_options(\n            isolation_level=\"AUTOCOMMIT\") as conn:\n        conn.execute(f'DROP DATABASE IF EXISTS {test_db_name}')\n        conn.execute(f'CREATE DATABASE {test_db_name}')\n    create_tables()\n    request.addfinalizer(lambda: _drop_database(_system_engine))", "func_src_after": "@pytest.fixture(scope='session', autouse=True)\ndef _create_database(request, _system_engine):\n    test_db_name = _get_test_db_name()\n    _run_system_commands(\n        _system_engine,\n        _drop_db_stmt(test_db_name), _create_db_stmt(test_db_name))\n    create_tables()\n    request.addfinalizer(lambda: _drop_database(_system_engine))", "line_changes": {"deleted": [{"line_no": 5, "char_start": 193, "char_end": 246, "line": "    with _system_engine.connect().execution_options(\n"}, {"line_no": 6, "char_start": 246, "char_end": 297, "line": "            isolation_level=\"AUTOCOMMIT\") as conn:\n"}, {"line_no": 7, "char_start": 297, "char_end": 361, "line": "        conn.execute(f'DROP DATABASE IF EXISTS {test_db_name}')\n"}, {"line_no": 8, "char_start": 361, "char_end": 417, "line": "        conn.execute(f'CREATE DATABASE {test_db_name}')\n"}], "added": [{"line_no": 4, "char_start": 133, "char_end": 159, "line": "    _run_system_commands(\n"}, {"line_no": 5, "char_start": 159, "char_end": 183, "line": "        _system_engine,\n"}, {"line_no": 6, "char_start": 183, "char_end": 251, "line": "        _drop_db_stmt(test_db_name), _create_db_stmt(test_db_name))\n"}]}, "char_changes": {"deleted": [{"char_start": 137, "char_end": 401, "chars": "# TODO(aershov182): use sqlalchemy for query generation\n    with _system_engine.connect().execution_options(\n            isolation_level=\"AUTOCOMMIT\") as conn:\n        conn.execute(f'DROP DATABASE IF EXISTS {test_db_name}')\n        conn.execute(f'CREATE DATABASE {"}, {"char_start": 413, "char_end": 415, "chars": "}'"}], "added": [{"char_start": 137, "char_end": 158, "chars": "_run_system_commands("}, {"char_start": 163, "char_end": 166, "chars": "   "}, {"char_start": 181, "char_end": 236, "chars": ",\n        _drop_db_stmt(test_db_name), _create_db_stmt("}, {"char_start": 248, "char_end": 249, "chars": ")"}]}, "commit_link": "github.com/alexandershov/pymash/commit/b62d144fb9350570f15a8bde3b0194ce5a66bf08", "file_name": "tests/test_views.py", "vul_type": "cwe-089"}
{"func_name": "getboundingMaille", "func_src_before": "@addObs.route('/load_bounding_box_mailles/<limit>', methods=['GET'])\r\ndef getboundingMaille(limit):\r\n    db = getConnexion()\r\n    sql = 'SELECT ST_TRANSFORM(ST_MakeEnvelope('+limit+', 4326),32620);'\r\n    db.cur.execute(sql)\r\n    bounding = db.cur.fetchone()\r\n    sql = \"\"\" SELECT row_to_json(fc)\r\n              FROM ( SELECT \r\n                'FeatureCollection' AS type, \r\n                array_to_json(array_agg(f)) AS features\r\n                FROM(\r\n                    SELECT 'Feature' AS type,\r\n                   ST_ASGeoJSON(ST_TRANSFORM(m.geom,4326))::json As geometry,\r\n                   row_to_json((SELECT l FROM(SELECT id_maille) AS l)) AS properties\r\n                   FROM layers.maille_1_2 AS m WHERE m.taille_maille='1' AND ST_Within(m.geom,ST_TRANSFORM(ST_MakeEnvelope(\"\"\"+limit+\"\"\", 4326),32620))  ) AS f)\r\n                AS fc; \"\"\"\r\n    db.cur.execute(sql)\r\n    res = db.cur.fetchone()\r\n    db.closeAll()\r\n    return Response(flask.json.dumps(res), mimetype='application/json')", "func_src_after": "@addObs.route('/load_bounding_box_mailles/<limit>', methods=['GET'])\r\ndef getboundingMaille(limit):\r\n    db = getConnexion()\r\n    sql = \"\"\" SELECT row_to_json(fc)\r\n              FROM ( SELECT \r\n                'FeatureCollection' AS type, \r\n                array_to_json(array_agg(f)) AS features\r\n                FROM(\r\n                    SELECT 'Feature' AS type,\r\n                   ST_ASGeoJSON(ST_TRANSFORM(m.geom,4326))::json As geometry,\r\n                   row_to_json((SELECT l FROM(SELECT id_maille) AS l)) AS properties\r\n                   FROM layers.maille_1_2 AS m WHERE m.taille_maille='1' AND ST_Within(m.geom,ST_TRANSFORM(ST_MakeEnvelope(%s, %s, %s, %s, 4326),32620))  ) AS f)\r\n                AS fc; \"\"\"\r\n    params = limit.split(',')\r\n    db.cur.execute(sql, params)\r\n    res = db.cur.fetchone()\r\n    db.closeAll()\r\n    return Response(flask.json.dumps(res), mimetype='application/json')", "line_changes": {"deleted": [{"line_no": 4, "char_start": 126, "char_end": 200, "line": "    sql = 'SELECT ST_TRANSFORM(ST_MakeEnvelope('+limit+', 4326),32620);'\r\n"}, {"line_no": 5, "char_start": 200, "char_end": 225, "line": "    db.cur.execute(sql)\r\n"}, {"line_no": 6, "char_start": 225, "char_end": 259, "line": "    bounding = db.cur.fetchone()\r\n"}, {"line_no": 15, "char_start": 666, "char_end": 828, "line": "                   FROM layers.maille_1_2 AS m WHERE m.taille_maille='1' AND ST_Within(m.geom,ST_TRANSFORM(ST_MakeEnvelope(\"\"\"+limit+\"\"\", 4326),32620))  ) AS f)\r\n"}, {"line_no": 17, "char_start": 856, "char_end": 881, "line": "    db.cur.execute(sql)\r\n"}], "added": [{"line_no": 12, "char_start": 533, "char_end": 696, "line": "                   FROM layers.maille_1_2 AS m WHERE m.taille_maille='1' AND ST_Within(m.geom,ST_TRANSFORM(ST_MakeEnvelope(%s, %s, %s, %s, 4326),32620))  ) AS f)\r\n"}, {"line_no": 14, "char_start": 724, "char_end": 755, "line": "    params = limit.split(',')\r\n"}, {"line_no": 15, "char_start": 755, "char_end": 788, "line": "    db.cur.execute(sql, params)\r\n"}]}, "char_changes": {"deleted": [{"char_start": 126, "char_end": 259, "chars": "    sql = 'SELECT ST_TRANSFORM(ST_MakeEnvelope('+limit+', 4326),32620);'\r\n    db.cur.execute(sql)\r\n    bounding = db.cur.fetchone()\r\n"}, {"char_start": 789, "char_end": 802, "chars": "\"\"\"+limit+\"\"\""}], "added": [{"char_start": 656, "char_end": 670, "chars": "%s, %s, %s, %s"}, {"char_start": 724, "char_end": 755, "chars": "    params = limit.split(',')\r\n"}, {"char_start": 777, "char_end": 785, "chars": ", params"}]}, "commit_link": "github.com/TheoLechemia/BDN/commit/d43117b5a6f8fbfcbcdaaabcba435f77e4f42e3e", "file_name": "Apps/addObs/addObsViews.py", "vul_type": "cwe-089"}
{"func_name": "getValues", "func_src_before": "@addObs.route('/loadValues/<protocole>', methods=['GET'])\r\ndef getValues(protocole):\r\n    db=getConnexion()\r\n    sql = \"SELECT * FROM \"+protocole\r\n    db.cur.execute(sql)\r\n    res = db.cur.fetchall()\r\n    finalDict = dict()\r\n    for r in res:\r\n        dictValues = ast.literal_eval(r[3])\r\n        finalDict[r[2]] = dictValues['values']\r\n    return Response(flask.json.dumps(finalDict), mimetype='application/json')", "func_src_after": "@addObs.route('/loadValues/<protocole>', methods=['GET'])\r\ndef getValues(protocole):\r\n    db=getConnexion()\r\n    if checkForInjection(protocole):\r\n        return Response(flask.json.dumps(\"Tu crois que tu vas m'injecter\"), mimetype='application/json')\r\n    else:\r\n        sql = \"SELECT * FROM \"+protocole\r\n        db.cur.execute(sql)\r\n        res = db.cur.fetchall()\r\n        finalDict = dict()\r\n        for r in res:\r\n            dictValues = ast.literal_eval(r[3])\r\n            finalDict[r[2]] = dictValues['values']\r\n        return Response(flask.json.dumps(finalDict), mimetype='application/json')", "line_changes": {"deleted": [{"line_no": 4, "char_start": 109, "char_end": 147, "line": "    sql = \"SELECT * FROM \"+protocole\r\n"}, {"line_no": 5, "char_start": 147, "char_end": 172, "line": "    db.cur.execute(sql)\r\n"}, {"line_no": 6, "char_start": 172, "char_end": 201, "line": "    res = db.cur.fetchall()\r\n"}, {"line_no": 7, "char_start": 201, "char_end": 225, "line": "    finalDict = dict()\r\n"}, {"line_no": 8, "char_start": 225, "char_end": 244, "line": "    for r in res:\r\n"}, {"line_no": 9, "char_start": 244, "char_end": 289, "line": "        dictValues = ast.literal_eval(r[3])\r\n"}, {"line_no": 10, "char_start": 289, "char_end": 337, "line": "        finalDict[r[2]] = dictValues['values']\r\n"}, {"line_no": 11, "char_start": 337, "char_end": 414, "line": "    return Response(flask.json.dumps(finalDict), mimetype='application/json')\r\n"}], "added": [{"line_no": 4, "char_start": 109, "char_end": 147, "line": "    if checkForInjection(protocole):\r\n"}, {"line_no": 5, "char_start": 147, "char_end": 253, "line": "        return Response(flask.json.dumps(\"Tu crois que tu vas m'injecter\"), mimetype='application/json')\r\n"}, {"line_no": 6, "char_start": 253, "char_end": 264, "line": "    else:\r\n"}, {"line_no": 7, "char_start": 264, "char_end": 306, "line": "        sql = \"SELECT * FROM \"+protocole\r\n"}, {"line_no": 8, "char_start": 306, "char_end": 335, "line": "        db.cur.execute(sql)\r\n"}, {"line_no": 9, "char_start": 335, "char_end": 368, "line": "        res = db.cur.fetchall()\r\n"}, {"line_no": 10, "char_start": 368, "char_end": 396, "line": "        finalDict = dict()\r\n"}, {"line_no": 11, "char_start": 396, "char_end": 419, "line": "        for r in res:\r\n"}, {"line_no": 12, "char_start": 419, "char_end": 468, "line": "            dictValues = ast.literal_eval(r[3])\r\n"}, {"line_no": 13, "char_start": 468, "char_end": 520, "line": "            finalDict[r[2]] = dictValues['values']\r\n"}, {"line_no": 14, "char_start": 520, "char_end": 601, "line": "        return Response(flask.json.dumps(finalDict), mimetype='application/json')\r\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 109, "char_end": 268, "chars": "    if checkForInjection(protocole):\r\n        return Response(flask.json.dumps(\"Tu crois que tu vas m'injecter\"), mimetype='application/json')\r\n    else:\r\n    "}, {"char_start": 306, "char_end": 310, "chars": "    "}, {"char_start": 339, "char_end": 340, "chars": " "}, {"char_start": 340, "char_end": 343, "chars": "   "}, {"char_start": 372, "char_end": 375, "chars": "   "}, {"char_start": 375, "char_end": 376, "chars": " "}, {"char_start": 396, "char_end": 400, "chars": "    "}, {"char_start": 427, "char_end": 428, "chars": " "}, {"char_start": 428, "char_end": 431, "chars": "   "}, {"char_start": 468, "char_end": 472, "chars": "    "}, {"char_start": 520, "char_end": 524, "chars": "    "}]}, "commit_link": "github.com/TheoLechemia/BDN/commit/d43117b5a6f8fbfcbcdaaabcba435f77e4f42e3e", "file_name": "Apps/addObs/addObsViews.py", "vul_type": "cwe-089"}
{"func_name": "is_valid_id", "func_src_before": "def is_valid_id(ss):\n    '''verifies if id is likely a valid discord id'''\n    if type(ss) == type('') and len(ss) >= 15 and len(ss) <= 20 and isInt(ss):\n        return True\n    return False", "func_src_after": "def is_valid_id(ss):\n    '''verifies if id is likely a valid discord id'''\n    if type(ss) == type('') and len(ss) >= 15 and len(ss) <= 20 and is_int(ss):\n        return True\n    return False", "line_changes": {"deleted": [{"line_no": 3, "char_start": 75, "char_end": 154, "line": "    if type(ss) == type('') and len(ss) >= 15 and len(ss) <= 20 and isInt(ss):\n"}], "added": [{"line_no": 3, "char_start": 75, "char_end": 155, "line": "    if type(ss) == type('') and len(ss) >= 15 and len(ss) <= 20 and is_int(ss):\n"}]}, "char_changes": {"deleted": [{"char_start": 145, "char_end": 146, "chars": "I"}], "added": [{"char_start": 145, "char_end": 147, "chars": "_i"}]}, "commit_link": "github.com/sycherng/fluffybot/commit/dea23ddd0e3bbe967cf04dac3663482adc5c7357", "file_name": "db.py", "vul_type": "cwe-089"}
{"func_name": "spawn_user", "func_src_before": "async def spawn_user(bot, message):\n    if not db.check(message.author.id, 'id', db.user_table):\n        db.update(\"INSERT INTO {} (id, nickname) VALUES ('{}', '{}');\".format(db.user_table, message.author.id, message.author))", "func_src_after": "async def spawn_user(bot, message):\n    if not db.check(message.author.id, 'id', db.users):\n        db.update(\"INSERT INTO {} (id, nickname) VALUES (%s, %s);\".format(db.users), (message.author.id, message.author.name))", "line_changes": {"deleted": [{"line_no": 2, "char_start": 36, "char_end": 97, "line": "    if not db.check(message.author.id, 'id', db.user_table):\n"}, {"line_no": 3, "char_start": 97, "char_end": 225, "line": "        db.update(\"INSERT INTO {} (id, nickname) VALUES ('{}', '{}');\".format(db.user_table, message.author.id, message.author))\n"}], "added": [{"line_no": 2, "char_start": 36, "char_end": 92, "line": "    if not db.check(message.author.id, 'id', db.users):\n"}, {"line_no": 3, "char_start": 92, "char_end": 218, "line": "        db.update(\"INSERT INTO {} (id, nickname) VALUES (%s, %s);\".format(db.users), (message.author.id, message.author.name))\n"}]}, "char_changes": {"deleted": [{"char_start": 88, "char_end": 94, "chars": "_table"}, {"char_start": 154, "char_end": 164, "chars": "'{}', '{}'"}, {"char_start": 182, "char_end": 188, "chars": "_table"}], "added": [{"char_start": 88, "char_end": 89, "chars": "s"}, {"char_start": 149, "char_end": 155, "chars": "%s, %s"}, {"char_start": 173, "char_end": 175, "chars": "s)"}, {"char_start": 177, "char_end": 178, "chars": "("}, {"char_start": 211, "char_end": 216, "chars": ".name"}]}, "commit_link": "github.com/sycherng/fluffybot/commit/dea23ddd0e3bbe967cf04dac3663482adc5c7357", "file_name": "user.py", "vul_type": "cwe-089"}
{"func_name": "user_add", "func_src_before": "async def user_add(bot, message):\n    #--- call: user add <id> <nickname>\n    if message.content.startswith('user add '):\n        msg = message.content.split()[2:]\n        if db.rank_check(message.author.id, 'user add') and len(msg) == 2 and db.is_valid_id(msg[0]):\n            db.update(\"INSERT INTO {} (id, nickname, rank) VALUES ('{}', '{}', 'member');\".format(db.user_table, msg[0], msg[1]))", "func_src_after": "async def user_add(bot, message):\n    #--- call: user add <id> <nickname>\n    if message.content.startswith('user add '):\n        msg = message.content.split()[2:]\n        if db.rank_check(message.author.id, 'user add') and len(msg) == 2 and db.is_valid_id(msg[0]):\n            db.update(\"INSERT INTO {} (id, nickname, rank) VALUES (%s, %s, 'member');\".format(db.users), (msg[0], msg[1]))", "line_changes": {"deleted": [{"line_no": 6, "char_start": 266, "char_end": 395, "line": "            db.update(\"INSERT INTO {} (id, nickname, rank) VALUES ('{}', '{}', 'member');\".format(db.user_table, msg[0], msg[1]))\n"}], "added": [{"line_no": 6, "char_start": 266, "char_end": 388, "line": "            db.update(\"INSERT INTO {} (id, nickname, rank) VALUES (%s, %s, 'member');\".format(db.users), (msg[0], msg[1]))\n"}]}, "char_changes": {"deleted": [{"char_start": 333, "char_end": 343, "chars": "'{}', '{}'"}, {"char_start": 371, "char_end": 377, "chars": "_table"}], "added": [{"char_start": 333, "char_end": 339, "chars": "%s, %s"}, {"char_start": 367, "char_end": 369, "chars": "s)"}, {"char_start": 371, "char_end": 372, "chars": "("}]}, "commit_link": "github.com/sycherng/fluffybot/commit/dea23ddd0e3bbe967cf04dac3663482adc5c7357", "file_name": "user.py", "vul_type": "cwe-089"}
{"func_name": "stars", "func_src_before": "@app.route('/stars/<int:page>/<int:limit>')\ndef stars(page, limit):\n    try:\n        query = \"SELECT * FROM star LIMIT %s OFFSET %s\"\n        db_res = MySQL.execute(DATABASE, query, [limit, page * limit])\n        resp = [dict(zip(db_res['columns'], [str(t) if type(t) is bytearray else t for t in row])) for row in\n                db_res['rows']]\n        return jsonify({'stars': resp, \"status\": {\"message\": \"Fetched %s stars\" % (len(resp),)}})\n    except Exception as err:\n        logger.exception(err)\n        return jsonify({\"status\": {\"message\": \"Something went wrong\"}}), 500", "func_src_after": "@app.route('/stars/<int:page>/<int:limit>')\ndef stars(page, limit):\n    \"\"\"\n    Retrieve stars page by page\n    :param page: page number\n    :param limit: number of stars in this page\n    :return:\n    \"\"\"\n    try:\n        query = \"SELECT * FROM star WHERE {} LIMIT %s OFFSET %s\".format(request.args.get(\"query\") or \"1 = 1\")\n        db_res = MySQL.execute(DATABASE, query, [limit, page * limit])\n        resp = [dict(zip(db_res['columns'], [str(t) if type(t) is bytearray else t for t in row])) for row in\n                db_res['rows']]\n        return jsonify({'stars': resp, \"status\": {\"message\": \"Fetched %s stars\" % (len(resp),)}})\n    except Exception as err:\n        logger.exception(err)\n        return jsonify({\"status\": {\"message\": \"Something went wrong\"}}), 500", "line_changes": {"deleted": [{"line_no": 4, "char_start": 77, "char_end": 133, "line": "        query = \"SELECT * FROM star LIMIT %s OFFSET %s\"\n"}], "added": [{"line_no": 3, "char_start": 68, "char_end": 76, "line": "    \"\"\"\n"}, {"line_no": 4, "char_start": 76, "char_end": 108, "line": "    Retrieve stars page by page\n"}, {"line_no": 5, "char_start": 108, "char_end": 137, "line": "    :param page: page number\n"}, {"line_no": 6, "char_start": 137, "char_end": 184, "line": "    :param limit: number of stars in this page\n"}, {"line_no": 7, "char_start": 184, "char_end": 197, "line": "    :return:\n"}, {"line_no": 8, "char_start": 197, "char_end": 205, "line": "    \"\"\"\n"}, {"line_no": 10, "char_start": 214, "char_end": 324, "line": "        query = \"SELECT * FROM star WHERE {} LIMIT %s OFFSET %s\".format(request.args.get(\"query\") or \"1 = 1\")\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 68, "char_end": 205, "chars": "    \"\"\"\n    Retrieve stars page by page\n    :param page: page number\n    :param limit: number of stars in this page\n    :return:\n    \"\"\"\n"}, {"char_start": 249, "char_end": 258, "chars": " WHERE {}"}, {"char_start": 278, "char_end": 323, "chars": ".format(request.args.get(\"query\") or \"1 = 1\")"}]}, "commit_link": "github.com/Nithanaroy/astronomy_visualizations/commit/4780258ab4d4fae526c24997b1de1c1a4bc08a1f", "file_name": "App/Server.py", "vul_type": "cwe-089"}
{"func_name": "user_authenticate", "func_src_before": "    def user_authenticate(self, login, password, dry=False):\n        \"\"\"Performs a password authentication on a user. Returns True if\n        \"passhash\" is the correct passhash for the given login, False\n        if the passhash does not match the password in the DB,\n        and None if the passhash in the DB is NULL.\n        Also returns False if the login does not exist (so if you want to\n        differentiate these cases, use get_user and catch an exception).\n        \"\"\"\n        query = \"SELECT passhash FROM login WHERE login = '%s';\" % login\n        if dry: return query\n        result = self.db.query(query)\n        if result.ntuples() == 1:\n            # Valid username. Check password.\n            passhash = result.getresult()[0][0]\n            if passhash is None:\n                return None\n            return _passhash(password) == passhash\n        else:\n            return False", "func_src_after": "    def user_authenticate(self, login, password, dry=False):\n        \"\"\"Performs a password authentication on a user. Returns True if\n        \"passhash\" is the correct passhash for the given login, False\n        if the passhash does not match the password in the DB,\n        and None if the passhash in the DB is NULL.\n        Also returns False if the login does not exist (so if you want to\n        differentiate these cases, use get_user and catch an exception).\n        \"\"\"\n        query = (\"SELECT passhash FROM login WHERE login = %s;\"\n            % _escape(login))\n        if dry: return query\n        result = self.db.query(query)\n        if result.ntuples() == 1:\n            # Valid username. Check password.\n            passhash = result.getresult()[0][0]\n            if passhash is None:\n                return None\n            return _passhash(password) == passhash\n        else:\n            return False", "line_changes": {"deleted": [{"line_no": 9, "char_start": 478, "char_end": 551, "line": "        query = \"SELECT passhash FROM login WHERE login = '%s';\" % login\n"}], "added": [{"line_no": 9, "char_start": 478, "char_end": 542, "line": "        query = (\"SELECT passhash FROM login WHERE login = %s;\"\n"}, {"line_no": 10, "char_start": 542, "char_end": 572, "line": "            % _escape(login))\n"}]}, "char_changes": {"deleted": [{"char_start": 536, "char_end": 537, "chars": "'"}, {"char_start": 539, "char_end": 540, "chars": "'"}, {"char_start": 542, "char_end": 545, "chars": " % "}], "added": [{"char_start": 494, "char_end": 495, "chars": "("}, {"char_start": 541, "char_end": 564, "chars": "\n            % _escape("}, {"char_start": 569, "char_end": 571, "chars": "))"}]}, "commit_link": "github.com/dcoles/ivle/commit/aa77ad447fe13cb83e0e72b077ad00e4a43a0cbf", "file_name": "lib/common/db.py", "vul_type": "cwe-089"}
{"func_name": "get_secrets", "func_src_before": "\tdef get_secrets(self, from_date_added=0):\n\t\tsecrets = []\n\t\tfor row in self.cursor.execute('SELECT encrypted, json_id, date_added FROM secret WHERE date_added > %s ORDER BY date_added DESC' % from_date_added):\n\t\t\taes_key, json_id, date_added = cryptlib.eciesDecrypt(row[0], self.privkey), row[1], row[2]\n\t\t\tif aes_key != None:\n\t\t\t\tsecrets.append([aes_key, json_id])\n\t\t\tfrom_date_added = max(from_date_added, date_added)\n\t\treturn (secrets, from_date_added)", "func_src_after": "\tdef get_secrets(self, from_date_added=0):\n\t\tsecrets = []\n\t\tfor row in self.cursor.execute('SELECT encrypted, json_id, date_added FROM secret WHERE date_added > ? ORDER BY date_added DESC', (from_date_added,)):\n\t\t\taes_key, json_id, date_added = cryptlib.eciesDecrypt(row[0], self.privkey), row[1], row[2]\n\t\t\tif aes_key != None:\n\t\t\t\tsecrets.append([aes_key, json_id])\n\t\t\tfrom_date_added = max(from_date_added, date_added)\n\t\treturn (secrets, from_date_added)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 58, "char_end": 210, "line": "\t\tfor row in self.cursor.execute('SELECT encrypted, json_id, date_added FROM secret WHERE date_added > %s ORDER BY date_added DESC' % from_date_added):\n"}], "added": [{"line_no": 3, "char_start": 58, "char_end": 211, "line": "\t\tfor row in self.cursor.execute('SELECT encrypted, json_id, date_added FROM secret WHERE date_added > ? ORDER BY date_added DESC', (from_date_added,)):\n"}]}, "char_changes": {"deleted": [{"char_start": 161, "char_end": 163, "chars": "%s"}, {"char_start": 189, "char_end": 192, "chars": " % "}], "added": [{"char_start": 161, "char_end": 162, "chars": "?"}, {"char_start": 188, "char_end": 191, "chars": ", ("}, {"char_start": 206, "char_end": 208, "chars": ",)"}]}, "commit_link": "github.com/imachug/ZeroMailProxy/commit/8f62d024c6c4c957079d147e59f26d15c07dc888", "file_name": "zeromail.py", "vul_type": "cwe-089"}
{"func_name": "update_phrase", "func_src_before": "    def update_phrase (self, entry, database='user_db'):\n        '''update phrase freqs'''\n        input_phrase, phrase, freq, user_freq = entry\n        sqlstr = '''UPDATE %(database)s.phrases\n                    SET user_freq = %(user_freq)s\n                    WHERE mlen = %(mlen)s\n                    AND clen = %(clen)s\n                    AND input_phrase = \"%(input_phrase)s\"\n                    AND phrase = \"%(phrase)s\";\n        ''' %{'database':database,\n              'user_freq': user_freq,\n              'mlen': len(input_phrase),\n              'clen': len(phrase),\n              'input_phrase': input_phrase,\n              'phrase': phrase}\n        self.db.execute(sqlstr)\n        self.db.commit()", "func_src_after": "    def update_phrase (self, entry, database='user_db'):\n        '''update phrase freqs'''\n        input_phrase, phrase, freq, user_freq = entry\n        sqlstr = '''\n        UPDATE %(database)s.phrases\n        SET user_freq = :user_freq\n        WHERE mlen = :mlen\n        AND clen = :clen\n        AND input_phrase = :input_phrase\n        AND phrase = :phrase\n        ;''' %{'database':database}\n        sqlargs = {'user_freq': user_freq,\n                   'mlen': len(input_phrase),\n                   'clen': len(phrase),\n                   'input_phrase': input_phrase,\n                   'phrase': phrase}\n        self.db.execute(sqlstr, sqlargs)\n        self.db.commit()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 145, "char_end": 193, "line": "        sqlstr = '''UPDATE %(database)s.phrases\n"}, {"line_no": 5, "char_start": 193, "char_end": 243, "line": "                    SET user_freq = %(user_freq)s\n"}, {"line_no": 6, "char_start": 243, "char_end": 285, "line": "                    WHERE mlen = %(mlen)s\n"}, {"line_no": 7, "char_start": 285, "char_end": 325, "line": "                    AND clen = %(clen)s\n"}, {"line_no": 8, "char_start": 325, "char_end": 383, "line": "                    AND input_phrase = \"%(input_phrase)s\"\n"}, {"line_no": 9, "char_start": 383, "char_end": 430, "line": "                    AND phrase = \"%(phrase)s\";\n"}, {"line_no": 10, "char_start": 430, "char_end": 465, "line": "        ''' %{'database':database,\n"}, {"line_no": 11, "char_start": 465, "char_end": 503, "line": "              'user_freq': user_freq,\n"}, {"line_no": 12, "char_start": 503, "char_end": 544, "line": "              'mlen': len(input_phrase),\n"}, {"line_no": 13, "char_start": 544, "char_end": 579, "line": "              'clen': len(phrase),\n"}, {"line_no": 14, "char_start": 579, "char_end": 623, "line": "              'input_phrase': input_phrase,\n"}, {"line_no": 15, "char_start": 623, "char_end": 655, "line": "              'phrase': phrase}\n"}, {"line_no": 16, "char_start": 655, "char_end": 687, "line": "        self.db.execute(sqlstr)\n"}], "added": [{"line_no": 4, "char_start": 145, "char_end": 166, "line": "        sqlstr = '''\n"}, {"line_no": 5, "char_start": 166, "char_end": 202, "line": "        UPDATE %(database)s.phrases\n"}, {"line_no": 6, "char_start": 202, "char_end": 237, "line": "        SET user_freq = :user_freq\n"}, {"line_no": 7, "char_start": 237, "char_end": 264, "line": "        WHERE mlen = :mlen\n"}, {"line_no": 8, "char_start": 264, "char_end": 289, "line": "        AND clen = :clen\n"}, {"line_no": 9, "char_start": 289, "char_end": 330, "line": "        AND input_phrase = :input_phrase\n"}, {"line_no": 10, "char_start": 330, "char_end": 359, "line": "        AND phrase = :phrase\n"}, {"line_no": 11, "char_start": 359, "char_end": 395, "line": "        ;''' %{'database':database}\n"}, {"line_no": 12, "char_start": 395, "char_end": 438, "line": "        sqlargs = {'user_freq': user_freq,\n"}, {"line_no": 13, "char_start": 438, "char_end": 484, "line": "                   'mlen': len(input_phrase),\n"}, {"line_no": 14, "char_start": 484, "char_end": 524, "line": "                   'clen': len(phrase),\n"}, {"line_no": 15, "char_start": 524, "char_end": 573, "line": "                   'input_phrase': input_phrase,\n"}, {"line_no": 16, "char_start": 573, "char_end": 610, "line": "                   'phrase': phrase}\n"}, {"line_no": 17, "char_start": 610, "char_end": 651, "line": "        self.db.execute(sqlstr, sqlargs)\n"}]}, "char_changes": {"deleted": [{"char_start": 193, "char_end": 205, "chars": "            "}, {"char_start": 229, "char_end": 231, "chars": "%("}, {"char_start": 240, "char_end": 242, "chars": ")s"}, {"char_start": 243, "char_end": 255, "chars": "            "}, {"char_start": 276, "char_end": 278, "chars": "%("}, {"char_start": 282, "char_end": 284, "chars": ")s"}, {"char_start": 285, "char_end": 297, "chars": "            "}, {"char_start": 316, "char_end": 318, "chars": "%("}, {"char_start": 322, "char_end": 337, "chars": ")s\n            "}, {"char_start": 364, "char_end": 367, "chars": "\"%("}, {"char_start": 379, "char_end": 382, "chars": ")s\""}, {"char_start": 383, "char_end": 395, "chars": "            "}, {"char_start": 416, "char_end": 419, "chars": "\"%("}, {"char_start": 425, "char_end": 429, "chars": ")s\";"}, {"char_start": 463, "char_end": 464, "chars": ","}, {"char_start": 473, "char_end": 479, "chars": "      "}], "added": [{"char_start": 165, "char_end": 174, "chars": "\n        "}, {"char_start": 226, "char_end": 227, "chars": ":"}, {"char_start": 258, "char_end": 259, "chars": ":"}, {"char_start": 283, "char_end": 284, "chars": ":"}, {"char_start": 288, "char_end": 289, "chars": "\n"}, {"char_start": 316, "char_end": 317, "chars": ":"}, {"char_start": 351, "char_end": 352, "chars": ":"}, {"char_start": 367, "char_end": 368, "chars": ";"}, {"char_start": 393, "char_end": 394, "chars": "}"}, {"char_start": 403, "char_end": 414, "chars": "sqlargs = {"}, {"char_start": 452, "char_end": 454, "chars": "  "}, {"char_start": 454, "char_end": 457, "chars": "   "}, {"char_start": 498, "char_end": 503, "chars": "     "}, {"char_start": 538, "char_end": 539, "chars": " "}, {"char_start": 539, "char_end": 543, "chars": "    "}, {"char_start": 573, "char_end": 578, "chars": "     "}, {"char_start": 640, "char_end": 649, "chars": ", sqlargs"}]}, "commit_link": "github.com/mike-fabian/ibus-typing-booster/commit/6aeb0840b637750f5ca00b83ff3b824666703fb2", "file_name": "ibus-typing-booster/engine/tabsqlitedb.py", "vul_type": "cwe-089"}
{"func_name": "select_words", "func_src_before": "    def select_words(self, input_phrase):\n        '''\n        Get phrases from database by tab_key objects\n        ( which should be equal or less than the max key length)\n        This method is called in hunspell_table.py by passing UserInput held data\n        Returns a list of matches where each match is a tuple\n        in the form of a database row, i.e. returns something like\n        [(id, mlen, clen, input_phrase, phrase, freq, user_freq), ...]\n        '''\n        if type(input_phrase) != type(u''):\n            input_phrase = input_phrase.decode('utf8')\n        # limit length of input phrase to max key length\n        # (Now that the  input_phrase is stored in a single\n        # column of type TEXT in sqlite3, this limit can be set as high\n        # as the maximum string length in sqlite3\n        # (by default 10^9, see http://www.sqlite.org/limits.html))\n        input_phrase = input_phrase[:self._mlen]\n        sqlstr = '''SELECT * FROM user_db.phrases WHERE phrase LIKE \"%(input_phrase)s%%\"\n                    UNION ALL\n                    SELECT  * FROM mudb.phrases WHERE phrase LIKE \"%(input_phrase)s%%\"\n                    ORDER BY user_freq DESC, freq DESC, id ASC, mlen ASC\n                    limit 1000;''' %{'input_phrase': input_phrase}\n        result = self.db.execute(sqlstr).fetchall()\n        hunspell_list = self.hunspell_obj.suggest(input_phrase)\n        for ele in hunspell_list:\n            result.append(tuple(ele))\n\n        usrdb={}\n        mudb={}\n        sysdb={}\n        map(lambda x: sysdb.update([(x[3:-2],x[:])]), filter(lambda x: not x[-1], result))\n        map(lambda x: usrdb.update([(x[3:-2], x[:])]), filter(lambda x: (x[-2] in [0,-1]) and x[-1], result))\n        map(lambda x: mudb.update([(x[3:-2], x[:])]), filter(lambda x: (x[-2] not in [0,-1]) and x[-1], result))\n\n        _cand = mudb.values()\n        map(_cand.append, filter(lambda x: x, map(lambda key: key not in mudb and usrdb[key], usrdb)))\n        map(_cand.append, filter(lambda x: x, map(lambda key: key not in mudb and key not in usrdb and sysdb[key], sysdb)))\n        _cand.sort(cmp=(lambda x,y:\n                        -(cmp(x[-1], y[-1]))    # user_freq descending\n                        or (cmp(x[1], y[1]))    # len(input_phrase) ascending\n                        or -(cmp(x[-2], y[-2])) # freq descending\n                        or (cmp(x[0], y[0]))    # id ascending\n                    ))\n        return _cand[:]", "func_src_after": "    def select_words(self, input_phrase):\n        '''\n        Get phrases from database by tab_key objects\n        ( which should be equal or less than the max key length)\n        This method is called in hunspell_table.py by passing UserInput held data\n        Returns a list of matches where each match is a tuple\n        in the form of a database row, i.e. returns something like\n        [(id, mlen, clen, input_phrase, phrase, freq, user_freq), ...]\n        '''\n        if type(input_phrase) != type(u''):\n            input_phrase = input_phrase.decode('utf8')\n        # limit length of input phrase to max key length\n        # (Now that the  input_phrase is stored in a single\n        # column of type TEXT in sqlite3, this limit can be set as high\n        # as the maximum string length in sqlite3\n        # (by default 10^9, see http://www.sqlite.org/limits.html))\n        input_phrase = input_phrase[:self._mlen]\n        sqlstr = '''\n        SELECT * FROM user_db.phrases WHERE input_phrase LIKE :input_phrase\n        UNION ALL\n        SELECT  * FROM mudb.phrases WHERE input_phrase LIKE :input_phrase\n        ORDER BY user_freq DESC, freq DESC, id ASC, mlen ASC\n        limit 1000\n        ;'''\n        sqlargs = {'input_phrase': input_phrase+'%'}\n        result = self.db.execute(sqlstr, sqlargs).fetchall()\n        hunspell_list = self.hunspell_obj.suggest(input_phrase)\n        for ele in hunspell_list:\n            result.append(tuple(ele))\n\n        usrdb={}\n        mudb={}\n        sysdb={}\n        map(lambda x: sysdb.update([(x[3:-2],x[:])]), filter(lambda x: not x[-1], result))\n        map(lambda x: usrdb.update([(x[3:-2], x[:])]), filter(lambda x: (x[-2] in [0,-1]) and x[-1], result))\n        map(lambda x: mudb.update([(x[3:-2], x[:])]), filter(lambda x: (x[-2] not in [0,-1]) and x[-1], result))\n\n        _cand = mudb.values()\n        map(_cand.append, filter(lambda x: x, map(lambda key: key not in mudb and usrdb[key], usrdb)))\n        map(_cand.append, filter(lambda x: x, map(lambda key: key not in mudb and key not in usrdb and sysdb[key], sysdb)))\n        _cand.sort(cmp=(lambda x,y:\n                        -(cmp(x[-1], y[-1]))    # user_freq descending\n                        or (cmp(x[1], y[1]))    # len(input_phrase) ascending\n                        or -(cmp(x[-2], y[-2])) # freq descending\n                        or (cmp(x[0], y[0]))    # id ascending\n                    ))\n        return _cand[:]", "line_changes": {"deleted": [{"line_no": 18, "char_start": 921, "char_end": 1010, "line": "        sqlstr = '''SELECT * FROM user_db.phrases WHERE phrase LIKE \"%(input_phrase)s%%\"\n"}, {"line_no": 19, "char_start": 1010, "char_end": 1040, "line": "                    UNION ALL\n"}, {"line_no": 20, "char_start": 1040, "char_end": 1127, "line": "                    SELECT  * FROM mudb.phrases WHERE phrase LIKE \"%(input_phrase)s%%\"\n"}, {"line_no": 21, "char_start": 1127, "char_end": 1200, "line": "                    ORDER BY user_freq DESC, freq DESC, id ASC, mlen ASC\n"}, {"line_no": 22, "char_start": 1200, "char_end": 1267, "line": "                    limit 1000;''' %{'input_phrase': input_phrase}\n"}, {"line_no": 23, "char_start": 1267, "char_end": 1319, "line": "        result = self.db.execute(sqlstr).fetchall()\n"}], "added": [{"line_no": 18, "char_start": 921, "char_end": 942, "line": "        sqlstr = '''\n"}, {"line_no": 19, "char_start": 942, "char_end": 1018, "line": "        SELECT * FROM user_db.phrases WHERE input_phrase LIKE :input_phrase\n"}, {"line_no": 20, "char_start": 1018, "char_end": 1036, "line": "        UNION ALL\n"}, {"line_no": 21, "char_start": 1036, "char_end": 1110, "line": "        SELECT  * FROM mudb.phrases WHERE input_phrase LIKE :input_phrase\n"}, {"line_no": 22, "char_start": 1110, "char_end": 1171, "line": "        ORDER BY user_freq DESC, freq DESC, id ASC, mlen ASC\n"}, {"line_no": 23, "char_start": 1171, "char_end": 1190, "line": "        limit 1000\n"}, {"line_no": 24, "char_start": 1190, "char_end": 1203, "line": "        ;'''\n"}, {"line_no": 25, "char_start": 1203, "char_end": 1256, "line": "        sqlargs = {'input_phrase': input_phrase+'%'}\n"}, {"line_no": 26, "char_start": 1256, "char_end": 1317, "line": "        result = self.db.execute(sqlstr, sqlargs).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 989, "char_end": 992, "chars": "\"%("}, {"char_start": 1004, "char_end": 1009, "chars": ")s%%\""}, {"char_start": 1018, "char_end": 1052, "chars": "            UNION ALL\n            "}, {"char_start": 1106, "char_end": 1109, "chars": "\"%("}, {"char_start": 1121, "char_end": 1139, "chars": ")s%%\"\n            "}, {"char_start": 1208, "char_end": 1236, "chars": "            limit 1000;''' %"}], "added": [{"char_start": 941, "char_end": 950, "chars": "\n        "}, {"char_start": 986, "char_end": 992, "chars": "input_"}, {"char_start": 1004, "char_end": 1005, "chars": ":"}, {"char_start": 1026, "char_end": 1036, "chars": "UNION ALL\n"}, {"char_start": 1078, "char_end": 1084, "chars": "input_"}, {"char_start": 1096, "char_end": 1097, "chars": ":"}, {"char_start": 1109, "char_end": 1110, "chars": "\n"}, {"char_start": 1179, "char_end": 1221, "chars": "limit 1000\n        ;'''\n        sqlargs = "}, {"char_start": 1250, "char_end": 1254, "chars": "+'%'"}, {"char_start": 1295, "char_end": 1304, "chars": ", sqlargs"}]}, "commit_link": "github.com/mike-fabian/ibus-typing-booster/commit/6aeb0840b637750f5ca00b83ff3b824666703fb2", "file_name": "ibus-typing-booster/engine/tabsqlitedb.py", "vul_type": "cwe-089"}
{"func_name": "check_phrase", "func_src_before": "    def check_phrase(self, phrase, input_phrase=None, database='main'):\n        '''Check word freq and user_freq\n        '''\n        if type(phrase) != type(u''):\n            phrase = phrase.decode('utf8')\n        if type(input_phrase) != type(u''):\n            input_phrase = input_phrase.decode('utf8')\n\n        if len(phrase) < 4:\n            return\n\n        sqlstr = '''\n                SELECT * FROM user_db.phrases WHERE phrase = \"%(phrase)s\" and input_phrase = \"%(input_phrase)s\"\n                UNION ALL\n                SELECT * FROM mudb.phrases WHERE phrase = \"%(phrase)s\" and input_phrase = \"%(input_phrase)s\"\n                ORDER BY user_freq DESC, freq DESC, id ASC;''' %{'phrase': phrase, 'input_phrase': input_phrase}\n        result = self.db.execute(sqlstr).fetchall()\n        # If phrase is among the suggestions of self.hunspell_obj.suggest(input_phrase)\n        # append it to results:\n        filter(lambda x: x[-3] == phrase and result.append(tuple(x)),\n               self.hunspell_obj.suggest(input_phrase))\n        if len(result) == 0:\n            # The phrase was neither found in user_db nor mudb nor\n            # does hunspell_obj.suggest(input_phrase) suggest such\n            # a phrase. Therefore, it is a completely new, user\n            # defined phrase and we add it into mudb:\n            self.add_phrase((input_phrase,phrase,-2,1), database = 'mudb')\n\n        sysdb = {}\n        usrdb = {}\n        mudb = {}\n        map(lambda x: sysdb.update([(x[3:-2],x[:])]), filter(lambda x: not x[-1], result))\n        map(lambda x: usrdb.update([(x[3:-2], x[:])]), filter(lambda x: (x[-2] in [0,-1]) and x[-1], result))\n        map(lambda x: mudb.update([(x[3:-2], x[:])]), filter(lambda x: (x[-2] not in [0,-1]) and x[-1], result))\n\n        # we remove the keys already contained in mudb{} from usrdb{}\n        map(usrdb.pop, filter(lambda key: key in mudb, usrdb.keys()))\n        # we remove the keys already contained in mudb{} or usrdb{} from sysdb{}\n        map(sysdb.pop, filter(lambda key: key in mudb or key in usrdb, sysdb.keys()))\n\n        map(lambda res: self.add_phrase((res[0],phrase,(-3 if usrdb[res][-2] == -1 else 1),usrdb[res][-1]+1), database = 'mudb'), usrdb.keys())\n        map(lambda res: self.add_phrase((res[0],phrase,2,1), database = 'mudb'), sysdb.keys())\n\n        map(lambda key:\n            self.update_phrase((mudb[key][3], mudb[key][4], mudb[key][5], mudb[key][6]+1),\n                               database='mudb'),\n            mudb.keys())", "func_src_after": "    def check_phrase(self, phrase, input_phrase=None, database='main'):\n        '''Check word freq and user_freq\n        '''\n        if type(phrase) != type(u''):\n            phrase = phrase.decode('utf8')\n        if type(input_phrase) != type(u''):\n            input_phrase = input_phrase.decode('utf8')\n\n        if len(phrase) < 4:\n            return\n\n        sqlstr = '''\n        SELECT * FROM user_db.phrases\n        WHERE phrase = :phrase AND input_phrase = :input_phrase\n        UNION ALL\n        SELECT * FROM mudb.phrases\n        WHERE phrase = :phrase AND input_phrase = :input_phrase\n        ORDER BY user_freq DESC, freq DESC, id ASC\n        ;'''\n        sqlargs = {'phrase': phrase, 'input_phrase': input_phrase}\n        result = self.db.execute(sqlstr, sqlargs).fetchall()\n        # If phrase is among the suggestions of self.hunspell_obj.suggest(input_phrase)\n        # append it to results:\n        filter(lambda x: x[-3] == phrase and result.append(tuple(x)),\n               self.hunspell_obj.suggest(input_phrase))\n        if len(result) == 0:\n            # The phrase was neither found in user_db nor mudb nor\n            # does hunspell_obj.suggest(input_phrase) suggest such\n            # a phrase. Therefore, it is a completely new, user\n            # defined phrase and we add it into mudb:\n            self.add_phrase((input_phrase,phrase,-2,1), database = 'mudb')\n\n        sysdb = {}\n        usrdb = {}\n        mudb = {}\n        map(lambda x: sysdb.update([(x[3:-2],x[:])]), filter(lambda x: not x[-1], result))\n        map(lambda x: usrdb.update([(x[3:-2], x[:])]), filter(lambda x: (x[-2] in [0,-1]) and x[-1], result))\n        map(lambda x: mudb.update([(x[3:-2], x[:])]), filter(lambda x: (x[-2] not in [0,-1]) and x[-1], result))\n\n        # we remove the keys already contained in mudb{} from usrdb{}\n        map(usrdb.pop, filter(lambda key: key in mudb, usrdb.keys()))\n        # we remove the keys already contained in mudb{} or usrdb{} from sysdb{}\n        map(sysdb.pop, filter(lambda key: key in mudb or key in usrdb, sysdb.keys()))\n\n        map(lambda res: self.add_phrase((res[0],phrase,(-3 if usrdb[res][-2] == -1 else 1),usrdb[res][-1]+1), database = 'mudb'), usrdb.keys())\n        map(lambda res: self.add_phrase((res[0],phrase,2,1), database = 'mudb'), sysdb.keys())\n\n        map(lambda key:\n            self.update_phrase((mudb[key][3], mudb[key][4], mudb[key][5], mudb[key][6]+1),\n                               database='mudb'),\n            mudb.keys())", "line_changes": {"deleted": [{"line_no": 13, "char_start": 375, "char_end": 487, "line": "                SELECT * FROM user_db.phrases WHERE phrase = \"%(phrase)s\" and input_phrase = \"%(input_phrase)s\"\n"}, {"line_no": 14, "char_start": 487, "char_end": 513, "line": "                UNION ALL\n"}, {"line_no": 15, "char_start": 513, "char_end": 622, "line": "                SELECT * FROM mudb.phrases WHERE phrase = \"%(phrase)s\" and input_phrase = \"%(input_phrase)s\"\n"}, {"line_no": 16, "char_start": 622, "char_end": 735, "line": "                ORDER BY user_freq DESC, freq DESC, id ASC;''' %{'phrase': phrase, 'input_phrase': input_phrase}\n"}, {"line_no": 17, "char_start": 735, "char_end": 787, "line": "        result = self.db.execute(sqlstr).fetchall()\n"}], "added": [{"line_no": 13, "char_start": 375, "char_end": 413, "line": "        SELECT * FROM user_db.phrases\n"}, {"line_no": 14, "char_start": 413, "char_end": 477, "line": "        WHERE phrase = :phrase AND input_phrase = :input_phrase\n"}, {"line_no": 15, "char_start": 477, "char_end": 495, "line": "        UNION ALL\n"}, {"line_no": 16, "char_start": 495, "char_end": 530, "line": "        SELECT * FROM mudb.phrases\n"}, {"line_no": 17, "char_start": 530, "char_end": 594, "line": "        WHERE phrase = :phrase AND input_phrase = :input_phrase\n"}, {"line_no": 18, "char_start": 594, "char_end": 645, "line": "        ORDER BY user_freq DESC, freq DESC, id ASC\n"}, {"line_no": 19, "char_start": 645, "char_end": 658, "line": "        ;'''\n"}, {"line_no": 20, "char_start": 658, "char_end": 725, "line": "        sqlargs = {'phrase': phrase, 'input_phrase': input_phrase}\n"}, {"line_no": 21, "char_start": 725, "char_end": 786, "line": "        result = self.db.execute(sqlstr, sqlargs).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 375, "char_end": 383, "chars": "        "}, {"char_start": 436, "char_end": 439, "chars": "\"%("}, {"char_start": 445, "char_end": 452, "chars": ")s\" and"}, {"char_start": 468, "char_end": 471, "chars": "\"%("}, {"char_start": 483, "char_end": 491, "chars": ")s\"\n    "}, {"char_start": 499, "char_end": 503, "chars": "    "}, {"char_start": 521, "char_end": 525, "chars": "    "}, {"char_start": 525, "char_end": 529, "chars": "    "}, {"char_start": 571, "char_end": 574, "chars": "\"%("}, {"char_start": 580, "char_end": 587, "chars": ")s\" and"}, {"char_start": 603, "char_end": 606, "chars": "\"%("}, {"char_start": 618, "char_end": 630, "chars": ")s\"\n        "}, {"char_start": 680, "char_end": 686, "chars": ";''' %"}], "added": [{"char_start": 412, "char_end": 420, "chars": "\n       "}, {"char_start": 436, "char_end": 437, "chars": ":"}, {"char_start": 443, "char_end": 447, "chars": " AND"}, {"char_start": 463, "char_end": 464, "chars": ":"}, {"char_start": 476, "char_end": 477, "chars": "\n"}, {"char_start": 529, "char_end": 537, "chars": "\n       "}, {"char_start": 553, "char_end": 554, "chars": ":"}, {"char_start": 560, "char_end": 564, "chars": " AND"}, {"char_start": 580, "char_end": 581, "chars": ":"}, {"char_start": 593, "char_end": 594, "chars": "\n"}, {"char_start": 644, "char_end": 676, "chars": "\n        ;'''\n        sqlargs = "}, {"char_start": 764, "char_end": 773, "chars": ", sqlargs"}]}, "commit_link": "github.com/mike-fabian/ibus-typing-booster/commit/6aeb0840b637750f5ca00b83ff3b824666703fb2", "file_name": "ibus-typing-booster/engine/tabsqlitedb.py", "vul_type": "cwe-089"}
{"func_name": "get_tweets", "func_src_before": "def get_tweets(keywords):\n    select_tweets = \"\"\"SELECT interactions.usr, interactions.other_usr, tweets.text\n                       FROM interactions\n                       INNER JOIN tweets\n                       ON tweets.twid = interactions.twid\n                       WHERE tweets.text LIKE '%{}%' \"\"\" + \"AND tweets.text LIKE '%{}%' \" * (len(keywords) - 1)\n    select_tweets = select_tweets.format(*keywords)\n    cursor = connection.cursor()\n    cursor.execute(select_tweets)\n    fetched = [None]\n    output = []\n    while len(fetched) > 0:\n        fetched = cursor.fetchall()\n        output.extend(fetched)\n    return output", "func_src_after": "def get_tweets(keywords):\n    select_tweets = \"\"\"SELECT interactions.usr, interactions.other_usr, tweets.text\n                       FROM interactions\n                       INNER JOIN tweets\n                       ON tweets.twid = interactions.twid\n                       WHERE tweets.text LIKE %s \"\"\" + \"AND tweets.text LIKE %s' \" * (len(keywords) - 1)\n    cursor = connection.cursor()\n    cursor.execute(select_tweets, ['%'+i+'%' for i in keywords])\n    fetched = [None]\n    output = []\n    while len(fetched) > 0:\n        fetched = cursor.fetchall()\n        output.extend(fetched)\n    return output", "line_changes": {"deleted": [{"line_no": 6, "char_start": 250, "char_end": 362, "line": "                       WHERE tweets.text LIKE '%{}%' \"\"\" + \"AND tweets.text LIKE '%{}%' \" * (len(keywords) - 1)\n"}, {"line_no": 7, "char_start": 362, "char_end": 414, "line": "    select_tweets = select_tweets.format(*keywords)\n"}, {"line_no": 9, "char_start": 447, "char_end": 481, "line": "    cursor.execute(select_tweets)\n"}], "added": [{"line_no": 6, "char_start": 250, "char_end": 355, "line": "                       WHERE tweets.text LIKE %s \"\"\" + \"AND tweets.text LIKE %s' \" * (len(keywords) - 1)\n"}, {"line_no": 8, "char_start": 388, "char_end": 453, "line": "    cursor.execute(select_tweets, ['%'+i+'%' for i in keywords])\n"}]}, "char_changes": {"deleted": [{"char_start": 296, "char_end": 302, "chars": "'%{}%'"}, {"char_start": 331, "char_end": 335, "chars": "'%{}"}, {"char_start": 362, "char_end": 414, "chars": "    select_tweets = select_tweets.format(*keywords)\n"}], "added": [{"char_start": 296, "char_end": 298, "chars": "%s"}, {"char_start": 328, "char_end": 329, "chars": "s"}, {"char_start": 420, "char_end": 451, "chars": ", ['%'+i+'%' for i in keywords]"}]}, "commit_link": "github.com/shashvatshukla/visualising-political-shills/commit/2a51a99c958f508ad926febef5c3241ac95c5543", "file_name": "metrics/Network/network_metrics.py", "vul_type": "cwe-089"}
{"func_name": "tables", "func_src_before": "@app.route('/tables')\ndef tables():\n\treturn render_template('tables.html', User=User.query.all())", "func_src_after": "@app.route('/tables')\ndef tables():\n\treturn render_template('tables.html', User=User.query.filter_by(email='fuck@email.com'))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 36, "char_end": 97, "line": "\treturn render_template('tables.html', User=User.query.all())\n"}], "added": [{"line_no": 3, "char_start": 36, "char_end": 125, "line": "\treturn render_template('tables.html', User=User.query.filter_by(email='fuck@email.com'))\n"}]}, "char_changes": {"deleted": [{"char_start": 91, "char_end": 95, "chars": "all("}], "added": [{"char_start": 91, "char_end": 123, "chars": "filter_by(email='fuck@email.com'"}]}, "commit_link": "github.com/spencerneveux/Maeve-s-Escape/commit/5ae0def44d06dcbac4307813fb17170d3bdbb430", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "login", "func_src_before": "@app.route('/login', methods=['GET', 'POST'])\ndef login():\n\tif request.method == 'POST':\n\t\tuser = User(request.form['email'], request.form['password'])\n\t\tdb.session.add(user)\n\t\tdb.session.commit()\n\t\treturn redirect(url_for('tables'))\n\treturn render_template('login.html')", "func_src_after": "@app.route('/login', methods=['GET', 'POST'])\ndef login():\n\tif request.method == 'POST':\n\t\tusername = request.form['name']\n\t\tpassword = request.form['password']\n\t\tvulnerability_list = [\"' or 1=1--\", \"' or 1=1#\", \"' or 1-1/*\"]\n\t\tif password in vulnerability_list:\n\t\t\tpassword = 'clementine'\n\t\treturn render_template('tables.html', User=User.query.filter_by(password=password))\n\treturn render_template('login.html')", "line_changes": {"deleted": [{"line_no": 4, "char_start": 89, "char_end": 152, "line": "\t\tuser = User(request.form['email'], request.form['password'])\n"}, {"line_no": 5, "char_start": 152, "char_end": 175, "line": "\t\tdb.session.add(user)\n"}, {"line_no": 6, "char_start": 175, "char_end": 197, "line": "\t\tdb.session.commit()\n"}, {"line_no": 7, "char_start": 197, "char_end": 234, "line": "\t\treturn redirect(url_for('tables'))\n"}], "added": [{"line_no": 4, "char_start": 89, "char_end": 123, "line": "\t\tusername = request.form['name']\n"}, {"line_no": 5, "char_start": 123, "char_end": 161, "line": "\t\tpassword = request.form['password']\n"}, {"line_no": 6, "char_start": 161, "char_end": 226, "line": "\t\tvulnerability_list = [\"' or 1=1--\", \"' or 1=1#\", \"' or 1-1/*\"]\n"}, {"line_no": 7, "char_start": 226, "char_end": 263, "line": "\t\tif password in vulnerability_list:\n"}, {"line_no": 8, "char_start": 263, "char_end": 290, "line": "\t\t\tpassword = 'clementine'\n"}, {"line_no": 9, "char_start": 290, "char_end": 376, "line": "\t\treturn render_template('tables.html', User=User.query.filter_by(password=password))\n"}]}, "char_changes": {"deleted": [{"char_start": 95, "char_end": 103, "chars": " = User("}, {"char_start": 117, "char_end": 125, "chars": "email'],"}, {"char_start": 150, "char_end": 151, "chars": ")"}, {"char_start": 154, "char_end": 231, "chars": "db.session.add(user)\n\t\tdb.session.commit()\n\t\treturn redirect(url_for('tables'"}], "added": [{"char_start": 95, "char_end": 102, "chars": "name = "}, {"char_start": 116, "char_end": 135, "chars": "name']\n\t\tpassword ="}, {"char_start": 163, "char_end": 373, "chars": "vulnerability_list = [\"' or 1=1--\", \"' or 1=1#\", \"' or 1-1/*\"]\n\t\tif password in vulnerability_list:\n\t\t\tpassword = 'clementine'\n\t\treturn render_template('tables.html', User=User.query.filter_by(password=password"}]}, "commit_link": "github.com/spencerneveux/Maeve-s-Escape/commit/5ae0def44d06dcbac4307813fb17170d3bdbb430", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "login", "func_src_before": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute('SELECT * FROM users WHERE name = \\'{}\\' AND password = \\'{}\\';'.format(user, password))\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "func_src_after": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute(\"SELECT * FROM users WHERE name = ? AND password = ?;\", [user, password])\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "line_changes": {"deleted": [{"line_no": 6, "char_start": 152, "char_end": 257, "line": "    cur.execute('SELECT * FROM users WHERE name = \\'{}\\' AND password = \\'{}\\';'.format(user, password))\n"}], "added": [{"line_no": 6, "char_start": 152, "char_end": 242, "line": "    cur.execute(\"SELECT * FROM users WHERE name = ? AND password = ?;\", [user, password])\n"}]}, "char_changes": {"deleted": [{"char_start": 168, "char_end": 169, "chars": "'"}, {"char_start": 202, "char_end": 208, "chars": "\\'{}\\'"}, {"char_start": 224, "char_end": 240, "chars": "\\'{}\\';'.format("}, {"char_start": 254, "char_end": 255, "chars": ")"}], "added": [{"char_start": 168, "char_end": 169, "chars": "\""}, {"char_start": 202, "char_end": 203, "chars": "?"}, {"char_start": 219, "char_end": 225, "chars": "?;\", ["}, {"char_start": 239, "char_end": 240, "chars": "]"}]}, "commit_link": "github.com/ChemiKyle/Waterspots/commit/3f9d5099496336f3f34c48abf0cf55acaaa29011", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "autocomplete", "func_src_before": "@locations.route(\"/autocomplete\", methods=[\"GET\"])\n@require_apikey\ndef autocomplete():\n    # TODO: Have fancier queries. For now, we will just take advantage of regex, which functions as a \"contains\"\n    # TODO: Since we can't let pymysql put quotes for us (we need the %'s in between to have regex), we have to do\n    # a direct format. This is a SQL injection vulnerability.\n    # First, get relevant cities.\n\n    conn = mysql.get_db()\n    location_objects = []\n    city_cur = conn.cursor()\n    city_cur.execute(\"SELECT cities.name, id AS city_id, region_id, country_id FROM cities WHERE cities.name REGEXP %s LIMIT 100\"\n                     , (request.args[\"input_text\"],))\n    location_objects.extend(convert_objects(city_cur.fetchall(), city_cur.description))\n    if len(location_objects) == 100:  # If we already have 100 results, which is plenty, let's just return those.\n        return make_response(jsonify(location_objects), HTTPStatus.OK)\n    region_cur = conn.cursor()\n    region_cur.execute(\"SELECT regions.name, 'null' AS city_id, id AS region_id, country_id FROM regions WHERE regions.name REGEXP %s LIMIT 100\"\n                       , (request.args[\"input_text\"],))\n    location_objects.extend(convert_objects(region_cur.fetchall(), region_cur.description))\n    if len(location_objects) == 100:\n        return make_response(jsonify(location_objects), HTTPStatus.OK)\n    country_cur = conn.cursor()\n    country_cur.execute(\"SELECT countries.name, 'null' AS city_id, 'null' AS region_id, id AS country_id FROM countries WHERE countries.name REGEXP %s LIMIT 100\"\n                        , (request.args[\"input_text\"],))\n    location_objects.extend(convert_objects(country_cur.fetchall(), country_cur.description))\n    return make_response(jsonify(location_objects), HTTPStatus.OK)", "func_src_after": "@locations.route(\"/autocomplete\", methods=[\"GET\"])\n@require_apikey\ndef autocomplete():\n    # TODO: Have fancier queries. For now, we will just take advantage of regex, which functions as a \"contains\"\n    # TODO: Since we can't let pymysql put quotes for us (we need the %'s in between to have regex), we have to do\n    # a direct format. This is a SQL injection vulnerability.\n    # First, get relevant cities.\n\n    conn = mysql.get_db()\n    location_objects = []\n    city_cur = conn.cursor()\n    city_cur.execute(\"SELECT cities.name, id AS city_id, region_id, country_id FROM cities  \\\n                      WHERE cities.name REGEXP %s LIMIT 100\", (request.args[\"input_text\"],))\n    location_objects.extend(convert_objects(city_cur.fetchall(), city_cur.description))\n    city_cur.close()\n    if len(location_objects) == 100:  # If we already have 100 results, which is plenty, let's just return those.\n        return make_response(jsonify(location_objects), HTTPStatus.OK)\n    region_cur = conn.cursor()\n    region_cur.execute(\"SELECT regions.name, 'null' AS city_id, id AS region_id, country_id FROM regions \\\n                        WHERE regions.name REGEXP %s LIMIT 100\", (request.args[\"input_text\"],))\n    location_objects.extend(convert_objects(region_cur.fetchall(), region_cur.description))\n    region_cur.close()\n    if len(location_objects) == 100:\n        return make_response(jsonify(location_objects), HTTPStatus.OK)\n    country_cur = conn.cursor()\n    country_cur.execute(\"SELECT countries.name, 'null' AS city_id, 'null' AS region_id, id AS country_id FROM countries \\\n                        WHERE countries.name REGEXP %s LIMIT 100\", (request.args[\"input_text\"],))\n    location_objects.extend(convert_objects(country_cur.fetchall(), country_cur.description))\n    country_cur.close()\n    return make_response(jsonify(location_objects), HTTPStatus.OK)", "line_changes": {"deleted": [{"line_no": 12, "char_start": 493, "char_end": 623, "line": "    city_cur.execute(\"SELECT cities.name, id AS city_id, region_id, country_id FROM cities WHERE cities.name REGEXP %s LIMIT 100\"\n"}, {"line_no": 13, "char_start": 623, "char_end": 677, "line": "                     , (request.args[\"input_text\"],))\n"}, {"line_no": 18, "char_start": 981, "char_end": 1126, "line": "    region_cur.execute(\"SELECT regions.name, 'null' AS city_id, id AS region_id, country_id FROM regions WHERE regions.name REGEXP %s LIMIT 100\"\n"}, {"line_no": 19, "char_start": 1126, "char_end": 1182, "line": "                       , (request.args[\"input_text\"],))\n"}, {"line_no": 24, "char_start": 1414, "char_end": 1576, "line": "    country_cur.execute(\"SELECT countries.name, 'null' AS city_id, 'null' AS region_id, id AS country_id FROM countries WHERE countries.name REGEXP %s LIMIT 100\"\n"}, {"line_no": 25, "char_start": 1576, "char_end": 1633, "line": "                        , (request.args[\"input_text\"],))\n"}], "added": [{"line_no": 12, "char_start": 493, "char_end": 587, "line": "    city_cur.execute(\"SELECT cities.name, id AS city_id, region_id, country_id FROM cities  \\\n"}, {"line_no": 13, "char_start": 587, "char_end": 680, "line": "                      WHERE cities.name REGEXP %s LIMIT 100\", (request.args[\"input_text\"],))\n"}, {"line_no": 15, "char_start": 768, "char_end": 789, "line": "    city_cur.close()\n"}, {"line_no": 19, "char_start": 1005, "char_end": 1112, "line": "    region_cur.execute(\"SELECT regions.name, 'null' AS city_id, id AS region_id, country_id FROM regions \\\n"}, {"line_no": 20, "char_start": 1112, "char_end": 1208, "line": "                        WHERE regions.name REGEXP %s LIMIT 100\", (request.args[\"input_text\"],))\n"}, {"line_no": 22, "char_start": 1300, "char_end": 1323, "line": "    region_cur.close()\n"}, {"line_no": 26, "char_start": 1463, "char_end": 1585, "line": "    country_cur.execute(\"SELECT countries.name, 'null' AS city_id, 'null' AS region_id, id AS country_id FROM countries \\\n"}, {"line_no": 27, "char_start": 1585, "char_end": 1683, "line": "                        WHERE countries.name REGEXP %s LIMIT 100\", (request.args[\"input_text\"],))\n"}, {"line_no": 29, "char_start": 1777, "char_end": 1801, "line": "    country_cur.close()\n"}]}, "char_changes": {"deleted": [{"char_start": 622, "char_end": 644, "chars": "\n                     "}, {"char_start": 1125, "char_end": 1149, "chars": "\n                       "}, {"char_start": 1575, "char_end": 1600, "chars": "\n                        "}], "added": [{"char_start": 584, "char_end": 609, "chars": " \\\n                      "}, {"char_start": 768, "char_end": 789, "chars": "    city_cur.close()\n"}, {"char_start": 1110, "char_end": 1136, "chars": "\\\n                        "}, {"char_start": 1300, "char_end": 1323, "chars": "    region_cur.close()\n"}, {"char_start": 1583, "char_end": 1609, "chars": "\\\n                        "}, {"char_start": 1777, "char_end": 1801, "chars": "    country_cur.close()\n"}]}, "commit_link": "github.com/codethechange/culturemesh-api/commit/bb279820045f9c61af16c9f65be17ca5e09cb7cc", "file_name": "api/blueprints/locations/controllers.py", "vul_type": "cwe-089"}
{"func_name": "addToDatabase", "func_src_before": "def addToDatabase(submissionList):\n\n    # Measure time\n    startTime = datetime.now()\n\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n\n    #reddit = getRedditInstance()\n\n    botUsername = getBotUsername()\n\n    # Get top level comments from submissions and get their first numbers with regex\n    for submission in reversed(list(submissionList)):\n        scoresInChallenge = [[-1, ''], [-2, ''], [-3, ''], [-4, '']] \n        for topLevelComment in submission.comments:\n\n            # Looks for !TrackThisSeries and !StopTracking posts and replies to them\n            try:\n                if topLevelComment.author.name == submission.author.name:\n                    alreadyReplied = False\n                    if '!trackthisseries' in topLevelComment.body.lower():\n                        print(\"Found track request: \" + str(submission.id))\n                        # Write new entries to the local database\n                        cursor.execute(\"INSERT OR REPLACE INTO SeriesTracking VALUES ('\" + getTitle(submission) + \"', '\" + getDate(submission) + \"')\")\n                        \n                        for reply in topLevelComment.replies:\n                            if reply.author.name == botUsername:\n                                alreadyReplied = True\n                                #cursor.execute(\"INSERT OR REPLACE INTO TrackingRequests VALUES ('\" + str(topLevelComment.fullname) + \"')\")\n\n                        #if cursor.execute(\"SELECT COUNT(*) FROM TrackingRequests WHERE CommentID = '\" + str(topLevelComment.fullname) + \"'\").fetchone()[0] == 0:\n                        if not alreadyReplied:\n                            replyToTrackRequest(topLevelComment, True)\n                    if '!stoptracking' in topLevelComment.body.lower():\n                        print(\"Found stop tracking request: \" + str(submission.id))\n                        # Delete old entries in the database\n                        cursor.execute(\"DELETE FROM SeriesTracking WHERE SeriesTitle = '\" + getTitle(submission) + \"'\")\n                        \n                        for reply in topLevelComment.replies:\n                            if reply.author.name == botUsername:\n                                alreadyReplied = True\n                                #cursor.execute(\"INSERT OR REPLACE INTO TrackingRequests VALUES ('\" + str(topLevelComment.fullname) + \"')\")\n\n                        #if cursor.execute(\"SELECT COUNT(*) FROM TrackingRequests WHERE CommentID = '\" + str(topLevelComment.fullname) + \"'\").fetchone()[0] == 0:\n                        if not alreadyReplied:\n                            replyToTrackRequest(topLevelComment, False)\n            except AttributeError:\n                pass\n\n            # Avoid comments which do not post their own score; Get the highest number in each comment and add it to the list with the user's username\n            if 'Previous win:' not in topLevelComment.body and 'for winning' not in topLevelComment.body and 'for tying' not in topLevelComment.body and '|' not in topLevelComment.body and topLevelComment is not None and topLevelComment.author is not None:\n                try:\n                    number = max([int(number.replace(',', '')) for number in re.findall('(?<!round )(?<!~~)(?<!\\w)\\d+\\,?\\d+', topLevelComment.body)])\n                except (IndexError, ValueError) as e:\n                    number = -1\n                    break\n                if 0 <= number <= 32395:\n                    scoresInChallenge.append([int(number), topLevelComment.author.name])\n        scoresInChallenge.sort(key = operator.itemgetter(0), reverse = True)\n\n        # If two players have the same score add the second one to the authors of the first challenge with a pipe character inbetween\n        for i in range(0, 3):\n            while scoresInChallenge[i][0] == scoresInChallenge[i + 1][0]:\n                scoresInChallenge[i][1] += \"|\" + scoresInChallenge[i + 1][1]\n                del scoresInChallenge[i + 1]\n        #print(index)\n        #print(getTitle(submission.title))\n        #print(submission.id)\n        #print(scoresInChallenge[0][1])\n        #print(scoresInChallenge[1][1])\n        #print(scoresInChallenge[2][1])\n        #print(submission.created)\n\n        # Write new entries to the local database\n        record = (str(submission.id), getTitle(submission), str(scoresInChallenge[0][1]), str(scoresInChallenge[1][1]), str(scoresInChallenge[2][1]), getDate(submission))\n        cursor.execute(\"INSERT OR REPLACE INTO ChallengeRankings VALUES (?, ?, ?, ?, ?, ?)\", record)\n\n        #if cursor.execute(\"SELECT COUNT(*) FROM ChallengeRankings WHERE SubmissionID = '\" + submission.id + \"'\").fetchone()[0] == 0:\n        #    cursor.execute(\"INSERT INTO ChallengeRankings VALUES (?, ?, ?, ?, ?, ?)\", record)\n        # Update existing entries in the local database\n        #else:\n        #    cursor.execute(\"UPDATE ChallengeRankings SET Place1 = '\" + str(scoresInChallenge[0][1]) + \"', Place2 = '\" + str(scoresInChallenge[1][1]) + \"', Place3 = '\" + str(scoresInChallenge[2][1]) + \"' WHERE SubmissionID = '\" + str(submission.id) + \"'\")\n\n    database.commit()\n    database.close()", "func_src_after": "def addToDatabase(submissionList):\n\n    # Measure time\n    startTime = datetime.now()\n\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n\n    #reddit = getRedditInstance()\n\n    botUsername = getBotUsername()\n\n    # Get top level comments from submissions and get their first numbers with regex\n    for submission in reversed(list(submissionList)):\n        scoresInChallenge = [[-1, ''], [-2, ''], [-3, ''], [-4, '']] \n        for topLevelComment in submission.comments:\n\n            # Looks for !TrackThisSeries and !StopTracking posts and replies to them\n            try:\n                if topLevelComment.author.name == submission.author.name:\n                    alreadyReplied = False\n                    if '!trackthisseries' in topLevelComment.body.lower():\n                        print(\"Found track request: \" + str(submission.id))\n                        # Write new entries to the local database\n                        cursor.execute(\"INSERT OR REPLACE INTO SeriesTracking VALUES (?, ?)\", [getTitle(submission), getDate(submission)])\n                        \n                        for reply in topLevelComment.replies:\n                            if reply.author.name == botUsername:\n                                alreadyReplied = True\n                                #cursor.execute(\"INSERT OR REPLACE INTO TrackingRequests VALUES ('\" + str(topLevelComment.fullname) + \"')\")\n\n                        #if cursor.execute(\"SELECT COUNT(*) FROM TrackingRequests WHERE CommentID = '\" + str(topLevelComment.fullname) + \"'\").fetchone()[0] == 0:\n                        if not alreadyReplied:\n                            replyToTrackRequest(topLevelComment, True)\n                    if '!stoptracking' in topLevelComment.body.lower():\n                        print(\"Found stop tracking request: \" + str(submission.id))\n                        # Delete old entries in the database\n                        cursor.execute(\"DELETE FROM SeriesTracking WHERE SeriesTitle = ?\", [getTitle(submission)])\n                        \n                        for reply in topLevelComment.replies:\n                            if reply.author.name == botUsername:\n                                alreadyReplied = True\n                                #cursor.execute(\"INSERT OR REPLACE INTO TrackingRequests VALUES ('\" + str(topLevelComment.fullname) + \"')\")\n\n                        #if cursor.execute(\"SELECT COUNT(*) FROM TrackingRequests WHERE CommentID = '\" + str(topLevelComment.fullname) + \"'\").fetchone()[0] == 0:\n                        if not alreadyReplied:\n                            replyToTrackRequest(topLevelComment, False)\n            except AttributeError:\n                pass\n\n            # Avoid comments which do not post their own score; Get the highest number in each comment and add it to the list with the user's username\n            if 'Previous win:' not in topLevelComment.body and 'for winning' not in topLevelComment.body and 'for tying' not in topLevelComment.body and '|' not in topLevelComment.body and topLevelComment is not None and topLevelComment.author is not None:\n                try:\n                    number = max([int(number.replace(',', '')) for number in re.findall('(?<!round )(?<!~~)(?<!\\w)\\d+\\,?\\d+', topLevelComment.body)])\n                except (IndexError, ValueError) as e:\n                    number = -1\n                    break\n                if 0 <= number <= 32395:\n                    scoresInChallenge.append([int(number), topLevelComment.author.name])\n        scoresInChallenge.sort(key = operator.itemgetter(0), reverse = True)\n\n        # If two players have the same score add the second one to the authors of the first challenge with a pipe character inbetween\n        for i in range(0, 3):\n            while scoresInChallenge[i][0] == scoresInChallenge[i + 1][0]:\n                scoresInChallenge[i][1] += \"|\" + scoresInChallenge[i + 1][1]\n                del scoresInChallenge[i + 1]\n        #print(index)\n        #print(getTitle(submission.title))\n        #print(submission.id)\n        #print(scoresInChallenge[0][1])\n        #print(scoresInChallenge[1][1])\n        #print(scoresInChallenge[2][1])\n        #print(submission.created)\n\n        # Write new entries to the local database\n        if getTitle(submission) != '':\n            record = (str(submission.id), getTitle(submission), str(scoresInChallenge[0][1]), str(scoresInChallenge[1][1]), str(scoresInChallenge[2][1]), getDate(submission))\n            cursor.execute(\"INSERT OR REPLACE INTO ChallengeRankings VALUES (?, ?, ?, ?, ?, ?)\", record)\n\n        #if cursor.execute(\"SELECT COUNT(*) FROM ChallengeRankings WHERE SubmissionID = '\" + submission.id + \"'\").fetchone()[0] == 0:\n        #    cursor.execute(\"INSERT INTO ChallengeRankings VALUES (?, ?, ?, ?, ?, ?)\", record)\n        # Update existing entries in the local database\n        #else:\n        #    cursor.execute(\"UPDATE ChallengeRankings SET Place1 = '\" + str(scoresInChallenge[0][1]) + \"', Place2 = '\" + str(scoresInChallenge[1][1]) + \"', Place3 = '\" + str(scoresInChallenge[2][1]) + \"' WHERE SubmissionID = '\" + str(submission.id) + \"'\")\n\n    database.commit()\n    database.close()", "line_changes": {"deleted": [{"line_no": 25, "char_start": 934, "char_end": 1085, "line": "                        cursor.execute(\"INSERT OR REPLACE INTO SeriesTracking VALUES ('\" + getTitle(submission) + \"', '\" + getDate(submission) + \"')\")\n"}, {"line_no": 38, "char_start": 1929, "char_end": 2049, "line": "                        cursor.execute(\"DELETE FROM SeriesTracking WHERE SeriesTitle = '\" + getTitle(submission) + \"'\")\n"}, {"line_no": 76, "char_start": 4294, "char_end": 4465, "line": "        record = (str(submission.id), getTitle(submission), str(scoresInChallenge[0][1]), str(scoresInChallenge[1][1]), str(scoresInChallenge[2][1]), getDate(submission))\n"}, {"line_no": 77, "char_start": 4465, "char_end": 4566, "line": "        cursor.execute(\"INSERT OR REPLACE INTO ChallengeRankings VALUES (?, ?, ?, ?, ?, ?)\", record)\n"}], "added": [{"line_no": 25, "char_start": 934, "char_end": 1073, "line": "                        cursor.execute(\"INSERT OR REPLACE INTO SeriesTracking VALUES (?, ?)\", [getTitle(submission), getDate(submission)])\n"}, {"line_no": 38, "char_start": 1917, "char_end": 2032, "line": "                        cursor.execute(\"DELETE FROM SeriesTracking WHERE SeriesTitle = ?\", [getTitle(submission)])\n"}, {"line_no": 76, "char_start": 4277, "char_end": 4316, "line": "        if getTitle(submission) != '':\n"}, {"line_no": 77, "char_start": 4316, "char_end": 4491, "line": "            record = (str(submission.id), getTitle(submission), str(scoresInChallenge[0][1]), str(scoresInChallenge[1][1]), str(scoresInChallenge[2][1]), getDate(submission))\n"}, {"line_no": 78, "char_start": 4491, "char_end": 4596, "line": "            cursor.execute(\"INSERT OR REPLACE INTO ChallengeRankings VALUES (?, ?, ?, ?, ?, ?)\", record)\n"}]}, "char_changes": {"deleted": [{"char_start": 1020, "char_end": 1025, "chars": "'\" + "}, {"char_start": 1045, "char_end": 1056, "chars": " + \"', '\" +"}, {"char_start": 1076, "char_end": 1083, "chars": " + \"')\""}, {"char_start": 2016, "char_end": 2021, "chars": "'\" + "}, {"char_start": 2041, "char_end": 2047, "chars": " + \"'\""}], "added": [{"char_start": 1020, "char_end": 1029, "chars": "?, ?)\", ["}, {"char_start": 1049, "char_end": 1050, "chars": ","}, {"char_start": 1070, "char_end": 1071, "chars": "]"}, {"char_start": 2004, "char_end": 2009, "chars": "?\", ["}, {"char_start": 2029, "char_end": 2030, "chars": "]"}, {"char_start": 4277, "char_end": 4320, "chars": "        if getTitle(submission) != '':\n    "}, {"char_start": 4491, "char_end": 4495, "chars": "    "}]}, "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "AddScoresToDatabase.py", "vul_type": "cwe-089"}
{"func_name": "checkForSeriesSubmissions", "func_src_before": "def checkForSeriesSubmissions(submissionList):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n\n    botUsername = getBotUsername()\n\n    for submission in submissionList:\n        if cursor.execute(\"SELECT COUNT(*) FROM SeriesTracking WHERE SeriesTitle = '\" + str(getTitle(submission)) + \"'\").fetchone()[0] != 0:\n            alreadyPosted = False\n            for reply in submission.comments:\n                try:\n                    if reply.author.name == botUsername:\n                        alreadyPosted = True\n                except AttributeError:\n                    pass\n            if not alreadyPosted and getSeriesDateFromDatabase(submission) <= getSubmissionDateFromDatabase(submission):\n                print(\"Replying to submission: \" + str(submission.id) + \" in series: \" + str(getTitle(submission)))\n                replyTrackedStats(submission)\n\n    database.close()", "func_src_after": "def checkForSeriesSubmissions(submissionList):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n\n    botUsername = getBotUsername()\n\n    for submission in submissionList:\n        if cursor.execute(\"SELECT COUNT(*) FROM SeriesTracking WHERE SeriesTitle = ?\", [getTitle(submission)]).fetchone()[0] != 0:\n            alreadyPosted = False\n            for reply in submission.comments:\n                try:\n                    if reply.author.name == botUsername:\n                        alreadyPosted = True\n                except AttributeError:\n                    pass\n            if not alreadyPosted and getSeriesDateFromDatabase(submission) <= getSubmissionDateFromDatabase(submission):\n                print(\"Replying to submission: %s in series: %s\" [str(submission.id), getTitle(submission)])\n                replyTrackedStats(submission)\n\n    reddit = getRedditInstance()\n    replyTrackedStats(reddit.submission(id = '6qhald'))\n\n    database.close()", "line_changes": {"deleted": [{"line_no": 8, "char_start": 199, "char_end": 340, "line": "        if cursor.execute(\"SELECT COUNT(*) FROM SeriesTracking WHERE SeriesTitle = '\" + str(getTitle(submission)) + \"'\").fetchone()[0] != 0:\n"}, {"line_no": 17, "char_start": 728, "char_end": 844, "line": "                print(\"Replying to submission: \" + str(submission.id) + \" in series: \" + str(getTitle(submission)))\n"}], "added": [{"line_no": 8, "char_start": 199, "char_end": 330, "line": "        if cursor.execute(\"SELECT COUNT(*) FROM SeriesTracking WHERE SeriesTitle = ?\", [getTitle(submission)]).fetchone()[0] != 0:\n"}, {"line_no": 17, "char_start": 718, "char_end": 827, "line": "                print(\"Replying to submission: %s in series: %s\" [str(submission.id), getTitle(submission)])\n"}, {"line_no": 20, "char_start": 874, "char_end": 907, "line": "    reddit = getRedditInstance()\n"}, {"line_no": 21, "char_start": 907, "char_end": 963, "line": "    replyTrackedStats(reddit.submission(id = '6qhald'))\n"}, {"line_no": 22, "char_start": 963, "char_end": 964, "line": "\n"}]}, "char_changes": {"deleted": [{"char_start": 282, "char_end": 291, "chars": "'\" + str("}, {"char_start": 311, "char_end": 318, "chars": ") + \"'\""}, {"char_start": 775, "char_end": 821, "chars": "\" + str(submission.id) + \" in series: \" + str("}, {"char_start": 841, "char_end": 842, "chars": ")"}], "added": [{"char_start": 282, "char_end": 287, "chars": "?\", ["}, {"char_start": 307, "char_end": 308, "chars": "]"}, {"char_start": 765, "char_end": 804, "chars": "%s in series: %s\" [str(submission.id), "}, {"char_start": 824, "char_end": 825, "chars": "]"}, {"char_start": 874, "char_end": 964, "chars": "    reddit = getRedditInstance()\n    replyTrackedStats(reddit.submission(id = '6qhald'))\n\n"}]}, "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089"}
{"func_name": "getGameCountInSeriesSoFar", "func_src_before": "def getGameCountInSeriesSoFar(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT COUNT(*) FROM ChallengeRankings WHERE SeriesTitle = '\" + getTitle(submission) + \"' AND Date <= '\" + getSubmissionDateFromDatabase(submission) + \"'\").fetchone()[0]\n    database.close()", "func_src_after": "def getGameCountInSeriesSoFar(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT COUNT(*) FROM ChallengeRankings WHERE SeriesTitle = ? AND Date <= ?\", [getTitle(submission), getSubmissionDateFromDatabase(submission)]).fetchone()[0]\n    database.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 120, "char_end": 317, "line": "    return cursor.execute(\"SELECT COUNT(*) FROM ChallengeRankings WHERE SeriesTitle = '\" + getTitle(submission) + \"' AND Date <= '\" + getSubmissionDateFromDatabase(submission) + \"'\").fetchone()[0]\n"}], "added": [{"line_no": 4, "char_start": 120, "char_end": 305, "line": "    return cursor.execute(\"SELECT COUNT(*) FROM ChallengeRankings WHERE SeriesTitle = ? AND Date <= ?\", [getTitle(submission), getSubmissionDateFromDatabase(submission)]).fetchone()[0]\n"}]}, "char_changes": {"deleted": [{"char_start": 206, "char_end": 211, "chars": "'\" + "}, {"char_start": 231, "char_end": 253, "chars": " + \"' AND Date <= '\" +"}, {"char_start": 295, "char_end": 301, "chars": " + \"'\""}], "added": [{"char_start": 206, "char_end": 225, "chars": "? AND Date <= ?\", ["}, {"char_start": 245, "char_end": 246, "chars": ","}, {"char_start": 288, "char_end": 289, "chars": "]"}]}, "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089"}
{"func_name": "getSeriesDateFromDatabase", "func_src_before": "def getSeriesDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = '\" + str(getTitle(submission)) + \"'\").fetchone()[0]\n    database.close()", "func_src_after": "def getSeriesDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = ?\", [getTitle(submission)]).fetchone()[0]\n    database.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 120, "char_end": 256, "line": "    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = '\" + str(getTitle(submission)) + \"'\").fetchone()[0]\n"}], "added": [{"line_no": 4, "char_start": 120, "char_end": 246, "line": "    return cursor.execute(\"SELECT StartDate FROM SeriesTracking WHERE SeriesTitle = ?\", [getTitle(submission)]).fetchone()[0]\n"}]}, "char_changes": {"deleted": [{"char_start": 204, "char_end": 213, "chars": "'\" + str("}, {"char_start": 233, "char_end": 240, "chars": ") + \"'\""}], "added": [{"char_start": 204, "char_end": 209, "chars": "?\", ["}, {"char_start": 229, "char_end": 230, "chars": "]"}]}, "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089"}
{"func_name": "getSubmissionDateFromDatabase", "func_src_before": "def getSubmissionDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT Date FROM ChallengeRankings WHERE SubmissionID = '\" + str(submission.id) + \"'\").fetchone()[0]\n    database.close()", "func_src_after": "def getSubmissionDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT Date FROM ChallengeRankings WHERE SubmissionID = ?\", [str(submission.id)]).fetchone()[0]\n    database.close()", "line_changes": {"deleted": [{"line_no": 4, "char_start": 124, "char_end": 252, "line": "    return cursor.execute(\"SELECT Date FROM ChallengeRankings WHERE SubmissionID = '\" + str(submission.id) + \"'\").fetchone()[0]\n"}], "added": [{"line_no": 4, "char_start": 124, "char_end": 247, "line": "    return cursor.execute(\"SELECT Date FROM ChallengeRankings WHERE SubmissionID = ?\", [str(submission.id)]).fetchone()[0]\n"}]}, "char_changes": {"deleted": [{"char_start": 207, "char_end": 212, "chars": "'\" + "}, {"char_start": 230, "char_end": 236, "chars": " + \"'\""}], "added": [{"char_start": 207, "char_end": 212, "chars": "?\", ["}, {"char_start": 230, "char_end": 231, "chars": "]"}]}, "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089"}
{"func_name": "getRankingsFromDatabase", "func_src_before": "def getRankingsFromDatabase(submission):\n    \n    # Connect to database\n    database = sqlite3.connect(\"database.db\")\n    cursor = database.cursor()\n\n    # Create a set with all the usernames in that series\n    nameSet = set()\n    for row in cursor.execute(\"SELECT Place1, Place2, Place3 FROM ChallengeRankings WHERE SeriesTitle = '\" + getTitle(submission) + \"' AND Date < '\" + str(getDate(submission)) + \"'\"):\n        for val in row:\n            if val is not '':\n                for author in val.split('|'):\n                    nameSet.add(author)\n                \n    nameList = [name for name in nameSet]\n\n    table = [[name, 0, 0, 0] for name in nameList]\n\n    # Iterate through every post in the series and increment the winners in the table\n    for i in range(1, 4):\n        for row in cursor.execute(\"SELECT Place\" + str(i) + \" FROM ChallengeRankings WHERE SeriesTitle = '\" + getTitle(submission) + \"' AND Date < '\" + str(getDate(submission)) + \"'\"):\n            for val in row:\n                if val is not '':\n                    for author in val.split('|'):\n                        table[nameList.index(author)][i] += 1\n\n    table.sort(reverse = True, key = operator.itemgetter(1, 2, 3))\n\n    database.close()\n\n    #print(table)\n    return table", "func_src_after": "def getRankingsFromDatabase(submission):\n    \n    # Connect to database\n    database = sqlite3.connect(\"database.db\")\n    cursor = database.cursor()\n\n    # Create a set with all the usernames in that series\n    nameSet = set()\n    for row in cursor.execute(\"SELECT Place1, Place2, Place3 FROM ChallengeRankings WHERE SeriesTitle = ? AND Date < ?\", [getTitle(submission), str(getDate(submission))]):\n        for val in row:\n            if val is not '':\n                for author in val.split('|'):\n                    nameSet.add(author)\n                \n    nameList = [name for name in nameSet]\n\n    table = [[name, 0, 0, 0] for name in nameList]\n\n    # Iterate through every post in the series and increment the winners in the table\n    for i in range(1, 4):\n        for row in cursor.execute(\"SELECT ? FROM ChallengeRankings WHERE SeriesTitle = ? AND Date < ?\", [\"Place\" + str(i), getTitle(submission), str(getDate(submission))]):\n            for val in row:\n                if val is not '':\n                    for author in val.split('|'):\n                        table[nameList.index(author)][i] += 1\n\n    table.sort(reverse = True, key = operator.itemgetter(1, 2, 3))\n\n    database.close()\n\n    #print(table)\n    return table", "line_changes": {"deleted": [{"line_no": 9, "char_start": 227, "char_end": 411, "line": "    for row in cursor.execute(\"SELECT Place1, Place2, Place3 FROM ChallengeRankings WHERE SeriesTitle = '\" + getTitle(submission) + \"' AND Date < '\" + str(getDate(submission)) + \"'\"):\n"}, {"line_no": 21, "char_start": 775, "char_end": 960, "line": "        for row in cursor.execute(\"SELECT Place\" + str(i) + \" FROM ChallengeRankings WHERE SeriesTitle = '\" + getTitle(submission) + \"' AND Date < '\" + str(getDate(submission)) + \"'\"):\n"}], "added": [{"line_no": 9, "char_start": 227, "char_end": 399, "line": "    for row in cursor.execute(\"SELECT Place1, Place2, Place3 FROM ChallengeRankings WHERE SeriesTitle = ? AND Date < ?\", [getTitle(submission), str(getDate(submission))]):\n"}, {"line_no": 21, "char_start": 763, "char_end": 936, "line": "        for row in cursor.execute(\"SELECT ? FROM ChallengeRankings WHERE SeriesTitle = ? AND Date < ?\", [\"Place\" + str(i), getTitle(submission), str(getDate(submission))]):\n"}]}, "char_changes": {"deleted": [{"char_start": 331, "char_end": 336, "chars": "'\" + "}, {"char_start": 356, "char_end": 377, "chars": " + \"' AND Date < '\" +"}, {"char_start": 402, "char_end": 408, "chars": " + \"'\""}, {"char_start": 817, "char_end": 836, "chars": "Place\" + str(i) + \""}, {"char_start": 880, "char_end": 926, "chars": "'\" + getTitle(submission) + \"' AND Date < '\" +"}, {"char_start": 951, "char_end": 957, "chars": " + \"'\""}], "added": [{"char_start": 331, "char_end": 349, "chars": "? AND Date < ?\", ["}, {"char_start": 369, "char_end": 370, "chars": ","}, {"char_start": 395, "char_end": 396, "chars": "]"}, {"char_start": 805, "char_end": 806, "chars": "?"}, {"char_start": 850, "char_end": 907, "chars": "? AND Date < ?\", [\"Place\" + str(i), getTitle(submission),"}, {"char_start": 932, "char_end": 933, "chars": "]"}]}, "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CreateTableFromDatabase.py", "vul_type": "cwe-089"}
{"func_name": "get_roster", "func_src_before": "    def get_roster(self, server_id):\n        sql = \"\"\"SELECT username, role\n                 FROM roles\n                 WHERE roles.server_id = {0};\n                 \"\"\".format(server_id)\n        self.cur.execute(sql)\n        return self.cur.fetchall()", "func_src_after": "    def get_roster(self, server_id):\n        sql = \"\"\"\n              SELECT username, role\n              FROM roles\n              WHERE roles.server_id = %s;\n              \"\"\"\n        self.cur.execute(sql, (server_id,))\n        return self.cur.fetchall()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 37, "char_end": 76, "line": "        sql = \"\"\"SELECT username, role\n"}, {"line_no": 3, "char_start": 76, "char_end": 104, "line": "                 FROM roles\n"}, {"line_no": 4, "char_start": 104, "char_end": 150, "line": "                 WHERE roles.server_id = {0};\n"}, {"line_no": 5, "char_start": 150, "char_end": 189, "line": "                 \"\"\".format(server_id)\n"}, {"line_no": 6, "char_start": 189, "char_end": 219, "line": "        self.cur.execute(sql)\n"}], "added": [{"line_no": 2, "char_start": 37, "char_end": 55, "line": "        sql = \"\"\"\n"}, {"line_no": 3, "char_start": 55, "char_end": 91, "line": "              SELECT username, role\n"}, {"line_no": 4, "char_start": 91, "char_end": 116, "line": "              FROM roles\n"}, {"line_no": 5, "char_start": 116, "char_end": 158, "line": "              WHERE roles.server_id = %s;\n"}, {"line_no": 6, "char_start": 158, "char_end": 176, "line": "              \"\"\"\n"}, {"line_no": 7, "char_start": 176, "char_end": 220, "line": "        self.cur.execute(sql, (server_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 90, "char_end": 91, "chars": " "}, {"char_start": 91, "char_end": 93, "chars": "  "}, {"char_start": 104, "char_end": 107, "chars": "   "}, {"char_start": 145, "char_end": 153, "chars": "{0};\n   "}, {"char_start": 170, "char_end": 188, "chars": ".format(server_id)"}], "added": [{"char_start": 54, "char_end": 69, "chars": "\n              "}, {"char_start": 154, "char_end": 158, "chars": "%s;\n"}, {"char_start": 204, "char_end": 218, "chars": ", (server_id,)"}]}, "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089"}
{"func_name": "update_roster", "func_src_before": "    def update_roster(self, username, role, server_id):\n        sql = []\n        sql.append(\"\"\"INSERT INTO users (username)\n                      VALUES ('{0}')\n                      ON DUPLICATE KEY UPDATE username = '{0}';\n                      \"\"\".format(username))\n        sql.append(\"\"\"INSERT INTO roles (username, server_id, role)\n                      VALUES ('{0}', '{1}', '{2}')\n                      ON DUPLICATE KEY UPDATE role = '{2}';\n                      \"\"\".format(username, server_id, role))\n        for query in sql:\n            self.cur.execute(query)\n        self.conn.commit()", "func_src_after": "    def update_roster(self, username, role, server_id):\n        sql1 = \"\"\"\n               INSERT INTO users (username)\n               VALUES (%s)\n               ON DUPLICATE KEY UPDATE username = %s;\n               \"\"\"\n        sql2 = \"\"\"\n               INSERT INTO roles (username, server_id, role)\n               VALUES (%s, %s, %s)\n               ON DUPLICATE KEY UPDATE role = %s;\n               \"\"\"\n        self.cur.execute(sql1, (username, username))\n        self.cur.execute(sql2, (username, server_id, role, role))\n        self.conn.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 56, "char_end": 73, "line": "        sql = []\n"}, {"line_no": 3, "char_start": 73, "char_end": 124, "line": "        sql.append(\"\"\"INSERT INTO users (username)\n"}, {"line_no": 4, "char_start": 124, "char_end": 161, "line": "                      VALUES ('{0}')\n"}, {"line_no": 5, "char_start": 161, "char_end": 225, "line": "                      ON DUPLICATE KEY UPDATE username = '{0}';\n"}, {"line_no": 6, "char_start": 225, "char_end": 269, "line": "                      \"\"\".format(username))\n"}, {"line_no": 7, "char_start": 269, "char_end": 337, "line": "        sql.append(\"\"\"INSERT INTO roles (username, server_id, role)\n"}, {"line_no": 8, "char_start": 337, "char_end": 388, "line": "                      VALUES ('{0}', '{1}', '{2}')\n"}, {"line_no": 9, "char_start": 388, "char_end": 448, "line": "                      ON DUPLICATE KEY UPDATE role = '{2}';\n"}, {"line_no": 10, "char_start": 448, "char_end": 509, "line": "                      \"\"\".format(username, server_id, role))\n"}, {"line_no": 11, "char_start": 509, "char_end": 535, "line": "        for query in sql:\n"}, {"line_no": 12, "char_start": 535, "char_end": 571, "line": "            self.cur.execute(query)\n"}], "added": [{"line_no": 2, "char_start": 56, "char_end": 75, "line": "        sql1 = \"\"\"\n"}, {"line_no": 3, "char_start": 75, "char_end": 119, "line": "               INSERT INTO users (username)\n"}, {"line_no": 4, "char_start": 119, "char_end": 146, "line": "               VALUES (%s)\n"}, {"line_no": 5, "char_start": 146, "char_end": 200, "line": "               ON DUPLICATE KEY UPDATE username = %s;\n"}, {"line_no": 6, "char_start": 200, "char_end": 219, "line": "               \"\"\"\n"}, {"line_no": 7, "char_start": 219, "char_end": 238, "line": "        sql2 = \"\"\"\n"}, {"line_no": 8, "char_start": 238, "char_end": 299, "line": "               INSERT INTO roles (username, server_id, role)\n"}, {"line_no": 9, "char_start": 299, "char_end": 334, "line": "               VALUES (%s, %s, %s)\n"}, {"line_no": 10, "char_start": 334, "char_end": 384, "line": "               ON DUPLICATE KEY UPDATE role = %s;\n"}, {"line_no": 11, "char_start": 384, "char_end": 403, "line": "               \"\"\"\n"}, {"line_no": 12, "char_start": 403, "char_end": 456, "line": "        self.cur.execute(sql1, (username, username))\n"}, {"line_no": 13, "char_start": 456, "char_end": 522, "line": "        self.cur.execute(sql2, (username, server_id, role, role))\n"}]}, "char_changes": {"deleted": [{"char_start": 70, "char_end": 73, "chars": "[]\n"}, {"char_start": 81, "char_end": 95, "chars": "sql.append(\"\"\""}, {"char_start": 139, "char_end": 145, "chars": "      "}, {"char_start": 145, "char_end": 146, "chars": " "}, {"char_start": 154, "char_end": 168, "chars": "'{0}')\n       "}, {"char_start": 218, "char_end": 223, "chars": "'{0}'"}, {"char_start": 247, "char_end": 291, "chars": "\"\"\".format(username))\n        sql.append(\"\"\""}, {"char_start": 352, "char_end": 359, "chars": "       "}, {"char_start": 367, "char_end": 395, "chars": "'{0}', '{1}', '{2}')\n       "}, {"char_start": 441, "char_end": 446, "chars": "'{2}'"}, {"char_start": 470, "char_end": 480, "chars": "\"\"\".format"}, {"char_start": 494, "char_end": 505, "chars": "ver_id, rol"}, {"char_start": 517, "char_end": 569, "chars": "for query in sql:\n            self.cur.execute(query"}], "added": [{"char_start": 67, "char_end": 68, "chars": "1"}, {"char_start": 71, "char_end": 74, "chars": "\"\"\""}, {"char_start": 83, "char_end": 90, "chars": "       "}, {"char_start": 142, "char_end": 146, "chars": "%s)\n"}, {"char_start": 196, "char_end": 198, "chars": "%s"}, {"char_start": 215, "char_end": 219, "chars": "\"\"\"\n"}, {"char_start": 226, "char_end": 253, "chars": " sql2 = \"\"\"\n               "}, {"char_start": 322, "char_end": 334, "chars": "%s, %s, %s)\n"}, {"char_start": 380, "char_end": 382, "chars": "%s"}, {"char_start": 399, "char_end": 403, "chars": "\"\"\"\n"}, {"char_start": 410, "char_end": 434, "chars": " self.cur.execute(sql1, "}, {"char_start": 445, "char_end": 446, "chars": "u"}, {"char_start": 449, "char_end": 452, "chars": "nam"}, {"char_start": 464, "char_end": 520, "chars": "self.cur.execute(sql2, (username, server_id, role, role)"}]}, "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089"}
{"func_name": "create_event", "func_src_before": "    def create_event(self, title, start_time, time_zone, server_id, description):\n        sql = \"\"\"INSERT INTO events (title, start_time, time_zone, server_id, description)\n                 VALUES ('{0}', '{1}', '{2}', '{3}', '{4}')\n                 \"\"\".format(title, start_time, time_zone, server_id, description)\n        self.cur.execute(sql)\n        self.conn.commit()", "func_src_after": "    def create_event(self, title, start_time, time_zone, server_id, description):\n        sql = \"\"\"\n              INSERT INTO events (title, start_time, time_zone, server_id, description)\n              VALUES (%s, %s, %s, %s, %s)\n              \"\"\"\n        self.cur.execute(sql, (title, start_time, time_zone, server_id, description))\n        self.conn.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 82, "char_end": 173, "line": "        sql = \"\"\"INSERT INTO events (title, start_time, time_zone, server_id, description)\n"}, {"line_no": 3, "char_start": 173, "char_end": 233, "line": "                 VALUES ('{0}', '{1}', '{2}', '{3}', '{4}')\n"}, {"line_no": 4, "char_start": 233, "char_end": 315, "line": "                 \"\"\".format(title, start_time, time_zone, server_id, description)\n"}, {"line_no": 5, "char_start": 315, "char_end": 345, "line": "        self.cur.execute(sql)\n"}], "added": [{"line_no": 2, "char_start": 82, "char_end": 100, "line": "        sql = \"\"\"\n"}, {"line_no": 3, "char_start": 100, "char_end": 188, "line": "              INSERT INTO events (title, start_time, time_zone, server_id, description)\n"}, {"line_no": 4, "char_start": 188, "char_end": 230, "line": "              VALUES (%s, %s, %s, %s, %s)\n"}, {"line_no": 5, "char_start": 230, "char_end": 248, "line": "              \"\"\"\n"}, {"line_no": 6, "char_start": 248, "char_end": 334, "line": "        self.cur.execute(sql, (title, start_time, time_zone, server_id, description))\n"}]}, "char_changes": {"deleted": [{"char_start": 187, "char_end": 190, "chars": "   "}, {"char_start": 198, "char_end": 260, "chars": "'{0}', '{1}', '{2}', '{3}', '{4}')\n                 \"\"\".format"}, {"char_start": 314, "char_end": 343, "chars": "\n        self.cur.execute(sql"}], "added": [{"char_start": 99, "char_end": 114, "chars": "\n              "}, {"char_start": 210, "char_end": 278, "chars": "%s, %s, %s, %s, %s)\n              \"\"\"\n        self.cur.execute(sql, "}]}, "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089"}
{"func_name": "get_events", "func_src_before": "    def get_events(self, server_id):\n        sql = \"\"\"SELECT events.event_id as e, title, description, start_time, time_zone, (\n                   SELECT GROUP_CONCAT(DISTINCT username)\n                   FROM user_event, events\n                   WHERE user_event.event_id = e\n                   AND events.server_id = {0}\n                   AND user_event.attending = 1)\n                   AS accepted, (\n                   SELECT GROUP_CONCAT(DISTINCT username)\n                   FROM user_event, events\n                   WHERE user_event.event_id = e\n                   AND events.server_id = {0}\n                   AND user_event.attending = 0)\n                   AS declined\n                 FROM events\n                 WHERE events.server_id = {0}\n                 GROUP BY event_id, title, description, start_time, time_zone;\n                 \"\"\".format(server_id)\n        self.cur.execute(sql)\n        return self.cur.fetchall()", "func_src_after": "    def get_events(self, server_id):\n        sql = \"\"\"\n              SELECT events.event_id as e, title, description, start_time, time_zone, (\n                SELECT GROUP_CONCAT(DISTINCT username)\n                FROM user_event, events\n                WHERE user_event.event_id = e\n                AND events.server_id = %s\n                AND user_event.attending = 1)\n                AS accepted, (\n                SELECT GROUP_CONCAT(DISTINCT username)\n                FROM user_event, events\n                WHERE user_event.event_id = e\n                AND events.server_id = %s\n                AND user_event.attending = 0)\n                AS declined\n              FROM events\n              WHERE events.server_id = %s\n              GROUP BY event_id, title, description, start_time, time_zone;\n              \"\"\"\n        self.cur.execute(sql, (server_id, server_id, server_id))\n        return self.cur.fetchall()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 37, "char_end": 128, "line": "        sql = \"\"\"SELECT events.event_id as e, title, description, start_time, time_zone, (\n"}, {"line_no": 3, "char_start": 128, "char_end": 186, "line": "                   SELECT GROUP_CONCAT(DISTINCT username)\n"}, {"line_no": 4, "char_start": 186, "char_end": 229, "line": "                   FROM user_event, events\n"}, {"line_no": 5, "char_start": 229, "char_end": 278, "line": "                   WHERE user_event.event_id = e\n"}, {"line_no": 6, "char_start": 278, "char_end": 324, "line": "                   AND events.server_id = {0}\n"}, {"line_no": 7, "char_start": 324, "char_end": 373, "line": "                   AND user_event.attending = 1)\n"}, {"line_no": 8, "char_start": 373, "char_end": 407, "line": "                   AS accepted, (\n"}, {"line_no": 9, "char_start": 407, "char_end": 465, "line": "                   SELECT GROUP_CONCAT(DISTINCT username)\n"}, {"line_no": 10, "char_start": 465, "char_end": 508, "line": "                   FROM user_event, events\n"}, {"line_no": 11, "char_start": 508, "char_end": 557, "line": "                   WHERE user_event.event_id = e\n"}, {"line_no": 12, "char_start": 557, "char_end": 603, "line": "                   AND events.server_id = {0}\n"}, {"line_no": 13, "char_start": 603, "char_end": 652, "line": "                   AND user_event.attending = 0)\n"}, {"line_no": 14, "char_start": 652, "char_end": 683, "line": "                   AS declined\n"}, {"line_no": 15, "char_start": 683, "char_end": 712, "line": "                 FROM events\n"}, {"line_no": 16, "char_start": 712, "char_end": 758, "line": "                 WHERE events.server_id = {0}\n"}, {"line_no": 17, "char_start": 758, "char_end": 837, "line": "                 GROUP BY event_id, title, description, start_time, time_zone;\n"}, {"line_no": 18, "char_start": 837, "char_end": 876, "line": "                 \"\"\".format(server_id)\n"}, {"line_no": 19, "char_start": 876, "char_end": 906, "line": "        self.cur.execute(sql)\n"}], "added": [{"line_no": 2, "char_start": 37, "char_end": 55, "line": "        sql = \"\"\"\n"}, {"line_no": 3, "char_start": 55, "char_end": 143, "line": "              SELECT events.event_id as e, title, description, start_time, time_zone, (\n"}, {"line_no": 4, "char_start": 143, "char_end": 198, "line": "                SELECT GROUP_CONCAT(DISTINCT username)\n"}, {"line_no": 5, "char_start": 198, "char_end": 238, "line": "                FROM user_event, events\n"}, {"line_no": 6, "char_start": 238, "char_end": 284, "line": "                WHERE user_event.event_id = e\n"}, {"line_no": 7, "char_start": 284, "char_end": 326, "line": "                AND events.server_id = %s\n"}, {"line_no": 8, "char_start": 326, "char_end": 372, "line": "                AND user_event.attending = 1)\n"}, {"line_no": 9, "char_start": 372, "char_end": 403, "line": "                AS accepted, (\n"}, {"line_no": 10, "char_start": 403, "char_end": 458, "line": "                SELECT GROUP_CONCAT(DISTINCT username)\n"}, {"line_no": 11, "char_start": 458, "char_end": 498, "line": "                FROM user_event, events\n"}, {"line_no": 12, "char_start": 498, "char_end": 544, "line": "                WHERE user_event.event_id = e\n"}, {"line_no": 13, "char_start": 544, "char_end": 586, "line": "                AND events.server_id = %s\n"}, {"line_no": 14, "char_start": 586, "char_end": 632, "line": "                AND user_event.attending = 0)\n"}, {"line_no": 15, "char_start": 632, "char_end": 660, "line": "                AS declined\n"}, {"line_no": 16, "char_start": 660, "char_end": 686, "line": "              FROM events\n"}, {"line_no": 17, "char_start": 686, "char_end": 728, "line": "              WHERE events.server_id = %s\n"}, {"line_no": 18, "char_start": 728, "char_end": 804, "line": "              GROUP BY event_id, title, description, start_time, time_zone;\n"}, {"line_no": 19, "char_start": 804, "char_end": 822, "line": "              \"\"\"\n"}, {"line_no": 20, "char_start": 822, "char_end": 887, "line": "        self.cur.execute(sql, (server_id, server_id, server_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 144, "char_end": 146, "chars": "  "}, {"char_start": 146, "char_end": 147, "chars": " "}, {"char_start": 186, "char_end": 189, "chars": "   "}, {"char_start": 245, "char_end": 248, "chars": "   "}, {"char_start": 294, "char_end": 295, "chars": " "}, {"char_start": 295, "char_end": 297, "chars": "  "}, {"char_start": 320, "char_end": 325, "chars": "{0}\n "}, {"char_start": 341, "char_end": 343, "chars": "  "}, {"char_start": 373, "char_end": 376, "chars": "   "}, {"char_start": 423, "char_end": 426, "chars": "   "}, {"char_start": 481, "char_end": 482, "chars": " "}, {"char_start": 482, "char_end": 484, "chars": "  "}, {"char_start": 508, "char_end": 511, "chars": "   "}, {"char_start": 557, "char_end": 560, "chars": "   "}, {"char_start": 599, "char_end": 606, "chars": "{0}\n   "}, {"char_start": 668, "char_end": 671, "chars": "   "}, {"char_start": 683, "char_end": 686, "chars": "   "}, {"char_start": 726, "char_end": 728, "chars": "  "}, {"char_start": 728, "char_end": 729, "chars": " "}, {"char_start": 754, "char_end": 761, "chars": "{0}\n   "}, {"char_start": 851, "char_end": 875, "chars": "   \"\"\".format(server_id)"}], "added": [{"char_start": 54, "char_end": 69, "chars": "\n              "}, {"char_start": 323, "char_end": 326, "chars": "%s\n"}, {"char_start": 583, "char_end": 586, "chars": "%s\n"}, {"char_start": 725, "char_end": 728, "chars": "%s\n"}, {"char_start": 818, "char_end": 821, "chars": "\"\"\""}, {"char_start": 850, "char_end": 885, "chars": ", (server_id, server_id, server_id)"}]}, "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089"}
{"func_name": "update_attendance", "func_src_before": "    def update_attendance(self, username, event_id, attending):\n        sql = []\n        sql.append(\"\"\"INSERT INTO users (username)\n                      VALUES ('{0}')\n                      ON DUPLICATE KEY UPDATE username = '{0}';\n                      \"\"\".format(username))\n        sql.append(\"\"\"INSERT INTO user_event (username, event_id, attending)\n                      VALUES ('{0}', '{1}', '{2}')\n                      ON DUPLICATE KEY UPDATE attending = '{2}';\n                      \"\"\".format(username, event_id, attending))\n        for query in sql:\n            self.cur.execute(query)\n        self.conn.commit()", "func_src_after": "    def update_attendance(self, username, event_id, attending):\n        sql1 = \"\"\"\n               INSERT INTO users (username)\n               VALUES (%s)\n               ON DUPLICATE KEY UPDATE username = %s;\n               \"\"\"\n        sql2 = \"\"\"\n               INSERT INTO user_event (username, event_id, attending)\n               VALUES (%s, %s, %s)\n               ON DUPLICATE KEY UPDATE attending = %s;\n               \"\"\"\n        self.cur.execute(sql1, (username, username))\n        self.cur.execute(sql2, (username, event_id, attending, attending))\n        self.conn.commit()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 64, "char_end": 81, "line": "        sql = []\n"}, {"line_no": 3, "char_start": 81, "char_end": 132, "line": "        sql.append(\"\"\"INSERT INTO users (username)\n"}, {"line_no": 4, "char_start": 132, "char_end": 169, "line": "                      VALUES ('{0}')\n"}, {"line_no": 5, "char_start": 169, "char_end": 233, "line": "                      ON DUPLICATE KEY UPDATE username = '{0}';\n"}, {"line_no": 6, "char_start": 233, "char_end": 277, "line": "                      \"\"\".format(username))\n"}, {"line_no": 7, "char_start": 277, "char_end": 354, "line": "        sql.append(\"\"\"INSERT INTO user_event (username, event_id, attending)\n"}, {"line_no": 8, "char_start": 354, "char_end": 405, "line": "                      VALUES ('{0}', '{1}', '{2}')\n"}, {"line_no": 9, "char_start": 405, "char_end": 470, "line": "                      ON DUPLICATE KEY UPDATE attending = '{2}';\n"}, {"line_no": 10, "char_start": 470, "char_end": 535, "line": "                      \"\"\".format(username, event_id, attending))\n"}, {"line_no": 11, "char_start": 535, "char_end": 561, "line": "        for query in sql:\n"}, {"line_no": 12, "char_start": 561, "char_end": 597, "line": "            self.cur.execute(query)\n"}], "added": [{"line_no": 2, "char_start": 64, "char_end": 83, "line": "        sql1 = \"\"\"\n"}, {"line_no": 3, "char_start": 83, "char_end": 127, "line": "               INSERT INTO users (username)\n"}, {"line_no": 4, "char_start": 127, "char_end": 154, "line": "               VALUES (%s)\n"}, {"line_no": 5, "char_start": 154, "char_end": 208, "line": "               ON DUPLICATE KEY UPDATE username = %s;\n"}, {"line_no": 6, "char_start": 208, "char_end": 227, "line": "               \"\"\"\n"}, {"line_no": 7, "char_start": 227, "char_end": 246, "line": "        sql2 = \"\"\"\n"}, {"line_no": 8, "char_start": 246, "char_end": 316, "line": "               INSERT INTO user_event (username, event_id, attending)\n"}, {"line_no": 9, "char_start": 316, "char_end": 351, "line": "               VALUES (%s, %s, %s)\n"}, {"line_no": 10, "char_start": 351, "char_end": 406, "line": "               ON DUPLICATE KEY UPDATE attending = %s;\n"}, {"line_no": 11, "char_start": 406, "char_end": 425, "line": "               \"\"\"\n"}, {"line_no": 12, "char_start": 425, "char_end": 478, "line": "        self.cur.execute(sql1, (username, username))\n"}, {"line_no": 13, "char_start": 478, "char_end": 553, "line": "        self.cur.execute(sql2, (username, event_id, attending, attending))\n"}]}, "char_changes": {"deleted": [{"char_start": 78, "char_end": 80, "chars": "[]"}, {"char_start": 89, "char_end": 103, "chars": "sql.append(\"\"\""}, {"char_start": 147, "char_end": 154, "chars": "       "}, {"char_start": 162, "char_end": 176, "chars": "'{0}')\n       "}, {"char_start": 226, "char_end": 231, "chars": "'{0}'"}, {"char_start": 255, "char_end": 299, "chars": "\"\"\".format(username))\n        sql.append(\"\"\""}, {"char_start": 369, "char_end": 376, "chars": "       "}, {"char_start": 384, "char_end": 408, "chars": "'{0}', '{1}', '{2}')\n   "}, {"char_start": 423, "char_end": 427, "chars": "    "}, {"char_start": 463, "char_end": 468, "chars": "'{2}'"}, {"char_start": 492, "char_end": 595, "chars": "\"\"\".format(username, event_id, attending))\n        for query in sql:\n            self.cur.execute(query"}], "added": [{"char_start": 75, "char_end": 76, "chars": "1"}, {"char_start": 79, "char_end": 82, "chars": "\"\"\""}, {"char_start": 91, "char_end": 98, "chars": "       "}, {"char_start": 150, "char_end": 154, "chars": "%s)\n"}, {"char_start": 204, "char_end": 206, "chars": "%s"}, {"char_start": 223, "char_end": 227, "chars": "\"\"\"\n"}, {"char_start": 234, "char_end": 261, "chars": " sql2 = \"\"\"\n               "}, {"char_start": 339, "char_end": 351, "chars": "%s, %s, %s)\n"}, {"char_start": 402, "char_end": 406, "chars": "%s;\n"}, {"char_start": 424, "char_end": 551, "chars": "\n        self.cur.execute(sql1, (username, username))\n        self.cur.execute(sql2, (username, event_id, attending, attending)"}]}, "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089"}
{"func_name": "get_event", "func_src_before": "    def get_event(self, event_id):\n        sql = \"\"\"SELECT title, description, start_time, time_zone, (\n                   SELECT GROUP_CONCAT(DISTINCT username)\n                   FROM user_event\n                   WHERE event_id = {0}\n                   AND user_event.attending = 1)\n                   AS accepted, (\n                   SELECT GROUP_CONCAT(DISTINCT username)\n                   FROM user_event\n                   WHERE event_id = {0}\n                   AND user_event.attending = 0)\n                   AS declined\n                 FROM events\n                 WHERE event_id = {0};\n                 \"\"\".format(event_id)\n        self.cur.execute(sql)\n        return self.cur.fetchall()", "func_src_after": "    def get_event(self, event_id):\n        sql = \"\"\"\n              SELECT title, description, start_time, time_zone, (\n                SELECT GROUP_CONCAT(DISTINCT username)\n                FROM user_event\n                WHERE event_id = %s\n                AND user_event.attending = 1)\n                AS accepted, (\n                SELECT GROUP_CONCAT(DISTINCT username)\n                FROM user_event\n                WHERE event_id = %s\n                AND user_event.attending = 0)\n                AS declined\n              FROM events\n              WHERE event_id = %s;\n              \"\"\"\n        self.cur.execute(sql, (event_id, event_id, event_id))\n        return self.cur.fetchall()", "line_changes": {"deleted": [{"line_no": 2, "char_start": 35, "char_end": 104, "line": "        sql = \"\"\"SELECT title, description, start_time, time_zone, (\n"}, {"line_no": 3, "char_start": 104, "char_end": 162, "line": "                   SELECT GROUP_CONCAT(DISTINCT username)\n"}, {"line_no": 4, "char_start": 162, "char_end": 197, "line": "                   FROM user_event\n"}, {"line_no": 5, "char_start": 197, "char_end": 237, "line": "                   WHERE event_id = {0}\n"}, {"line_no": 6, "char_start": 237, "char_end": 286, "line": "                   AND user_event.attending = 1)\n"}, {"line_no": 7, "char_start": 286, "char_end": 320, "line": "                   AS accepted, (\n"}, {"line_no": 8, "char_start": 320, "char_end": 378, "line": "                   SELECT GROUP_CONCAT(DISTINCT username)\n"}, {"line_no": 9, "char_start": 378, "char_end": 413, "line": "                   FROM user_event\n"}, {"line_no": 10, "char_start": 413, "char_end": 453, "line": "                   WHERE event_id = {0}\n"}, {"line_no": 11, "char_start": 453, "char_end": 502, "line": "                   AND user_event.attending = 0)\n"}, {"line_no": 12, "char_start": 502, "char_end": 533, "line": "                   AS declined\n"}, {"line_no": 13, "char_start": 533, "char_end": 562, "line": "                 FROM events\n"}, {"line_no": 14, "char_start": 562, "char_end": 601, "line": "                 WHERE event_id = {0};\n"}, {"line_no": 15, "char_start": 601, "char_end": 639, "line": "                 \"\"\".format(event_id)\n"}, {"line_no": 16, "char_start": 639, "char_end": 669, "line": "        self.cur.execute(sql)\n"}], "added": [{"line_no": 2, "char_start": 35, "char_end": 53, "line": "        sql = \"\"\"\n"}, {"line_no": 3, "char_start": 53, "char_end": 119, "line": "              SELECT title, description, start_time, time_zone, (\n"}, {"line_no": 4, "char_start": 119, "char_end": 174, "line": "                SELECT GROUP_CONCAT(DISTINCT username)\n"}, {"line_no": 5, "char_start": 174, "char_end": 206, "line": "                FROM user_event\n"}, {"line_no": 6, "char_start": 206, "char_end": 242, "line": "                WHERE event_id = %s\n"}, {"line_no": 7, "char_start": 242, "char_end": 288, "line": "                AND user_event.attending = 1)\n"}, {"line_no": 8, "char_start": 288, "char_end": 319, "line": "                AS accepted, (\n"}, {"line_no": 9, "char_start": 319, "char_end": 374, "line": "                SELECT GROUP_CONCAT(DISTINCT username)\n"}, {"line_no": 10, "char_start": 374, "char_end": 406, "line": "                FROM user_event\n"}, {"line_no": 11, "char_start": 406, "char_end": 442, "line": "                WHERE event_id = %s\n"}, {"line_no": 12, "char_start": 442, "char_end": 488, "line": "                AND user_event.attending = 0)\n"}, {"line_no": 13, "char_start": 488, "char_end": 516, "line": "                AS declined\n"}, {"line_no": 14, "char_start": 516, "char_end": 542, "line": "              FROM events\n"}, {"line_no": 15, "char_start": 542, "char_end": 577, "line": "              WHERE event_id = %s;\n"}, {"line_no": 16, "char_start": 577, "char_end": 595, "line": "              \"\"\"\n"}, {"line_no": 17, "char_start": 595, "char_end": 657, "line": "        self.cur.execute(sql, (event_id, event_id, event_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 120, "char_end": 123, "chars": "   "}, {"char_start": 178, "char_end": 181, "chars": "   "}, {"char_start": 213, "char_end": 215, "chars": "  "}, {"char_start": 215, "char_end": 216, "chars": " "}, {"char_start": 233, "char_end": 238, "chars": "{0}\n "}, {"char_start": 254, "char_end": 256, "chars": "  "}, {"char_start": 302, "char_end": 305, "chars": "   "}, {"char_start": 320, "char_end": 323, "chars": "   "}, {"char_start": 394, "char_end": 397, "chars": "   "}, {"char_start": 413, "char_end": 416, "chars": "   "}, {"char_start": 449, "char_end": 456, "chars": "{0}\n   "}, {"char_start": 518, "char_end": 521, "chars": "   "}, {"char_start": 533, "char_end": 536, "chars": "   "}, {"char_start": 576, "char_end": 577, "chars": " "}, {"char_start": 577, "char_end": 579, "chars": "  "}, {"char_start": 596, "char_end": 599, "chars": "{0}"}, {"char_start": 615, "char_end": 616, "chars": " "}, {"char_start": 616, "char_end": 618, "chars": "  "}, {"char_start": 621, "char_end": 638, "chars": ".format(event_id)"}], "added": [{"char_start": 52, "char_end": 67, "chars": "\n              "}, {"char_start": 239, "char_end": 242, "chars": "%s\n"}, {"char_start": 439, "char_end": 442, "chars": "%s\n"}, {"char_start": 573, "char_end": 575, "chars": "%s"}, {"char_start": 623, "char_end": 655, "chars": ", (event_id, event_id, event_id)"}]}, "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089"}
{"func_name": "delete_event", "func_src_before": "    def delete_event(self, event_id):\n        sql = \"\"\"DELETE FROM events\n                 WHERE event_id = {0}\n                 \"\"\".format(event_id)\n        affected_count = self.cur.execute(sql)\n        self.conn.commit()\n        return affected_count", "func_src_after": "    def delete_event(self, event_id):\n        sql = \"\"\"\n              DELETE FROM events\n              WHERE event_id = %s\n              \"\"\"\n        affected_count = self.cur.execute(sql, (event_id,))\n        self.conn.commit()\n        return affected_count", "line_changes": {"deleted": [{"line_no": 2, "char_start": 38, "char_end": 74, "line": "        sql = \"\"\"DELETE FROM events\n"}, {"line_no": 3, "char_start": 74, "char_end": 112, "line": "                 WHERE event_id = {0}\n"}, {"line_no": 4, "char_start": 112, "char_end": 150, "line": "                 \"\"\".format(event_id)\n"}, {"line_no": 5, "char_start": 150, "char_end": 197, "line": "        affected_count = self.cur.execute(sql)\n"}], "added": [{"line_no": 2, "char_start": 38, "char_end": 56, "line": "        sql = \"\"\"\n"}, {"line_no": 3, "char_start": 56, "char_end": 89, "line": "              DELETE FROM events\n"}, {"line_no": 4, "char_start": 89, "char_end": 123, "line": "              WHERE event_id = %s\n"}, {"line_no": 5, "char_start": 123, "char_end": 141, "line": "              \"\"\"\n"}, {"line_no": 6, "char_start": 141, "char_end": 201, "line": "        affected_count = self.cur.execute(sql, (event_id,))\n"}]}, "char_changes": {"deleted": [{"char_start": 88, "char_end": 91, "chars": "   "}, {"char_start": 108, "char_end": 115, "chars": "{0}\n   "}, {"char_start": 132, "char_end": 149, "chars": ".format(event_id)"}], "added": [{"char_start": 55, "char_end": 70, "chars": "\n              "}, {"char_start": 120, "char_end": 123, "chars": "%s\n"}, {"char_start": 186, "char_end": 199, "chars": ", (event_id,)"}]}, "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089"}
{"func_name": "login", "func_src_before": "\tdef login(self, username, pattern):\n\t\tcnx = mysql.connector.connect(user='root', password='p@ssword',host='127.0.0.1',database='weather_app')\n\t\tquery = (\"SELECT name,email,record_time FROM users WHERE users.name = '{}' AND users.pattern = '{}';\".format(username,pattern))\n\t\tcursor = cnx.cursor()\n\t\tcursor.execute(query)\n\t\tresult = []\n\t\tfor row in cursor:\n\t\t\tresult.append(row)\n\t\tcursor.close()\n\t\tcnx.close()\n\t\tif len(result) > 0:\n\t\t\tself.user_logged = { 'name': result[0][0],\n\t\t\t\t\t     'mail': result[0][1],\n\t\t\t\t\t     'wait': result[0][2] }\n\t\telse:\n\t\t\traise Exception(\"User not found\")", "func_src_after": "\tdef login(self, username, pattern):\n\t\tcnx = mysql.connector.connect(user='root', password='p@ssword',host='127.0.0.1',database='weather_app')\n\t\t# This is unsafe\n\t\tquery = \"SELECT name,email,record_time FROM users WHERE users.name = '%s' AND users.pattern = '%s';\" % (username,pattern)\n\t\tcursor = cnx.cursor()\n\t\tcursor.execute(query)\n\t\tresult = []\n\t\tfor row in cursor:\n\t\t\tresult.append(row)\n\t\tcursor.close()\n\t\tcnx.close()\n\t\tif len(result) > 0:\n\t\t\tself.user_logged = { 'name': result[0][0],\n\t\t\t\t\t     'mail': result[0][1],\n\t\t\t\t\t     'wait': result[0][2] }\n\t\telse:\n\t\t\traise Exception(\"User not found\")", "line_changes": {"deleted": [{"line_no": 3, "char_start": 143, "char_end": 273, "line": "\t\tquery = (\"SELECT name,email,record_time FROM users WHERE users.name = '{}' AND users.pattern = '{}';\".format(username,pattern))\n"}], "added": [{"line_no": 4, "char_start": 162, "char_end": 286, "line": "\t\tquery = \"SELECT name,email,record_time FROM users WHERE users.name = '%s' AND users.pattern = '%s';\" % (username,pattern)\n"}]}, "char_changes": {"deleted": [{"char_start": 153, "char_end": 154, "chars": "("}, {"char_start": 216, "char_end": 218, "chars": "{}"}, {"char_start": 241, "char_end": 243, "chars": "{}"}, {"char_start": 246, "char_end": 253, "chars": ".format"}, {"char_start": 271, "char_end": 272, "chars": ")"}], "added": [{"char_start": 143, "char_end": 162, "chars": "\t\t# This is unsafe\n"}, {"char_start": 234, "char_end": 236, "chars": "%s"}, {"char_start": 259, "char_end": 261, "chars": "%s"}, {"char_start": 264, "char_end": 267, "chars": " % "}]}, "commit_link": "github.com/dglozano/raspberryWeather/commit/24a31089f6077f938c1f40adeece957b982e512b", "file_name": "weather_app.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "\tdef add_input(self, data):\n\t\tconnection=self.connect()\n\t\ttry:\n\t\t\t# The following introduces a deliberate security flaw\n\t\t\tquery=\"INSERT INTO crimes (description) VALUES('{}');\".format(data)\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "func_src_after": "\tdef add_input(self, data):\n\t\tconnection=self.connect()\n\t\ttry:\n\t\t\tquery='INSERT INTO crimes (description) VALUES (%s);'\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query, data)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 120, "char_end": 191, "line": "\t\t\tquery=\"INSERT INTO crimes (description) VALUES('{}');\".format(data)\n"}, {"line_no": 7, "char_start": 230, "char_end": 256, "line": "\t\t\t\tcursor.execute(query)\n"}], "added": [{"line_no": 4, "char_start": 63, "char_end": 120, "line": "\t\t\tquery='INSERT INTO crimes (description) VALUES (%s);'\n"}, {"line_no": 6, "char_start": 159, "char_end": 191, "line": "\t\t\t\tcursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 63, "char_end": 120, "chars": "\t\t\t# The following introduces a deliberate security flaw\n"}, {"char_start": 129, "char_end": 130, "chars": "\""}, {"char_start": 169, "char_end": 190, "chars": "('{}');\".format(data)"}, {"char_start": 230, "char_end": 230, "chars": ""}], "added": [{"char_start": 72, "char_end": 73, "chars": "'"}, {"char_start": 112, "char_end": 119, "chars": " (%s);'"}, {"char_start": 183, "char_end": 189, "chars": ", data"}]}, "commit_link": "github.com/Marundu/crimemap/commit/5796a509ecd5e23f58f77b4375bd0ee6c1d976c5", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "get_full_sql", "func_src_before": "def get_full_sql(db, filter):\n    db.cursor.execute(\"\"\"SELECT\n                         submission.id,\n                         submission.sheet_id,\n                         submission.student_id,\n                         submission.time,\n                         submission.files_path,\n                         student.primary_alias,\n                         grading_result.grader,\n                         grading_result.decipoints,\n                         grading_result.status\n                         FROM\n                         submission\n                         INNER JOIN student ON\n                         submission.student_id = student.id\n                         AND student.deleted IS NOT 1\n                         AND submission.deleted IS NOT 1\n                         %s\n                         LEFT OUTER JOIN grading_result ON\n                         submission.id = grading_result.submission_id\n                         ORDER BY submission.id DESC\n                         \"\"\" %\n                      (\" AND %s\" % filter if filter else \"\"))\n    rows = db.cursor.fetchall()\n\n    all_full = []\n\n    for row in rows:\n        id, sheet_id, student_id, time, files_path, primary_alias, grader, decipoints, status = row\n        all_full.append({\n            \"id\": id,\n            \"sheet_id\": sheet_id,\n            \"student_id\": student_id,\n            \"time\": time,\n            \"files_path\": files_path,\n            \"primary_alias\": primary_alias,\n            \"grader\": grader,\n            \"decipoints\": decipoints,\n            \"status\": status if status else \"Unbearbeitet\"\n        })\n\n    return all_full", "func_src_after": "def get_full_sql(db, filter_sql, filter_params=[]):\n    db.cursor.execute(\"\"\"SELECT\n                         submission.id,\n                         submission.sheet_id,\n                         submission.student_id,\n                         submission.time,\n                         submission.files_path,\n                         student.primary_alias,\n                         grading_result.grader,\n                         grading_result.decipoints,\n                         grading_result.status\n                         FROM\n                         submission\n                         INNER JOIN student ON\n                         submission.student_id = student.id\n                         AND student.deleted IS NOT 1\n                         AND submission.deleted IS NOT 1\n                         %s\n                         LEFT OUTER JOIN grading_result ON\n                         submission.id = grading_result.submission_id\n                         ORDER BY submission.id DESC\n                         \"\"\" %\n                      (\" AND %s\" % filter if filter else \"\"), filter_params)\n    rows = db.cursor.fetchall()\n\n    all_full = []\n\n    for row in rows:\n        id, sheet_id, student_id, time, files_path, primary_alias, grader, decipoints, status = row\n        all_full.append({\n            \"id\": id,\n            \"sheet_id\": sheet_id,\n            \"student_id\": student_id,\n            \"time\": time,\n            \"files_path\": files_path,\n            \"primary_alias\": primary_alias,\n            \"grader\": grader,\n            \"decipoints\": decipoints,\n            \"status\": status if status else \"Unbearbeitet\"\n        })\n\n    return all_full", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 30, "line": "def get_full_sql(db, filter):\n"}, {"line_no": 23, "char_start": 1006, "char_end": 1068, "line": "                      (\" AND %s\" % filter if filter else \"\"))\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 52, "line": "def get_full_sql(db, filter_sql, filter_params=[]):\n"}, {"line_no": 23, "char_start": 1028, "char_end": 1105, "line": "                      (\" AND %s\" % filter if filter else \"\"), filter_params)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 27, "char_end": 49, "chars": "_sql, filter_params=[]"}, {"char_start": 1088, "char_end": 1103, "chars": ", filter_params"}]}, "commit_link": "github.com/hhucn/netsec-uebungssystem/commit/8659c789a05fa45722e8b34d319dd4d4cbd468a0", "file_name": "netsecus/submission.py", "vul_type": "cwe-089"}
{"func_name": "db_get_file_details", "func_src_before": "def db_get_file_details(path):\n    \"\"\" This function queries the database for details\n    and returns a list of results or false \"\"\"\n    status = {'id': 0,\n              'name': 0,\n              'size': 0,\n              'age': 0,\n              'passes': 0,\n              'verified': 0}\n    cur.execute('SELECT * '\n                'FROM files '\n                'WHERE name=\"' + path + '\";')\n    result = cur.fetchall()\n    if cur.rowcount >= 1:\n        for row in result:\n            # See other/db_script.txt for table structure\n            status = {'id': row[0],\n                      'name': path,\n                      'size': int(row[2]),\n                      'age': float(row[3]),\n                      'passes': row[4],\n                      'verified': row[5]}\n    return status", "func_src_after": "def db_get_file_details(path):\n    \"\"\" This function queries the database for details\n    and returns a list of results or false \"\"\"\n    status = {...}\n    cur.execute('SELECT * '\n                'FROM files '\n                'WHERE name=%s;',\n                [path])\n    result = cur.fetchall()\n    if cur.rowcount >= 1:\n        for row in result:\n            # See other/db_script.txt for table structure\n            status = {'id': row[0],\n                      'name': path,\n                      'size': int(row[2]),\n                      'age': float(row[3]),\n                      'passes': row[4],\n                      'verified': row[5]}\n    else:\n        status = False\n    return status", "line_changes": {"deleted": [{"line_no": 4, "char_start": 133, "char_end": 156, "line": "    status = {'id': 0,\n"}, {"line_no": 5, "char_start": 156, "char_end": 181, "line": "              'name': 0,\n"}, {"line_no": 6, "char_start": 181, "char_end": 206, "line": "              'size': 0,\n"}, {"line_no": 7, "char_start": 206, "char_end": 230, "line": "              'age': 0,\n"}, {"line_no": 8, "char_start": 230, "char_end": 257, "line": "              'passes': 0,\n"}, {"line_no": 9, "char_start": 257, "char_end": 286, "line": "              'verified': 0}\n"}, {"line_no": 12, "char_start": 344, "char_end": 390, "line": "                'WHERE name=\"' + path + '\";')\n"}], "added": [{"line_no": 4, "char_start": 133, "char_end": 152, "line": "    status = {...}\n"}, {"line_no": 7, "char_start": 210, "char_end": 244, "line": "                'WHERE name=%s;',\n"}, {"line_no": 8, "char_start": 244, "char_end": 268, "line": "                [path])\n"}, {"line_no": 19, "char_start": 648, "char_end": 658, "line": "    else:\n"}, {"line_no": 20, "char_start": 658, "char_end": 681, "line": "        status = False\n"}]}, "char_changes": {"deleted": [{"char_start": 147, "char_end": 284, "chars": "'id': 0,\n              'name': 0,\n              'size': 0,\n              'age': 0,\n              'passes': 0,\n              'verified': 0"}, {"char_start": 372, "char_end": 388, "chars": "\"' + path + '\";'"}], "added": [{"char_start": 147, "char_end": 150, "chars": "..."}, {"char_start": 238, "char_end": 266, "chars": "%s;',\n                [path]"}, {"char_start": 648, "char_end": 681, "chars": "    else:\n        status = False\n"}]}, "commit_link": "github.com/CSCfi/lega-mirroring/commit/9136db2e49be874b1f161491cdff1fc8668b5db5", "file_name": "cf_dir.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following is susceptable to SQL injection\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\" \\\n                    .format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following is susceptable to SQL injection\n            # query = \"INSERT INTO crimes (description) VALUES ('{}');\" \\\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 140, "char_end": 212, "line": "            query = \"INSERT INTO crimes (description) VALUES ('{}');\" \\\n"}, {"line_no": 6, "char_start": 212, "char_end": 246, "line": "                    .format(data)\n"}, {"line_no": 8, "char_start": 294, "char_end": 332, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 6, "char_start": 214, "char_end": 282, "line": "            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 8, "char_start": 330, "char_end": 374, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 224, "char_end": 245, "chars": "        .format(data)"}, {"char_start": 294, "char_end": 294, "chars": ""}], "added": [{"char_start": 151, "char_end": 153, "chars": " #"}, {"char_start": 226, "char_end": 281, "chars": "query = \"INSERT INTO crimes (description) VALUES (%s);\""}, {"char_start": 366, "char_end": 372, "chars": ", data"}]}, "commit_link": "github.com/claudemuller/crimemap/commit/451f64f238357fa8786039a2b81158020bb76bff", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "top_karma", "func_src_before": "def top_karma(bot, trigger):\n    \"\"\"\n    Show karma status for the top n number of IRC users.\n    \"\"\"\n    if trigger.group(2):\n        top_limit = int(trigger.group(2).strip())\n    else:\n        top_limit = 5\n\n    karmalist = bot.db.execute(\"SELECT slug, value FROM nick_values NATURAL JOIN nicknames WHERE key = 'karma' ORDER BY value DESC LIMIT \" + str(top_limit)).fetchall()\n    for user in karmalist:\n        bot.say(\"%s == %s\" % (user[0], user[1]))", "func_src_after": "def top_karma(bot, trigger):\n    \"\"\"\n    Show karma status for the top n number of IRC users.\n    \"\"\"\n    try:\n        top_limit = int(trigger.group(2).strip())\n    except ValueError:\n        top_limit = 5\n\n    query = \"SELECT slug, value FROM nick_values NATURAL JOIN nicknames \\\n        WHERE key = 'karma' ORDER BY value DESC LIMIT %d\"\n    karmalist = bot.db.execute(query % top_limit).fetchall()\n    for user in karmalist:\n        bot.say(\"%s == %s\" % (user[0], user[1]))", "line_changes": {"deleted": [{"line_no": 5, "char_start": 102, "char_end": 127, "line": "    if trigger.group(2):\n"}, {"line_no": 7, "char_start": 177, "char_end": 187, "line": "    else:\n"}, {"line_no": 10, "char_start": 210, "char_end": 378, "line": "    karmalist = bot.db.execute(\"SELECT slug, value FROM nick_values NATURAL JOIN nicknames WHERE key = 'karma' ORDER BY value DESC LIMIT \" + str(top_limit)).fetchall()\n"}], "added": [{"line_no": 5, "char_start": 102, "char_end": 111, "line": "    try:\n"}, {"line_no": 7, "char_start": 161, "char_end": 184, "line": "    except ValueError:\n"}, {"line_no": 10, "char_start": 207, "char_end": 281, "line": "    query = \"SELECT slug, value FROM nick_values NATURAL JOIN nicknames \\\n"}, {"line_no": 11, "char_start": 281, "char_end": 339, "line": "        WHERE key = 'karma' ORDER BY value DESC LIMIT %d\"\n"}, {"line_no": 12, "char_start": 339, "char_end": 400, "line": "    karmalist = bot.db.execute(query % top_limit).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 106, "char_end": 125, "chars": "if trigger.group(2)"}, {"char_start": 182, "char_end": 185, "chars": "lse"}, {"char_start": 214, "char_end": 241, "chars": "karmalist = bot.db.execute("}, {"char_start": 347, "char_end": 355, "chars": "\" + str("}, {"char_start": 365, "char_end": 366, "chars": ")"}], "added": [{"char_start": 106, "char_end": 109, "chars": "try"}, {"char_start": 166, "char_end": 182, "chars": "xcept ValueError"}, {"char_start": 211, "char_end": 219, "chars": "query = "}, {"char_start": 279, "char_end": 289, "chars": "\\\n        "}, {"char_start": 335, "char_end": 378, "chars": "%d\"\n    karmalist = bot.db.execute(query % "}]}, "commit_link": "github.com/OpCode1300/sopel-karma/commit/c126bea8b81a434f986414e7f63ec7db9465b9f2", "file_name": "sopel_modules/karma/karma.py", "vul_type": "cwe-089"}
{"func_name": "top_karma", "func_src_before": "def top_karma(bot, trigger):\n    \"\"\"\n    Show karma status for the top n number of IRC users.\n    \"\"\"\n    try:\n        top_limit = int(trigger.group(2).strip())\n    except ValueError:\n        top_limit = 5\n\n    query = \"SELECT slug, value FROM nick_values NATURAL JOIN nicknames \\\n        WHERE key = 'karma' ORDER BY value DESC LIMIT %d\"\n    karmalist = bot.db.execute(query % top_limit).fetchall()\n    for user in karmalist:\n        bot.say(\"%s == %s\" % (user[0], user[1]))", "func_src_after": "def top_karma(bot, trigger):\n    \"\"\"\n    Show karma status for the top n number of IRC users.\n    \"\"\"\n    try:\n        top_limit = int(trigger.group(2).strip())\n    except ValueError:\n        top_limit = 5\n\n    query = \"SELECT slug, value FROM nick_values NATURAL JOIN nicknames \\\n        WHERE key = 'karma' ORDER BY value DESC LIMIT ?\"\n    karmalist = bot.db.execute(query, str(top_limit)).fetchall()\n    for user in karmalist:\n        bot.say(\"%s == %s\" % (user[0], user[1]))", "line_changes": {"deleted": [{"line_no": 11, "char_start": 281, "char_end": 339, "line": "        WHERE key = 'karma' ORDER BY value DESC LIMIT %d\"\n"}, {"line_no": 12, "char_start": 339, "char_end": 400, "line": "    karmalist = bot.db.execute(query % top_limit).fetchall()\n"}], "added": [{"line_no": 11, "char_start": 281, "char_end": 338, "line": "        WHERE key = 'karma' ORDER BY value DESC LIMIT ?\"\n"}, {"line_no": 12, "char_start": 338, "char_end": 403, "line": "    karmalist = bot.db.execute(query, str(top_limit)).fetchall()\n"}]}, "char_changes": {"deleted": [{"char_start": 335, "char_end": 337, "chars": "%d"}, {"char_start": 375, "char_end": 378, "chars": " % "}], "added": [{"char_start": 335, "char_end": 336, "chars": "?"}, {"char_start": 374, "char_end": 380, "chars": ", str("}, {"char_start": 390, "char_end": 391, "chars": ")"}]}, "commit_link": "github.com/OpCode1300/sopel-karma/commit/e4d49f7b3d88f8874c7862392f3f4c2065a25695", "file_name": "sopel_modules/karma/karma.py", "vul_type": "cwe-089"}
{"func_name": "achievements_list_player", "func_src_before": "@app.route('/players/<int:player_id>/achievements')\ndef achievements_list_player(player_id):\n    \"\"\"Lists the progress of achievements for a player.\n\n    :param player_id: ID of the player.\n\n    :return:\n        If successful, this method returns a response body with the following structure::\n\n            {\n              \"items\": [\n                {\n                  \"achievement_id\": string,\n                  \"state\": string,\n                  \"current_steps\": integer,\n                  \"create_time\": long,\n                  \"update_time\": long\n                }\n              ]\n            }\n    \"\"\"\n    with db.connection:\n        cursor = db.connection.cursor(db.pymysql.cursors.DictCursor)\n        cursor.execute(\"\"\"SELECT\n                            achievement_id,\n                            current_steps,\n                            state,\n                            UNIX_TIMESTAMP(create_time) as create_time,\n                            UNIX_TIMESTAMP(update_time) as update_time\n                        FROM player_achievements\n                        WHERE player_id = '%s'\"\"\" % player_id)\n\n        return flask.jsonify(items=cursor.fetchall())", "func_src_after": "@app.route('/players/<int:player_id>/achievements')\ndef achievements_list_player(player_id):\n    \"\"\"Lists the progress of achievements for a player.\n\n    :param player_id: ID of the player.\n\n    :return:\n        If successful, this method returns a response body with the following structure::\n\n            {\n              \"items\": [\n                {\n                  \"achievement_id\": string,\n                  \"state\": string,\n                  \"current_steps\": integer,\n                  \"create_time\": long,\n                  \"update_time\": long\n                }\n              ]\n            }\n    \"\"\"\n    with db.connection:\n        cursor = db.connection.cursor(db.pymysql.cursors.DictCursor)\n        cursor.execute(\"\"\"SELECT\n                            achievement_id,\n                            current_steps,\n                            state,\n                            UNIX_TIMESTAMP(create_time) as create_time,\n                            UNIX_TIMESTAMP(update_time) as update_time\n                        FROM player_achievements\n                        WHERE player_id = %s\"\"\", player_id)\n\n        return flask.jsonify(items=cursor.fetchall())", "line_changes": {"deleted": [{"line_no": 31, "char_start": 1048, "char_end": 1111, "line": "                        WHERE player_id = '%s'\"\"\" % player_id)\n"}], "added": [{"line_no": 31, "char_start": 1048, "char_end": 1108, "line": "                        WHERE player_id = %s\"\"\", player_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 1090, "char_end": 1091, "chars": "'"}, {"char_start": 1093, "char_end": 1094, "chars": "'"}, {"char_start": 1097, "char_end": 1099, "chars": " %"}], "added": [{"char_start": 1095, "char_end": 1096, "chars": ","}]}, "commit_link": "github.com/FAForever/api/commit/5fe7f23868cd191616b088bdd5b24010f004dd5a", "file_name": "api/achievements.py", "vul_type": "cwe-089"}
{"func_name": "__init__", "func_src_before": "    def __init__(self, path, host = \"apex.oracle.com\"):\n        self.host = host\n        self.path = path\n        self.conn = httplib.HTTPSConnection(self.host)\n        self.credentials = None\n        credentials_file = os.path.join(os.path.dirname(__file__), \"credentials.oracle\")\n        \n        if os.path.isfile(credentials_file):\n            f = open(credentials_file, \"r\")\n            self.credentials = json.load(f)\n            f.close()\n            for key, value in self.credentials.items(): #remove whitespace\n                self.credentials[key] = value.strip()\n        else:\n            print \"credentials file not found\"\n\n        self.default_data = { \"Content-type\": \"text/plain\", \"Accept\": \"text/plain\" }", "func_src_after": "    def __init__(self, path, host = \"apex.oracle.com\"):\n        self.host = host\n        self.path = path\n        self.conn = httplib.HTTPSConnection(self.host)\n        self.credentials = None\n        credentials_file = os.path.join(os.path.dirname(__file__), \"credentials.oracle\")\n        \n        if os.path.isfile(credentials_file):\n            f = open(credentials_file, \"r\")\n            self.credentials = json.load(f)\n            f.close()\n            for key, value in self.credentials.items(): #remove whitespace\n                self.credentials[key] = value.strip()\n        else:\n            print(\"Credentials file not found\")\n\n        self.default_data = { \"Content-type\": \"text/plain\", \"Accept\": \"text/plain\" }", "line_changes": {"deleted": [{"line_no": 15, "char_start": 589, "char_end": 636, "line": "            print \"credentials file not found\"\n"}], "added": [{"line_no": 15, "char_start": 589, "char_end": 637, "line": "            print(\"Credentials file not found\")\n"}]}, "char_changes": {"deleted": [{"char_start": 606, "char_end": 609, "chars": " \"c"}], "added": [{"char_start": 606, "char_end": 609, "chars": "(\"C"}, {"char_start": 635, "char_end": 636, "chars": ")"}]}, "commit_link": "github.com/MartinSMilligan/RaspberryPi-WeatherStation/commit/a62284052a6933a05945790395f3eceb3984a66f", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "__init__", "func_src_before": "    def __init__(self):\n        self.db = mysql_database()\n        self.insert_template = \"INSERT INTO WEATHER_MEASUREMENT (AMBIENT_TEMPERATURE, GROUND_TEMPERATURE, AIR_QUALITY, AIR_PRESSURE, HUMIDITY, WIND_DIRECTION, WIND_SPEED, WIND_GUST_SPEED, RAINFALL, CREATED) VALUES({0}, {1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}, '{9}');\"\n        self.update_template =  \"UPDATE WEATHER_MEASUREMENT SET REMOTE_ID={0} WHERE ID={1};\"\n        self.upload_select_template = \"SELECT * FROM WEATHER_MEASUREMENT WHERE REMOTE_ID IS NULL;\"", "func_src_after": "    def __init__(self):\n        self.db = mysql_database()\n        self.insert_template = \"INSERT INTO WEATHER_MEASUREMENT (AMBIENT_TEMPERATURE, GROUND_TEMPERATURE, AIR_QUALITY, AIR_PRESSURE, HUMIDITY, WIND_DIRECTION, WIND_SPEED, WIND_GUST_SPEED, RAINFALL, CREATED) VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\"\n        self.update_template =  \"UPDATE WEATHER_MEASUREMENT SET REMOTE_ID=%s WHERE ID=%s;\"\n        self.upload_select_template = \"SELECT * FROM WEATHER_MEASUREMENT WHERE REMOTE_ID IS NULL;\"", "line_changes": {"deleted": [{"line_no": 3, "char_start": 59, "char_end": 327, "line": "        self.insert_template = \"INSERT INTO WEATHER_MEASUREMENT (AMBIENT_TEMPERATURE, GROUND_TEMPERATURE, AIR_QUALITY, AIR_PRESSURE, HUMIDITY, WIND_DIRECTION, WIND_SPEED, WIND_GUST_SPEED, RAINFALL, CREATED) VALUES({0}, {1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}, '{9}');\"\n"}, {"line_no": 4, "char_start": 327, "char_end": 420, "line": "        self.update_template =  \"UPDATE WEATHER_MEASUREMENT SET REMOTE_ID={0} WHERE ID={1};\"\n"}], "added": [{"line_no": 3, "char_start": 59, "char_end": 315, "line": "        self.insert_template = \"INSERT INTO WEATHER_MEASUREMENT (AMBIENT_TEMPERATURE, GROUND_TEMPERATURE, AIR_QUALITY, AIR_PRESSURE, HUMIDITY, WIND_DIRECTION, WIND_SPEED, WIND_GUST_SPEED, RAINFALL, CREATED) VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\"\n"}, {"line_no": 4, "char_start": 315, "char_end": 406, "line": "        self.update_template =  \"UPDATE WEATHER_MEASUREMENT SET REMOTE_ID=%s WHERE ID=%s;\"\n"}]}, "char_changes": {"deleted": [{"char_start": 273, "char_end": 323, "chars": "{0}, {1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}, '{9}'"}, {"char_start": 401, "char_end": 404, "chars": "{0}"}, {"char_start": 414, "char_end": 417, "chars": "{1}"}], "added": [{"char_start": 273, "char_end": 311, "chars": "%s, %s, %s, %s, %s, %s, %s, %s, %s, %s"}, {"char_start": 389, "char_end": 391, "chars": "%s"}, {"char_start": 401, "char_end": 403, "chars": "%s"}]}, "commit_link": "github.com/MartinSMilligan/RaspberryPi-WeatherStation/commit/a62284052a6933a05945790395f3eceb3984a66f", "file_name": "database.py", "vul_type": "cwe-089"}
{"func_name": "get_articles_by_subject", "func_src_before": "def get_articles_by_subject(subject):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE subject='\" + subject + \"' ORDER BY last_submitted DESC\"\n        cur.execute(query)\n        articles = cur.fetchall()\n        return articles", "func_src_after": "def get_articles_by_subject(subject):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE subject=%s ORDER BY last_submitted DESC\"\n        cur.execute(query, (subject,))\n        articles = cur.fetchall()\n        return articles", "line_changes": {"deleted": [{"line_no": 3, "char_start": 94, "char_end": 196, "line": "        query = \"SELECT * FROM articles WHERE subject='\" + subject + \"' ORDER BY last_submitted DESC\"\n"}, {"line_no": 4, "char_start": 196, "char_end": 223, "line": "        cur.execute(query)\n"}], "added": [{"line_no": 3, "char_start": 94, "char_end": 181, "line": "        query = \"SELECT * FROM articles WHERE subject=%s ORDER BY last_submitted DESC\"\n"}, {"line_no": 4, "char_start": 181, "char_end": 220, "line": "        cur.execute(query, (subject,))\n"}]}, "char_changes": {"deleted": [{"char_start": 148, "char_end": 165, "chars": "'\" + subject + \"'"}], "added": [{"char_start": 148, "char_end": 150, "chars": "%s"}, {"char_start": 206, "char_end": 218, "chars": ", (subject,)"}]}, "commit_link": "github.com/sepehr125/arxiv-doc2vec-recommender/commit/f23a4c32e6192b145017f64734b0a9a384c9123a", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "get_article", "func_src_before": "def get_article(index):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE index=\"+str(index)\n        cur.execute(query)\n        article = cur.fetchone()\n        return article", "func_src_after": "def get_article(index):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE index=%s\"\n        cur.execute(query, (index, ))\n        article = cur.fetchone()\n        return article", "line_changes": {"deleted": [{"line_no": 3, "char_start": 80, "char_end": 145, "line": "        query = \"SELECT * FROM articles WHERE index=\"+str(index)\n"}, {"line_no": 4, "char_start": 145, "char_end": 172, "line": "        cur.execute(query)\n"}], "added": [{"line_no": 3, "char_start": 80, "char_end": 136, "line": "        query = \"SELECT * FROM articles WHERE index=%s\"\n"}, {"line_no": 4, "char_start": 136, "char_end": 174, "line": "        cur.execute(query, (index, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 132, "char_end": 144, "chars": "\"+str(index)"}], "added": [{"char_start": 132, "char_end": 135, "chars": "%s\""}, {"char_start": 161, "char_end": 172, "chars": ", (index, )"}]}, "commit_link": "github.com/sepehr125/arxiv-doc2vec-recommender/commit/f23a4c32e6192b145017f64734b0a9a384c9123a", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "read", "func_src_before": "    def read(self, query_params=None):\n        '''\n        Modified to (temporarily) support interim UI specification for output\n        '''\n        query_params = query_params or {}\n\n        if query_params:\n            where_clause, query_items = self._build_where_clause(query_params)\n            query = 'SELECT * FROM ' + self.table_name + ' WHERE ' + where_clause\n            answer = self.sql.perform(query, query_items)\n        else:\n            query = 'SELECT * FROM %s;' % (self.table_name)\n\n            answer = self.sql.perform(query)\n\n        return answer", "func_src_after": "    def read(self, query_params=None):\n        '''\n        Modified to (temporarily) support interim UI specification for output\n        '''\n        if obj_id:\n            query = 'SELECT * FROM ' + self.tbl + ' WHERE %s = ' + self.holder + ';' % (self.where_param)\n            answer = self.sql.perform(query, obj_id)\n        else:\n            query = 'SELECT * FROM ' + self.tbl + ';'\n            answer = self.sql.perform(query, None)\n        return answer", "line_changes": {"deleted": [{"line_no": 5, "char_start": 141, "char_end": 183, "line": "        query_params = query_params or {}\n"}, {"line_no": 6, "char_start": 183, "char_end": 184, "line": "\n"}, {"line_no": 7, "char_start": 184, "char_end": 209, "line": "        if query_params:\n"}, {"line_no": 8, "char_start": 209, "char_end": 288, "line": "            where_clause, query_items = self._build_where_clause(query_params)\n"}, {"line_no": 9, "char_start": 288, "char_end": 370, "line": "            query = 'SELECT * FROM ' + self.table_name + ' WHERE ' + where_clause\n"}, {"line_no": 10, "char_start": 370, "char_end": 428, "line": "            answer = self.sql.perform(query, query_items)\n"}, {"line_no": 12, "char_start": 442, "char_end": 502, "line": "            query = 'SELECT * FROM %s;' % (self.table_name)\n"}, {"line_no": 13, "char_start": 502, "char_end": 503, "line": "\n"}, {"line_no": 14, "char_start": 503, "char_end": 548, "line": "            answer = self.sql.perform(query)\n"}, {"line_no": 15, "char_start": 548, "char_end": 549, "line": "\n"}], "added": [{"line_no": 5, "char_start": 141, "char_end": 160, "line": "        if obj_id:\n"}, {"line_no": 6, "char_start": 160, "char_end": 266, "line": "            query = 'SELECT * FROM ' + self.tbl + ' WHERE %s = ' + self.holder + ';' % (self.where_param)\n"}, {"line_no": 7, "char_start": 266, "char_end": 319, "line": "            answer = self.sql.perform(query, obj_id)\n"}, {"line_no": 9, "char_start": 333, "char_end": 387, "line": "            query = 'SELECT * FROM ' + self.tbl + ';'\n"}, {"line_no": 10, "char_start": 387, "char_end": 438, "line": "            answer = self.sql.perform(query, None)\n"}]}, "char_changes": {"deleted": [{"char_start": 149, "char_end": 287, "chars": "query_params = query_params or {}\n\n        if query_params:\n            where_clause, query_items = self._build_where_clause(query_params)"}, {"char_start": 333, "char_end": 334, "chars": "a"}, {"char_start": 336, "char_end": 342, "chars": "e_name"}, {"char_start": 353, "char_end": 369, "chars": "' + where_clause"}, {"char_start": 415, "char_end": 426, "chars": "query_items"}, {"char_start": 477, "char_end": 485, "chars": "%s;' % ("}, {"char_start": 491, "char_end": 492, "chars": "a"}, {"char_start": 494, "char_end": 502, "chars": "e_name)\n"}, {"char_start": 547, "char_end": 548, "chars": "\n"}], "added": [{"char_start": 149, "char_end": 159, "chars": "if obj_id:"}, {"char_start": 218, "char_end": 265, "chars": "%s = ' + self.holder + ';' % (self.where_param)"}, {"char_start": 311, "char_end": 317, "chars": "obj_id"}, {"char_start": 368, "char_end": 372, "chars": "' + "}, {"char_start": 380, "char_end": 386, "chars": " + ';'"}, {"char_start": 430, "char_end": 436, "chars": ", None"}]}, "commit_link": "github.com/asascience-open/ooi-ui-services/commit/e8999ac0b0161a9b0a10d0c6c7c64cb990b2cd1a", "file_name": "ooiservices/model/sqlmodel.py", "vul_type": "cwe-089"}
{"func_name": "reportMatch._checkPairing", "func_src_before": "    def _checkPairing():\n        if winner == loser:\n            raise ValueError('Attempt to match player against self')\n\n        q = '''\n        SELECT COUNT(*) FROM matches\n        WHERE (matches.winner_id = %s AND matches.loser_id = %s)\n              OR (matches.winner_id = %s AND matches.loser_id = %s);\n        ''' % (winner, loser, loser, winner)\n        cur.execute(q)\n        if cur.fetchone()[0] > 0:\n            raise ValueError('Pairing %s, %s already played' % (winner, loser))", "func_src_after": "    def _checkPairing():\n        if winner == loser:\n            raise ValueError('Attempt to match player against self')\n\n        q = '''\n        SELECT COUNT(*) FROM matches\n        WHERE (matches.winner_id = %s AND matches.loser_id = %s)\n              OR (matches.winner_id = %s AND matches.loser_id = %s);\n        '''\n        cur.execute(q, (winner, loser, loser, winner))\n        if cur.fetchone()[0] > 0:\n            raise ValueError('Pairing %s, %s already played' % (winner, loser))", "line_changes": {"deleted": [{"line_no": 9, "char_start": 310, "char_end": 355, "line": "        ''' % (winner, loser, loser, winner)\n"}, {"line_no": 10, "char_start": 355, "char_end": 378, "line": "        cur.execute(q)\n"}], "added": [{"line_no": 9, "char_start": 310, "char_end": 322, "line": "        '''\n"}, {"line_no": 10, "char_start": 322, "char_end": 377, "line": "        cur.execute(q, (winner, loser, loser, winner))\n"}]}, "char_changes": {"deleted": [{"char_start": 321, "char_end": 323, "chars": " %"}, {"char_start": 354, "char_end": 376, "chars": "\n        cur.execute(q"}], "added": [{"char_start": 321, "char_end": 344, "chars": "\n        cur.execute(q,"}]}, "commit_link": "github.com/juanchopanza/Tournament/commit/5799aee52d2cabb685800b88977257bd0964d0da", "file_name": "vagrant/tournament/tournament.py", "vul_type": "cwe-089"}
{"func_name": "get_all_tenta_mounted_modules_of_selected_ay", "func_src_before": "def get_all_tenta_mounted_modules_of_selected_ay(selected_ay):\n    '''\n        Get the module code, name, AY/Sem and quota of all tenta mounted mods of a selected AY\n    '''\n    sql_command = \"SELECT m2.moduleCode, m1.name, m2.acadYearAndSem, m2.quota \" +\\\n                  \"FROM module m1, moduleMountTentative m2 WHERE m2.moduleCode = m1.code \" +\\\n                  \"AND M2.acadYearAndSem LIKE '\" + selected_ay + \"%' \" +\\\n                  \"ORDER BY m2.moduleCode, m2.acadYearAndSem\"\n    DB_CURSOR.execute(sql_command)\n    return DB_CURSOR.fetchall()", "func_src_after": "def get_all_tenta_mounted_modules_of_selected_ay(selected_ay):\n    '''\n        Get the module code, name, AY/Sem and quota of all tenta mounted mods of a selected AY\n    '''\n    sql_command = \"SELECT m2.moduleCode, m1.name, m2.acadYearAndSem, m2.quota \" +\\\n                  \"FROM module m1, moduleMountTentative m2 WHERE m2.moduleCode = m1.code \" +\\\n                  \"AND M2.acadYearAndSem LIKE %s\" + \\\n                  \"ORDER BY m2.moduleCode, m2.acadYearAndSem\"\n    processed_ay = selected_ay + \"%\"\n\n    DB_CURSOR.execute(sql_command, (processed_ay,))\n    return DB_CURSOR.fetchall()", "line_changes": {"deleted": [{"line_no": 7, "char_start": 351, "char_end": 425, "line": "                  \"AND M2.acadYearAndSem LIKE '\" + selected_ay + \"%' \" +\\\n"}, {"line_no": 9, "char_start": 487, "char_end": 522, "line": "    DB_CURSOR.execute(sql_command)\n"}], "added": [{"line_no": 7, "char_start": 351, "char_end": 405, "line": "                  \"AND M2.acadYearAndSem LIKE %s\" + \\\n"}, {"line_no": 9, "char_start": 467, "char_end": 504, "line": "    processed_ay = selected_ay + \"%\"\n"}, {"line_no": 10, "char_start": 504, "char_end": 505, "line": "\n"}, {"line_no": 11, "char_start": 505, "char_end": 557, "line": "    DB_CURSOR.execute(sql_command, (processed_ay,))\n"}]}, "char_changes": {"deleted": [{"char_start": 397, "char_end": 420, "chars": "'\" + selected_ay + \"%' "}], "added": [{"char_start": 397, "char_end": 399, "chars": "%s"}, {"char_start": 467, "char_end": 505, "chars": "    processed_ay = selected_ay + \"%\"\n\n"}, {"char_start": 538, "char_end": 555, "chars": ", (processed_ay,)"}]}, "commit_link": "github.com/nus-mtp/cs-modify/commit/719faacc0cffcb9cba9b4a942b914f423f4913d4", "file_name": "components/model.py", "vul_type": "cwe-089"}
{"func_name": "get_mod_taken_together_with", "func_src_before": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = '\" + code + \"' AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command)\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "func_src_after": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = %s AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command, (code,))\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "line_changes": {"deleted": [{"line_no": 16, "char_start": 665, "char_end": 730, "line": "                \"WHERE sp1.moduleCode = '\" + code + \"' AND \" + \\\n"}, {"line_no": 23, "char_start": 1035, "char_end": 1070, "line": "    DB_CURSOR.execute(sql_command)\n"}], "added": [{"line_no": 16, "char_start": 665, "char_end": 718, "line": "                \"WHERE sp1.moduleCode = %s AND \" + \\\n"}, {"line_no": 23, "char_start": 1023, "char_end": 1067, "line": "    DB_CURSOR.execute(sql_command, (code,))\n"}]}, "char_changes": {"deleted": [{"char_start": 705, "char_end": 719, "chars": "'\" + code + \"'"}], "added": [{"char_start": 705, "char_end": 707, "chars": "%s"}, {"char_start": 1056, "char_end": 1065, "chars": ", (code,)"}]}, "commit_link": "github.com/nus-mtp/cs-modify/commit/79b4b1dd7eba5445751808e4c50b49d2dd08366b", "file_name": "components/model.py", "vul_type": "cwe-089"}
{"func_name": "updateAnswer", "func_src_before": "def updateAnswer(database, q_id, answer, update_type): \n\t'''\n\tAdds the provided question to the questions table in the given database. \n\t'''\n\tconn = dbConnect(database)\n\tcurs = conn.cursor(MySQLdb.cursors.DictCursor)\n\tstatement = \"SELECT * FROM questions WHERE id=\" + q_id # won't come from the user\n\tcurs.execute(statement)\n\trow = curs.fetchone() # only one result\n\ttimestamp = row['ts']\n\t# timestamp automatically changes on update - so you have to replace it with the old value\n\n\tif update_type == 'publish':\n\t\tstatement = \"update questions set status='completed', answer=%s, ts=%s where id=%s\"\n\t\t# change the status to completed\n\tif update_type == 'save': \n\t\tstatement = \"update questions set status='in-progress', answer=%s, ts=%s where id=%s\"\n\t\t# change the status to in-progress\n\n\tcurs.execute(statement, (answer, timestamp, q_id))", "func_src_after": "def updateAnswer(database, q_id, answer, update_type): \n\t'''\n\tAdds the provided question to the questions table in the given database. \n\t'''\n\tconn = dbConnect(database)\n\tcurs = conn.cursor(MySQLdb.cursors.DictCursor)\n\tstatement = \"SELECT * FROM questions WHERE id=%s\"\n\tcurs.execute(statement, q_id)\n\trow = curs.fetchone() # only one result\n\ttimestamp = row['ts']\n\t# timestamp automatically changes on update - so you have to replace it with the old value\n\tif update_type == 'publish':\n\t\tstatement = \"update questions set status='completed', answer=%s, ts=%s where id=%s\"\n\t\t# change the status to completed\n\tif update_type == 'save': \n\t\tstatement = \"update questions set status='in-progress', answer=%s, ts=%s where id=%s\"\n\t\t# change the status to in-progress\n\n\tcurs.execute(statement, (answer, timestamp, q_id))", "line_changes": {"deleted": [{"line_no": 7, "char_start": 217, "char_end": 300, "line": "\tstatement = \"SELECT * FROM questions WHERE id=\" + q_id # won't come from the user\n"}, {"line_no": 8, "char_start": 300, "char_end": 325, "line": "\tcurs.execute(statement)\n"}, {"line_no": 12, "char_start": 481, "char_end": 482, "line": "\n"}], "added": [{"line_no": 7, "char_start": 217, "char_end": 268, "line": "\tstatement = \"SELECT * FROM questions WHERE id=%s\"\n"}, {"line_no": 8, "char_start": 268, "char_end": 299, "line": "\tcurs.execute(statement, q_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 264, "char_end": 299, "chars": "\" + q_id # won't come from the user"}, {"char_start": 481, "char_end": 482, "chars": "\n"}], "added": [{"char_start": 264, "char_end": 267, "chars": "%s\""}, {"char_start": 291, "char_end": 297, "chars": ", q_id"}]}, "commit_link": "github.com/mantaleigh/SHE-nonymous/commit/c5abf0b5406753bd1dabba8ef0c5aed0f7e33eb5", "file_name": "answerQuestions.py", "vul_type": "cwe-089"}
{"func_name": "getQuestions", "func_src_before": "def getQuestions(database): \n\t'''\n\tReturns a list (ul) string of all of the questions in the questions table of the database\n\n\tTODO: Select only those questions that have an answer\n\n\t'''\n\tconn = dbConnect(database)\n\tcurs = conn.cursor(MySQLdb.cursors.DictCursor) # results as Dictionaries\n\tstatement = \"SELECT * FROM questions WHERE status='completed' ORDER BY ts DESC;\"\n\tcurs.execute(statement)\n\tlines = []\n\tlines.append(\"<ul>\")\n\twhile True:\n\t\trow = curs.fetchone()\n\t\tif row == None: \n\t\t\tlines.append(\"</ul>\")\n\t\t\treturn \"\\n\".join(lines)\n\t\tlines.append(\"<li>ID: {id}, TIMESTAMP: {ts} <br>QUESTION: {question}<br>Answer: {ans}\".format(id=row['id'], ts=row['ts'], question=row['question'], ans=row['answer']))", "func_src_after": "def getQuestions(database): \n\t'''\n\tReturns a list (ul) string of all of the questions in the questions table of the database\n\n\tTODO: Select only those questions that have an answer\n\n\t'''\n\tconn = dbConnect(database)\n\tcurs = conn.cursor(MySQLdb.cursors.DictCursor) # results as Dictionaries\n\tstatement = \"SELECT * FROM questions WHERE status='completed' ORDER BY ts DESC;\"\n\tcurs.execute(statement)\n\tlines = []\n\tlines.append(\"<ul>\")\n\twhile True:\n\t\trow = curs.fetchone()\n\t\tif row == None: \n\t\t\tlines.append(\"</ul>\")\n\t\t\treturn \"\\n\".join(lines)\n\t\tlines.append(\"<li>ID: {id}, TIMESTAMP: {ts} <br>QUESTION: {question}<br><br>ANSWER: {ans}\".format(id=row['id'], ts=row['ts'], question=row['question'], ans=row['answer']))", "line_changes": {"deleted": [{"line_no": 19, "char_start": 538, "char_end": 707, "line": "\t\tlines.append(\"<li>ID: {id}, TIMESTAMP: {ts} <br>QUESTION: {question}<br>Answer: {ans}\".format(id=row['id'], ts=row['ts'], question=row['question'], ans=row['answer']))\n"}], "added": [{"line_no": 19, "char_start": 538, "char_end": 711, "line": "\t\tlines.append(\"<li>ID: {id}, TIMESTAMP: {ts} <br>QUESTION: {question}<br><br>ANSWER: {ans}\".format(id=row['id'], ts=row['ts'], question=row['question'], ans=row['answer']))\n"}]}, "char_changes": {"deleted": [{"char_start": 612, "char_end": 618, "chars": "Answer"}], "added": [{"char_start": 612, "char_end": 622, "chars": "<br>ANSWER"}]}, "commit_link": "github.com/mantaleigh/SHE-nonymous/commit/c5abf0b5406753bd1dabba8ef0c5aed0f7e33eb5", "file_name": "index.py", "vul_type": "cwe-089"}
{"func_name": "get", "func_src_before": "    def get(self, request):\n        item = request.query_params.get('item')\n        city = request.query_params.get('city')\n\n        # If item and city are both excluded from the request, return\n        # a json blob with a status of 404.\n        if not item and not city:\n            return Response(NOT_FOUND_JSON_RESPONSE)\n\n        # Raw SQL using built-in mode() function within postgres\n        # Returns a single row with the highest most frequent list price and\n        # count of items found for the given search parameters.\n        sql = '''SELECT\n                    mode() WITHIN GROUP (ORDER BY list_price DESC) AS model_value,\n                    count(*)\n                 FROM\n                    \"itemPrices_itemsale\"\n              '''\n        if item and city:\n            sql = \"{} WHERE city = '{}' and title = '{}'\".format(sql, city, item)\n        elif item:\n            sql = \"{} WHERE title = '{}'\".format(sql, item)\n        elif city:\n            sql = \"{} WHERE city = '{}'\".format(sql, city)\n\n        with connection.cursor() as c:\n            c.execute(sql)\n            price_mode, count = c.fetchone()\n\n        # More traditional django ORM route of doing the above.\n        # The above seems to be slightly faster, based on the\n        # throughput I observed in jmeter, but is database specific.\n        # Adding caching and reworking the ORM query might be a better\n        # choice moving forward.\n\n        # query = ItemSale.objects\n        # if item:\n        #     query = query.filter(title__startswith=item)\n        # if city:\n        #     query = query.filter(city=city)\n\n        # # Get total item count for given parameters.\n        # count = query.count()\n\n        # Find list_price mode for given parameters.\n        # query = query.order_by('list_price').values('list_price').annotate(price_count=Count('list_price'))\n        # price_mode = query.order_by('-price_count', '-list_price').first()\n        # if price_mode:\n        #     price_mode = price_mode.get('list_price')\n\n        # If we didn't find anything, return 404 response, just as if item and\n        # city weren't passed in.\n        if count == 0:\n            return Response(NOT_FOUND_JSON_RESPONSE)\n\n        return Response({\n            'status': 200,\n            'content': {\n                'item': item or 'Not specified',\n                'item_count': count,\n                'price_suggestion': price_mode,\n                'city': city or 'Not specified',\n            }\n        })", "func_src_after": "    def get(self, request):\n        item = request.query_params.get('item')\n        city = request.query_params.get('city')\n\n        # If item and city are both excluded from the request, return\n        # a json blob with a status of 404.\n        if not item and not city:\n            return Response(NOT_FOUND_JSON_RESPONSE)\n\n        # Raw SQL using built-in mode() function within postgres\n        # Returns a single row with the highest most frequent list price and\n        # count of items found for the given search parameters.\n        #\n        # -- This code is unsafe and is vulnerable to sql injection. incoming\n        #    parameters need to be escaped in some manner to be safe to query on.\n        #\n        # sql = '''SELECT\n        #             mode() WITHIN GROUP (ORDER BY list_price DESC) AS model_value,\n        #             count(*)\n        #          FROM\n        #             \"itemPrices_itemsale\"\n        #       '''\n        # if item and city:\n        #     sql = \"{} WHERE city = '{}' and title = '{}'\".format(sql, city, item)\n        # elif item:\n        #     sql = \"{} WHERE title = '{}'\".format(sql, item)\n        # elif city:\n        #     sql = \"{} WHERE city = '{}'\".format(sql, city)\n\n        # with connection.cursor() as c:\n        #     c.execute(sql)\n        #     price_mode, count = c.fetchone()\n\n        # More traditional django ORM route of doing the above.\n        # The above seems to be slightly faster, based on the\n        # throughput I observed in jmeter, but is database specific.\n        # Adding caching and reworking the ORM query might be a better\n        # choice moving forward.\n\n        query = ItemSale.objects\n        if item:\n            query = query.filter(title__startswith=item)\n        if city:\n            query = query.filter(city=city)\n\n        # # Get total item count for given parameters.\n        count = query.count()\n\n        # Find list_price mode for given parameters.\n        query = query.order_by('list_price').values('list_price').annotate(price_count=Count('list_price'))\n        price_mode = query.order_by('-price_count', '-list_price').first()\n        if price_mode:\n            price_mode = price_mode.get('list_price')\n\n        # If we didn't find anything, return 404 response, just as if item and\n        # city weren't passed in.\n        if count == 0:\n            return Response(NOT_FOUND_JSON_RESPONSE)\n\n        return Response({\n            'status': 200,\n            'content': {\n                'item': item or 'Not specified',\n                'item_count': count,\n                'price_suggestion': price_mode,\n                'city': city or 'Not specified',\n            }\n        })", "line_changes": {"deleted": [{"line_no": 13, "char_start": 533, "char_end": 557, "line": "        sql = '''SELECT\n"}, {"line_no": 14, "char_start": 557, "char_end": 640, "line": "                    mode() WITHIN GROUP (ORDER BY list_price DESC) AS model_value,\n"}, {"line_no": 15, "char_start": 640, "char_end": 669, "line": "                    count(*)\n"}, {"line_no": 16, "char_start": 669, "char_end": 691, "line": "                 FROM\n"}, {"line_no": 17, "char_start": 691, "char_end": 733, "line": "                    \"itemPrices_itemsale\"\n"}, {"line_no": 18, "char_start": 733, "char_end": 751, "line": "              '''\n"}, {"line_no": 19, "char_start": 751, "char_end": 777, "line": "        if item and city:\n"}, {"line_no": 20, "char_start": 777, "char_end": 859, "line": "            sql = \"{} WHERE city = '{}' and title = '{}'\".format(sql, city, item)\n"}, {"line_no": 21, "char_start": 859, "char_end": 878, "line": "        elif item:\n"}, {"line_no": 22, "char_start": 878, "char_end": 938, "line": "            sql = \"{} WHERE title = '{}'\".format(sql, item)\n"}, {"line_no": 23, "char_start": 938, "char_end": 957, "line": "        elif city:\n"}, {"line_no": 24, "char_start": 957, "char_end": 1016, "line": "            sql = \"{} WHERE city = '{}'\".format(sql, city)\n"}, {"line_no": 26, "char_start": 1017, "char_end": 1056, "line": "        with connection.cursor() as c:\n"}, {"line_no": 27, "char_start": 1056, "char_end": 1083, "line": "            c.execute(sql)\n"}, {"line_no": 28, "char_start": 1083, "char_end": 1128, "line": "            price_mode, count = c.fetchone()\n"}], "added": [{"line_no": 40, "char_start": 1639, "char_end": 1672, "line": "        query = ItemSale.objects\n"}, {"line_no": 41, "char_start": 1672, "char_end": 1689, "line": "        if item:\n"}, {"line_no": 42, "char_start": 1689, "char_end": 1746, "line": "            query = query.filter(title__startswith=item)\n"}, {"line_no": 43, "char_start": 1746, "char_end": 1763, "line": "        if city:\n"}, {"line_no": 44, "char_start": 1763, "char_end": 1807, "line": "            query = query.filter(city=city)\n"}, {"line_no": 47, "char_start": 1863, "char_end": 1893, "line": "        count = query.count()\n"}, {"line_no": 50, "char_start": 1947, "char_end": 2055, "line": "        query = query.order_by('list_price').values('list_price').annotate(price_count=Count('list_price'))\n"}, {"line_no": 51, "char_start": 2055, "char_end": 2130, "line": "        price_mode = query.order_by('-price_count', '-list_price').first()\n"}, {"line_no": 52, "char_start": 2130, "char_end": 2153, "line": "        if price_mode:\n"}, {"line_no": 53, "char_start": 2153, "char_end": 2207, "line": "            price_mode = price_mode.get('list_price')\n"}]}, "char_changes": {"deleted": [{"char_start": 1436, "char_end": 1438, "chars": " #"}, {"char_start": 1471, "char_end": 1473, "chars": " #"}, {"char_start": 1491, "char_end": 1492, "chars": "#"}, {"char_start": 1496, "char_end": 1497, "chars": " "}, {"char_start": 1549, "char_end": 1551, "chars": " #"}, {"char_start": 1568, "char_end": 1570, "chars": " #"}, {"char_start": 1670, "char_end": 1672, "chars": " #"}, {"char_start": 1756, "char_end": 1758, "chars": " #"}, {"char_start": 1866, "char_end": 1868, "chars": " #"}, {"char_start": 1943, "char_end": 1945, "chars": " #"}, {"char_start": 1968, "char_end": 1970, "chars": " #"}], "added": [{"char_start": 540, "char_end": 722, "chars": " #\n        # -- This code is unsafe and is vulnerable to sql injection. incoming\n        #    parameters need to be escaped in some manner to be safe to query on.\n        #\n        #"}, {"char_start": 746, "char_end": 748, "chars": " #"}, {"char_start": 831, "char_end": 833, "chars": " #"}, {"char_start": 862, "char_end": 864, "chars": " #"}, {"char_start": 886, "char_end": 888, "chars": " #"}, {"char_start": 931, "char_end": 932, "chars": "#"}, {"char_start": 938, "char_end": 939, "chars": " "}, {"char_start": 950, "char_end": 952, "chars": " #"}, {"char_start": 978, "char_end": 980, "chars": " #"}, {"char_start": 1062, "char_end": 1064, "chars": " #"}, {"char_start": 1083, "char_end": 1085, "chars": " #"}, {"char_start": 1145, "char_end": 1147, "chars": " #"}, {"char_start": 1166, "char_end": 1168, "chars": " #"}, {"char_start": 1228, "char_end": 1230, "chars": " #"}, {"char_start": 1269, "char_end": 1271, "chars": " #"}, {"char_start": 1298, "char_end": 1300, "chars": " #"}]}, "commit_link": "github.com/nullpuppy/ouchallenge/commit/16ef753b2663923ef049747b8ca234d30ed8b263", "file_name": "ouchallenge/itemPrices/views.py", "vul_type": "cwe-089"}
{"func_name": "sanitize_fields", "func_src_before": "\tdef sanitize_fields(self):\n\t\t'''\n\t\t\tregex : ^.*[,();].*\n\t\t\tpurpose : The regex will look for malicious patterns like `,`, '(', ')', ';' in each\n\t\t\t\t\tfield which may leads to sql injection.\n\t\t\texample :\n\t\t\t\tfield = \"`DocType`.`issingle`, version()\"\n\n\t\t\tAs field contains `,` and mysql function `version()`, with the help of regex\n\t\t\tthe system will filter out this field.\n\t\t'''\n\t\tregex = re.compile('^.*[,();].*')\n\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n\t\tblacklisted_functions = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n\t\t\t'connection_id', 'current_user', 'database', 'last_insert_id', 'session_user',\n\t\t\t'system_user', 'user', 'version']\n\n\t\tdef _raise_exception():\n\t\t\tfrappe.throw(_('Cannot use sub-query or function in fields'), frappe.DataError)\n\n\t\tfor field in self.fields:\n\t\t\tif regex.match(field):\n\t\t\t\tif any(keyword in field.lower() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() \\\n\t\t\t\t\tfor keyword in blacklisted_functions):\n\t\t\t\t\t_raise_exception()", "func_src_after": "\tdef sanitize_fields(self):\n\t\t'''\n\t\t\tregex : ^.*[,();].*\n\t\t\tpurpose : The regex will look for malicious patterns like `,`, '(', ')', ';' in each\n\t\t\t\t\tfield which may leads to sql injection.\n\t\t\texample :\n\t\t\t\tfield = \"`DocType`.`issingle`, version()\"\n\n\t\t\tAs field contains `,` and mysql function `version()`, with the help of regex\n\t\t\tthe system will filter out this field.\n\t\t'''\n\n\t\tsub_query_regex = re.compile(\"^.*[,();].*\")\n\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n\t\tblacklisted_functions = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n\t\t\t'connection_id', 'current_user', 'database', 'last_insert_id', 'session_user',\n\t\t\t'system_user', 'user', 'version']\n\n\t\tdef _raise_exception():\n\t\t\tfrappe.throw(_('Cannot use sub-query or function in fields'), frappe.DataError)\n\n\t\tfor field in self.fields:\n\t\t\tif sub_query_regex.match(field):\n\t\t\t\tif any(keyword in field.lower().split() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"({0}\".format(keyword) in field.lower() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() for keyword in blacklisted_functions):\n\t\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile(\"[a-zA-Z]+\\s*'\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile('[a-zA-Z]+\\s*,').match(field):\n\t\t\t\t_raise_exception()", "line_changes": {"deleted": [{"line_no": 12, "char_start": 378, "char_end": 414, "line": "\t\tregex = re.compile('^.*[,();].*')\n"}, {"line_no": 22, "char_start": 852, "char_end": 878, "line": "\t\t\tif regex.match(field):\n"}, {"line_no": 23, "char_start": 878, "char_end": 952, "line": "\t\t\t\tif any(keyword in field.lower() for keyword in blacklisted_keywords):\n"}, {"line_no": 26, "char_start": 977, "char_end": 1030, "line": "\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() \\\n"}, {"line_no": 27, "char_start": 1030, "char_end": 1074, "line": "\t\t\t\t\tfor keyword in blacklisted_functions):\n"}], "added": [{"line_no": 12, "char_start": 378, "char_end": 379, "line": "\n"}, {"line_no": 13, "char_start": 379, "char_end": 425, "line": "\t\tsub_query_regex = re.compile(\"^.*[,();].*\")\n"}, {"line_no": 23, "char_start": 863, "char_end": 899, "line": "\t\t\tif sub_query_regex.match(field):\n"}, {"line_no": 24, "char_start": 899, "char_end": 981, "line": "\t\t\t\tif any(keyword in field.lower().split() for keyword in blacklisted_keywords):\n"}, {"line_no": 25, "char_start": 981, "char_end": 1005, "line": "\t\t\t\t\t_raise_exception()\n"}, {"line_no": 26, "char_start": 1005, "char_end": 1006, "line": "\n"}, {"line_no": 27, "char_start": 1006, "char_end": 1095, "line": "\t\t\t\tif any(\"({0}\".format(keyword) in field.lower() for keyword in blacklisted_keywords):\n"}, {"line_no": 30, "char_start": 1120, "char_end": 1210, "line": "\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() for keyword in blacklisted_functions):\n"}]}, "char_changes": {"deleted": [{"char_start": 399, "char_end": 400, "chars": "'"}, {"char_start": 411, "char_end": 412, "chars": "'"}, {"char_start": 992, "char_end": 993, "chars": "("}, {"char_start": 1028, "char_end": 1075, "chars": "\\\n\t\t\t\t\tfor keyword in blacklisted_functions):\n\t"}], "added": [{"char_start": 378, "char_end": 379, "chars": "\n"}, {"char_start": 381, "char_end": 391, "chars": "sub_query_"}, {"char_start": 410, "char_end": 411, "chars": "\""}, {"char_start": 422, "char_end": 423, "chars": "\""}, {"char_start": 869, "char_end": 879, "chars": "sub_query_"}, {"char_start": 934, "char_end": 942, "chars": ".split()"}, {"char_start": 1018, "char_end": 1019, "chars": "("}, {"char_start": 1057, "char_end": 1355, "chars": "for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() for keyword in blacklisted_functions):\n\t\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile(\"[a-zA-Z]+\\s*'\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile('[a-zA-Z]+\\s*,').match(field):\n"}]}, "commit_link": "github.com/omirajkar/bench_frappe/commit/e2b1ebe84cb848e79caef763594e45d734b86475", "file_name": "frappe/model/db_query.py", "vul_type": "cwe-089"}
{"func_name": "sanitize_searchfield", "func_src_before": "def sanitize_searchfield(searchfield):\n\tblacklisted_keywords = ['select', 'delete', 'drop', 'update', 'case', 'and', 'or', 'like']\n\n\tdef _raise_exception():\n\t\tfrappe.throw(_('Invalid Search Field'), frappe.DataError)\n\n\tif len(searchfield) >= 3:\n\n\t\t# to avoid 1=1\n\t\tif '=' in searchfield:\n\t\t\t_raise_exception()\n\n\t\t# in mysql -- is used for commenting the query\n\t\telif ' --' in searchfield:\n\t\t\t_raise_exception()\n\n\t\t# to avoid and, or and like\n\t\telif any(' {0} '.format(keyword) in searchfield.split() for keyword in blacklisted_keywords):\n\t\t\t_raise_exception()\n\n\t\t# to avoid select, delete, drop, update and case\n\t\telif any(keyword in searchfield.split() for keyword in blacklisted_keywords):\n\t\t\t_raise_exception()", "func_src_after": "def sanitize_searchfield(searchfield):\n\tblacklisted_keywords = ['select', 'delete', 'drop', 'update', 'case', 'and', 'or', 'like']\n\n\tdef _raise_exception(searchfield):\n\t\tfrappe.throw(_('Invalid Search Field {0}').format(searchfield), frappe.DataError)\n\n\tif len(searchfield) == 1:\n\t\t# do not allow special characters to pass as searchfields\n\t\tregex = re.compile('^.*[=;*,\\'\"$\\-+%#@()_].*')\n\t\tif regex.match(searchfield):\n\t\t\t_raise_exception(searchfield)\n\n\tif len(searchfield) >= 3:\n\n\t\t# to avoid 1=1\n\t\tif '=' in searchfield:\n\t\t\t_raise_exception(searchfield)\n\n\t\t# in mysql -- is used for commenting the query\n\t\telif ' --' in searchfield:\n\t\t\t_raise_exception(searchfield)\n\n\t\t# to avoid and, or and like\n\t\telif any(' {0} '.format(keyword) in searchfield.split() for keyword in blacklisted_keywords):\n\t\t\t_raise_exception(searchfield)\n\n\t\t# to avoid select, delete, drop, update and case\n\t\telif any(keyword in searchfield.split() for keyword in blacklisted_keywords):\n\t\t\t_raise_exception(searchfield)\n\n\t\telse:\n\t\t\tregex = re.compile('^.*[=;*,\\'\"$\\-+%#@()].*')\n\t\t\tif any(regex.match(f) for f in searchfield.split()):\n\t\t\t\t_raise_exception(searchfield)", "line_changes": {"deleted": [{"line_no": 11, "char_start": 288, "char_end": 310, "line": "\t\t\t_raise_exception()\n"}, {"line_no": 15, "char_start": 389, "char_end": 411, "line": "\t\t\t_raise_exception()\n"}, {"line_no": 19, "char_start": 538, "char_end": 560, "line": "\t\t\t_raise_exception()\n"}, {"line_no": 23, "char_start": 692, "char_end": 713, "line": "\t\t\t_raise_exception()\n"}], "added": [{"line_no": 17, "char_start": 524, "char_end": 557, "line": "\t\t\t_raise_exception(searchfield)\n"}, {"line_no": 21, "char_start": 636, "char_end": 669, "line": "\t\t\t_raise_exception(searchfield)\n"}, {"line_no": 25, "char_start": 796, "char_end": 829, "line": "\t\t\t_raise_exception(searchfield)\n"}, {"line_no": 29, "char_start": 961, "char_end": 994, "line": "\t\t\t_raise_exception(searchfield)\n"}, {"line_no": 30, "char_start": 994, "char_end": 995, "line": "\n"}, {"line_no": 31, "char_start": 995, "char_end": 1003, "line": "\t\telse:\n"}, {"line_no": 32, "char_start": 1003, "char_end": 1052, "line": "\t\t\tregex = re.compile('^.*[=;*,\\'\"$\\-+%#@()].*')\n"}, {"line_no": 33, "char_start": 1052, "char_end": 1108, "line": "\t\t\tif any(regex.match(f) for f in searchfield.split()):\n"}, {"line_no": 34, "char_start": 1108, "char_end": 1141, "line": "\t\t\t\t_raise_exception(searchfield)\n"}]}, "char_changes": {"deleted": [{"char_start": 195, "char_end": 215, "chars": "'), frappe.DataError"}, {"char_start": 692, "char_end": 692, "chars": ""}], "added": [{"char_start": 154, "char_end": 165, "chars": "searchfield"}, {"char_start": 206, "char_end": 451, "chars": " {0}').format(searchfield), frappe.DataError)\n\n\tif len(searchfield) == 1:\n\t\t# do not allow special characters to pass as searchfields\n\t\tregex = re.compile('^.*[=;*,\\'\"$\\-+%#@()_].*')\n\t\tif regex.match(searchfield):\n\t\t\t_raise_exception(searchfield"}, {"char_start": 544, "char_end": 555, "chars": "searchfield"}, {"char_start": 656, "char_end": 667, "chars": "searchfield"}, {"char_start": 816, "char_end": 827, "chars": "searchfield"}, {"char_start": 981, "char_end": 1140, "chars": "searchfield)\n\n\t\telse:\n\t\t\tregex = re.compile('^.*[=;*,\\'\"$\\-+%#@()].*')\n\t\t\tif any(regex.match(f) for f in searchfield.split()):\n\t\t\t\t_raise_exception(searchfield"}]}, "commit_link": "github.com/omirajkar/bench_frappe/commit/081b17fbe89f49acf6bd33a96d6845f1b9160eb7", "file_name": "frappe/desk/search.py", "vul_type": "cwe-089"}
{"func_name": "sanitize_fields", "func_src_before": "\tdef sanitize_fields(self):\n\t\t'''\n\t\t\tregex : ^.*[,();].*\n\t\t\tpurpose : The regex will look for malicious patterns like `,`, '(', ')', ';' in each\n\t\t\t\t\tfield which may leads to sql injection.\n\t\t\texample :\n\t\t\t\tfield = \"`DocType`.`issingle`, version()\"\n\n\t\t\tAs field contains `,` and mysql function `version()`, with the help of regex\n\t\t\tthe system will filter out this field.\n\t\t'''\n\n\t\tsub_query_regex = re.compile(\"^.*[,();].*\")\n\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n\t\tblacklisted_functions = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n\t\t\t'connection_id', 'current_user', 'database', 'last_insert_id', 'session_user',\n\t\t\t'system_user', 'user', 'version']\n\n\t\tdef _raise_exception():\n\t\t\tfrappe.throw(_('Cannot use sub-query or function in fields'), frappe.DataError)\n\n\t\tfor field in self.fields:\n\t\t\tif sub_query_regex.match(field):\n\t\t\t\tif any(keyword in field.lower().split() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"({0}\".format(keyword) in field.lower() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() for keyword in blacklisted_functions):\n\t\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile(\"[a-zA-Z]+\\s*'\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile('[a-zA-Z]+\\s*,').match(field):\n\t\t\t\t_raise_exception()", "func_src_after": "\tdef sanitize_fields(self):\n\t\t'''\n\t\t\tregex : ^.*[,();].*\n\t\t\tpurpose : The regex will look for malicious patterns like `,`, '(', ')', ';' in each\n\t\t\t\t\tfield which may leads to sql injection.\n\t\t\texample :\n\t\t\t\tfield = \"`DocType`.`issingle`, version()\"\n\n\t\t\tAs field contains `,` and mysql function `version()`, with the help of regex\n\t\t\tthe system will filter out this field.\n\t\t'''\n\n\t\tsub_query_regex = re.compile(\"^.*[,();].*\")\n\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case',\n\t\t\t'from', 'group', 'order', 'by']\n\t\tblacklisted_functions = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n\t\t\t'connection_id', 'current_user', 'database', 'last_insert_id', 'session_user',\n\t\t\t'system_user', 'user', 'version']\n\n\t\tdef _raise_exception():\n\t\t\tfrappe.throw(_('Use of sub-query or function is restricted'), frappe.DataError)\n\n\t\tdef _is_query(field):\n\t\t\tif re.compile(\"^(select|delete|update|drop|create)\\s\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\telif re.compile(\"\\s*[a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\tfor field in self.fields:\n\t\t\tif sub_query_regex.match(field):\n\t\t\t\tif any(keyword in field.lower().split() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"({0}\".format(keyword) in field.lower() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() for keyword in blacklisted_functions):\n\t\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile(\"[a-zA-Z]+\\s*'\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile('[a-zA-Z]+\\s*,').match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\t_is_query(field)", "line_changes": {"deleted": [{"line_no": 14, "char_start": 425, "char_end": 517, "line": "\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n"}, {"line_no": 20, "char_start": 751, "char_end": 834, "line": "\t\t\tfrappe.throw(_('Cannot use sub-query or function in fields'), frappe.DataError)\n"}], "added": [{"line_no": 14, "char_start": 425, "char_end": 517, "line": "\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case',\n"}, {"line_no": 15, "char_start": 517, "char_end": 552, "line": "\t\t\t'from', 'group', 'order', 'by']\n"}, {"line_no": 21, "char_start": 786, "char_end": 869, "line": "\t\t\tfrappe.throw(_('Use of sub-query or function is restricted'), frappe.DataError)\n"}, {"line_no": 22, "char_start": 869, "char_end": 870, "line": "\n"}, {"line_no": 23, "char_start": 870, "char_end": 894, "line": "\t\tdef _is_query(field):\n"}, {"line_no": 24, "char_start": 894, "char_end": 966, "line": "\t\t\tif re.compile(\"^(select|delete|update|drop|create)\\s\").match(field):\n"}, {"line_no": 25, "char_start": 966, "char_end": 989, "line": "\t\t\t\t_raise_exception()\n"}, {"line_no": 26, "char_start": 989, "char_end": 990, "line": "\n"}, {"line_no": 27, "char_start": 990, "char_end": 1087, "line": "\t\t\telif re.compile(\"\\s*[a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n"}, {"line_no": 28, "char_start": 1087, "char_end": 1110, "line": "\t\t\t\t_raise_exception()\n"}]}, "char_changes": {"deleted": [{"char_start": 517, "char_end": 517, "chars": ""}, {"char_start": 770, "char_end": 780, "chars": "Cannot use"}, {"char_start": 804, "char_end": 812, "chars": "n fields"}, {"char_start": 1355, "char_end": 1355, "chars": ""}], "added": [{"char_start": 515, "char_end": 550, "chars": ",\n\t\t\t'from', 'group', 'order', 'by'"}, {"char_start": 805, "char_end": 811, "chars": "Use of"}, {"char_start": 835, "char_end": 847, "chars": "s restricted"}, {"char_start": 870, "char_end": 1111, "chars": "\t\tdef _is_query(field):\n\t\t\tif re.compile(\"^(select|delete|update|drop|create)\\s\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\telif re.compile(\"\\s*[a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n\t\t\t\t_raise_exception()\n\n"}, {"char_start": 1653, "char_end": 1674, "chars": "\n\n\t\t\t_is_query(field)"}]}, "commit_link": "github.com/omirajkar/bench_frappe/commit/a1e68b6fd5617b70ba4c163ac1b84851fbd17aeb", "file_name": "frappe/model/db_query.py", "vul_type": "cwe-089"}
{"func_name": "sanitize_fields", "func_src_before": "\tdef sanitize_fields(self):\n\t\t'''\n\t\t\tregex : ^.*[,();].*\n\t\t\tpurpose : The regex will look for malicious patterns like `,`, '(', ')', ';' in each\n\t\t\t\t\tfield which may leads to sql injection.\n\t\t\texample :\n\t\t\t\tfield = \"`DocType`.`issingle`, version()\"\n\n\t\t\tAs field contains `,` and mysql function `version()`, with the help of regex\n\t\t\tthe system will filter out this field.\n\t\t'''\n\n\t\tsub_query_regex = re.compile(\"^.*[,();].*\")\n\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case',\n\t\t\t'from', 'group', 'order', 'by']\n\t\tblacklisted_functions = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n\t\t\t'connection_id', 'current_user', 'database', 'last_insert_id', 'session_user',\n\t\t\t'system_user', 'user', 'version']\n\n\t\tdef _raise_exception():\n\t\t\tfrappe.throw(_('Use of sub-query or function is restricted'), frappe.DataError)\n\n\t\tdef _is_query(field):\n\t\t\tif re.compile(\"^(select|delete|update|drop|create)\\s\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\telif re.compile(\"\\s*[a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\tfor field in self.fields:\n\t\t\tif sub_query_regex.match(field):\n\t\t\t\tif any(keyword in field.lower().split() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"({0}\".format(keyword) in field.lower() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() for keyword in blacklisted_functions):\n\t\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile(\"[a-zA-Z]+\\s*'\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile('[a-zA-Z]+\\s*,').match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\t_is_query(field)", "func_src_after": "\tdef sanitize_fields(self):\n\t\t'''\n\t\t\tregex : ^.*[,();].*\n\t\t\tpurpose : The regex will look for malicious patterns like `,`, '(', ')', ';' in each\n\t\t\t\t\tfield which may leads to sql injection.\n\t\t\texample :\n\t\t\t\tfield = \"`DocType`.`issingle`, version()\"\n\n\t\t\tAs field contains `,` and mysql function `version()`, with the help of regex\n\t\t\tthe system will filter out this field.\n\t\t'''\n\n\t\tsub_query_regex = re.compile(\"^.*[,();].*\")\n\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n\t\tblacklisted_functions = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n\t\t\t'connection_id', 'current_user', 'database', 'last_insert_id', 'session_user',\n\t\t\t'system_user', 'user', 'version']\n\n\t\tdef _raise_exception():\n\t\t\tfrappe.throw(_('Use of sub-query or function is restricted'), frappe.DataError)\n\n\t\tdef _is_query(field):\n\t\t\tif re.compile(\"^(select|delete|update|drop|create)\\s\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\telif re.compile(\"\\s*[a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\tfor field in self.fields:\n\t\t\tif sub_query_regex.match(field):\n\t\t\t\tif any(keyword in field.lower().split() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"({0}\".format(keyword) in field.lower() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() for keyword in blacklisted_functions):\n\t\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile(\"[a-zA-Z]+\\s*'\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile('[a-zA-Z]+\\s*,').match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\t_is_query(field)", "line_changes": {"deleted": [{"line_no": 14, "char_start": 425, "char_end": 517, "line": "\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case',\n"}, {"line_no": 15, "char_start": 517, "char_end": 552, "line": "\t\t\t'from', 'group', 'order', 'by']\n"}], "added": [{"line_no": 14, "char_start": 425, "char_end": 517, "line": "\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n"}]}, "char_changes": {"deleted": [{"char_start": 515, "char_end": 550, "chars": ",\n\t\t\t'from', 'group', 'order', 'by'"}], "added": []}, "commit_link": "github.com/omirajkar/bench_frappe/commit/856a721073122a8e487a13ba50b97a8b90916e12", "file_name": "frappe/model/db_query.py", "vul_type": "cwe-089"}
{"func_name": "sanitize_fields", "func_src_before": "\tdef sanitize_fields(self):\n\t\t'''\n\t\t\tregex : ^.*[,();].*\n\t\t\tpurpose : The regex will look for malicious patterns like `,`, '(', ')', ';' in each\n\t\t\t\t\tfield which may leads to sql injection.\n\t\t\texample :\n\t\t\t\tfield = \"`DocType`.`issingle`, version()\"\n\n\t\t\tAs field contains `,` and mysql function `version()`, with the help of regex\n\t\t\tthe system will filter out this field.\n\t\t'''\n\n\t\tsub_query_regex = re.compile(\"^.*[,();].*\")\n\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n\t\tblacklisted_functions = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n\t\t\t'connection_id', 'current_user', 'database', 'last_insert_id', 'session_user',\n\t\t\t'system_user', 'user', 'version']\n\n\t\tdef _raise_exception():\n\t\t\tfrappe.throw(_('Use of sub-query or function is restricted'), frappe.DataError)\n\n\t\tdef _is_query(field):\n\t\t\tif re.compile(\"^(select|delete|update|drop|create)\\s\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\telif re.compile(\"\\s*[a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\tfor field in self.fields:\n\t\t\tif sub_query_regex.match(field):\n\t\t\t\tif any(keyword in field.lower().split() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"({0}\".format(keyword) in field.lower() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() for keyword in blacklisted_functions):\n\t\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile(\"[a-zA-Z]+\\s*'\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile('[a-zA-Z]+\\s*,').match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\t_is_query(field)", "func_src_after": "\tdef sanitize_fields(self):\n\t\t'''\n\t\t\tregex : ^.*[,();].*\n\t\t\tpurpose : The regex will look for malicious patterns like `,`, '(', ')', ';' in each\n\t\t\t\t\tfield which may leads to sql injection.\n\t\t\texample :\n\t\t\t\tfield = \"`DocType`.`issingle`, version()\"\n\n\t\t\tAs field contains `,` and mysql function `version()`, with the help of regex\n\t\t\tthe system will filter out this field.\n\t\t'''\n\n\t\tsub_query_regex = re.compile(\"^.*[,();].*\")\n\t\tblacklisted_keywords = ['select', 'create', 'insert', 'delete', 'drop', 'update', 'case']\n\t\tblacklisted_functions = ['concat', 'concat_ws', 'if', 'ifnull', 'nullif', 'coalesce',\n\t\t\t'connection_id', 'current_user', 'database', 'last_insert_id', 'session_user',\n\t\t\t'system_user', 'user', 'version']\n\n\t\tdef _raise_exception():\n\t\t\tfrappe.throw(_('Use of sub-query or function is restricted'), frappe.DataError)\n\n\t\tdef _is_query(field):\n\t\t\tif re.compile(\"^(select|delete|update|drop|create)\\s\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\telif re.compile(\"\\s*[0-9a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\tfor field in self.fields:\n\t\t\tif sub_query_regex.match(field):\n\t\t\t\tif any(keyword in field.lower().split() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"({0}\".format(keyword) in field.lower() for keyword in blacklisted_keywords):\n\t\t\t\t\t_raise_exception()\n\n\t\t\t\tif any(\"{0}(\".format(keyword) in field.lower() for keyword in blacklisted_functions):\n\t\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile(\"[0-9a-zA-Z]+\\s*'\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\tif re.compile('[0-9a-zA-Z]+\\s*,').match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\t_is_query(field)", "line_changes": {"deleted": [{"line_no": 40, "char_start": 1476, "char_end": 1524, "line": "\t\t\tif re.compile(\"[a-zA-Z]+\\s*'\").match(field):\n"}, {"line_no": 43, "char_start": 1548, "char_end": 1596, "line": "\t\t\tif re.compile('[a-zA-Z]+\\s*,').match(field):\n"}], "added": [{"line_no": 40, "char_start": 1479, "char_end": 1530, "line": "\t\t\tif re.compile(\"[0-9a-zA-Z]+\\s*'\").match(field):\n"}, {"line_no": 43, "char_start": 1554, "char_end": 1605, "line": "\t\t\tif re.compile('[0-9a-zA-Z]+\\s*,').match(field):\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 979, "char_end": 982, "chars": "0-9"}, {"char_start": 1498, "char_end": 1501, "chars": "0-9"}, {"char_start": 1573, "char_end": 1576, "chars": "0-9"}]}, "commit_link": "github.com/omirajkar/bench_frappe/commit/4738a9711a40a49645946c8765e99da37394f94b", "file_name": "frappe/model/db_query.py", "vul_type": "cwe-089"}
{"func_name": "sanitize_fields._is_query", "func_src_before": "\t\tdef _is_query(field):\n\t\t\tif re.compile(\"^(select|delete|update|drop|create)\\s\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\telif re.compile(\"\\s*[a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n\t\t\t\t_raise_exception()", "func_src_after": "\t\tdef _is_query(field):\n\t\t\tif re.compile(\"^(select|delete|update|drop|create)\\s\").match(field):\n\t\t\t\t_raise_exception()\n\n\t\t\telif re.compile(\"\\s*[0-9a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n\t\t\t\t_raise_exception()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 120, "char_end": 217, "line": "\t\t\telif re.compile(\"\\s*[a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n"}], "added": [{"line_no": 5, "char_start": 120, "char_end": 220, "line": "\t\t\telif re.compile(\"\\s*[0-9a-zA-z]*\\s*( from | group by | order by | where | join )\").match(field):\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 144, "char_end": 147, "chars": "0-9"}]}, "commit_link": "github.com/omirajkar/bench_frappe/commit/4738a9711a40a49645946c8765e99da37394f94b", "file_name": "frappe/model/db_query.py", "vul_type": "cwe-089"}
{"func_name": "actors_filtered", "func_src_before": "@app.route('/actors/condition2')\ndef actors_filtered():\n    '''\n    Find the names (first and last) of all the actors and customers whose\n    first name is the same as the first name of the actor with ID 8.\n    Do not return the actor with ID 8 himself.\n    Note that you cannot use the name of the actor with ID 8 as a constant\n    (only the ID)\n    '''\n    cur.execute(f\"\"\"\n                    SELECT\n                        a.first_name a_first_name,\n                        a.last_name a_last_name,\n                        c.first_name c_first_name,\n                        c.last_name c_last_name\n                    FROM\n                        actor a\n                    INNER JOIN\n                        customer c ON a.first_name = c.first_name\n                    WHERE a.first_name IN (\n                        SELECT a.first_name from actor a WHERE actor_id = 8\n                    )\n                \"\"\"\n    )\n    res = cur.fetchall()\n    result_list = []\n    for row in res:\n        result_list.append(row[:2])\n        result_list.append(row[2:])\n    actor_8 = result_list.pop(0) # remove the actor with id 8 who is the first match\n    results = list(set(result_list))\n    return render_template('actors.html', title='Actors', actors=results)", "func_src_after": "@app.route('/actors/condition2')\ndef actors_filtered():\n    '''\n    Find the names (first and last) of all the actors and customers whose\n    first name is the same as the first name of the actor with ID 8.\n    Do not return the actor with ID 8 himself.\n    Note that you cannot use the name of the actor with ID 8 as a constant\n    (only the ID)\n    '''\n    cur.execute(\"\"\"\n                    SELECT\n                        a.first_name a_first_name,\n                        a.last_name a_last_name,\n                        c.first_name c_first_name,\n                        c.last_name c_last_name\n                    FROM\n                        actor a\n                    INNER JOIN\n                        customer c ON a.first_name = c.first_name\n                    WHERE a.first_name IN (\n                        SELECT a.first_name from actor a WHERE actor_id = 8\n                    )\n                \"\"\"\n    )\n    res = cur.fetchall()\n    result_list = []\n    for row in res:\n        result_list.append(row[:2])\n        result_list.append(row[2:])\n    actor_8 = result_list.pop(0) # remove the actor with id 8 who is the first match\n    results = list(set(result_list))\n    return render_template('actors.html', title='Actors', actors=results)", "line_changes": {"deleted": [{"line_no": 10, "char_start": 355, "char_end": 376, "line": "    cur.execute(f\"\"\"\n"}], "added": [{"line_no": 10, "char_start": 355, "char_end": 375, "line": "    cur.execute(\"\"\"\n"}]}, "char_changes": {"deleted": [{"char_start": 371, "char_end": 372, "chars": "f"}], "added": []}, "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "categories_filtered", "func_src_before": "@app.route('/categories/condition3')\ndef categories_filtered():\n    '''b\n    Find all the film categories in which there are between 55 and 65 films.\n    Return the names of these categories and the number of films per category, sorted by the number of films.\n    '''\n    cur.execute(f\"\"\"\n                    select c.name, COUNT(fc.film_id) as num_film\n                    from category c\n                    join film_category fc\n                    ON c.category_id = fc.category_id\n                    GROUP BY c.name\n                    HAVING COUNT(fc.film_id) BETWEEN 55 AND 65\n                    ORDER BY COUNT(fc.film_id) DESC\n                \"\"\"\n    )\n    res = cur.fetchall()\n    data = json.dumps(res)\n    return render_template('categories.html', title='Categories', categories=res)", "func_src_after": "@app.route('/categories/condition3')\ndef categories_filtered():\n    '''b\n    Find all the film categories in which there are between 55 and 65 films.\n    Return the names of these categories and the number of films per category, sorted by the number of films.\n    '''\n    cur.execute(\"\"\"\n                    select c.name, COUNT(fc.film_id) as num_film\n                    from category c\n                    join film_category fc\n                    ON c.category_id = fc.category_id\n                    GROUP BY c.name\n                    HAVING COUNT(fc.film_id) BETWEEN 55 AND 65\n                    ORDER BY COUNT(fc.film_id) DESC\n                \"\"\"\n    )\n    res = cur.fetchall()\n    data = json.dumps(res)\n    return render_template('categories.html', title='Categories', categories=res)", "line_changes": {"deleted": [{"line_no": 7, "char_start": 268, "char_end": 289, "line": "    cur.execute(f\"\"\"\n"}], "added": [{"line_no": 7, "char_start": 268, "char_end": 288, "line": "    cur.execute(\"\"\"\n"}]}, "char_changes": {"deleted": [{"char_start": 284, "char_end": 285, "chars": "f"}], "added": []}, "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "search_films", "func_src_before": "@app.route('/movies/search', methods=['GET', 'POST'])\ndef search_films():\n    form = SearchForm()\n    if not form.validate_on_submit():\n        return render_template('search.html', title='Search for films', form=form)\n    search_terms = form.data['term'].split(' ')\n    search_string = ' & '.join(search_terms)\n    cur.execute(f\"SELECT * FROM film where fulltext @@ to_tsquery('{search_string}')\")\n    res = cur.fetchall()\n    return render_template('search_results.html', title='Home', res=len(res))", "func_src_after": "@app.route('/movies/search', methods=['GET', 'POST'])\ndef search_films():\n    form = SearchForm()\n    if not form.validate_on_submit():\n        return render_template('search.html', title='Search for films', form=form)\n    search_terms = form.data['term'].split(' ')\n    search_string = ' & '.join(search_terms)\n    cur.execute(\"SELECT * FROM film where fulltext @@ to_tsquery(%s)\", (search_string, ))\n    res = cur.fetchall()\n    return render_template('search_results.html', title='Home', res=len(res))", "line_changes": {"deleted": [{"line_no": 8, "char_start": 312, "char_end": 399, "line": "    cur.execute(f\"SELECT * FROM film where fulltext @@ to_tsquery('{search_string}')\")\n"}], "added": [{"line_no": 8, "char_start": 312, "char_end": 402, "line": "    cur.execute(\"SELECT * FROM film where fulltext @@ to_tsquery(%s)\", (search_string, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 328, "char_end": 329, "chars": "f"}, {"char_start": 378, "char_end": 380, "chars": "'{"}, {"char_start": 393, "char_end": 397, "chars": "}')\""}], "added": [{"char_start": 377, "char_end": 384, "chars": "%s)\", ("}, {"char_start": 397, "char_end": 400, "chars": ", )"}]}, "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "add_movie", "func_src_before": "@app.route('/movies/add', methods=['GET', 'POST'])\ndef add_movie():\n    form = MovieForm()\n    if not form.validate_on_submit():\n        return render_template('new_movie.html', title='Add New Movie', form=form)\n    lang_id = add_language(form.data['language'])\n    movie = {\n            'title': '',\n            'description': '',\n            'release_year': 0,\n            'rental_duration': 0,\n            'rental_rate': 0.00,\n            'length': 0,\n            'replacement_cost': 0.00\n        }\n    for k, v in movie.items():\n        movie[k] = form.data[k]\n    movie['language_id'] = movie.get('language_id', lang_id)\n    cur.execute(\n        \"\"\"\n        INSERT INTO film (title, description, release_year, language_id, rental_duration, rental_rate, length, replacement_cost)\n        VALUES ('{}', '{}', {}, {}, {}, {}, {}, {})\n        \"\"\".format(*[v for k, v in movie.items()])\n    )\n    try:\n        cur.execute(f\"SELECT * FROM film where fulltext @@ to_tsquery('Dark Knight')\")\n        res = cur.fetchall()\n        conn.commit()\n        return redirect(url_for('movies'))\n    except Exception as e:\n        return redirect(url_for('index'))", "func_src_after": "@app.route('/movies/add', methods=['GET', 'POST'])\ndef add_movie():\n    form = MovieForm()\n    if not form.validate_on_submit():\n        return render_template('new_movie.html', title='Add New Movie', form=form)\n    lang_id = add_language(form.data['language'])\n    movie = {\n            'title': '',\n            'description': '',\n            'release_year': 0,\n            'rental_duration': 0,\n            'rental_rate': 0.00,\n            'length': 0,\n            'replacement_cost': 0.00\n        }\n    for k, v in movie.items():\n        movie[k] = form.data[k]\n    movie['language_id'] = movie.get('language_id', lang_id)\n    cur.execute(\n        \"\"\"\n        INSERT INTO film (title, description, release_year, language_id, rental_duration, rental_rate, length, replacement_cost)\n        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n        \"\"\", [(v, ) for k, v in movie.items()]\n    )\n    try:\n        cur.execute(\"SELECT * FROM film where fulltext @@ to_tsquery(%s)\", (movie['title'], ))\n        res = cur.fetchall()\n        conn.commit()\n        return redirect(url_for('movies'))\n    except Exception as e:\n        return redirect(url_for('index'))", "line_changes": {"deleted": [{"line_no": 22, "char_start": 784, "char_end": 836, "line": "        VALUES ('{}', '{}', {}, {}, {}, {}, {}, {})\n"}, {"line_no": 23, "char_start": 836, "char_end": 887, "line": "        \"\"\".format(*[v for k, v in movie.items()])\n"}, {"line_no": 26, "char_start": 902, "char_end": 989, "line": "        cur.execute(f\"SELECT * FROM film where fulltext @@ to_tsquery('Dark Knight')\")\n"}], "added": [{"line_no": 22, "char_start": 784, "char_end": 832, "line": "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n"}, {"line_no": 23, "char_start": 832, "char_end": 879, "line": "        \"\"\", [(v, ) for k, v in movie.items()]\n"}, {"line_no": 26, "char_start": 894, "char_end": 989, "line": "        cur.execute(\"SELECT * FROM film where fulltext @@ to_tsquery(%s)\", (movie['title'], ))\n"}]}, "char_changes": {"deleted": [{"char_start": 800, "char_end": 834, "chars": "'{}', '{}', {}, {}, {}, {}, {}, {}"}, {"char_start": 847, "char_end": 858, "chars": ".format(*[v"}, {"char_start": 885, "char_end": 886, "chars": ")"}, {"char_start": 922, "char_end": 923, "chars": "f"}, {"char_start": 972, "char_end": 987, "chars": "'Dark Knight')\""}], "added": [{"char_start": 800, "char_end": 830, "chars": "%s, %s, %s, %s, %s, %s, %s, %s"}, {"char_start": 843, "char_end": 851, "chars": ", [(v, )"}, {"char_start": 963, "char_end": 987, "chars": "%s)\", (movie['title'], )"}]}, "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "add_language", "func_src_before": "def add_language(lang):\n    try:\n        cur.execute(f\"INSERT INTO language (name) VALUES ('{lang}')\")\n    except Exception as e:\n        pass\n    cur.execute(f\"SELECT language_id FROM language where name='{lang}'\")\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "func_src_after": "def add_language(lang):\n    try:\n        cur.execute(\"INSERT INTO language (name) VALUES (%s)\", (lang, ))\n    except Exception as e:\n        pass\n    cur.execute(\"SELECT language_id FROM language where name=%s\", (lang, ))\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "line_changes": {"deleted": [{"line_no": 3, "char_start": 33, "char_end": 103, "line": "        cur.execute(f\"INSERT INTO language (name) VALUES ('{lang}')\")\n"}, {"line_no": 6, "char_start": 143, "char_end": 216, "line": "    cur.execute(f\"SELECT language_id FROM language where name='{lang}'\")\n"}], "added": [{"line_no": 3, "char_start": 33, "char_end": 106, "line": "        cur.execute(\"INSERT INTO language (name) VALUES (%s)\", (lang, ))\n"}, {"line_no": 6, "char_start": 146, "char_end": 222, "line": "    cur.execute(\"SELECT language_id FROM language where name=%s\", (lang, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 53, "char_end": 54, "chars": "f"}, {"char_start": 91, "char_end": 101, "chars": "'{lang}')\""}, {"char_start": 159, "char_end": 160, "chars": "f"}, {"char_start": 205, "char_end": 207, "chars": "'{"}, {"char_start": 211, "char_end": 214, "chars": "}'\""}], "added": [{"char_start": 90, "char_end": 104, "chars": "%s)\", (lang, )"}, {"char_start": 207, "char_end": 213, "chars": "%s\", ("}, {"char_start": 217, "char_end": 220, "chars": ", )"}]}, "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089"}
{"func_name": "get_result", "func_src_before": "def get_result(project_id, query_name, query_params={}, query_dir='bqsql', cache_dir='bqcache', reload=False):\n\n    # compute file name and params hash\n    qhash = query_hash(project_id, query_name, **query_params)\n\n    # check if hash.pkl file exists or reload\n    cache_file_name = os.path.join(cache_dir, \"{}.pkl\".format(qhash))\n\n    if not reload and os.path.exists(cache_file_name):\n        res = pd.read_pickle(cache_file_name)\n    else:\n\n        # read query from file\n        query_fn = os.path.join(query_dir, \"{}.sql\".format(query_name))\n        with open(query_fn, 'r') as query_f:\n            query_templ = query_f.read()\n\n        # substitute parameters\n        query_str = query_templ.format(**query_params)\n\n        res = pd.io.gbq.read_gbq(query_str, project_id=project_id, dialect=\"standard\")\n\n        os.makedirs(cache_dir, exist_ok=True)\n        res.to_pickle(cache_file_name)\n\n    return res", "func_src_after": "def get_result(project_id, query_name, query_params={}, query_dir='bqsql', cache_dir='bqcache', reload=False):\n\n    # compute file name and params hash\n    qhash = query_hash(project_id, query_name, **query_params)\n\n    # check if hash.pkl file exists or reload\n    cache_file_name = os.path.join(cache_dir, \"{}.pkl\".format(qhash))\n\n    if not reload and os.path.exists(cache_file_name):\n        res = pd.read_pickle(cache_file_name)\n    else:\n\n        # read query from file\n        query_fn = os.path.join(query_dir, \"{}.sql\".format(query_name))\n        with open(query_fn, 'r') as query_f:\n            query_templ = query_f.read()\n\n        # substitute parameters\n        safe_params = escape_params(query_params)\n        query_str = query_templ.format(**safe_params)\n\n        res = pd.io.gbq.read_gbq(query_str, project_id=project_id, dialect=\"standard\")\n\n        os.makedirs(cache_dir, exist_ok=True)\n        res.to_pickle(cache_file_name)\n\n    return res", "line_changes": {"deleted": [{"line_no": 19, "char_start": 667, "char_end": 722, "line": "        query_str = query_templ.format(**query_params)\n"}, {"line_no": 26, "char_start": 897, "char_end": 911, "line": "    return res\n"}], "added": [{"line_no": 19, "char_start": 667, "char_end": 717, "line": "        safe_params = escape_params(query_params)\n"}, {"line_no": 20, "char_start": 717, "char_end": 771, "line": "        query_str = query_templ.format(**safe_params)\n"}]}, "char_changes": {"deleted": [{"char_start": 708, "char_end": 713, "chars": "query"}], "added": [{"char_start": 667, "char_end": 717, "chars": "        safe_params = escape_params(query_params)\n"}, {"char_start": 758, "char_end": 762, "chars": "safe"}]}, "commit_link": "github.com/philya/ljbq/commit/772cc371808aa2563e0bf37d24b76bb31e9d745b", "file_name": "ljbq/__init__.py", "vul_type": "cwe-089"}
{"func_name": "dbtables_to_csv", "func_src_before": "def dbtables_to_csv():\n    with create_connection() as conn:\n        table_names = conn.cursor().execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n    table_names = [x[0] for x in table_names]\n    open_query = \"SELECT * FROM {}\"\n    for table in table_names:\n        with create_connection() as conn:\n            pd.read_sql(open_query.format(table), conn).to_csv('{}.csv'.format(table), index=False)", "func_src_after": "def dbtables_to_csv():\n    with create_connection() as conn:\n        table_names = conn.cursor().execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n    table_names = [x[0] for x in table_names]\n    open_query = \"SELECT * FROM ?\"\n    for table in table_names:\n        with create_connection() as conn:\n            pd.read_sql(open_query, conn, params=[table]).to_csv(f'{table}.csv', index=False)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 216, "char_end": 252, "line": "    open_query = \"SELECT * FROM {}\"\n"}, {"line_no": 8, "char_start": 324, "char_end": 423, "line": "            pd.read_sql(open_query.format(table), conn).to_csv('{}.csv'.format(table), index=False)\n"}], "added": [{"line_no": 5, "char_start": 216, "char_end": 251, "line": "    open_query = \"SELECT * FROM ?\"\n"}, {"line_no": 8, "char_start": 323, "char_end": 416, "line": "            pd.read_sql(open_query, conn, params=[table]).to_csv(f'{table}.csv', index=False)\n"}]}, "char_changes": {"deleted": [{"char_start": 248, "char_end": 250, "chars": "{}"}, {"char_start": 358, "char_end": 378, "chars": ".format(table), conn"}, {"char_start": 395, "char_end": 409, "chars": ".format(table)"}], "added": [{"char_start": 248, "char_end": 249, "chars": "?"}, {"char_start": 357, "char_end": 379, "chars": ", conn, params=[table]"}, {"char_start": 388, "char_end": 389, "chars": "f"}, {"char_start": 391, "char_end": 396, "chars": "table"}]}, "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "db_tools.py", "vul_type": "cwe-089"}
{"func_name": "process_as_form", "func_src_before": "def process_as_form(email_obj):\n    dict_input = {\n        unquote(x.split('=')[0]):str(unquote(x.split('=')[1])).replace('+', ' ') for x in email_obj['content'].split('&')}\n    job_number = dict_input['job_number']\n    with create_connection() as conn:\n        try:\n            was_prev_closed = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn).iloc[0].closed\n        except IndexError:\n            was_prev_closed = 0\n    receiver_email = re.findall('<?(\\S+@\\S+\\.\\w+)>?', email_obj[\"sender\"])[0].lower()\n    dict_input.update({\"receiver_email\": receiver_email})\n    try:\n        if dict_input['cc_email'] != '':\n            dict_input['cc_email'] += '@dilfo.com'\n    except KeyError:\n        pass\n    try:\n        dcn_key = dict_input.pop('link_to_cert')\n    except (IndexError, KeyError):\n        dcn_key = ''\n    if dcn_key:\n        try:\n            dcn_key = dcn_key.split('-notices/')[1]\n        except IndexError:\n            pass\n        dcn_key = re.findall('[\\w-]*',dcn_key)[0]\n    try:\n        dict_input.pop('instant_scan')\n        instant_scan = True\n    except (IndexError, KeyError):\n        instant_scan = False\n    if was_prev_closed:\n        logger.info(f\"job was already matched successfully and logged as `closed`. Sending e-mail!\")\n        # Send email to inform of previous match\n        with create_connection() as conn:\n            prev_match = pd.read_sql(\n                \"SELECT * FROM df_matched WHERE job_number=? AND ground_truth=1\",\n                conn, params=[job_number]).iloc[0]\n        verifier = prev_match.verifier\n        log_date = prev_match.log_date\n        dcn_key = prev_match.dcn_key\n        message = (\n        f\"From: Dilfo HBR Bot\"\n        f\"\\n\"\n        f\"To: {receiver_email}\"\n        f\"\\n\"\n        f\"Subject: Previously Matched: #{job_number}\"\n        f\"\\n\\n\"\n        f\"Hi {receiver_email.split('.')[0].title()},\"\n        f\"\\n\\n\"\n        f\"It looks like \"\n        f\"job #{job_number} corresponds to the following certificate:\\n\"\n        f\"{lookup_url}{dcn_key}\"\n        f\"\\n\\n\"\n        f\"This confirmation was provided by {verifier.split('.')[0].title()}\"\n        f\"{' on ' + log_date if log_date is not None else ''}.\"\n        f\"\\n\\n\"\n        f\"If any of the information above seems to be inaccurate, please reply \"\n        f\"to this e-mail for corrective action.\"\n        f\"\\n\\n\"\n        f\"Thanks,\\n\"\n\t\tf\"Dilfo HBR Bot\\n\"\n        )\n        try:\n            context = ssl.create_default_context()\n            with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n                server.login(sender_email, password)\n                server.sendmail(sender_email, [receiver_email], message)\n            logger.info(f\"Successfully sent an email to {receiver_email}\")\n        except (FileNotFoundError, NameError):\n            logger.info(\"password not available -> could not send e-mail\")\n        return\n    elif dcn_key:\n        dict_input.update({\"closed\": 1})\n        with create_connection() as conn:\n            df = pd.read_sql(\"SELECT * FROM df_matched\", conn)\n            match_dict_input = {\n                'job_number': dict_input['job_number'],\n                'dcn_key': dcn_key,\n                'ground_truth': 1,\n                'verifier': dict_input['receiver_email'],\n                'source': 'input',\n                'log_date': str(datetime.datetime.now().date()),\n                'validate': 0,\n            }\n            df = df.append(match_dict_input, ignore_index=True)\n            df = df.drop_duplicates(subset=[\"job_number\", \"dcn_key\"], keep='last')\n            df.to_sql('df_matched', conn, if_exists='replace', index=False)\n    else:\n        dict_input.update({\"closed\": 0})\n    with create_connection() as conn:\n        df = pd.read_sql(\"SELECT * FROM df_dilfo\", conn)\n        df = df.append(dict_input, ignore_index=True)\n        #loop through duplicates to drop the first records but retain their contacts\n        for dup_i in df[df.duplicated(subset=[\"job_number\"], keep='last')].index:\n            dup_job_number = df.iloc[dup_i].job_number\n            dup_receiver = df.iloc[dup_i].receiver_email\n            dup_cc = df.iloc[dup_i].cc_email\n            df = df.drop(dup_i)\n            try:\n                dup_addrs = '; '.join([x for x in dup_cc + dup_receiver if x]) # filter out empty addresses and join them into one string  \n                update_i = df[df.job_number==dup_job_number].index\n                df.loc[update_i,'cc_email'] = df.loc[update_i,'cc_email'] + '; ' + dup_addrs\n            except TypeError:\n                pass\n        df.to_sql('df_dilfo', conn, if_exists='replace', index=False)  # we're replacing here instead of appending because of the 2 previous lines\n        if instant_scan:\n            dilfo_query = \"SELECT * FROM df_dilfo WHERE job_number=?\"\n            with create_connection() as conn:\n                df_dilfo = pd.read_sql(dilfo_query, conn, params=[job_number])\n            hist_query = \"SELECT * FROM df_hist ORDER BY pub_date DESC LIMIT 2000\"\n            with create_connection() as conn:\n                df_web = pd.read_sql(hist_query, conn)\n            results = match(df_dilfo=df_dilfo, df_web=df_web, test=False)\n            if len(results[results.pred_match==1]) == 0:\n                message = (\n                    f\"From: Dilfo HBR Bot\"\n                    f\"\\n\"\n                    f\"To: {receiver_email}\"\n                    f\"\\n\"\n                    f\"Subject: Successful Project Sign-Up: #{job_number}\"\n                    f\"\\n\\n\"\n                    f\"Hi {receiver_email.split('.')[0].title()},\"\n                    f\"\\n\\n\"\n                    f\"Your information for project #{job_number} was logged \"\n                    f\"successfully but no corresponding certificates in recent \"\n                    f\"history were matched to it.\"\n                    f\"\\n\\n\"\n                    f\"Going forward, the Daily Commercial News website will be \"\n                    f\"scraped on a daily basis in search of your project. You \"\n                    f\"will be notified if a possible match has been detected.\"\n                    f\"\\n\\n\"\n                    f\"Thanks,\\n\"\n                    f\"Dilfo HBR Bot\\n\"\n                )\n                try:\n                    context = ssl.create_default_context()\n                    with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n                        server.login(sender_email, password)\n                        server.sendmail(sender_email, [receiver_email], message)\n                    logger.info(f\"Successfully sent an email to {receiver_email}\")\n                except (FileNotFoundError, NameError):\n                    logger.info(\"password not available -> could not send e-mail\")", "func_src_after": "def process_as_form(email_obj):\n    dict_input = {\n        unquote(x.split('=')[0]):str(unquote(x.split('=')[1])).replace('+', ' ') for x in email_obj['content'].split('&')}\n    job_number = dict_input['job_number']\n    with create_connection() as conn:\n        try:\n            was_prev_closed = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number]).iloc[0].closed\n        except IndexError:\n            was_prev_closed = 0\n    receiver_email = re.findall('<?(\\S+@\\S+\\.\\w+)>?', email_obj[\"sender\"])[0].lower()\n    dict_input.update({\"receiver_email\": receiver_email})\n    try:\n        if dict_input['cc_email'] != '':\n            dict_input['cc_email'] += '@dilfo.com'\n    except KeyError:\n        pass\n    try:\n        dcn_key = dict_input.pop('link_to_cert')\n    except (IndexError, KeyError):\n        dcn_key = ''\n    if dcn_key:\n        try:\n            dcn_key = dcn_key.split('-notices/')[1]\n        except IndexError:\n            pass\n        dcn_key = re.findall('[\\w-]*',dcn_key)[0]\n    try:\n        dict_input.pop('instant_scan')\n        instant_scan = True\n    except (IndexError, KeyError):\n        instant_scan = False\n    if was_prev_closed:\n        logger.info(f\"job was already matched successfully and logged as `closed`. Sending e-mail!\")\n        # Send email to inform of previous match\n        with create_connection() as conn:\n            prev_match = pd.read_sql(\n                \"SELECT * FROM df_matched WHERE job_number=? AND ground_truth=1\",\n                conn, params=[job_number]).iloc[0]\n        verifier = prev_match.verifier\n        log_date = prev_match.log_date\n        dcn_key = prev_match.dcn_key\n        message = (\n        f\"From: Dilfo HBR Bot\"\n        f\"\\n\"\n        f\"To: {receiver_email}\"\n        f\"\\n\"\n        f\"Subject: Previously Matched: #{job_number}\"\n        f\"\\n\\n\"\n        f\"Hi {receiver_email.split('.')[0].title()},\"\n        f\"\\n\\n\"\n        f\"It looks like \"\n        f\"job #{job_number} corresponds to the following certificate:\\n\"\n        f\"{lookup_url}{dcn_key}\"\n        f\"\\n\\n\"\n        f\"This confirmation was provided by {verifier.split('.')[0].title()}\"\n        f\"{' on ' + log_date if log_date is not None else ''}.\"\n        f\"\\n\\n\"\n        f\"If any of the information above seems to be inaccurate, please reply \"\n        f\"to this e-mail for corrective action.\"\n        f\"\\n\\n\"\n        f\"Thanks,\\n\"\n\t\tf\"Dilfo HBR Bot\\n\"\n        )\n        try:\n            context = ssl.create_default_context()\n            with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n                server.login(sender_email, password)\n                server.sendmail(sender_email, [receiver_email], message)\n            logger.info(f\"Successfully sent an email to {receiver_email}\")\n        except (FileNotFoundError, NameError):\n            logger.info(\"password not available -> could not send e-mail\")\n        return\n    elif dcn_key:\n        dict_input.update({\"closed\": 1})\n        with create_connection() as conn:\n            df = pd.read_sql(\"SELECT * FROM df_matched\", conn)\n            match_dict_input = {\n                'job_number': dict_input['job_number'],\n                'dcn_key': dcn_key,\n                'ground_truth': 1,\n                'verifier': dict_input['receiver_email'],\n                'source': 'input',\n                'log_date': str(datetime.datetime.now().date()),\n                'validate': 0,\n            }\n            df = df.append(match_dict_input, ignore_index=True)\n            df = df.drop_duplicates(subset=[\"job_number\", \"dcn_key\"], keep='last')\n            df.to_sql('df_matched', conn, if_exists='replace', index=False)\n    else:\n        dict_input.update({\"closed\": 0})\n    with create_connection() as conn:\n        df = pd.read_sql(\"SELECT * FROM df_dilfo\", conn)\n        df = df.append(dict_input, ignore_index=True)\n        #loop through duplicates to drop the first records but retain their contacts\n        for dup_i in df[df.duplicated(subset=[\"job_number\"], keep='last')].index:\n            dup_job_number = df.iloc[dup_i].job_number\n            dup_receiver = df.iloc[dup_i].receiver_email\n            dup_cc = df.iloc[dup_i].cc_email\n            df = df.drop(dup_i)\n            try:\n                dup_addrs = '; '.join([x for x in dup_cc + dup_receiver if x]) # filter out empty addresses and join them into one string  \n                update_i = df[df.job_number==dup_job_number].index\n                df.loc[update_i,'cc_email'] = df.loc[update_i,'cc_email'] + '; ' + dup_addrs\n            except TypeError:\n                pass\n        df.to_sql('df_dilfo', conn, if_exists='replace', index=False)  # we're replacing here instead of appending because of the 2 previous lines\n        if instant_scan:\n            dilfo_query = \"SELECT * FROM df_dilfo WHERE job_number=?\"\n            with create_connection() as conn:\n                df_dilfo = pd.read_sql(dilfo_query, conn, params=[job_number])\n            hist_query = \"SELECT * FROM df_hist ORDER BY pub_date DESC LIMIT 2000\"\n            with create_connection() as conn:\n                df_web = pd.read_sql(hist_query, conn)\n            results = match(df_dilfo=df_dilfo, df_web=df_web, test=False)\n            if len(results[results.pred_match==1]) == 0:\n                message = (\n                    f\"From: Dilfo HBR Bot\"\n                    f\"\\n\"\n                    f\"To: {receiver_email}\"\n                    f\"\\n\"\n                    f\"Subject: Successful Project Sign-Up: #{job_number}\"\n                    f\"\\n\\n\"\n                    f\"Hi {receiver_email.split('.')[0].title()},\"\n                    f\"\\n\\n\"\n                    f\"Your information for project #{job_number} was logged \"\n                    f\"successfully but no corresponding certificates in recent \"\n                    f\"history were matched to it.\"\n                    f\"\\n\\n\"\n                    f\"Going forward, the Daily Commercial News website will be \"\n                    f\"scraped on a daily basis in search of your project. You \"\n                    f\"will be notified if a possible match has been detected.\"\n                    f\"\\n\\n\"\n                    f\"Thanks,\\n\"\n                    f\"Dilfo HBR Bot\\n\"\n                )\n                try:\n                    context = ssl.create_default_context()\n                    with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n                        server.login(sender_email, password)\n                        server.sendmail(sender_email, [receiver_email], message)\n                    logger.info(f\"Successfully sent an email to {receiver_email}\")\n                except (FileNotFoundError, NameError):\n                    logger.info(\"password not available -> could not send e-mail\")", "line_changes": {"deleted": [{"line_no": 7, "char_start": 267, "char_end": 387, "line": "            was_prev_closed = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn).iloc[0].closed\n"}], "added": [{"line_no": 7, "char_start": 267, "char_end": 396, "line": "            was_prev_closed = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number]).iloc[0].closed\n"}]}, "char_changes": {"deleted": [{"char_start": 309, "char_end": 310, "chars": "f"}, {"char_start": 351, "char_end": 352, "chars": "{"}, {"char_start": 362, "char_end": 370, "chars": "}\", conn"}], "added": [{"char_start": 350, "char_end": 368, "chars": "?\", conn, params=["}, {"char_start": 378, "char_end": 379, "chars": "]"}]}, "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "inbox_scanner.py", "vul_type": "cwe-089"}
{"func_name": "process_as_reply", "func_src_before": "def process_as_reply(email_obj):\n    job_number = email_obj['subject'].split(': #')[1]\n    feedback = re.findall(\"^[\\W]*([Oo\\d]){1}(?=[\\W]*)\", email_obj['content'].replace('#','').replace('link', ''))[0]\n    feedback = int(0 if feedback == ('O' or 'o') else feedback)\n    dcn_key = re.findall('\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}', email_obj['content'])[0]\n    logger.info(f\"got feedback `{feedback}` for job #`{job_number}`\")\n    with create_connection() as conn:\n        was_prev_closed = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn).iloc[0].closed\n    if was_prev_closed:\n        logger.info(f\"job was already matched successfully and logged as `closed`... skipping.\")\n        return\n    if feedback == 1:\n        logger.info(f\"got feeback that DCN key {dcn_key} was correct\")\n        update_status_query = \"UPDATE df_dilfo SET closed = 1 WHERE job_number = {}\"\n        with create_connection() as conn:\n            conn.cursor().execute(update_status_query.format(job_number))\n        logger.info(f\"updated df_dilfo to show `closed` status for job #{job_number}\")\n    with create_connection() as conn:\n        df = pd.read_sql(\"SELECT * FROM df_matched\", conn)\n        match_dict_input = {\n            'job_number': job_number,\n            'dcn_key': dcn_key,\n            'ground_truth': 1 if feedback == 1 else 0,\n            'multi_phase': 1 if feedback == 2 else 0,\n            'verifier': email_obj[\"sender\"],\n            'source': 'feedback',\n            'log_date': str(datetime.datetime.now().date()),\n            'validate': 0,\n        }\n        df = df.append(match_dict_input, ignore_index=True)\n        df = df.drop_duplicates(subset=[\"job_number\", \"dcn_key\"], keep='last')\n        df.to_sql('df_matched', conn, if_exists='replace', index=False)\n        logger.info(\n            f\"DCN key `{dcn_key}` was a \"\n            f\"{'successful match' if feedback == 1 else 'mis-match'} for job \"\n            f\"#{job_number}\"\n        )", "func_src_after": "def process_as_reply(email_obj):\n    job_number = email_obj['subject'].split(': #')[1]\n    feedback = re.findall(\"^[\\W]*([Oo\\d]){1}(?=[\\W]*)\", email_obj['content'].replace('#','').replace('link', ''))[0]\n    feedback = int(0 if feedback == ('O' or 'o') else feedback)\n    dcn_key = re.findall('\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}', email_obj['content'])[0]\n    logger.info(f\"got feedback `{feedback}` for job #`{job_number}`\")\n    with create_connection() as conn:\n        was_prev_closed = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number]).iloc[0].closed\n    if was_prev_closed:\n        logger.info(f\"job was already matched successfully and logged as `closed`... skipping.\")\n        return\n    if feedback == 1:\n        logger.info(f\"got feeback that DCN key {dcn_key} was correct\")\n        update_status_query = \"UPDATE df_dilfo SET closed = 1 WHERE job_number = ?\"\n        with create_connection() as conn:\n            conn.cursor().execute(update_status_query, [job_number])\n        logger.info(f\"updated df_dilfo to show `closed` status for job #{job_number}\")\n    with create_connection() as conn:\n        df = pd.read_sql(\"SELECT * FROM df_matched\", conn)\n        match_dict_input = {\n            'job_number': job_number,\n            'dcn_key': dcn_key,\n            'ground_truth': 1 if feedback == 1 else 0,\n            'multi_phase': 1 if feedback == 2 else 0,\n            'verifier': email_obj[\"sender\"],\n            'source': 'feedback',\n            'log_date': str(datetime.datetime.now().date()),\n            'validate': 0,\n        }\n        df = df.append(match_dict_input, ignore_index=True)\n        df = df.drop_duplicates(subset=[\"job_number\", \"dcn_key\"], keep='last')\n        df.to_sql('df_matched', conn, if_exists='replace', index=False)\n        logger.info(\n            f\"DCN key `{dcn_key}` was a \"\n            f\"{'successful match' if feedback == 1 else 'mis-match'} for job \"\n            f\"#{job_number}\"\n        )", "line_changes": {"deleted": [{"line_no": 8, "char_start": 460, "char_end": 576, "line": "        was_prev_closed = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn).iloc[0].closed\n"}, {"line_no": 14, "char_start": 805, "char_end": 890, "line": "        update_status_query = \"UPDATE df_dilfo SET closed = 1 WHERE job_number = {}\"\n"}, {"line_no": 16, "char_start": 932, "char_end": 1006, "line": "            conn.cursor().execute(update_status_query.format(job_number))\n"}], "added": [{"line_no": 8, "char_start": 460, "char_end": 585, "line": "        was_prev_closed = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number]).iloc[0].closed\n"}, {"line_no": 14, "char_start": 814, "char_end": 898, "line": "        update_status_query = \"UPDATE df_dilfo SET closed = 1 WHERE job_number = ?\"\n"}, {"line_no": 16, "char_start": 940, "char_end": 1009, "line": "            conn.cursor().execute(update_status_query, [job_number])\n"}]}, "char_changes": {"deleted": [{"char_start": 498, "char_end": 499, "chars": "f"}, {"char_start": 540, "char_end": 541, "chars": "{"}, {"char_start": 551, "char_end": 559, "chars": "}\", conn"}, {"char_start": 886, "char_end": 888, "chars": "{}"}, {"char_start": 985, "char_end": 993, "chars": ".format("}, {"char_start": 1003, "char_end": 1004, "chars": ")"}], "added": [{"char_start": 539, "char_end": 557, "chars": "?\", conn, params=["}, {"char_start": 567, "char_end": 568, "chars": "]"}, {"char_start": 895, "char_end": 896, "chars": "?"}, {"char_start": 993, "char_end": 996, "chars": ", ["}, {"char_start": 1006, "char_end": 1007, "chars": "]"}]}, "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "inbox_scanner.py", "vul_type": "cwe-089"}
{"func_name": "test_process_as_form", "func_src_before": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert.format(job_number, was_prev_closed))\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 1))\n                else:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 0))\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_pre = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_post = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "func_src_after": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert, [job_number, was_prev_closed])\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert, [job_number, 1])\n                else:\n                    conn.cursor().execute(fake_match_insert, [job_number, 0])\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_pre = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_post = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "line_changes": {"deleted": [{"line_no": 18, "char_start": 823, "char_end": 876, "line": "            VALUES ({}, 'alex.roy616@gmail.com', {})\n"}, {"line_no": 22, "char_start": 992, "char_end": 1045, "line": "            VALUES ({}, 'alex.roy616@gmail.com', {})\n"}, {"line_no": 26, "char_start": 1151, "char_end": 1244, "line": "                conn.cursor().execute(fake_dilfo_insert.format(job_number, was_prev_closed))\n"}, {"line_no": 29, "char_start": 1313, "char_end": 1396, "line": "                    conn.cursor().execute(fake_match_insert.format(job_number, 1))\n"}, {"line_no": 31, "char_start": 1418, "char_end": 1501, "line": "                    conn.cursor().execute(fake_match_insert.format(job_number, 0))\n"}, {"line_no": 33, "char_start": 1543, "char_end": 1645, "line": "            df_dilfo_pre = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n"}, {"line_no": 34, "char_start": 1645, "char_end": 1751, "line": "            df_matched_pre = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n"}, {"line_no": 38, "char_start": 1897, "char_end": 2000, "line": "            df_dilfo_post = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n"}, {"line_no": 39, "char_start": 2000, "char_end": 2107, "line": "            df_matched_post = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n"}], "added": [{"line_no": 18, "char_start": 823, "char_end": 874, "line": "            VALUES (?, 'alex.roy616@gmail.com', ?)\n"}, {"line_no": 22, "char_start": 990, "char_end": 1041, "line": "            VALUES (?, 'alex.roy616@gmail.com', ?)\n"}, {"line_no": 26, "char_start": 1147, "char_end": 1235, "line": "                conn.cursor().execute(fake_dilfo_insert, [job_number, was_prev_closed])\n"}, {"line_no": 29, "char_start": 1304, "char_end": 1382, "line": "                    conn.cursor().execute(fake_match_insert, [job_number, 1])\n"}, {"line_no": 31, "char_start": 1404, "char_end": 1482, "line": "                    conn.cursor().execute(fake_match_insert, [job_number, 0])\n"}, {"line_no": 33, "char_start": 1524, "char_end": 1635, "line": "            df_dilfo_pre = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n"}, {"line_no": 34, "char_start": 1635, "char_end": 1750, "line": "            df_matched_pre = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n"}, {"line_no": 38, "char_start": 1896, "char_end": 2008, "line": "            df_dilfo_post = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n"}, {"line_no": 39, "char_start": 2008, "char_end": 2124, "line": "            df_matched_post = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n"}]}, "char_changes": {"deleted": [{"char_start": 843, "char_end": 845, "chars": "{}"}, {"char_start": 872, "char_end": 874, "chars": "{}"}, {"char_start": 1012, "char_end": 1014, "chars": "{}"}, {"char_start": 1041, "char_end": 1043, "chars": "{}"}, {"char_start": 1206, "char_end": 1214, "chars": ".format("}, {"char_start": 1241, "char_end": 1242, "chars": ")"}, {"char_start": 1372, "char_end": 1380, "chars": ".format("}, {"char_start": 1393, "char_end": 1394, "chars": ")"}, {"char_start": 1477, "char_end": 1485, "chars": ".format("}, {"char_start": 1498, "char_end": 1499, "chars": ")"}, {"char_start": 1582, "char_end": 1583, "chars": "f"}, {"char_start": 1624, "char_end": 1625, "chars": "{"}, {"char_start": 1635, "char_end": 1643, "chars": "}\", conn"}, {"char_start": 1686, "char_end": 1687, "chars": "f"}, {"char_start": 1730, "char_end": 1731, "chars": "{"}, {"char_start": 1741, "char_end": 1749, "chars": "}\", conn"}, {"char_start": 1937, "char_end": 1938, "chars": "f"}, {"char_start": 1979, "char_end": 1980, "chars": "{"}, {"char_start": 1990, "char_end": 1998, "chars": "}\", conn"}, {"char_start": 2042, "char_end": 2043, "chars": "f"}, {"char_start": 2086, "char_end": 2087, "chars": "{"}, {"char_start": 2097, "char_end": 2105, "chars": "}\", conn"}], "added": [{"char_start": 843, "char_end": 844, "chars": "?"}, {"char_start": 871, "char_end": 872, "chars": "?"}, {"char_start": 1010, "char_end": 1011, "chars": "?"}, {"char_start": 1038, "char_end": 1039, "chars": "?"}, {"char_start": 1202, "char_end": 1205, "chars": ", ["}, {"char_start": 1232, "char_end": 1233, "chars": "]"}, {"char_start": 1363, "char_end": 1366, "chars": ", ["}, {"char_start": 1379, "char_end": 1380, "chars": "]"}, {"char_start": 1463, "char_end": 1466, "chars": ", ["}, {"char_start": 1479, "char_end": 1480, "chars": "]"}, {"char_start": 1604, "char_end": 1622, "chars": "?\", conn, params=["}, {"char_start": 1632, "char_end": 1633, "chars": "]"}, {"char_start": 1719, "char_end": 1737, "chars": "?\", conn, params=["}, {"char_start": 1747, "char_end": 1748, "chars": "]"}, {"char_start": 1977, "char_end": 1995, "chars": "?\", conn, params=["}, {"char_start": 2005, "char_end": 2006, "chars": "]"}, {"char_start": 2093, "char_end": 2111, "chars": "?\", conn, params=["}, {"char_start": 2121, "char_end": 2122, "chars": "]"}]}, "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "tests.py", "vul_type": "cwe-089"}
{"func_name": "test_process_as_reply", "func_src_before": "    @unpack\n    def test_process_as_reply(self, job_number, dcn_key, ground_truth,\n            was_prev_matched, was_prev_closed):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : f\"Re: [EXTERNAL] Upcoming Holdback Release: #{job_number}\",\n            'date' : \"Thu, 30 May 2019 00:41:05 +0000\",\n            'content' : (\n                f\"{ground_truth}\\r\\n\\r\\nAlex Roy\\r\\nDilfo Mechanical\\r\\n(613) 899-9324\\r\\n\\r\\n\"\n                f\"________________________________\\r\\nFrom: Dilfo HBR Bot \"\n                f\"<dilfo.hb.release@gmail.com>\\r\\nSent: Wednesday, May 29, 2019 8:40 \"\n                f\"PM\\r\\nTo: Alex Roy\\r\\nSubject: [EXTERNAL] #{job_number} - Upcoming \"\n                f\"Holdback Release\\r\\n\\r\\nHi Alex,\\r\\n\\r\\nYou're receiving this \"\n                f\"e-mail notification because you added the project #{job_number} - DWS \"\n                f\"Building Expansion to the watchlist of upcoming holdback releases. \"\n                f\"\\r\\n\\r\\nBefore going any further, please follow the link below to \"\n                f\"make sure the algorithm correctly matched the project in \"\n                f\"question:\\r\\nhttps://link.spamstopshere.net/u/f544cec5/\"\n                f\"3CEdd3OC6RGV00Hm8I9C_g?u=https%3A%2F%2Fcanada.constructconnect\"\n                f\".com%2Fdcn%2Fcertificates-and-notices%2F%2F{dcn_key}\\r\\n\\r\\nIf it's the \"\n                f\"right project, then the \"\n                f\"certificate was just published this past Wednesday on March 6, \"\n                f\"2019. This means a valid holdback release invoice could be submitted \"\n                f\"as of:\\r\\nA) April 20, 2019 if the contract was signed before \"\n                f\"October 1, 2019 or;\\r\\nB) May 5, 2019 if the contract was signed \"\n                f\"since then.\\r\\n\\r\\nPlease be aware this is a fully automated message. \"\n                f\"The info presented above could be erroneous.\\r\\nYou can help improve \"\n                f\"the matching algorithms by replying to this e-mail with a simple `1` \"\n                f\"or `0` to confirm whether or not the linked certificate represents the \"\n                f\"project in question.\\r\\n\\r\\nThanks,\\r\\nDilfo HBR Bot\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, closed)\n            VALUES ({}, {})\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, ground_truth)\n            VALUES ({}, {})\n        \"\"\"\n        with create_connection() as conn:\n            conn.cursor().execute(fake_dilfo_insert.format(job_number, was_prev_closed))\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 1))\n                else:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 0))\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_pre = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        process_as_reply(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_post = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        self.assertEqual(len(df_dilfo_pre), len(df_dilfo_post))\n        self.assertEqual(df_dilfo_post.iloc[0].closed, was_prev_closed or ground_truth)\n        self.assertEqual(any(df_matched_post.ground_truth), was_prev_closed or ground_truth)\n        self.assertEqual(len(df_matched_pre) + (not was_prev_closed), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "func_src_after": "    @unpack\n    def test_process_as_reply(self, job_number, dcn_key, ground_truth,\n            was_prev_matched, was_prev_closed):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : f\"Re: [EXTERNAL] Upcoming Holdback Release: #{job_number}\",\n            'date' : \"Thu, 30 May 2019 00:41:05 +0000\",\n            'content' : (\n                f\"{ground_truth}\\r\\n\\r\\nAlex Roy\\r\\nDilfo Mechanical\\r\\n(613) 899-9324\\r\\n\\r\\n\"\n                f\"________________________________\\r\\nFrom: Dilfo HBR Bot \"\n                f\"<dilfo.hb.release@gmail.com>\\r\\nSent: Wednesday, May 29, 2019 8:40 \"\n                f\"PM\\r\\nTo: Alex Roy\\r\\nSubject: [EXTERNAL] #{job_number} - Upcoming \"\n                f\"Holdback Release\\r\\n\\r\\nHi Alex,\\r\\n\\r\\nYou're receiving this \"\n                f\"e-mail notification because you added the project #{job_number} - DWS \"\n                f\"Building Expansion to the watchlist of upcoming holdback releases. \"\n                f\"\\r\\n\\r\\nBefore going any further, please follow the link below to \"\n                f\"make sure the algorithm correctly matched the project in \"\n                f\"question:\\r\\nhttps://link.spamstopshere.net/u/f544cec5/\"\n                f\"3CEdd3OC6RGV00Hm8I9C_g?u=https%3A%2F%2Fcanada.constructconnect\"\n                f\".com%2Fdcn%2Fcertificates-and-notices%2F%2F{dcn_key}\\r\\n\\r\\nIf it's the \"\n                f\"right project, then the \"\n                f\"certificate was just published this past Wednesday on March 6, \"\n                f\"2019. This means a valid holdback release invoice could be submitted \"\n                f\"as of:\\r\\nA) April 20, 2019 if the contract was signed before \"\n                f\"October 1, 2019 or;\\r\\nB) May 5, 2019 if the contract was signed \"\n                f\"since then.\\r\\n\\r\\nPlease be aware this is a fully automated message. \"\n                f\"The info presented above could be erroneous.\\r\\nYou can help improve \"\n                f\"the matching algorithms by replying to this e-mail with a simple `1` \"\n                f\"or `0` to confirm whether or not the linked certificate represents the \"\n                f\"project in question.\\r\\n\\r\\nThanks,\\r\\nDilfo HBR Bot\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, closed)\n            VALUES (?, ?)\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, ground_truth)\n            VALUES (?, ?)\n        \"\"\"\n        with create_connection() as conn:\n            conn.cursor().execute(fake_dilfo_insert, [job_number, was_prev_closed])\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert, [job_number, 1])\n                else:\n                    conn.cursor().execute(fake_match_insert, [job_number, 0])\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_pre = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        process_as_reply(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_post = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        self.assertEqual(len(df_dilfo_pre), len(df_dilfo_post))\n        self.assertEqual(df_dilfo_post.iloc[0].closed, was_prev_closed or ground_truth)\n        self.assertEqual(any(df_matched_post.ground_truth), was_prev_closed or ground_truth)\n        self.assertEqual(len(df_matched_pre) + (not was_prev_closed), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "line_changes": {"deleted": [{"line_no": 36, "char_start": 2369, "char_end": 2397, "line": "            VALUES ({}, {})\n"}, {"line_no": 40, "char_start": 2503, "char_end": 2531, "line": "            VALUES ({}, {})\n"}, {"line_no": 43, "char_start": 2585, "char_end": 2674, "line": "            conn.cursor().execute(fake_dilfo_insert.format(job_number, was_prev_closed))\n"}, {"line_no": 46, "char_start": 2743, "char_end": 2826, "line": "                    conn.cursor().execute(fake_match_insert.format(job_number, 1))\n"}, {"line_no": 48, "char_start": 2848, "char_end": 2931, "line": "                    conn.cursor().execute(fake_match_insert.format(job_number, 0))\n"}, {"line_no": 50, "char_start": 2973, "char_end": 3075, "line": "            df_dilfo_pre = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n"}, {"line_no": 51, "char_start": 3075, "char_end": 3181, "line": "            df_matched_pre = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n"}, {"line_no": 55, "char_start": 3328, "char_end": 3431, "line": "            df_dilfo_post = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n"}, {"line_no": 56, "char_start": 3431, "char_end": 3538, "line": "            df_matched_post = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n"}], "added": [{"line_no": 36, "char_start": 2369, "char_end": 2395, "line": "            VALUES (?, ?)\n"}, {"line_no": 40, "char_start": 2501, "char_end": 2527, "line": "            VALUES (?, ?)\n"}, {"line_no": 43, "char_start": 2581, "char_end": 2665, "line": "            conn.cursor().execute(fake_dilfo_insert, [job_number, was_prev_closed])\n"}, {"line_no": 46, "char_start": 2734, "char_end": 2812, "line": "                    conn.cursor().execute(fake_match_insert, [job_number, 1])\n"}, {"line_no": 48, "char_start": 2834, "char_end": 2912, "line": "                    conn.cursor().execute(fake_match_insert, [job_number, 0])\n"}, {"line_no": 50, "char_start": 2954, "char_end": 3065, "line": "            df_dilfo_pre = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n"}, {"line_no": 51, "char_start": 3065, "char_end": 3180, "line": "            df_matched_pre = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n"}, {"line_no": 55, "char_start": 3327, "char_end": 3439, "line": "            df_dilfo_post = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n"}, {"line_no": 56, "char_start": 3439, "char_end": 3555, "line": "            df_matched_post = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n"}]}, "char_changes": {"deleted": [{"char_start": 2389, "char_end": 2395, "chars": "{}, {}"}, {"char_start": 2523, "char_end": 2529, "chars": "{}, {}"}, {"char_start": 2636, "char_end": 2644, "chars": ".format("}, {"char_start": 2671, "char_end": 2672, "chars": ")"}, {"char_start": 2802, "char_end": 2810, "chars": ".format("}, {"char_start": 2823, "char_end": 2824, "chars": ")"}, {"char_start": 2907, "char_end": 2915, "chars": ".format("}, {"char_start": 2928, "char_end": 2929, "chars": ")"}, {"char_start": 3012, "char_end": 3013, "chars": "f"}, {"char_start": 3054, "char_end": 3055, "chars": "{"}, {"char_start": 3065, "char_end": 3073, "chars": "}\", conn"}, {"char_start": 3116, "char_end": 3117, "chars": "f"}, {"char_start": 3160, "char_end": 3161, "chars": "{"}, {"char_start": 3171, "char_end": 3179, "chars": "}\", conn"}, {"char_start": 3368, "char_end": 3369, "chars": "f"}, {"char_start": 3410, "char_end": 3411, "chars": "{"}, {"char_start": 3421, "char_end": 3429, "chars": "}\", conn"}, {"char_start": 3473, "char_end": 3474, "chars": "f"}, {"char_start": 3517, "char_end": 3518, "chars": "{"}, {"char_start": 3528, "char_end": 3536, "chars": "}\", conn"}], "added": [{"char_start": 2389, "char_end": 2393, "chars": "?, ?"}, {"char_start": 2521, "char_end": 2525, "chars": "?, ?"}, {"char_start": 2632, "char_end": 2635, "chars": ", ["}, {"char_start": 2662, "char_end": 2663, "chars": "]"}, {"char_start": 2793, "char_end": 2796, "chars": ", ["}, {"char_start": 2809, "char_end": 2810, "chars": "]"}, {"char_start": 2893, "char_end": 2896, "chars": ", ["}, {"char_start": 2909, "char_end": 2910, "chars": "]"}, {"char_start": 3034, "char_end": 3052, "chars": "?\", conn, params=["}, {"char_start": 3062, "char_end": 3063, "chars": "]"}, {"char_start": 3149, "char_end": 3167, "chars": "?\", conn, params=["}, {"char_start": 3177, "char_end": 3178, "chars": "]"}, {"char_start": 3408, "char_end": 3426, "chars": "?\", conn, params=["}, {"char_start": 3436, "char_end": 3437, "chars": "]"}, {"char_start": 3524, "char_end": 3542, "chars": "?\", conn, params=["}, {"char_start": 3552, "char_end": 3553, "chars": "]"}]}, "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "tests.py", "vul_type": "cwe-089"}
{"func_name": "measure_numerators_by_org", "func_src_before": "@api_view(['GET'])\ndef measure_numerators_by_org(request, format=None):\n    measure = request.query_params.get('measure', None)\n    org_id, org_type = _get_org_id_and_type_from_request(request)\n    this_month = ImportLog.objects.latest_in_category('prescribing').current_at\n    three_months_ago = (\n        this_month - relativedelta(months=2)).strftime('%Y-%m-01')\n    m = Measure.objects.get(pk=measure)\n    if m.numerator_is_list_of_bnf_codes:\n        if org_type in ['stp_id', 'regional_team_id']:\n            extra_join = '''\n            INNER JOIN frontend_practice pr\n            ON p.practice_id = pr.code\n            INNER JOIN frontend_pct\n            ON frontend_pct.code = pr.ccg_id\n            '''\n        elif org_type == 'pr.ccg_id':\n            extra_join = '''\n            INNER JOIN frontend_practice pr\n            ON p.practice_id = pr.code\n            '''\n        else:\n            extra_join = ''\n\n        # For measures whose numerator sums one of the columns in the\n        # prescribing table, we order the presentations by that column.\n        # For other measures, the columns used to calculate the numerator is\n        # not available here (it's in BQ) so we order by total_items, which is\n        # the best we can do.\n        #\n        # But because the columns in BQ don't match the columns in PG (items vs\n        # total_items), and because we alias a column in the query below\n        # (actual_cost vs cost) we need to translate the name of the column we\n        # use for ordering the results.\n        match = re.match(\n            'SUM\\((items|quantity|actual_cost)\\) AS numerator',\n            m.numerator_columns\n        )\n\n        if match:\n            order_col = {\n                'items': 'total_items',\n                'actual_cost': 'cost',\n                'quantity': 'quantity',\n            }[match.groups()[0]]\n        else:\n            order_col = 'total_items'\n\n        # The redundancy in the following column names is so we can\n        # support various flavours of `WHERE` clause from the measure\n        # definitions that may use a subset of any of these column\n        # names\n        focus_on_org = org_id and org_type\n        params = {\n            \"numerator_bnf_codes\": m.numerator_bnf_codes,\n            \"three_months_ago\": three_months_ago,\n        }\n        if focus_on_org:\n            org_condition = \"{org_type} = %(org_id)s AND \".format(\n                org_type=org_type)\n            org_group = \"{org_type}, \".format(\n                org_type=org_type)\n            params[\"org_id\"] = org_id\n        else:\n            org_condition = \"\"\n            org_group = \"\"\n        query = \"\"\"\n            SELECT\n              presentation_code AS bnf_code,\n              pn.name AS presentation_name,\n              SUM(total_items) AS total_items,\n              SUM(actual_cost) AS cost,\n              SUM(quantity) AS quantity\n            FROM\n              frontend_prescription p\n            INNER JOIN\n              frontend_presentation pn\n            ON p.presentation_code = pn.bnf_code\n            {extra_join}\n            WHERE\n              {org_condition}\n              processing_date >= %(three_months_ago)s\n              AND\n              pn.bnf_code = ANY(%(numerator_bnf_codes)s)\n            GROUP BY\n              {org_group}\n              presentation_code, pn.name\n            ORDER BY {order_col} DESC\n            LIMIT 50\n        \"\"\".format(\n            org_condition=org_condition,\n            org_group=org_group,\n            org_type=org_type,\n            three_months_ago=three_months_ago,\n            extra_join=extra_join,\n            order_col=order_col,\n        )\n        data = utils.execute_query(query, params)\n    else:\n        data = []\n    response = Response(data)\n    filename = \"%s-%s-breakdown.csv\" % (measure, org_id)\n    if request.accepted_renderer.format == 'csv':\n        response['content-disposition'] = \"attachment; filename=%s\" % filename\n    return response", "func_src_after": "@api_view(['GET'])\ndef measure_numerators_by_org(request, format=None):\n    measure = request.query_params.get('measure', None)\n    org_id, org_field = _get_org_id_and_field_from_request(request)\n    this_month = ImportLog.objects.latest_in_category('prescribing').current_at\n    three_months_ago = (\n        this_month - relativedelta(months=2)).strftime('%Y-%m-01')\n    m = Measure.objects.get(pk=measure)\n    if m.numerator_is_list_of_bnf_codes:\n        if org_field in ['stp_id', 'regional_team_id']:\n            extra_join = '''\n            INNER JOIN frontend_practice pr\n            ON p.practice_id = pr.code\n            INNER JOIN frontend_pct\n            ON frontend_pct.code = pr.ccg_id\n            '''\n        elif org_field == 'pr.ccg_id':\n            extra_join = '''\n            INNER JOIN frontend_practice pr\n            ON p.practice_id = pr.code\n            '''\n        else:\n            extra_join = ''\n\n        # For measures whose numerator sums one of the columns in the\n        # prescribing table, we order the presentations by that column.\n        # For other measures, the columns used to calculate the numerator is\n        # not available here (it's in BQ) so we order by total_items, which is\n        # the best we can do.\n        #\n        # But because the columns in BQ don't match the columns in PG (items vs\n        # total_items), and because we alias a column in the query below\n        # (actual_cost vs cost) we need to translate the name of the column we\n        # use for ordering the results.\n        match = re.match(\n            'SUM\\((items|quantity|actual_cost)\\) AS numerator',\n            m.numerator_columns\n        )\n\n        if match:\n            order_col = {\n                'items': 'total_items',\n                'actual_cost': 'cost',\n                'quantity': 'quantity',\n            }[match.groups()[0]]\n        else:\n            order_col = 'total_items'\n\n        # The redundancy in the following column names is so we can\n        # support various flavours of `WHERE` clause from the measure\n        # definitions that may use a subset of any of these column\n        # names\n        focus_on_org = org_id and org_field\n        params = {\n            \"numerator_bnf_codes\": m.numerator_bnf_codes,\n            \"three_months_ago\": three_months_ago,\n        }\n        if focus_on_org:\n            org_condition = \"{org_field} = %(org_id)s AND \".format(\n                org_field=org_field)\n            org_group = \"{org_field}, \".format(\n                org_field=org_field)\n            params[\"org_id\"] = org_id\n        else:\n            org_condition = \"\"\n            org_group = \"\"\n        query = \"\"\"\n            SELECT\n              presentation_code AS bnf_code,\n              pn.name AS presentation_name,\n              SUM(total_items) AS total_items,\n              SUM(actual_cost) AS cost,\n              SUM(quantity) AS quantity\n            FROM\n              frontend_prescription p\n            INNER JOIN\n              frontend_presentation pn\n            ON p.presentation_code = pn.bnf_code\n            {extra_join}\n            WHERE\n              {org_condition}\n              processing_date >= %(three_months_ago)s\n              AND\n              pn.bnf_code = ANY(%(numerator_bnf_codes)s)\n            GROUP BY\n              {org_group}\n              presentation_code, pn.name\n            ORDER BY {order_col} DESC\n            LIMIT 50\n        \"\"\".format(\n            org_condition=org_condition,\n            org_group=org_group,\n            org_field=org_field,\n            three_months_ago=three_months_ago,\n            extra_join=extra_join,\n            order_col=order_col,\n        )\n        data = utils.execute_query(query, params)\n    else:\n        data = []\n    response = Response(data)\n    filename = \"%s-%s-breakdown.csv\" % (measure, org_id)\n    if request.accepted_renderer.format == 'csv':\n        response['content-disposition'] = \"attachment; filename=%s\" % filename\n    return response", "line_changes": {"deleted": [{"line_no": 4, "char_start": 128, "char_end": 194, "line": "    org_id, org_type = _get_org_id_and_type_from_request(request)\n"}, {"line_no": 10, "char_start": 447, "char_end": 502, "line": "        if org_type in ['stp_id', 'regional_team_id']:\n"}, {"line_no": 17, "char_start": 711, "char_end": 749, "line": "        elif org_type == 'pr.ccg_id':\n"}, {"line_no": 53, "char_start": 2133, "char_end": 2176, "line": "        focus_on_org = org_id and org_type\n"}, {"line_no": 59, "char_start": 2338, "char_end": 2405, "line": "            org_condition = \"{org_type} = %(org_id)s AND \".format(\n"}, {"line_no": 60, "char_start": 2405, "char_end": 2440, "line": "                org_type=org_type)\n"}, {"line_no": 61, "char_start": 2440, "char_end": 2487, "line": "            org_group = \"{org_type}, \".format(\n"}, {"line_no": 62, "char_start": 2487, "char_end": 2522, "line": "                org_type=org_type)\n"}, {"line_no": 93, "char_start": 3496, "char_end": 3527, "line": "            org_type=org_type,\n"}], "added": [{"line_no": 4, "char_start": 128, "char_end": 196, "line": "    org_id, org_field = _get_org_id_and_field_from_request(request)\n"}, {"line_no": 10, "char_start": 449, "char_end": 505, "line": "        if org_field in ['stp_id', 'regional_team_id']:\n"}, {"line_no": 17, "char_start": 714, "char_end": 753, "line": "        elif org_field == 'pr.ccg_id':\n"}, {"line_no": 53, "char_start": 2137, "char_end": 2181, "line": "        focus_on_org = org_id and org_field\n"}, {"line_no": 59, "char_start": 2343, "char_end": 2411, "line": "            org_condition = \"{org_field} = %(org_id)s AND \".format(\n"}, {"line_no": 60, "char_start": 2411, "char_end": 2448, "line": "                org_field=org_field)\n"}, {"line_no": 61, "char_start": 2448, "char_end": 2496, "line": "            org_group = \"{org_field}, \".format(\n"}, {"line_no": 62, "char_start": 2496, "char_end": 2533, "line": "                org_field=org_field)\n"}, {"line_no": 93, "char_start": 3507, "char_end": 3540, "line": "            org_field=org_field,\n"}]}, "char_changes": {"deleted": [{"char_start": 144, "char_end": 148, "chars": "type"}, {"char_start": 167, "char_end": 171, "chars": "type"}, {"char_start": 462, "char_end": 466, "chars": "type"}, {"char_start": 728, "char_end": 732, "chars": "type"}, {"char_start": 2171, "char_end": 2175, "chars": "type"}, {"char_start": 2372, "char_end": 2376, "chars": "type"}, {"char_start": 2425, "char_end": 2438, "chars": "type=org_type"}, {"char_start": 2470, "char_end": 2474, "chars": "type"}, {"char_start": 2507, "char_end": 2520, "chars": "type=org_type"}, {"char_start": 3512, "char_end": 3525, "chars": "type=org_type"}], "added": [{"char_start": 144, "char_end": 149, "chars": "field"}, {"char_start": 168, "char_end": 173, "chars": "field"}, {"char_start": 464, "char_end": 469, "chars": "field"}, {"char_start": 731, "char_end": 736, "chars": "field"}, {"char_start": 2175, "char_end": 2180, "chars": "field"}, {"char_start": 2377, "char_end": 2382, "chars": "field"}, {"char_start": 2431, "char_end": 2446, "chars": "field=org_field"}, {"char_start": 2478, "char_end": 2483, "chars": "field"}, {"char_start": 2516, "char_end": 2531, "chars": "field=org_field"}, {"char_start": 3523, "char_end": 3538, "chars": "field=org_field"}]}, "commit_link": "github.com/ebmdatalab/openprescribing/commit/c632bfb008ba3306615f804048f979b85524e267", "file_name": "openprescribing/api/views_measures.py", "vul_type": "cwe-089"}
{"func_name": "get", "func_src_before": "    def get(self, email):\n        \"\"\" Fetch data for admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from admins where email = '{email}'\"\"\")", "func_src_after": "    def get(self, email):\n        \"\"\" Fetch data for admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from admins where email = %s\"\"\", (email, ))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 92, "char_end": 192, "line": "        return database_utilities.execute_query(f\"\"\"select * from admins where email = '{email}'\"\"\")\n"}], "added": [{"line_no": 3, "char_start": 92, "char_end": 196, "line": "        return database_utilities.execute_query(f\"\"\"select * from admins where email = %s\"\"\", (email, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 179, "char_end": 191, "chars": "'{email}'\"\"\""}], "added": [{"char_start": 179, "char_end": 195, "chars": "%s\"\"\", (email, )"}]}, "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/admins.py", "vul_type": "cwe-089"}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = '{email}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = %s\"\"\", (email, ))", "line_changes": {"deleted": [{"line_no": 4, "char_start": 106, "char_end": 204, "line": "        return database_utilities.execute_query(f\"\"\"delete from admins where email = '{email}'\"\"\")\n"}], "added": [{"line_no": 4, "char_start": 106, "char_end": 208, "line": "        return database_utilities.execute_query(f\"\"\"delete from admins where email = %s\"\"\", (email, ))"}]}, "char_changes": {"deleted": [{"char_start": 191, "char_end": 203, "chars": "'{email}'\"\"\""}], "added": [{"char_start": 191, "char_end": 207, "chars": "%s\"\"\", (email, )"}]}, "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/admins.py", "vul_type": "cwe-089"}
{"func_name": "post", "func_src_before": "    def post(self):\n        \"\"\" Returns JWT upon login verification \"\"\"\n        json_data = request.get_json()\n        if not json_data['email']:\n            return jsonify({\"msg\": \"Missing email\"}), 400\n\n        data = database_utilities.execute_query(\n            f\"\"\"select * from admins where email = '{json_data['email']}'\"\"\")\n        if data:\n            email = data[0]['email']\n            access_token = create_access_token(identity=email)\n            refresh_token = create_refresh_token(identity=email)\n\n            resp = jsonify({\"login\": True})\n            set_access_cookies(resp, access_token)\n            set_refresh_cookies(resp, refresh_token)\n            return resp\n        else:\n            return jsonify({\"msg\": \"User is not an admin\"})", "func_src_after": "    def post(self):\n        \"\"\" Returns JWT upon login verification \"\"\"\n        json_data = request.get_json()\n        if not json_data['email']:\n            return jsonify({\"msg\": \"Missing email\"}), 400\n\n        data = database_utilities.execute_query(\n            f\"\"\"select * from admins where email = %s\"\"\", (json_data['email'], ))\n        if data:\n            email = data[0]['email']\n            access_token = create_access_token(identity=email)\n            refresh_token = create_refresh_token(identity=email)\n\n            resp = jsonify({\"login\": True})\n            set_access_cookies(resp, access_token)\n            set_refresh_cookies(resp, refresh_token)\n            return resp\n        else:\n            return jsonify({\"msg\": \"User is not an admin\"})", "line_changes": {"deleted": [{"line_no": 8, "char_start": 254, "char_end": 332, "line": "            f\"\"\"select * from admins where email = '{json_data['email']}'\"\"\")\n"}], "added": [{"line_no": 8, "char_start": 254, "char_end": 336, "line": "            f\"\"\"select * from admins where email = %s\"\"\", (json_data['email'], ))\n"}]}, "char_changes": {"deleted": [{"char_start": 305, "char_end": 307, "chars": "'{"}, {"char_start": 325, "char_end": 330, "chars": "}'\"\"\""}], "added": [{"char_start": 305, "char_end": 313, "chars": "%s\"\"\", ("}, {"char_start": 331, "char_end": 334, "chars": ", )"}]}, "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/login.py", "vul_type": "cwe-089"}
{"func_name": "get", "func_src_before": "    def get(self, space_id):\n        \"\"\" Fetch data for space with the corresponding space_id \"\"\"\n        return database_utilities.execute_query(\n            f\"\"\"select * from spaces where space_id = '{space_id}'\"\"\")", "func_src_after": "    def get(self, space_id):\n        \"\"\" Fetch data for space with the corresponding space_id \"\"\"\n        return database_utilities.execute_query(\n            f\"\"\"select * from spaces where space_id = %s\"\"\", (space_id, ))", "line_changes": {"deleted": [{"line_no": 4, "char_start": 147, "char_end": 217, "line": "            f\"\"\"select * from spaces where space_id = '{space_id}'\"\"\")\n"}], "added": [{"line_no": 4, "char_start": 147, "char_end": 221, "line": "            f\"\"\"select * from spaces where space_id = %s\"\"\", (space_id, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 201, "char_end": 203, "chars": "'{"}, {"char_start": 211, "char_end": 216, "chars": "}'\"\"\""}], "added": [{"char_start": 201, "char_end": 209, "chars": "%s\"\"\", ("}, {"char_start": 217, "char_end": 220, "chars": ", )"}]}, "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/spaces.py", "vul_type": "cwe-089"}
{"func_name": "get", "func_src_before": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = %s\"\"\", (user_id, ))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 91, "char_end": 194, "line": "        return database_utilities.execute_query(f\"\"\"select * from users where user_id = '{user_id}'\"\"\")\n"}], "added": [{"line_no": 3, "char_start": 91, "char_end": 198, "line": "        return database_utilities.execute_query(f\"\"\"select * from users where user_id = %s\"\"\", (user_id, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 179, "char_end": 181, "chars": "'{"}, {"char_start": 188, "char_end": 193, "chars": "}'\"\"\""}], "added": [{"char_start": 179, "char_end": 187, "chars": "%s\"\"\", ("}, {"char_start": 194, "char_end": 197, "chars": ", )"}]}, "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089"}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = %s\"\"\", (user_id, ))", "line_changes": {"deleted": [{"line_no": 4, "char_start": 109, "char_end": 210, "line": "        return database_utilities.execute_query(f\"\"\"delete from users where user_id = '{user_id}'\"\"\")\n"}], "added": [{"line_no": 4, "char_start": 109, "char_end": 214, "line": "        return database_utilities.execute_query(f\"\"\"delete from users where user_id = %s\"\"\", (user_id, ))\n"}]}, "char_changes": {"deleted": [{"char_start": 195, "char_end": 197, "chars": "'{"}, {"char_start": 204, "char_end": 209, "chars": "}'\"\"\""}], "added": [{"char_start": 195, "char_end": 203, "chars": "%s\"\"\", ("}, {"char_start": 210, "char_end": 213, "chars": ", )"}]}, "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089"}
{"func_name": "patch", "func_src_before": "    @jwt_required\n    def patch(self, user_id):\n        \"\"\" Replaces information of corresponding user_id with request body \"\"\"\n        query = f\"\"\"update users set user_id = %s \"\"\"\n        query += f\"\"\"where user_id = '{user_id}'\"\"\"\n        json_data = request.get_json()\n        parameters = (json_data['user_id'], )\n        database_utilities.execute_query(query, parameters)", "func_src_after": "    @jwt_required\n    def patch(self, user_id):\n        \"\"\" Replaces information of corresponding user_id with request body \"\"\"\n        query = f\"\"\"update users set user_id = %s \"\"\"\n        query += f\"\"\"where user_id = %s\"\"\"\n        json_data = request.get_json()\n        parameters = (json_data['user_id'], user_id)\n        database_utilities.execute_query(query, parameters)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 182, "char_end": 234, "line": "        query += f\"\"\"where user_id = '{user_id}'\"\"\"\n"}, {"line_no": 7, "char_start": 273, "char_end": 319, "line": "        parameters = (json_data['user_id'], )\n"}], "added": [{"line_no": 5, "char_start": 182, "char_end": 225, "line": "        query += f\"\"\"where user_id = %s\"\"\"\n"}, {"line_no": 7, "char_start": 264, "char_end": 317, "line": "        parameters = (json_data['user_id'], user_id)\n"}]}, "char_changes": {"deleted": [{"char_start": 219, "char_end": 230, "chars": "'{user_id}'"}], "added": [{"char_start": 219, "char_end": 221, "chars": "%s"}, {"char_start": 308, "char_end": 315, "chars": "user_id"}]}, "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089"}
{"func_name": "get_sales_details", "func_src_before": "def get_sales_details(filters):\n\n\tdata = []\n\titem_details_map = {}\n\n\tdate_field = \"s.transaction_date\" if filters[\"based_on\"] == \"Sales Order\" else \"s.posting_date\"\n\n\tsales_data = frappe.db.sql(\"\"\"\n\t\tselect s.territory, s.customer, si.item_group, si.item_name, si.qty, {date_field} as last_order_date,\n\t\tDATEDIFF(CURDATE(), {date_field}) as days_since_last_order\n\t\tfrom `tab{doctype}` s, `tab{doctype} Item` si\n\t\twhere s.name = si.parent and s.docstatus = 1\n\t\tgroup by si.name order by days_since_last_order \"\"\"\n\t\t.format(date_field = date_field, doctype = filters['based_on']), as_dict=1)\n\n\tfor d in sales_data:\n\t\titem_details_map.setdefault(d.item_name, d)\n\n\treturn item_details_map", "func_src_after": "def get_sales_details(filters):\n\n\tdata = []\n\titem_details_map = {}\n\n\tdate_field = \"s.transaction_date\" if filters[\"based_on\"] == \"Sales Order\" else \"s.posting_date\"\n\n\tsales_data = frappe.db.sql(\"\"\"\n\t\tselect s.territory, s.customer, si.item_group, si.item_name, si.qty, {date_field} as last_order_date,\n\t\tDATEDIFF(CURDATE(), {date_field}) as days_since_last_order\n\t\tfrom `tab{doctype}` s, `tab{doctype} Item` si\n\t\twhere s.name = si.parent and s.docstatus = 1\n\t\tgroup by si.name order by days_since_last_order \"\"\" #nosec\n\t\t.format(date_field = date_field, doctype = filters['based_on']), as_dict=1)\n\n\tfor d in sales_data:\n\t\titem_details_map.setdefault(d.item_name, d)\n\n\treturn item_details_map", "line_changes": {"deleted": [{"line_no": 13, "char_start": 458, "char_end": 512, "line": "\t\tgroup by si.name order by days_since_last_order \"\"\"\n"}], "added": [{"line_no": 13, "char_start": 458, "char_end": 519, "line": "\t\tgroup by si.name order by days_since_last_order \"\"\" #nosec\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 511, "char_end": 518, "chars": " #nosec"}]}, "commit_link": "github.com/arohan-infocare/erpnext/commit/a981a8a1536d053dd644534e7fc865bc68d5c8b1", "file_name": "erpnext/stock/report/inactive_items/inactive_items.py", "vul_type": "cwe-089"}
{"func_name": "user_view", "func_src_before": "@bp.route('/user_view')\n@bp.route('/user_view/<sort>')\n@admin_required\ndef user_view(sort='id.asc'):\n    db = get_db()\n    sortBy = sort.split('.')[0]\n    sortOrder = sort.split('.')[1]\n\n\n    query = 'SELECT * FROM user AS u LEFT OUTER JOIN (SELECT uid, count(uid) AS follower FROM follows GROUP BY uid) AS f ON u.id = f.uid ORDER BY ? {}'.format(sortOrder)\n    users = db.execute(\n        query, (sortBy,)\n    ).fetchall()\n    return render_template('admin/userview.html', users = users, sort='{}.{}'.format(sortBy, sortOrder))", "func_src_after": "@bp.route('/user_view')\n@bp.route('/user_view/<sort>')\n@admin_required\ndef user_view(sort='id.asc'):\n    db = get_db()\n    sortBy = sort.split('.')[0]\n    sortOrder = sort.split('.')[1]\n    if sortBy not in ['id', 'name', 'follower', 'registered']:\n        sortBy = 'id'\n    if sortOrder not in ['asc', 'desc']:\n        sortOrder = 'asc'\n        \n    query = 'SELECT * FROM user AS u LEFT OUTER JOIN (SELECT uid, count(uid) AS follower FROM follows GROUP BY uid) AS f ON u.id = f.uid ORDER BY {} {}'.format(sortBy, sortOrder)\n    users = db.execute(\n        query\n    ).fetchall()\n    return render_template('admin/userview.html', users = users, sort='{}.{}'.format(sortBy, sortOrder))", "line_changes": {"deleted": [{"line_no": 8, "char_start": 186, "char_end": 187, "line": "\n"}, {"line_no": 9, "char_start": 187, "char_end": 188, "line": "\n"}, {"line_no": 10, "char_start": 188, "char_end": 358, "line": "    query = 'SELECT * FROM user AS u LEFT OUTER JOIN (SELECT uid, count(uid) AS follower FROM follows GROUP BY uid) AS f ON u.id = f.uid ORDER BY ? {}'.format(sortOrder)\n"}, {"line_no": 12, "char_start": 382, "char_end": 407, "line": "        query, (sortBy,)\n"}], "added": [{"line_no": 8, "char_start": 186, "char_end": 249, "line": "    if sortBy not in ['id', 'name', 'follower', 'registered']:\n"}, {"line_no": 9, "char_start": 249, "char_end": 271, "line": "        sortBy = 'id'\n"}, {"line_no": 10, "char_start": 271, "char_end": 312, "line": "    if sortOrder not in ['asc', 'desc']:\n"}, {"line_no": 11, "char_start": 312, "char_end": 338, "line": "        sortOrder = 'asc'\n"}, {"line_no": 12, "char_start": 338, "char_end": 347, "line": "        \n"}, {"line_no": 13, "char_start": 347, "char_end": 526, "line": "    query = 'SELECT * FROM user AS u LEFT OUTER JOIN (SELECT uid, count(uid) AS follower FROM follows GROUP BY uid) AS f ON u.id = f.uid ORDER BY {} {}'.format(sortBy, sortOrder)\n"}, {"line_no": 15, "char_start": 550, "char_end": 564, "line": "        query\n"}]}, "char_changes": {"deleted": [{"char_start": 186, "char_end": 187, "chars": "\n"}, {"char_start": 334, "char_end": 335, "chars": "?"}, {"char_start": 395, "char_end": 406, "chars": ", (sortBy,)"}], "added": [{"char_start": 186, "char_end": 346, "chars": "    if sortBy not in ['id', 'name', 'follower', 'registered']:\n        sortBy = 'id'\n    if sortOrder not in ['asc', 'desc']:\n        sortOrder = 'asc'\n        "}, {"char_start": 493, "char_end": 495, "chars": "{}"}, {"char_start": 507, "char_end": 515, "chars": "sortBy, "}]}, "commit_link": "github.com/np1e/DefinitelyNotTwitter/commit/f498d2f5c2a8eeb8673f8c8e12eb554065d87ac8", "file_name": "DefinitelyNotTwitter/admin.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # This will cause a security flaw.\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 127, "char_end": 210, "line": "            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n"}, {"line_no": 7, "char_start": 258, "char_end": 296, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 4, "char_start": 80, "char_end": 148, "line": "            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 6, "char_start": 196, "char_end": 240, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 80, "char_end": 127, "chars": "            # This will cause a security flaw.\n"}, {"char_start": 189, "char_end": 209, "chars": "'{}');\".format(data)"}, {"char_start": 258, "char_end": 258, "chars": ""}], "added": [{"char_start": 142, "char_end": 147, "chars": "%s);\""}, {"char_start": 232, "char_end": 238, "chars": ", data"}]}, "commit_link": "github.com/kayfay/python-flask-crime-map/commit/614e4cbb056f041e3da6d4b46e360c18f1b16a4f", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "tid_to_tid_num", "func_src_before": "    def tid_to_tid_num(self, tid):\n        ''' Returns tid_num, given tid. '''\n\n        q = \"SELECT rowid FROM tids WHERE tid = '\" + tid + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "func_src_after": "    def tid_to_tid_num(self, tid):\n        ''' Returns tid_num, given tid. '''\n\n        q = \"SELECT rowid FROM tids WHERE tid = ?\"\n        self.query(q, tid)\n        return self.c.fetchone()[0]", "line_changes": {"deleted": [{"line_no": 4, "char_start": 80, "char_end": 143, "line": "        q = \"SELECT rowid FROM tids WHERE tid = '\" + tid + \"'\"\n"}, {"line_no": 5, "char_start": 143, "char_end": 165, "line": "        self.query(q)\n"}], "added": [{"line_no": 4, "char_start": 80, "char_end": 131, "line": "        q = \"SELECT rowid FROM tids WHERE tid = ?\"\n"}, {"line_no": 5, "char_start": 131, "char_end": 158, "line": "        self.query(q, tid)\n"}]}, "char_changes": {"deleted": [{"char_start": 128, "char_end": 141, "chars": "'\" + tid + \"'"}], "added": [{"char_start": 128, "char_end": 129, "chars": "?"}, {"char_start": 151, "char_end": 156, "chars": ", tid"}]}, "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089"}
{"func_name": "tid_num_to_tid", "func_src_before": "    def tid_num_to_tid(self, tid_num):\n        ''' Returns tid, given tid_num. '''\n\n        q = \"SELECT tid FROM tids WHERE rowid = '\" + str(tid_num) + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "func_src_after": "    def tid_num_to_tid(self, tid_num):\n        ''' Returns tid, given tid_num. '''\n\n        q = \"SELECT tid FROM tids WHERE rowid = ?\"\n        self.query(q, tid_num)\n        return self.c.fetchone()[0]", "line_changes": {"deleted": [{"line_no": 4, "char_start": 84, "char_end": 156, "line": "        q = \"SELECT tid FROM tids WHERE rowid = '\" + str(tid_num) + \"'\"\n"}, {"line_no": 5, "char_start": 156, "char_end": 178, "line": "        self.query(q)\n"}], "added": [{"line_no": 4, "char_start": 84, "char_end": 135, "line": "        q = \"SELECT tid FROM tids WHERE rowid = ?\"\n"}, {"line_no": 5, "char_start": 135, "char_end": 166, "line": "        self.query(q, tid_num)\n"}]}, "char_changes": {"deleted": [{"char_start": 132, "char_end": 154, "chars": "'\" + str(tid_num) + \"'"}], "added": [{"char_start": 132, "char_end": 133, "chars": "?"}, {"char_start": 155, "char_end": 164, "chars": ", tid_num"}]}, "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089"}
{"func_name": "tid_num_to_tag_nums", "func_src_before": "    def tid_num_to_tag_nums(self, tid_num):\n        ''' Returns list of the associated tag_nums to the given tid_num. '''\n\n        q = \"SELECT tag FROM tid_tag WHERE tid = '\" + str(tid_num) + \"'\"\n        self.query(q)\n        return [i[0] for i in self.c.fetchall()]", "func_src_after": "    def tid_num_to_tag_nums(self, tid_num):\n        ''' Returns list of the associated tag_nums to the given tid_num. '''\n\n        q = \"SELECT tag FROM tid_tag WHERE tid = ?\"\n        self.query(q, tid_num)\n        return [i[0] for i in self.c.fetchall()]", "line_changes": {"deleted": [{"line_no": 4, "char_start": 123, "char_end": 196, "line": "        q = \"SELECT tag FROM tid_tag WHERE tid = '\" + str(tid_num) + \"'\"\n"}, {"line_no": 5, "char_start": 196, "char_end": 218, "line": "        self.query(q)\n"}], "added": [{"line_no": 4, "char_start": 123, "char_end": 175, "line": "        q = \"SELECT tag FROM tid_tag WHERE tid = ?\"\n"}, {"line_no": 5, "char_start": 175, "char_end": 206, "line": "        self.query(q, tid_num)\n"}]}, "char_changes": {"deleted": [{"char_start": 172, "char_end": 194, "chars": "'\" + str(tid_num) + \"'"}], "added": [{"char_start": 172, "char_end": 173, "chars": "?"}, {"char_start": 195, "char_end": 204, "chars": ", tid_num"}]}, "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089"}
{"func_name": "tag_num_to_tag", "func_src_before": "    def tag_num_to_tag(self, tag_num):\n        ''' Returns tag given tag_num. '''\n\n        q = \"SELECT tag FROM tags WHERE rowid = '\" + str(tag_num) + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "func_src_after": "    def tag_num_to_tag(self, tag_num):\n        ''' Returns tag given tag_num. '''\n\n        q = \"SELECT tag FROM tags WHERE rowid = ?\"\n        self.query(q, tag_num)\n        return self.c.fetchone()[0]", "line_changes": {"deleted": [{"line_no": 4, "char_start": 83, "char_end": 155, "line": "        q = \"SELECT tag FROM tags WHERE rowid = '\" + str(tag_num) + \"'\"\n"}, {"line_no": 5, "char_start": 155, "char_end": 177, "line": "        self.query(q)\n"}], "added": [{"line_no": 4, "char_start": 83, "char_end": 134, "line": "        q = \"SELECT tag FROM tags WHERE rowid = ?\"\n"}, {"line_no": 5, "char_start": 134, "char_end": 165, "line": "        self.query(q, tag_num)\n"}]}, "char_changes": {"deleted": [{"char_start": 131, "char_end": 153, "chars": "'\" + str(tag_num) + \"'"}], "added": [{"char_start": 131, "char_end": 132, "chars": "?"}, {"char_start": 154, "char_end": 163, "chars": ", tag_num"}]}, "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089"}
{"func_name": "tag_to_tag_num", "func_src_before": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = '\" + tag + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "func_src_after": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = ?\"\n        self.query(q, tag)\n        return self.c.fetchone()[0]", "line_changes": {"deleted": [{"line_no": 4, "char_start": 79, "char_end": 142, "line": "        q = \"SELECT rowid FROM tags WHERE tag = '\" + tag + \"'\"\n"}, {"line_no": 5, "char_start": 142, "char_end": 164, "line": "        self.query(q)\n"}], "added": [{"line_no": 4, "char_start": 79, "char_end": 130, "line": "        q = \"SELECT rowid FROM tags WHERE tag = ?\"\n"}, {"line_no": 5, "char_start": 130, "char_end": 157, "line": "        self.query(q, tag)\n"}]}, "char_changes": {"deleted": [{"char_start": 127, "char_end": 140, "chars": "'\" + tag + \"'"}], "added": [{"char_start": 127, "char_end": 128, "chars": "?"}, {"char_start": 150, "char_end": 155, "chars": ", tag"}]}, "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089"}
{"func_name": "_get_degree_2", "func_src_before": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC' % (user_id, user_id, user_id)\n    with cnx.cursor() as cursor:\n        cursor.execute(sql)\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "func_src_after": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC'\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "line_changes": {"deleted": [{"line_no": 26, "char_start": 912, "char_end": 973, "line": "    'ORDER BY num_mutual DESC' % (user_id, user_id, user_id)\n"}, {"line_no": 28, "char_start": 1006, "char_end": 1034, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 26, "char_start": 912, "char_end": 943, "line": "    'ORDER BY num_mutual DESC'\n"}, {"line_no": 28, "char_start": 976, "char_end": 1033, "line": "        cursor.execute(sql, (user_id, user_id, user_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 942, "char_end": 972, "chars": " % (user_id, user_id, user_id)"}], "added": [{"char_start": 1002, "char_end": 1031, "chars": ", (user_id, user_id, user_id)"}]}, "commit_link": "github.com/young-goons/rifflo-server/commit/fb311df76713b638c9486250f9badb288ffb2189", "file_name": "server/ygoons/modules/user/follow_suggest.py", "vul_type": "cwe-089"}
{"func_name": "_get_degree_2", "func_src_before": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC'\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "func_src_after": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC'\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "line_changes": {"deleted": [{"line_no": 13, "char_start": 382, "char_end": 431, "line": "    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n"}], "added": [{"line_no": 13, "char_start": 382, "char_end": 417, "line": "    sql = 'WITH tmp_suggest AS ' \\\n"}]}, "char_changes": {"deleted": [{"char_start": 409, "char_end": 423, "chars": " (followed_id)"}], "added": []}, "commit_link": "github.com/young-goons/rifflo-server/commit/7392c7eae96dd03a46d20dc0222b911974e8ed99", "file_name": "server/ygoons/modules/user/follow_suggest.py", "vul_type": "cwe-089"}
{"func_name": "_get_degree_2", "func_src_before": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC'\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "func_src_after": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n    '(' \\\n        'SELECT b.followed_id AS followed_id ' \\\n        'FROM ' \\\n            'tbl_follow a INNER JOIN tbl_follow b ' \\\n            'ON a.followed_id = b.follower_id ' \\\n        'WHERE a.follower_id = %s ' \\\n        'AND b.followed_id NOT IN ' \\\n            '(SELECT followed_id FROM tbl_follow WHERE follower_id = %s) ' \\\n        'AND b.followed_id != %s ' \\\n    ') ' \\\n    'SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest ' \\\n    'GROUP BY followed_id ' \\\n    'ORDER BY num_mutual DESC'\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "line_changes": {"deleted": [{"line_no": 13, "char_start": 382, "char_end": 417, "line": "    sql = 'WITH tmp_suggest AS ' \\\n"}], "added": [{"line_no": 13, "char_start": 382, "char_end": 431, "line": "    sql = 'WITH tmp_suggest (followed_id) AS ' \\\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 409, "char_end": 423, "chars": " (followed_id)"}]}, "commit_link": "github.com/young-goons/rifflo-server/commit/e6d943188447879dd5be99e84cc40f7e784086e0", "file_name": "server/ygoons/modules/user/follow_suggest.py", "vul_type": "cwe-089"}
{"func_name": "_sort_similarity", "func_src_before": "def _sort_similarity(user_id, cands, cnx):\n    \"\"\"Get most similar users according to taste.\n    Args:\n        user_id (int): id of user to suggest for\n        cands (list(int)): ids of candidate users\n        cnx: DB connection\n\n    Returns:\n        list: cands ordered by decreasing similarity\n    \"\"\"\n    users_tmp = ', '.join(list(map(str, [user_id] + cands)))\n    sql = '''\n    WITH all_songs_analysis AS\n    (\n        SELECT\n            tbl_like.user_id AS user_id,\n            danceability,\n            energy,\n            loudness,\n            acousticness,\n            instrumentalness,\n            liveness,\n            valence\n        FROM\n            tbl_like JOIN tbl_post\n            ON (tbl_like.post_id = tbl_post.post_id)\n            JOIN tbl_music_analysis\n            ON (tbl_post.song_id = tbl_music_analysis.song_id)\n        WHERE tbl_like.user_id IN (%s)\n    )\n    SELECT\n        user_id,\n        AVG(danceability),\n        AVG(energy),\n        AVG(loudness),\n        AVG(acousticness),\n        AVG(instrumentalness),\n        AVG(liveness),\n        AVG(valence)\n    FROM all_songs_analysis\n    GROUP BY user_id\n    ''' % (users_tmp)\n    with cnx.cursor() as cursor:\n        cursor.execute(sql)\n        res = cursor.fetchall()\n    attributes_map = {}\n    for i in range(len(res)):\n        uid = res[i][0]\n        uattributes = np.array(res[i][1:])\n        attributes_map[uid] = uattributes\n\n    # Sort by cosine similarity\n    def _cosine_similarity(u, v):\n        try:\n            a = attributes_map[u]\n            b = attributes_map[v]\n        except KeyError:\n            return -2.  # Smaller than smallest possible cosine\n\n        return np.dot(a, b) / np.linalg.norm(a) / np.linalg.norm(b)\n\n    return sorted(cands, key=lambda uid: _cosine_similarity(user_id, uid))", "func_src_after": "def _sort_similarity(user_id, cands, cnx):\n    \"\"\"Get most similar users according to taste.\n    Args:\n        user_id (int): id of user to suggest for\n        cands (list(int)): ids of candidate users\n        cnx: DB connection\n\n    Returns:\n        list: cands ordered by decreasing similarity\n    \"\"\"\n    fmt_str = ','.join(['%s'] * (1 + len(cands)))\n    sql = '''\n    SELECT\n        user_id,\n        AVG(danceability),\n        AVG(energy),\n        AVG(loudness),\n        AVG(acousticness),\n        AVG(instrumentalness),\n        AVG(liveness),\n        AVG(valence)\n    FROM\n    (\n        SELECT\n            tbl_like.user_id AS user_id,\n            danceability,\n            energy,\n            loudness,\n            acousticness,\n            instrumentalness,\n            liveness,\n            valence\n        FROM\n            tbl_like JOIN tbl_post\n            ON (tbl_like.post_id = tbl_post.post_id)\n            JOIN tbl_music_analysis\n            ON (tbl_post.song_id = tbl_music_analysis.song_id)\n        WHERE tbl_like.user_id IN (%s)\n    ) all_songs_analysis\n    GROUP BY user_id\n    ''' % fmt_str\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, ([user_id] + cands))\n        res = cursor.fetchall()\n    attributes_map = {}\n    for i in range(len(res)):\n        uid = res[i][0]\n        uattributes = np.array(res[i][1:])\n        attributes_map[uid] = uattributes\n\n    # Sort by cosine similarity\n    def _cosine_similarity(u, v):\n        try:\n            a = attributes_map[u]\n            b = attributes_map[v]\n        except KeyError:\n            return -2.  # Smaller than smallest possible cosine\n\n        return np.dot(a, b) / np.linalg.norm(a) / np.linalg.norm(b)\n\n    return sorted(cands, key=lambda uid: _cosine_similarity(user_id, uid))", "line_changes": {"deleted": [{"line_no": 11, "char_start": 304, "char_end": 365, "line": "    users_tmp = ', '.join(list(map(str, [user_id] + cands)))\n"}, {"line_no": 13, "char_start": 379, "char_end": 410, "line": "    WITH all_songs_analysis AS\n"}, {"line_no": 30, "char_start": 877, "char_end": 883, "line": "    )\n"}, {"line_no": 31, "char_start": 883, "char_end": 894, "line": "    SELECT\n"}, {"line_no": 32, "char_start": 894, "char_end": 911, "line": "        user_id,\n"}, {"line_no": 33, "char_start": 911, "char_end": 938, "line": "        AVG(danceability),\n"}, {"line_no": 34, "char_start": 938, "char_end": 959, "line": "        AVG(energy),\n"}, {"line_no": 35, "char_start": 959, "char_end": 982, "line": "        AVG(loudness),\n"}, {"line_no": 36, "char_start": 982, "char_end": 1009, "line": "        AVG(acousticness),\n"}, {"line_no": 37, "char_start": 1009, "char_end": 1040, "line": "        AVG(instrumentalness),\n"}, {"line_no": 38, "char_start": 1040, "char_end": 1063, "line": "        AVG(liveness),\n"}, {"line_no": 39, "char_start": 1063, "char_end": 1084, "line": "        AVG(valence)\n"}, {"line_no": 40, "char_start": 1084, "char_end": 1112, "line": "    FROM all_songs_analysis\n"}, {"line_no": 42, "char_start": 1133, "char_end": 1155, "line": "    ''' % (users_tmp)\n"}, {"line_no": 44, "char_start": 1188, "char_end": 1216, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 11, "char_start": 304, "char_end": 354, "line": "    fmt_str = ','.join(['%s'] * (1 + len(cands)))\n"}, {"line_no": 13, "char_start": 368, "char_end": 379, "line": "    SELECT\n"}, {"line_no": 14, "char_start": 379, "char_end": 396, "line": "        user_id,\n"}, {"line_no": 15, "char_start": 396, "char_end": 423, "line": "        AVG(danceability),\n"}, {"line_no": 16, "char_start": 423, "char_end": 444, "line": "        AVG(energy),\n"}, {"line_no": 17, "char_start": 444, "char_end": 467, "line": "        AVG(loudness),\n"}, {"line_no": 18, "char_start": 467, "char_end": 494, "line": "        AVG(acousticness),\n"}, {"line_no": 19, "char_start": 494, "char_end": 525, "line": "        AVG(instrumentalness),\n"}, {"line_no": 20, "char_start": 525, "char_end": 548, "line": "        AVG(liveness),\n"}, {"line_no": 21, "char_start": 548, "char_end": 569, "line": "        AVG(valence)\n"}, {"line_no": 22, "char_start": 569, "char_end": 578, "line": "    FROM\n"}, {"line_no": 39, "char_start": 1045, "char_end": 1070, "line": "    ) all_songs_analysis\n"}, {"line_no": 41, "char_start": 1091, "char_end": 1109, "line": "    ''' % fmt_str\n"}, {"line_no": 43, "char_start": 1142, "char_end": 1191, "line": "        cursor.execute(sql, ([user_id] + cands))\n"}]}, "char_changes": {"deleted": [{"char_start": 308, "char_end": 317, "chars": "users_tmp"}, {"char_start": 322, "char_end": 323, "chars": " "}, {"char_start": 330, "char_end": 356, "chars": "list(map(str, [user_id] + "}, {"char_start": 383, "char_end": 409, "chars": "WITH all_songs_analysis AS"}, {"char_start": 882, "char_end": 1092, "chars": "\n    SELECT\n        user_id,\n        AVG(danceability),\n        AVG(energy),\n        AVG(loudness),\n        AVG(acousticness),\n        AVG(instrumentalness),\n        AVG(liveness),\n        AVG(valence)\n    FROM"}, {"char_start": 1143, "char_end": 1154, "chars": "(users_tmp)"}], "added": [{"char_start": 308, "char_end": 315, "chars": "fmt_str"}, {"char_start": 327, "char_end": 345, "chars": "['%s'] * (1 + len("}, {"char_start": 372, "char_end": 577, "chars": "SELECT\n        user_id,\n        AVG(danceability),\n        AVG(energy),\n        AVG(loudness),\n        AVG(acousticness),\n        AVG(instrumentalness),\n        AVG(liveness),\n        AVG(valence)\n    FROM"}, {"char_start": 1101, "char_end": 1108, "chars": "fmt_str"}, {"char_start": 1168, "char_end": 1189, "chars": ", ([user_id] + cands)"}]}, "commit_link": "github.com/young-goons/rifflo-server/commit/6fbd812eb91eb83f1b1bff59354ce1ea75a992eb", "file_name": "server/ygoons/modules/user/follow_suggest.py", "vul_type": "cwe-089"}
{"func_name": "_get_degree_2", "func_src_before": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = '''\n    WITH tmp_suggest (followed_id) AS\n    (\n        SELECT b.followed_id AS followed_id\n        FROM\n            tbl_follow a INNER JOIN tbl_follow b\n            ON a.followed_id = b.follower_id\n        WHERE a.follower_id = %s\n        AND b.followed_id NOT IN\n            (SELECT followed_id FROM tbl_follow WHERE follower_id = %s)\n        AND b.followed_id != %s\n    )\n    SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest\n    GROUP BY followed_id\n    ORDER BY num_mutual DESC\n    ''' % (user_id, user_id, user_id)\n    with cnx.cursor() as cursor:\n        cursor.execute(sql)\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "func_src_after": "def _get_degree_2(user_id, cnx):\n    \"\"\"Get all users of degree 2 follow that are not currently followed.\n    Example:\n        this user (follows) user B (follows) user B\n        AND user (does NOT follow) user B\n        means that user B will be in the list\n    Args:\n        user_id (int): id of user\n        cnx: DB connection\n    Returns:\n        list: list of user_ids\n    \"\"\"\n    sql = '''\n    SELECT followed_id, COUNT(*) AS num_mutual FROM\n    (\n        SELECT b.followed_id AS followed_id\n        FROM\n            tbl_follow a INNER JOIN tbl_follow b\n            ON a.followed_id = b.follower_id\n        WHERE a.follower_id = %s\n        AND b.followed_id NOT IN\n            (SELECT followed_id FROM tbl_follow WHERE follower_id = %s)\n        AND b.followed_id != %s\n    ) tbl_all_followed\n    GROUP BY followed_id\n    ORDER BY num_mutual DESC\n    '''\n    with cnx.cursor() as cursor:\n        cursor.execute(sql, (user_id, user_id, user_id))\n        res = cursor.fetchall()\n    return list(map(lambda x: x[0], res))", "line_changes": {"deleted": [{"line_no": 14, "char_start": 396, "char_end": 434, "line": "    WITH tmp_suggest (followed_id) AS\n"}, {"line_no": 24, "char_start": 761, "char_end": 767, "line": "    )\n"}, {"line_no": 25, "char_start": 767, "char_end": 831, "line": "    SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest\n"}, {"line_no": 28, "char_start": 885, "char_end": 923, "line": "    ''' % (user_id, user_id, user_id)\n"}, {"line_no": 30, "char_start": 956, "char_end": 984, "line": "        cursor.execute(sql)\n"}], "added": [{"line_no": 14, "char_start": 396, "char_end": 448, "line": "    SELECT followed_id, COUNT(*) AS num_mutual FROM\n"}, {"line_no": 24, "char_start": 775, "char_end": 798, "line": "    ) tbl_all_followed\n"}, {"line_no": 27, "char_start": 852, "char_end": 860, "line": "    '''\n"}, {"line_no": 29, "char_start": 893, "char_end": 950, "line": "        cursor.execute(sql, (user_id, user_id, user_id))\n"}]}, "char_changes": {"deleted": [{"char_start": 400, "char_end": 433, "chars": "WITH tmp_suggest (followed_id) AS"}, {"char_start": 766, "char_end": 830, "chars": "\n    SELECT followed_id, COUNT(*) AS num_mutual FROM tmp_suggest"}, {"char_start": 892, "char_end": 922, "chars": " % (user_id, user_id, user_id)"}], "added": [{"char_start": 400, "char_end": 447, "chars": "SELECT followed_id, COUNT(*) AS num_mutual FROM"}, {"char_start": 780, "char_end": 797, "chars": " tbl_all_followed"}, {"char_start": 919, "char_end": 948, "chars": ", (user_id, user_id, user_id)"}]}, "commit_link": "github.com/young-goons/rifflo-server/commit/6fbd812eb91eb83f1b1bff59354ce1ea75a992eb", "file_name": "server/ygoons/modules/user/follow_suggest.py", "vul_type": "cwe-089"}
{"func_name": "db_addDialog", "func_src_before": "def db_addDialog(nameDialog):\n    sql = (\"INSERT INTO dialogs (name, created_at)\\n\"\n           \"VALUES ('%s', NOW())\"\n           ) % nameDialog\n    return {'status': 1}", "func_src_after": "def db_addDialog(nameDialog):\n    sql='''\n        INSERT INTO dialogs (name, created_at)\n        VALUES ('{name}', NOW()) RETURNING id;\n    '''.format(**nameDialog)\n    dialogID = sql_execute(sql, fetch_all=False)\n    return dialogID['id']", "line_changes": {"deleted": [{"line_no": 2, "char_start": 30, "char_end": 84, "line": "    sql = (\"INSERT INTO dialogs (name, created_at)\\n\"\n"}, {"line_no": 3, "char_start": 84, "char_end": 118, "line": "           \"VALUES ('%s', NOW())\"\n"}, {"line_no": 4, "char_start": 118, "char_end": 144, "line": "           ) % nameDialog\n"}, {"line_no": 5, "char_start": 144, "char_end": 168, "line": "    return {'status': 1}\n"}], "added": [{"line_no": 2, "char_start": 30, "char_end": 42, "line": "    sql='''\n"}, {"line_no": 3, "char_start": 42, "char_end": 89, "line": "        INSERT INTO dialogs (name, created_at)\n"}, {"line_no": 4, "char_start": 89, "char_end": 136, "line": "        VALUES ('{name}', NOW()) RETURNING id;\n"}, {"line_no": 5, "char_start": 136, "char_end": 165, "line": "    '''.format(**nameDialog)\n"}, {"line_no": 6, "char_start": 165, "char_end": 214, "line": "    dialogID = sql_execute(sql, fetch_all=False)\n"}, {"line_no": 7, "char_start": 214, "char_end": 239, "line": "    return dialogID['id']\n"}]}, "char_changes": {"deleted": [{"char_start": 37, "char_end": 42, "chars": " = (\""}, {"char_start": 80, "char_end": 85, "chars": "\\n\"\n "}, {"char_start": 93, "char_end": 96, "chars": "  \""}, {"char_start": 105, "char_end": 107, "chars": "%s"}, {"char_start": 116, "char_end": 168, "chars": "\"\n           ) % nameDialog\n    return {'status': 1}"}], "added": [{"char_start": 37, "char_end": 50, "chars": "='''\n        "}, {"char_start": 88, "char_end": 89, "chars": "\n"}, {"char_start": 106, "char_end": 112, "chars": "{name}"}, {"char_start": 121, "char_end": 239, "chars": " RETURNING id;\n    '''.format(**nameDialog)\n    dialogID = sql_execute(sql, fetch_all=False)\n    return dialogID['id']"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/MessagesManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_addUserInDialog", "func_src_before": "def db_addUserInDialog(userID, dialogID, permission):\n    sql = (\"INSERT INTO dialogUser (dialog_id, user_id, permission)\\n\"\n           \"VALUES (%d, %d, %d)\"\n           ) % dialogID, userID, permission\n    return {'status': 1}", "func_src_after": "def db_addUserInDialog(userID, dialogID, permission):\n    sql='''\n        INSERT INTO dialogUser (dialog_id, user_id, permission)\n        VALUES ('{:d}', '{:d}', '{:d}'})\n    '''.format(dialogID, userID, permission)\n    sql_execute(sql, fetch_all=False)\n    return {'status': 1}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 54, "char_end": 125, "line": "    sql = (\"INSERT INTO dialogUser (dialog_id, user_id, permission)\\n\"\n"}, {"line_no": 3, "char_start": 125, "char_end": 158, "line": "           \"VALUES (%d, %d, %d)\"\n"}, {"line_no": 4, "char_start": 158, "char_end": 202, "line": "           ) % dialogID, userID, permission\n"}], "added": [{"line_no": 2, "char_start": 54, "char_end": 66, "line": "    sql='''\n"}, {"line_no": 3, "char_start": 66, "char_end": 130, "line": "        INSERT INTO dialogUser (dialog_id, user_id, permission)\n"}, {"line_no": 4, "char_start": 130, "char_end": 171, "line": "        VALUES ('{:d}', '{:d}', '{:d}'})\n"}, {"line_no": 5, "char_start": 171, "char_end": 216, "line": "    '''.format(dialogID, userID, permission)\n"}, {"line_no": 6, "char_start": 216, "char_end": 254, "line": "    sql_execute(sql, fetch_all=False)\n"}]}, "char_changes": {"deleted": [{"char_start": 61, "char_end": 66, "chars": " = (\""}, {"char_start": 121, "char_end": 128, "chars": "\\n\"\n   "}, {"char_start": 136, "char_end": 137, "chars": "\""}, {"char_start": 145, "char_end": 201, "chars": "%d, %d, %d)\"\n           ) % dialogID, userID, permission"}], "added": [{"char_start": 61, "char_end": 74, "chars": "='''\n        "}, {"char_start": 129, "char_end": 130, "chars": "\n"}, {"char_start": 146, "char_end": 253, "chars": "'{:d}', '{:d}', '{:d}'})\n    '''.format(dialogID, userID, permission)\n    sql_execute(sql, fetch_all=False)"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/MessagesManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_addMessageForDialog", "func_src_before": "def db_addMessageForDialog(userID, content, dialogID, section_id=0):\n    sql = (\"INSERT INTO messages (dialog_id, content, created_at, user_id, section_id)\\n\"\n           \"VALUES (%d, '%s', NOW(), %d, %d)\"\n           ) % (dialogID, content, userID, section_id)\n    return {'status': 1}", "func_src_after": "def db_addMessageForDialog(userID, content, dialogID, section_id=0):\n    sql='''\n        INSERT INTO messages (dialog_id, content, created_at, user_id, section_id)\n        VALUES ('{:d}', '{}', NOW(), '{:d}', '{:d}')\n    '''.format(dialogID, userID, section_id, content)\n    sql_execute(sql, fetch_all=False)\n    return {'status': 1}", "line_changes": {"deleted": [{"line_no": 2, "char_start": 69, "char_end": 159, "line": "    sql = (\"INSERT INTO messages (dialog_id, content, created_at, user_id, section_id)\\n\"\n"}, {"line_no": 3, "char_start": 159, "char_end": 205, "line": "           \"VALUES (%d, '%s', NOW(), %d, %d)\"\n"}, {"line_no": 4, "char_start": 205, "char_end": 260, "line": "           ) % (dialogID, content, userID, section_id)\n"}], "added": [{"line_no": 2, "char_start": 69, "char_end": 81, "line": "    sql='''\n"}, {"line_no": 3, "char_start": 81, "char_end": 164, "line": "        INSERT INTO messages (dialog_id, content, created_at, user_id, section_id)\n"}, {"line_no": 4, "char_start": 164, "char_end": 217, "line": "        VALUES ('{:d}', '{}', NOW(), '{:d}', '{:d}')\n"}, {"line_no": 5, "char_start": 217, "char_end": 271, "line": "    '''.format(dialogID, userID, section_id, content)\n"}, {"line_no": 6, "char_start": 271, "char_end": 309, "line": "    sql_execute(sql, fetch_all=False)\n"}]}, "char_changes": {"deleted": [{"char_start": 76, "char_end": 81, "chars": " = (\""}, {"char_start": 155, "char_end": 161, "chars": "\\n\"\n  "}, {"char_start": 169, "char_end": 171, "chars": " \""}, {"char_start": 179, "char_end": 181, "chars": "%d"}, {"char_start": 184, "char_end": 186, "chars": "%s"}, {"char_start": 196, "char_end": 220, "chars": "%d, %d)\"\n           ) % "}, {"char_start": 230, "char_end": 239, "chars": " content,"}], "added": [{"char_start": 76, "char_end": 89, "chars": "='''\n        "}, {"char_start": 163, "char_end": 164, "chars": "\n"}, {"char_start": 180, "char_end": 186, "chars": "'{:d}'"}, {"char_start": 189, "char_end": 191, "chars": "{}"}, {"char_start": 201, "char_end": 307, "chars": "'{:d}', '{:d}')\n    '''.format(dialogID, userID, section_id, content)\n    sql_execute(sql, fetch_all=False"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/MessagesManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_addProfile", "func_src_before": "def db_addProfile(data):\n    sql='''\n        INSERT INTO users (first_name, second_name, created_at, last_visit, is_blocked, is_online, is_deleted) \n        VALUES ('{first_name}', '{second_name}', NOW(), NOW(), false, true, false) RETURNING id;\n    '''.format(**data)\n    user_id = sql_execute(sql, fetch_all=True)\n    sql = \"\"\"\n        INSERT INTO authentications (user_id, login, password) \n        VALUES ('{}', '{login}', '{password}');\n    \"\"\".format(user_id[0]['id'], **data)\n    sql_execute(sql, fetch_all=False)\n    return {'status': 1}", "func_src_after": "def db_addProfile(data):\n    sql='''\n        INSERT INTO users (first_name, second_name, created_at, last_visit, is_blocked, is_online, is_deleted) \n        VALUES ('{first_name}', '{second_name}', NOW(), NOW(), false, true, false) RETURNING id;\n    '''.format(**data)\n    user_id = sql_execute(sql, fetch_all=False)\n    sql = \"\"\"\n        INSERT INTO authentications (user_id, login, password) \n        VALUES ('{:d}', '{login}', '{password}');\n    \"\"\".format(user_id[0]['id'], **data)\n    sql_execute(sql, fetch_all=False)\n    return {'status': 1}", "line_changes": {"deleted": [{"line_no": 6, "char_start": 269, "char_end": 316, "line": "    user_id = sql_execute(sql, fetch_all=True)\n"}, {"line_no": 9, "char_start": 394, "char_end": 442, "line": "        VALUES ('{}', '{login}', '{password}');\n"}], "added": [{"line_no": 6, "char_start": 269, "char_end": 317, "line": "    user_id = sql_execute(sql, fetch_all=False)\n"}, {"line_no": 9, "char_start": 395, "char_end": 445, "line": "        VALUES ('{:d}', '{login}', '{password}');\n"}]}, "char_changes": {"deleted": [{"char_start": 310, "char_end": 313, "chars": "Tru"}], "added": [{"char_start": 310, "char_end": 314, "chars": "Fals"}, {"char_start": 413, "char_end": 415, "chars": ":d"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_isProfileExists", "func_src_before": "def db_isProfileExists(data):\n    sql = \"SELECT count(login) FROM authentications \"\n\n    if type(data) == int:\n        sql += \"WHERE user_id='%d';\" % data\n    elif type(data) == dict:\n        sql += \"WHERE login='%(login)s';\" % data\n\n\n    users = sql_execute(sql, fetch_all=False)['count']\n    return bool(users)", "func_src_after": "def db_isProfileExists(data):\n    sql = \"SELECT count(login) FROM authentications \"\n\n    if type(data) == int:\n        sql += \"WHERE user_id='{:d}';\".format(data)\n    elif type(data) == dict:\n        sql += \"WHERE login='{login}';\".format(**data)\n\n\n    users = sql_execute(sql, fetch_all=False)['count']\n    return bool(users)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 111, "char_end": 155, "line": "        sql += \"WHERE user_id='%d';\" % data\n"}, {"line_no": 7, "char_start": 184, "char_end": 233, "line": "        sql += \"WHERE login='%(login)s';\" % data\n"}], "added": [{"line_no": 5, "char_start": 111, "char_end": 163, "line": "        sql += \"WHERE user_id='{:d}';\".format(data)\n"}, {"line_no": 7, "char_start": 192, "char_end": 247, "line": "        sql += \"WHERE login='{login}';\".format(**data)\n"}]}, "char_changes": {"deleted": [{"char_start": 142, "char_end": 150, "chars": "%d';\" % "}, {"char_start": 213, "char_end": 215, "chars": "%("}, {"char_start": 220, "char_end": 222, "chars": ")s"}, {"char_start": 225, "char_end": 228, "chars": " % "}], "added": [{"char_start": 142, "char_end": 157, "chars": "{:d}';\".format("}, {"char_start": 161, "char_end": 162, "chars": ")"}, {"char_start": 221, "char_end": 222, "chars": "{"}, {"char_start": 227, "char_end": 228, "chars": "}"}, {"char_start": 231, "char_end": 241, "chars": ".format(**"}, {"char_start": 245, "char_end": 246, "chars": ")"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_setLastVisit", "func_src_before": "def db_setLastVisit(ID):\n    sql='''\n        UPDATE users\n        SET last_visit = NOW()\n        WHERE id='%d';\n    ''' % ID\n    sql_execute(sql, fetch_all=False)", "func_src_after": "def db_setLastVisit(ID):\n    sql='''\n        UPDATE users\n        SET last_visit = NOW()\n        WHERE id='{:d}';\n    '''.format(ID)\n    sql_execute(sql, fetch_all=False)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 89, "char_end": 112, "line": "        WHERE id='%d';\n"}, {"line_no": 6, "char_start": 112, "char_end": 125, "line": "    ''' % ID\n"}], "added": [{"line_no": 5, "char_start": 89, "char_end": 114, "line": "        WHERE id='{:d}';\n"}, {"line_no": 6, "char_start": 114, "char_end": 133, "line": "    '''.format(ID)\n"}]}, "char_changes": {"deleted": [{"char_start": 107, "char_end": 109, "chars": "%d"}, {"char_start": 119, "char_end": 122, "chars": " % "}], "added": [{"char_start": 107, "char_end": 111, "chars": "{:d}"}, {"char_start": 121, "char_end": 129, "chars": ".format("}, {"char_start": 131, "char_end": 132, "chars": ")"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_blockProfile", "func_src_before": "def db_blockProfile(ID, status=True):\n    sql='''\n        UPDATE users\n        SET is_blocked='%s'\n        WHERE id='%d';\n    ''' % (status, ID)\n    sql_execute(sql, fetch_all=False)", "func_src_after": "def db_blockProfile(ID, status=True):\n    sql='''\n        UPDATE users\n        SET is_blocked='{}'\n        WHERE id='{:d}';\n    '''.format(status, ID)\n    sql_execute(sql, fetch_all=False)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 71, "char_end": 99, "line": "        SET is_blocked='%s'\n"}, {"line_no": 5, "char_start": 99, "char_end": 122, "line": "        WHERE id='%d';\n"}, {"line_no": 6, "char_start": 122, "char_end": 145, "line": "    ''' % (status, ID)\n"}], "added": [{"line_no": 4, "char_start": 71, "char_end": 99, "line": "        SET is_blocked='{}'\n"}, {"line_no": 5, "char_start": 99, "char_end": 124, "line": "        WHERE id='{:d}';\n"}, {"line_no": 6, "char_start": 124, "char_end": 151, "line": "    '''.format(status, ID)\n"}]}, "char_changes": {"deleted": [{"char_start": 95, "char_end": 97, "chars": "%s"}, {"char_start": 117, "char_end": 119, "chars": "%d"}, {"char_start": 129, "char_end": 132, "chars": " % "}], "added": [{"char_start": 95, "char_end": 97, "chars": "{}"}, {"char_start": 117, "char_end": 121, "chars": "{:d}"}, {"char_start": 131, "char_end": 138, "chars": ".format"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_getUserID", "func_src_before": "def db_getUserID(data):\n    sql='''\n        SELECT user_id\n        FROM authentications\n        WHERE login='%(login)s';\n    ''' % data\n    user_id = sql_execute(sql, fetch_all=False)\n    return user_id['user_id']", "func_src_after": "def db_getUserID(data):\n    sql='''\n        SELECT user_id\n        FROM authentications\n        WHERE login='{login}';\n    '''.format(**data)\n    user_id = sql_execute(sql, fetch_all=False)\n    return user_id['user_id']", "line_changes": {"deleted": [{"line_no": 5, "char_start": 88, "char_end": 121, "line": "        WHERE login='%(login)s';\n"}, {"line_no": 6, "char_start": 121, "char_end": 136, "line": "    ''' % data\n"}], "added": [{"line_no": 5, "char_start": 88, "char_end": 119, "line": "        WHERE login='{login}';\n"}, {"line_no": 6, "char_start": 119, "char_end": 142, "line": "    '''.format(**data)\n"}]}, "char_changes": {"deleted": [{"char_start": 109, "char_end": 111, "chars": "%("}, {"char_start": 116, "char_end": 118, "chars": ")s"}, {"char_start": 128, "char_end": 131, "chars": " % "}], "added": [{"char_start": 109, "char_end": 110, "chars": "{"}, {"char_start": 115, "char_end": 116, "chars": "}"}, {"char_start": 126, "char_end": 136, "chars": ".format(**"}, {"char_start": 140, "char_end": 141, "chars": ")"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_delProfile", "func_src_before": "def db_delProfile(ID, status=True):\n    # TODO: \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0437\u0430\u043f\u0440\u043e\u0441 \u043d\u0430 \u0443\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\n    sql='''\n        UPDATE users \n        SET is_deleted='%s'\n        WHERE id='%d';\n    ''' % (status, ID)\n    return sql_execute(sql, fetch_all=True)", "func_src_after": "def db_delProfile(ID, status=True):\n    # TODO: \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0437\u0430\u043f\u0440\u043e\u0441 \u043d\u0430 \u0443\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\n    sql='''\n        UPDATE users \n        SET is_deleted='{}'\n        WHERE id='{:d}';\n    '''.format(status, ID)\n    return sql_execute(sql, fetch_all=True)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 123, "char_end": 151, "line": "        SET is_deleted='%s'\n"}, {"line_no": 6, "char_start": 151, "char_end": 174, "line": "        WHERE id='%d';\n"}, {"line_no": 7, "char_start": 174, "char_end": 197, "line": "    ''' % (status, ID)\n"}], "added": [{"line_no": 5, "char_start": 123, "char_end": 151, "line": "        SET is_deleted='{}'\n"}, {"line_no": 6, "char_start": 151, "char_end": 176, "line": "        WHERE id='{:d}';\n"}, {"line_no": 7, "char_start": 176, "char_end": 203, "line": "    '''.format(status, ID)\n"}]}, "char_changes": {"deleted": [{"char_start": 147, "char_end": 149, "chars": "%s"}, {"char_start": 169, "char_end": 171, "chars": "%d"}, {"char_start": 181, "char_end": 184, "chars": " % "}], "added": [{"char_start": 147, "char_end": 149, "chars": "{}"}, {"char_start": 169, "char_end": 173, "chars": "{:d}"}, {"char_start": 183, "char_end": 190, "chars": ".format"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_FullDelProfile", "func_src_before": "def db_FullDelProfile(ID):\n    # TODO: \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0437\u0430\u043f\u0440\u043e\u0441 \u043d\u0430 \u0443\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\n    sql='''\n        DELETE FROM authentications\n        WHERE user_id='%d';\n        DELETE FROM users\n        WHERE id='%d';\n    ''' % (ID, ID)\n    sql_execute(sql, fetch_all=True)\n    return {'status': 1}", "func_src_after": "def db_FullDelProfile(ID):\n    # TODO: \u0414\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0437\u0430\u043f\u0440\u043e\u0441 \u043d\u0430 \u0443\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\n    sql='''\n        DELETE FROM authentications\n        WHERE user_id='{:d}';\n        DELETE FROM users\n        WHERE id='{:d}';\n    '''.format(ID, ID)\n    sql_execute(sql, fetch_all=True)\n    return {'status': 1}", "line_changes": {"deleted": [{"line_no": 5, "char_start": 128, "char_end": 156, "line": "        WHERE user_id='%d';\n"}, {"line_no": 7, "char_start": 182, "char_end": 205, "line": "        WHERE id='%d';\n"}, {"line_no": 8, "char_start": 205, "char_end": 224, "line": "    ''' % (ID, ID)\n"}], "added": [{"line_no": 5, "char_start": 128, "char_end": 158, "line": "        WHERE user_id='{:d}';\n"}, {"line_no": 7, "char_start": 184, "char_end": 209, "line": "        WHERE id='{:d}';\n"}, {"line_no": 8, "char_start": 209, "char_end": 232, "line": "    '''.format(ID, ID)\n"}]}, "char_changes": {"deleted": [{"char_start": 151, "char_end": 153, "chars": "%d"}, {"char_start": 200, "char_end": 202, "chars": "%d"}, {"char_start": 212, "char_end": 215, "chars": " % "}], "added": [{"char_start": 151, "char_end": 155, "chars": "{:d}"}, {"char_start": 202, "char_end": 206, "chars": "{:d}"}, {"char_start": 216, "char_end": 223, "chars": ".format"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_getProfileInfo", "func_src_before": "def db_getProfileInfo(ID):\n    sql='''\n        SELECT first_name, second_name, id, last_visit, is_deleted, is_blocked\n        FROM users\n        WHERE id='%d';\n    ''' % ID\n    return sql_execute(sql, fetch_all=False)", "func_src_after": "def db_getProfileInfo(ID):\n    sql='''\n        SELECT first_name, second_name, id, last_visit, is_deleted, is_blocked\n        FROM users\n        WHERE id='{:d}';\n    '''.format(ID)\n    return sql_execute(sql, fetch_all=False)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 137, "char_end": 160, "line": "        WHERE id='%d';\n"}, {"line_no": 6, "char_start": 160, "char_end": 173, "line": "    ''' % ID\n"}], "added": [{"line_no": 5, "char_start": 137, "char_end": 162, "line": "        WHERE id='{:d}';\n"}, {"line_no": 6, "char_start": 162, "char_end": 181, "line": "    '''.format(ID)\n"}]}, "char_changes": {"deleted": [{"char_start": 155, "char_end": 157, "chars": "%d"}, {"char_start": 167, "char_end": 170, "chars": " % "}], "added": [{"char_start": 155, "char_end": 159, "chars": "{:d}"}, {"char_start": 169, "char_end": 177, "chars": ".format("}, {"char_start": 179, "char_end": 180, "chars": ")"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_updateProfileInfo", "func_src_before": "def db_updateProfileInfo(ID, data):\n    rows = []\n    for key in data:\n        if not key in ('first_name', 'second_name'):\n            return {'status': 0, 'message': '\u041d\u0435\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u043e\u0435 \u043f\u043e\u043b\u0435. \u041c\u0435\u043d\u044f\u0442\u044c \u043c\u043e\u0436\u043d\u043e \u0442\u043e\u043b\u044c\u043a\u043e first_name/second_name'}\n\n        if data[key]:\n            sql='''\n                SELECT first_name, second_name\n                FROM users\n                WHERE id='%d'\n            ''' % ID\n            answer = sql_execute(sql, fetch_all=False)\n\n            if data[key] == answer[key]: # \u0415\u0441\u043b\u0438 \u0432\u0432\u0435\u0434\u0451\u043d\u043d\u043e\u0435 \u0438 \u0438\u0437 \u0411\u0414 \u043f\u043e\u043b\u044f \u044d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u044b, \u0442\u043e \u0432\u044b\u043a\u0438\u0434\u044b\u0432\u0430\u0435\u043c \u043e\u0448\u0438\u0431\u043a\u0443.\n                rows.append(key)\n                continue\n\n            sql = '''\n                UPDATE users\n                SET %s='%s' \n                WHERE id='%d';\n            ''' % (key, data[key], ID)\n            sql_execute(sql, fetch_all=False)\n\n    if not len(rows):\n        return {'status': 1}\n    elif len(rows) >= 1:\n        return {'status': 1, 'message': '\u042d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u043d\u043e\u0435 \u043f\u043e\u043b\u0435 {} \u043d\u0435 \u0431\u044b\u043b\u043e \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u043e'.format(rows)}\n    else:\n        return {'status': 0, 'message': '\u042d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u043d\u044b\u0435 \u043f\u043e\u043b\u044f {} \u043d\u0435 \u0431\u044b\u043b\u0438 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u044b'.format(rows)}", "func_src_after": "def db_updateProfileInfo(ID, data):\n    rows = []\n    for key in data:\n        if not key in ('first_name', 'second_name'):\n            return {'status': 0, 'message': '\u041d\u0435\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u043e\u0435 \u043f\u043e\u043b\u0435. \u041c\u0435\u043d\u044f\u0442\u044c \u043c\u043e\u0436\u043d\u043e \u0442\u043e\u043b\u044c\u043a\u043e first_name/second_name'}\n\n        if data[key]:\n            sql='''\n                SELECT first_name, second_name\n                FROM users\n                WHERE id='{:d}'\n            '''.format(ID)\n            answer = sql_execute(sql, fetch_all=False)\n\n            if data[key] == answer[key]: # \u0415\u0441\u043b\u0438 \u0432\u0432\u0435\u0434\u0451\u043d\u043d\u043e\u0435 \u0438 \u0438\u0437 \u0411\u0414 \u043f\u043e\u043b\u044f \u044d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u044b, \u0442\u043e \u0432\u044b\u043a\u0438\u0434\u044b\u0432\u0430\u0435\u043c \u043e\u0448\u0438\u0431\u043a\u0443.\n                rows.append(key)\n                continue\n\n            sql = '''\n                UPDATE users\n                SET {}='{}' \n                WHERE id='{:d}';\n            '''.format(key, data[key], ID)\n            sql_execute(sql, fetch_all=False)\n\n    if not len(rows):\n        return {'status': 1}\n    elif len(rows) >= 1:\n        return {'status': 1, 'message': '\u042d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u043d\u043e\u0435 \u043f\u043e\u043b\u0435 {} \u043d\u0435 \u0431\u044b\u043b\u043e \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u043e'.format(rows)}\n    else:\n        return {'status': 0, 'message': '\u042d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u043d\u044b\u0435 \u043f\u043e\u043b\u044f {} \u043d\u0435 \u0431\u044b\u043b\u0438 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u044b'.format(rows)}", "line_changes": {"deleted": [{"line_no": 11, "char_start": 349, "char_end": 379, "line": "                WHERE id='%d'\n"}, {"line_no": 12, "char_start": 379, "char_end": 400, "line": "            ''' % ID\n"}, {"line_no": 21, "char_start": 672, "char_end": 701, "line": "                SET %s='%s' \n"}, {"line_no": 22, "char_start": 701, "char_end": 732, "line": "                WHERE id='%d';\n"}, {"line_no": 23, "char_start": 732, "char_end": 771, "line": "            ''' % (key, data[key], ID)\n"}], "added": [{"line_no": 11, "char_start": 349, "char_end": 381, "line": "                WHERE id='{:d}'\n"}, {"line_no": 12, "char_start": 381, "char_end": 408, "line": "            '''.format(ID)\n"}, {"line_no": 21, "char_start": 680, "char_end": 709, "line": "                SET {}='{}' \n"}, {"line_no": 22, "char_start": 709, "char_end": 742, "line": "                WHERE id='{:d}';\n"}, {"line_no": 23, "char_start": 742, "char_end": 785, "line": "            '''.format(key, data[key], ID)\n"}]}, "char_changes": {"deleted": [{"char_start": 375, "char_end": 377, "chars": "%d"}, {"char_start": 394, "char_end": 397, "chars": " % "}, {"char_start": 692, "char_end": 698, "chars": "%s='%s"}, {"char_start": 727, "char_end": 729, "chars": "%d"}, {"char_start": 747, "char_end": 750, "chars": " % "}], "added": [{"char_start": 375, "char_end": 379, "chars": "{:d}"}, {"char_start": 396, "char_end": 404, "chars": ".format("}, {"char_start": 406, "char_end": 407, "chars": ")"}, {"char_start": 700, "char_end": 706, "chars": "{}='{}"}, {"char_start": 735, "char_end": 739, "chars": "{:d}"}, {"char_start": 757, "char_end": 764, "chars": ".format"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "test_d_update_user", "func_src_before": "    def test_d_update_user(self):\n        string = ''.join([chr(random.randint(33, 126)) for _ in range(9)])\n        resp = requests.get('http://127.0.0.1:5000/profiles')\n        self.assertEqual(resp.status_code, 200)\n        self.assertIsNotNone(resp.text)\n        users = json.loads(resp.text)\n        for user in users:\n            if user['id'] != 191:\n                # \u041d\u0435\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u043e\u0435 \u043f\u043e\u043b\u0435. \u041c\u0435\u043d\u044f\u0442\u044c \u043c\u043e\u0436\u043d\u043e \u0442\u043e\u043b\u044c\u043a\u043e fist_name/second_name\n                data = {\n                    string: string,\n                    string: string,\n                }\n                resp = requests.put('http://127.0.0.1:5000/profile/{}'.format(user['id']), json=data)\n                response = json.loads(resp.text)\n                print(response)\n                self.assertEqual(resp.status_code, 200)\n                self.assertIsNotNone(resp.text)\n                self.assertEqual(response['status'], 0)\n                self.assertIsNotNone(response['message'])\n                print('[1] /profile/{} update_user: {}'.format(user['id'], resp.text))\n\n                # 1 \u044d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u043d\u043e\u0435 \u043f\u043e\u043b\u0435 \u043d\u0435 \u0431\u044b\u043b\u043e \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u043e\n                resp = requests.get('http://127.0.0.1:5000/profile/{}'.format(user['id']), json=data)\n                response = json.loads(resp.text)\n                data = {\n                    'first_name': response['first_name'],\n                    'second_name': string,\n                }\n                resp = requests.put('http://127.0.0.1:5000/profile/{}'.format(user['id']), json=data)\n                response2 = json.loads(resp.text)\n                self.assertEqual(resp.status_code, 200)\n                self.assertEqual(response2['status'], 1)\n                self.assertIsNotNone(response2['message'])\n                print('[2] /profile/{} update_user: {}'.format(user['id'], resp.text))\n\n                # {'status': 1}\n                data = {\n                    'first_name': string + 'a',\n                    'second_name': string + 'a',\n                }\n                resp = requests.put('http://127.0.0.1:5000/profile/{}'.format(user['id']), json=data)\n                response = json.loads(resp.text)\n                self.assertEqual(resp.status_code, 200)\n                self.assertEqual(response['status'], 1)\n                print('[3] /profile/{} update_user: {}'.format(user['id'], resp.text))", "func_src_after": "    def test_d_update_user(self):\n        string = ''.join([chr(random.randint(33, 126)) for _ in range(9)])\n        resp = requests.get('http://127.0.0.1:5000/profile/all')\n        self.assertEqual(resp.status_code, 200)\n        self.assertIsNotNone(resp.text)\n        users = json.loads(resp.text)\n        for user in users:\n            if user['id'] != 191:\n                # \u041d\u0435\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u043e\u0435 \u043f\u043e\u043b\u0435. \u041c\u0435\u043d\u044f\u0442\u044c \u043c\u043e\u0436\u043d\u043e \u0442\u043e\u043b\u044c\u043a\u043e fist_name/second_name\n                data = {\n                    string: string,\n                    string: string,\n                }\n                resp = requests.put('http://127.0.0.1:5000/profile/{}'.format(user['id']), json=data)\n                response = json.loads(resp.text)\n                print(response)\n                self.assertEqual(resp.status_code, 200)\n                self.assertIsNotNone(resp.text)\n                self.assertEqual(response['status'], 0)\n                self.assertIsNotNone(response['message'])\n                print('[1] /profile/{} update_user: {}'.format(user['id'], resp.text))\n\n                # 1 \u044d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u043d\u043e\u0435 \u043f\u043e\u043b\u0435 \u043d\u0435 \u0431\u044b\u043b\u043e \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u043e\n                resp = requests.get('http://127.0.0.1:5000/profile/{}'.format(user['id']), json=data)\n                response = json.loads(resp.text)\n                data = {\n                    'first_name': response['first_name'],\n                    'second_name': string,\n                }\n                resp = requests.put('http://127.0.0.1:5000/profile/{}'.format(user['id']), json=data)\n                response2 = json.loads(resp.text)\n                self.assertEqual(resp.status_code, 200)\n                self.assertEqual(response2['status'], 1)\n                self.assertIsNotNone(response2['message'])\n                print('[2] /profile/{} update_user: {}'.format(user['id'], resp.text))\n\n                # {'status': 1}\n                data = {\n                    'first_name': string + 'a',\n                    'second_name': string + 'a',\n                }\n                resp = requests.put('http://127.0.0.1:5000/profile/{}'.format(user['id']), json=data)\n                response = json.loads(resp.text)\n                self.assertEqual(resp.status_code, 200)\n                self.assertEqual(response['status'], 1)\n                print('[3] /profile/{} update_user: {}'.format(user['id'], resp.text))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 109, "char_end": 171, "line": "        resp = requests.get('http://127.0.0.1:5000/profiles')\n"}], "added": [{"line_no": 3, "char_start": 109, "char_end": 174, "line": "        resp = requests.get('http://127.0.0.1:5000/profile/all')\n"}]}, "char_changes": {"deleted": [{"char_start": 167, "char_end": 168, "chars": "s"}], "added": [{"char_start": 167, "char_end": 171, "chars": "/all"}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/0c65886a68eddda29b6d5c2033b1311659595c86", "file_name": "tests/tests.py", "vul_type": "cwe-089"}
{"func_name": "db_isAuthDataValid", "func_src_before": "def db_isAuthDataValid(data):\n    print(data)\n    sql='''\n        SELECT user_id\n        FROM authentications\n        WHERE login='{login}' AND password='{password}';\n    '''.format(**data)\n    answer = sql_execute(sql, fetch_all=False)\n    return True if answer is not None else False", "func_src_after": "def db_isAuthDataValid(data):\n    print(data)\n    sql='''\n        SELECT user_id\n        FROM authentications\n        WHERE login='{login}' AND password='{password}';\n    '''.format(**data)\n    answer = sql_execute(sql, fetch_all=False)\n    return answer is not None", "line_changes": {"deleted": [{"line_no": 9, "char_start": 237, "char_end": 285, "line": "    return True if answer is not None else False\n"}], "added": [{"line_no": 9, "char_start": 237, "char_end": 266, "line": "    return answer is not None\n"}]}, "char_changes": {"deleted": [{"char_start": 248, "char_end": 256, "chars": "True if "}, {"char_start": 274, "char_end": 285, "chars": " else False"}], "added": []}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/138e81fb0f38503c32f6e6a0dfd0259966343b7d", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "db_isProfileExists", "func_src_before": "def db_isProfileExists(data):\n    sql = \"SELECT count(login) FROM authentications \"\n\n    if type(data) == int:\n        sql += \"WHERE user_id='{:d}';\".format(data)\n    elif type(data) == dict:\n        sql += \"WHERE login='{login}';\".format(**data)\n\n\n    users = sql_execute(sql, fetch_all=False)['count']\n    return bool(users)", "func_src_after": "def db_isProfileExists(data):\n    sql = \"SELECT count(login) FROM authentications \"\n\n    if type(data) == int:\n        sql += \" WHERE user_id='{:d}';\".format(data)\n    elif type(data) == dict:\n        sql += \" WHERE login='{login}';\".format(**data)\n\n\n    users = sql_execute(sql, fetch_all=False)['count']\n    return bool(users)", "line_changes": {"deleted": [{"line_no": 5, "char_start": 111, "char_end": 163, "line": "        sql += \"WHERE user_id='{:d}';\".format(data)\n"}, {"line_no": 7, "char_start": 192, "char_end": 247, "line": "        sql += \"WHERE login='{login}';\".format(**data)\n"}], "added": [{"line_no": 5, "char_start": 111, "char_end": 164, "line": "        sql += \" WHERE user_id='{:d}';\".format(data)\n"}, {"line_no": 7, "char_start": 193, "char_end": 249, "line": "        sql += \" WHERE login='{login}';\".format(**data)\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 127, "char_end": 128, "chars": " "}, {"char_start": 209, "char_end": 210, "chars": " "}]}, "commit_link": "github.com/tensor-nsk-lesson/messenger_1/commit/eb7fe285e57a5672efc2a124ca107aebf190a83f", "file_name": "src/modules/ProfileManager/api/db_methods.py", "vul_type": "cwe-089"}
{"func_name": "get_table_summary", "func_src_before": "    def get_table_summary(self, connection_url, table_name):\n        # TODO check table_name is a valid SQL table\n        query = \"select * from {} limit 10000\".format(table_name)\n        return self.execute_query(connection_url, query)", "func_src_after": "    def get_table_summary(self, connection_url, table_name):\n        query = select([text('*')]).select_from(table(table_name)).limit(10000)\n        return self.execute_query(connection_url, query)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 114, "char_end": 180, "line": "        query = \"select * from {} limit 10000\".format(table_name)\n"}], "added": [{"line_no": 2, "char_start": 61, "char_end": 141, "line": "        query = select([text('*')]).select_from(table(table_name)).limit(10000)\n"}]}, "char_changes": {"deleted": [{"char_start": 61, "char_end": 114, "chars": "        # TODO check table_name is a valid SQL table\n"}, {"char_start": 130, "char_end": 131, "chars": "\""}, {"char_start": 137, "char_end": 178, "chars": " * from {} limit 10000\".format(table_name"}], "added": [{"char_start": 83, "char_end": 139, "chars": "([text('*')]).select_from(table(table_name)).limit(10000"}]}, "commit_link": "github.com/pbugnion/jupyterlab-sql/commit/59d826adc9eca7894736267107b0567c80e23707", "file_name": "jupyterlab_sql/executor.py", "vul_type": "cwe-089"}
{"func_name": "update_sources", "func_src_before": "def update_sources(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the source table.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    old_sources = get_all_old_sources(conn, sqlite)\n\n    # Check if the source table is allready filled and this is not the first checkup\n    source_table_is_filled = len(old_sources) > 100\n\n    for old_source in old_sources:\n        if source_table_is_filled and old_source not in current_sources:\n            message = \"Die SID %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die SID aus der Datenbank loeschen.\" % old_source\n            send_message(message)\n\n    for current_source in current_sources:\n        if current_source not in old_sources:\n            message = \"The source %s is new in Solr.\" % current_source\n            if source_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO source (source) VALUES (%s)\" % current_source\n            sqlite.execute(sql)\n            conn.commit()", "func_src_after": "def update_sources(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the source table.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    old_sources = get_all_old_sources(conn, sqlite)\n\n    # Check if the source table is allready filled and this is not the first checkup\n    source_table_is_filled = len(old_sources) > 100\n\n    for old_source in old_sources:\n        if source_table_is_filled and old_source not in current_sources:\n            message = \"Die SID %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die SID aus der Datenbank loeschen.\" % old_source\n            send_message(message)\n\n    for current_source in current_sources:\n        if current_source not in old_sources:\n            message = \"The source %s is new in Solr.\" % current_source\n            if source_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO source (source) VALUES (?)\"\n            sqlite.execute(sql, (current_source,))\n            conn.commit()", "line_changes": {"deleted": [{"line_no": 23, "char_start": 943, "char_end": 1020, "line": "            sql = \"INSERT INTO source (source) VALUES (%s)\" % current_source\n"}, {"line_no": 24, "char_start": 1020, "char_end": 1052, "line": "            sqlite.execute(sql)\n"}], "added": [{"line_no": 23, "char_start": 943, "char_end": 1002, "line": "            sql = \"INSERT INTO source (source) VALUES (?)\"\n"}, {"line_no": 24, "char_start": 1002, "char_end": 1053, "line": "            sqlite.execute(sql, (current_source,))\n"}]}, "char_changes": {"deleted": [{"char_start": 998, "char_end": 1019, "chars": "%s)\" % current_source"}], "added": [{"char_start": 998, "char_end": 1001, "chars": "?)\""}, {"char_start": 1032, "char_end": 1051, "chars": ", (current_source,)"}]}, "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089"}
{"func_name": "get_old_sourcebyinstitution_number", "func_src_before": "def get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution):\n    \"\"\"\n    Get all the old sourcebyinstitution number from the SQLite database.\n    \"\"\"\n    query = \"\"\"\n        SELECT\n            titles\n        FROM\n            history\n        WHERE\n            sourcebyinstitution = \"%s\"\n        ORDER BY\n            titles DESC\n        LIMIT 1\n    \"\"\" % sourcebyinstitution\n\n    sqlite.execute(query)\n    for record in sqlite:\n        old_sourcebyinstitution_number = record[0]\n        return old_sourcebyinstitution_number", "func_src_after": "def get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution):\n    \"\"\"\n    Get all the old sourcebyinstitution number from the SQLite database.\n    \"\"\"\n    query = \"\"\"\n        SELECT\n            titles\n        FROM\n            history\n        WHERE\n            sourcebyinstitution = ?\n        ORDER BY\n            titles DESC\n        LIMIT 1\n    \"\"\"\n\n    sqlite.execute(query, (sourcebyinstitution,))\n    for record in sqlite:\n        old_sourcebyinstitution_number = record[0]\n        return old_sourcebyinstitution_number", "line_changes": {"deleted": [{"line_no": 11, "char_start": 261, "char_end": 300, "line": "            sourcebyinstitution = \"%s\"\n"}, {"line_no": 15, "char_start": 357, "char_end": 387, "line": "    \"\"\" % sourcebyinstitution\n"}, {"line_no": 17, "char_start": 388, "char_end": 414, "line": "    sqlite.execute(query)\n"}], "added": [{"line_no": 11, "char_start": 261, "char_end": 297, "line": "            sourcebyinstitution = ?\n"}, {"line_no": 15, "char_start": 354, "char_end": 362, "line": "    \"\"\"\n"}, {"line_no": 17, "char_start": 363, "char_end": 413, "line": "    sqlite.execute(query, (sourcebyinstitution,))\n"}]}, "char_changes": {"deleted": [{"char_start": 295, "char_end": 299, "chars": "\"%s\""}, {"char_start": 364, "char_end": 386, "chars": " % sourcebyinstitution"}], "added": [{"char_start": 295, "char_end": 296, "chars": "?"}, {"char_start": 387, "char_end": 411, "chars": ", (sourcebyinstitution,)"}]}, "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089"}
{"func_name": "update_institutions", "func_src_before": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES ('%s')\" % current_institution\n            sqlite.execute(sql)\n            conn.commit()", "func_src_after": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES (?)\"\n            sqlite.execute(sql, (current_institution,))\n            conn.commit()", "line_changes": {"deleted": [{"line_no": 25, "char_start": 1155, "char_end": 1249, "line": "            sql = \"INSERT INTO institution (institution) VALUES ('%s')\" % current_institution\n"}, {"line_no": 26, "char_start": 1249, "char_end": 1281, "line": "            sqlite.execute(sql)\n"}], "added": [{"line_no": 25, "char_start": 1155, "char_end": 1224, "line": "            sql = \"INSERT INTO institution (institution) VALUES (?)\"\n"}, {"line_no": 26, "char_start": 1224, "char_end": 1280, "line": "            sqlite.execute(sql, (current_institution,))\n"}]}, "char_changes": {"deleted": [{"char_start": 1220, "char_end": 1248, "chars": "'%s')\" % current_institution"}], "added": [{"char_start": 1220, "char_end": 1223, "chars": "?)\""}, {"char_start": 1254, "char_end": 1278, "chars": ", (current_institution,)"}]}, "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089"}
{"func_name": "update_history_and_sourcebyinstitution", "func_src_before": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                sqlite.execute(sql)\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                    sqlite.execute(sql)\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES ('%s')\" % sourcebyinstitution\n                sqlite.execute(sql)\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "func_src_after": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                sqlite.execute(sql, (sourcebyinstitution, number))\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                    sqlite.execute(sql, (sourcebyinstitution, number))\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES (?)\"\n                sqlite.execute(sql, (sourcebyinstitution))\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "line_changes": {"deleted": [{"line_no": 30, "char_start": 1094, "char_end": 1218, "line": "                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n"}, {"line_no": 31, "char_start": 1218, "char_end": 1254, "line": "                sqlite.execute(sql)\n"}, {"line_no": 39, "char_start": 1516, "char_end": 1644, "line": "                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n"}, {"line_no": 40, "char_start": 1644, "char_end": 1684, "line": "                    sqlite.execute(sql)\n"}, {"line_no": 45, "char_start": 1875, "char_end": 1989, "line": "                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES ('%s')\" % sourcebyinstitution\n"}, {"line_no": 46, "char_start": 1989, "char_end": 2025, "line": "                sqlite.execute(sql)\n"}], "added": [{"line_no": 30, "char_start": 1094, "char_end": 1182, "line": "                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n"}, {"line_no": 31, "char_start": 1182, "char_end": 1249, "line": "                sqlite.execute(sql, (sourcebyinstitution, number))\n"}, {"line_no": 39, "char_start": 1511, "char_end": 1603, "line": "                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n"}, {"line_no": 40, "char_start": 1603, "char_end": 1674, "line": "                    sqlite.execute(sql, (sourcebyinstitution, number))\n"}, {"line_no": 45, "char_start": 1865, "char_end": 1954, "line": "                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES (?)\"\n"}, {"line_no": 46, "char_start": 1954, "char_end": 2013, "line": "                sqlite.execute(sql, (sourcebyinstitution))\n"}]}, "char_changes": {"deleted": [{"char_start": 1175, "char_end": 1217, "chars": "\"%s\", %s)' % (sourcebyinstitution, number)"}, {"char_start": 1601, "char_end": 1643, "chars": "\"%s\", %s)' % (sourcebyinstitution, number)"}, {"char_start": 1960, "char_end": 1988, "chars": "'%s')\" % sourcebyinstitution"}], "added": [{"char_start": 1175, "char_end": 1181, "chars": "?, ?)'"}, {"char_start": 1216, "char_end": 1247, "chars": ", (sourcebyinstitution, number)"}, {"char_start": 1596, "char_end": 1602, "chars": "?, ?)'"}, {"char_start": 1641, "char_end": 1672, "chars": ", (sourcebyinstitution, number)"}, {"char_start": 1950, "char_end": 1953, "chars": "?)\""}, {"char_start": 1988, "char_end": 2011, "chars": ", (sourcebyinstitution)"}]}, "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089"}
{"func_name": "create_where", "func_src_before": "    def create_where(self, where):\n        sql = 'WHERE '\n\n        lucene_parser = LuceneParser()\n        where_tuples = lucene_parser.parse(where)\n\n        for tuple in where_tuples:\n            sql += '{} {} {}'.format(tuple[0], tuple[1], tuple[2])\n\n        return sql", "func_src_after": "    def create_where(self, where):\n        lucene_parser = LuceneParser()\n        where_string, where_replacement = lucene_parser.parse(where)\n\n        return where_string, where_replacement", "line_changes": {"deleted": [{"line_no": 2, "char_start": 35, "char_end": 58, "line": "        sql = 'WHERE '\n"}, {"line_no": 3, "char_start": 58, "char_end": 59, "line": "\n"}, {"line_no": 5, "char_start": 98, "char_end": 148, "line": "        where_tuples = lucene_parser.parse(where)\n"}, {"line_no": 6, "char_start": 148, "char_end": 149, "line": "\n"}, {"line_no": 7, "char_start": 149, "char_end": 184, "line": "        for tuple in where_tuples:\n"}, {"line_no": 8, "char_start": 184, "char_end": 251, "line": "            sql += '{} {} {}'.format(tuple[0], tuple[1], tuple[2])\n"}, {"line_no": 10, "char_start": 252, "char_end": 270, "line": "        return sql\n"}], "added": [{"line_no": 3, "char_start": 74, "char_end": 143, "line": "        where_string, where_replacement = lucene_parser.parse(where)\n"}, {"line_no": 5, "char_start": 144, "char_end": 190, "line": "        return where_string, where_replacement\n"}]}, "char_changes": {"deleted": [{"char_start": 35, "char_end": 59, "chars": "        sql = 'WHERE '\n\n"}, {"char_start": 112, "char_end": 118, "chars": "tuples"}, {"char_start": 157, "char_end": 270, "chars": "for tuple in where_tuples:\n            sql += '{} {} {}'.format(tuple[0], tuple[1], tuple[2])\n\n        return sql"}], "added": [{"char_start": 88, "char_end": 113, "chars": "string, where_replacement"}, {"char_start": 152, "char_end": 190, "chars": "return where_string, where_replacement"}]}, "commit_link": "github.com/gregchagnon/orm.cloud/commit/a82ec5e45404b1c2ff222d8ce4c3760ea4494c58", "file_name": "orm_cloud/database_adapters/ms_sql_adapter.py", "vul_type": "cwe-089"}
{"func_name": "construct_select_statement", "func_src_before": "def construct_select_statement(spy: ISpy, from_: str) -> str:\n    return f\"\"\"SELECT {', '.join(construct_selects(spy))} FROM {from_}\"\"\"", "func_src_after": "def construct_select_statement(spy: ISpy, from_: str, *, where: Optional[SupportsRendering] = None) -> str:\n    clause = f\"\"\"SELECT {', '.join(construct_selects(spy))} FROM {from_}\"\"\"\n    if where:\n        clause += f' WHERE {where.render()}'\n    return clause", "line_changes": {"deleted": [{"line_no": 1, "char_start": 0, "char_end": 62, "line": "def construct_select_statement(spy: ISpy, from_: str) -> str:\n"}], "added": [{"line_no": 1, "char_start": 0, "char_end": 108, "line": "def construct_select_statement(spy: ISpy, from_: str, *, where: Optional[SupportsRendering] = None) -> str:\n"}, {"line_no": 2, "char_start": 108, "char_end": 184, "line": "    clause = f\"\"\"SELECT {', '.join(construct_selects(spy))} FROM {from_}\"\"\"\n"}, {"line_no": 3, "char_start": 184, "char_end": 198, "line": "    if where:\n"}, {"line_no": 4, "char_start": 198, "char_end": 243, "line": "        clause += f' WHERE {where.render()}'\n"}, {"line_no": 5, "char_start": 243, "char_end": 260, "line": "    return clause\n"}]}, "char_changes": {"deleted": [{"char_start": 66, "char_end": 72, "chars": "return"}], "added": [{"char_start": 52, "char_end": 98, "chars": ", *, where: Optional[SupportsRendering] = None"}, {"char_start": 112, "char_end": 120, "chars": "clause ="}, {"char_start": 183, "char_end": 260, "chars": "\n    if where:\n        clause += f' WHERE {where.render()}'\n    return clause"}]}, "commit_link": "github.com/cybojenix/py-libsalesforce/commit/5468b6043196a403cd6bb9c493864ddacdb51c67", "file_name": "libsalesforce/query/construct.py", "vul_type": "cwe-089"}
{"func_name": "construct_subquery", "func_src_before": "def construct_subquery(spy: ISpy, name: str) -> str:\n    select_fields = _flatten(\n        construct_selects(field_spy, field_name)\n        for field_name, field_spy in spy.selected_fields.items()\n    )\n    return f\"\"\"(SELECT {', '.join(select_fields)} FROM {name})\"\"\"", "func_src_after": "def construct_subquery(spy: ISpy, name: str) -> str:\n    select_fields = _flatten(\n        construct_selects(field_spy, field_name)\n        for field_name, field_spy in spy.selected_fields.items()\n    )\n    inner_clause = f\"\"\"SELECT {', '.join(select_fields)} FROM {name}\"\"\"\n    if spy.where:\n        inner_clause += f\" WHERE {spy.where.render()}\"\n    return f\"({inner_clause})\"", "line_changes": {"deleted": [{"line_no": 6, "char_start": 203, "char_end": 268, "line": "    return f\"\"\"(SELECT {', '.join(select_fields)} FROM {name})\"\"\"\n"}], "added": [{"line_no": 6, "char_start": 203, "char_end": 275, "line": "    inner_clause = f\"\"\"SELECT {', '.join(select_fields)} FROM {name}\"\"\"\n"}, {"line_no": 7, "char_start": 275, "char_end": 293, "line": "    if spy.where:\n"}, {"line_no": 8, "char_start": 293, "char_end": 348, "line": "        inner_clause += f\" WHERE {spy.where.render()}\"\n"}, {"line_no": 9, "char_start": 348, "char_end": 378, "line": "    return f\"({inner_clause})\"\n"}]}, "char_changes": {"deleted": [{"char_start": 207, "char_end": 213, "chars": "return"}, {"char_start": 218, "char_end": 219, "chars": "("}, {"char_start": 264, "char_end": 265, "chars": ")"}], "added": [{"char_start": 207, "char_end": 221, "chars": "inner_clause ="}, {"char_start": 273, "char_end": 377, "chars": "\"\n    if spy.where:\n        inner_clause += f\" WHERE {spy.where.render()}\"\n    return f\"({inner_clause})"}]}, "commit_link": "github.com/cybojenix/py-libsalesforce/commit/5468b6043196a403cd6bb9c493864ddacdb51c67", "file_name": "libsalesforce/query/construct.py", "vul_type": "cwe-089"}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(\n                data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "line_changes": {"deleted": [{"line_no": 5, "char_start": 182, "char_end": 260, "line": "            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(\n"}, {"line_no": 6, "char_start": 260, "char_end": 282, "line": "                data)\n"}, {"line_no": 8, "char_start": 330, "char_end": 368, "line": "                cursor.execute(query)\n"}], "added": [{"line_no": 5, "char_start": 182, "char_end": 250, "line": "            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n"}, {"line_no": 7, "char_start": 298, "char_end": 342, "line": "                cursor.execute(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 244, "char_end": 281, "chars": "'{}');\".format(\n                data)"}], "added": [{"char_start": 244, "char_end": 249, "chars": "%s);\""}, {"char_start": 334, "char_end": 340, "chars": ", data"}]}, "commit_link": "github.com/JeremiahO/crimemap/commit/c17537fcd7aa4e2a26f7ca5cefaeb356ff646858", "file_name": "dbhelper.py", "vul_type": "cwe-089"}
{"func_name": "create_modeling_tables", "func_src_before": "def create_modeling_tables():\n    \"\"\"Create tables for machine learning modeling.\"\"\"\n\n    # Define parameters\n    spi_keys = ['date', 'league', 'team1', 'team2']\n    fd_keys = ['Date', 'Div', 'HomeTeam', 'AwayTeam']\n    input_cols = ['spi1', 'spi2', 'prob1', 'prob2', 'probtie', 'proj_score1', 'proj_score2', 'importance1', 'importance2', 'BbAvH', 'BbAvA', 'BbAvD', 'BbAv>2.5', 'BbAv<2.5', 'BbAHh', 'BbAvAHH', 'BbAvAHA']\n    output_cols = ['score1', 'score2', 'xg1', 'xg2', 'nsxg1', 'nsxg2', 'adj_score1', 'adj_score2']\n    odds_cols_mapping = {'PSH': 'H', 'PSA': 'A', 'PSD': 'D', 'BbMx>2.5': 'over_2.5', 'BbMx<2.5': 'under_2.5', 'BbAHh': 'handicap', 'BbMxAHH': 'handicap_home', 'BbMxAHA': 'handicap_away'}\n    \n    # Load data\n    data = {}\n    for name in ('spi_historical', 'spi_fixtures', 'fd_historical', 'fd_fixtures', 'names_mapping'):\n        parse_dates = ['date'] if name in ('spi_historical', 'spi_fixtures') else ['Date'] if name in ('fd_historical', 'fd_fixtures') else None\n        data[name] = pd.read_sql('select * from %s' % name, DB_CONNECTION, parse_dates=parse_dates)\n\n    # Rename teams\n    for col in ['team1', 'team2']:\n        for name in ('spi_historical', 'spi_fixtures'):\n            data[name] = pd.merge(data[name], data['names_mapping'], left_on=col, right_on='left_team', how='left').drop(columns=[col, 'left_team']).rename(columns={'right_team': col})\n\n    # Combine data\n    historical = pd.merge(data['spi_historical'], data['fd_historical'], left_on=spi_keys, right_on=fd_keys).dropna(subset=odds_cols_mapping.keys(), how='any').reset_index(drop=True)\n    fixtures = pd.merge(data['spi_fixtures'], data['fd_fixtures'], left_on=spi_keys, right_on=fd_keys)\n\n    # Extract training, odds and fixtures\n    X = historical.loc[:, ['season'] + spi_keys + input_cols]\n    y = historical.loc[:, output_cols]\n    odds = historical.loc[:, spi_keys + list(odds_cols_mapping.keys())].rename(columns=odds_cols_mapping)\n    X_test = fixtures.loc[:, spi_keys + input_cols]\n    odds_test = fixtures.loc[:, spi_keys + list(odds_cols_mapping.keys())].rename(columns=odds_cols_mapping)\n\n    # Add average scores columns\n    for ind in (1, 2):\n        y['avg_score%s' % ind] =  y[['score%s' % ind, 'xg%s' % ind, 'nsxg%s' % ind]].mean(axis=1)\n\n    # Add combined odds columns\n    for target_type in TARGET_TYPES_MAPPING.keys():\n        if '+' in target_type:\n            target_types = target_type.split('+')\n            odds = combine_odds(odds, target_types)\n            odds_test = combine_odds(odds_test, target_types)\n\n    # Feature extraction\n    with np.errstate(divide='ignore',invalid='ignore'):\n        for df in (X, X_test):\n            df['quality'] = hmean(df[['spi1', 'spi2']], axis=1)\n            df['importance'] = df[['importance1', 'importance2']].mean(axis=1)\n            df['rating'] = df[['quality', 'importance']].mean(axis=1)\n            df['sum_proj_score'] = df['proj_score1'] + df['proj_score2']\n\n    # Save tables\n    for name, df in zip(['X', 'y', 'odds', 'X_test', 'odds_test'], [X, y, odds, X_test, odds_test]):\n        df.to_sql(name, DB_CONNECTION, index=False, if_exists='replace')", "func_src_after": "def create_modeling_tables():\n    \"\"\"Create tables for machine learning modeling.\"\"\"\n\n    # Define parameters\n    spi_keys = ['date', 'league', 'team1', 'team2']\n    fd_keys = ['Date', 'Div', 'HomeTeam', 'AwayTeam']\n    input_cols = ['spi1', 'spi2', 'prob1', 'prob2', 'probtie', 'proj_score1', 'proj_score2', 'importance1', 'importance2', 'BbAvH', 'BbAvA', 'BbAvD', 'BbAv>2.5', 'BbAv<2.5', 'BbAHh', 'BbAvAHH', 'BbAvAHA']\n    output_cols = ['score1', 'score2', 'xg1', 'xg2', 'nsxg1', 'nsxg2', 'adj_score1', 'adj_score2']\n    odds_cols_mapping = {'PSH': 'H', 'PSA': 'A', 'PSD': 'D', 'BbMx>2.5': 'over_2.5', 'BbMx<2.5': 'under_2.5', 'BbAHh': 'handicap', 'BbMxAHH': 'handicap_home', 'BbMxAHA': 'handicap_away'}\n    \n    # Load data\n    data = {}\n    for name in ('spi_historical', 'spi_fixtures', 'fd_historical', 'fd_fixtures', 'names_mapping'):\n        parse_dates = ['date'] if name in ('spi_historical', 'spi_fixtures') else ['Date'] if name in ('fd_historical', 'fd_fixtures') else None\n        sql_query = 'select * from {}'.format(name)\n        data[name] = pd.read_sql(sql_query, DB_CONNECTION, parse_dates=parse_dates)\n\n    # Rename teams\n    for col in ['team1', 'team2']:\n        for name in ('spi_historical', 'spi_fixtures'):\n            data[name] = pd.merge(data[name], data['names_mapping'], left_on=col, right_on='left_team', how='left').drop(columns=[col, 'left_team']).rename(columns={'right_team': col})\n\n    # Combine data\n    historical = pd.merge(data['spi_historical'], data['fd_historical'], left_on=spi_keys, right_on=fd_keys).dropna(subset=odds_cols_mapping.keys(), how='any').reset_index(drop=True)\n    fixtures = pd.merge(data['spi_fixtures'], data['fd_fixtures'], left_on=spi_keys, right_on=fd_keys)\n\n    # Extract training, odds and fixtures\n    X = historical.loc[:, ['season'] + spi_keys + input_cols]\n    y = historical.loc[:, output_cols]\n    odds = historical.loc[:, spi_keys + list(odds_cols_mapping.keys())].rename(columns=odds_cols_mapping)\n    X_test = fixtures.loc[:, spi_keys + input_cols]\n    odds_test = fixtures.loc[:, spi_keys + list(odds_cols_mapping.keys())].rename(columns=odds_cols_mapping)\n\n    # Add average scores columns\n    for ind in (1, 2):\n        y['avg_score%s' % ind] =  y[['score%s' % ind, 'xg%s' % ind, 'nsxg%s' % ind]].mean(axis=1)\n\n    # Add combined odds columns\n    for target_type in TARGET_TYPES_MAPPING.keys():\n        if '+' in target_type:\n            target_types = target_type.split('+')\n            odds = combine_odds(odds, target_types)\n            odds_test = combine_odds(odds_test, target_types)\n\n    # Feature extraction\n    with np.errstate(divide='ignore',invalid='ignore'):\n        for df in (X, X_test):\n            df['quality'] = hmean(df[['spi1', 'spi2']], axis=1)\n            df['importance'] = df[['importance1', 'importance2']].mean(axis=1)\n            df['rating'] = df[['quality', 'importance']].mean(axis=1)\n            df['sum_proj_score'] = df['proj_score1'] + df['proj_score2']\n\n    # Save tables\n    for name, df in zip(['X', 'y', 'odds', 'X_test', 'odds_test'], [X, y, odds, X_test, odds_test]):\n        df.to_sql(name, DB_CONNECTION, index=False, if_exists='replace')", "line_changes": {"deleted": [{"line_no": 15, "char_start": 988, "char_end": 1088, "line": "        data[name] = pd.read_sql('select * from %s' % name, DB_CONNECTION, parse_dates=parse_dates)\n"}], "added": [{"line_no": 15, "char_start": 988, "char_end": 1040, "line": "        sql_query = 'select * from {}'.format(name)\n"}, {"line_no": 16, "char_start": 1040, "char_end": 1124, "line": "        data[name] = pd.read_sql(sql_query, DB_CONNECTION, parse_dates=parse_dates)\n"}]}, "char_changes": {"deleted": [{"char_start": 996, "char_end": 1046, "chars": "data[name] = pd.read_sql('select * from %s' % name"}], "added": [{"char_start": 996, "char_end": 1082, "chars": "sql_query = 'select * from {}'.format(name)\n        data[name] = pd.read_sql(sql_query"}]}, "commit_link": "github.com/AlgoWit/sports-betting/commit/7a169111dd1ef8ebaf89d6f01fc4b3082c9b6728", "file_name": "sportsbet/soccer/data.py", "vul_type": "cwe-089"}
{"func_name": "get_users", "func_src_before": "@app.route('/users')\ndef get_users():\n    mysql = connectToMySQL(\"users_db\")\n    users = mysql.query_db(\"SELECT * FROM users;\")\n    return render_template('index.html', users=users)", "func_src_after": "@app.route('/users')\ndef get_users():\n    mysql = connectToMySQL(database)\n    users = mysql.query_db(\"SELECT * FROM users;\")\n    return render_template('index.html', users=users)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 38, "char_end": 77, "line": "    mysql = connectToMySQL(\"users_db\")\n"}], "added": [{"line_no": 3, "char_start": 38, "char_end": 75, "line": "    mysql = connectToMySQL(database)\n"}]}, "char_changes": {"deleted": [{"char_start": 65, "char_end": 75, "chars": "\"users_db\""}], "added": [{"char_start": 65, "char_end": 73, "chars": "database"}]}, "commit_link": "github.com/apseftis86/python_schoolwork/commit/de375b933a798f7c66b8bbc0a89d24c5aa867a75", "file_name": "flask/flask_mysql/users/server.py", "vul_type": "cwe-089"}
{"func_name": "show_user", "func_src_before": "@app.route('/users/<id>')\ndef show_user(id):\n    mysql = connectToMySQL(\"users_db\")\n    user = mysql.query_db(\"SELECT * FROM users WHERE id = {};\".format(id))\n    return render_template('user.html', user=user[0])", "func_src_after": "@app.route('/users/<id>')\ndef show_user(id):\n    mysql = connectToMySQL(database)\n    data = {\n        'userid': id\n    }\n    query = \"SELECT * FROM users WHERE id = %(userid)s;\"\n    user = mysql.query_db(query, data)\n    return render_template('user.html', user=user[0])", "line_changes": {"deleted": [{"line_no": 3, "char_start": 45, "char_end": 84, "line": "    mysql = connectToMySQL(\"users_db\")\n"}, {"line_no": 4, "char_start": 84, "char_end": 159, "line": "    user = mysql.query_db(\"SELECT * FROM users WHERE id = {};\".format(id))\n"}], "added": [{"line_no": 3, "char_start": 45, "char_end": 82, "line": "    mysql = connectToMySQL(database)\n"}, {"line_no": 4, "char_start": 82, "char_end": 95, "line": "    data = {\n"}, {"line_no": 5, "char_start": 95, "char_end": 116, "line": "        'userid': id\n"}, {"line_no": 6, "char_start": 116, "char_end": 122, "line": "    }\n"}, {"line_no": 7, "char_start": 122, "char_end": 179, "line": "    query = \"SELECT * FROM users WHERE id = %(userid)s;\"\n"}, {"line_no": 8, "char_start": 179, "char_end": 218, "line": "    user = mysql.query_db(query, data)\n"}]}, "char_changes": {"deleted": [{"char_start": 72, "char_end": 84, "chars": "\"users_db\")\n"}, {"char_start": 92, "char_end": 101, "chars": " = mysql."}, {"char_start": 106, "char_end": 110, "chars": "_db("}, {"char_start": 142, "char_end": 157, "chars": "{};\".format(id)"}], "added": [{"char_start": 72, "char_end": 126, "chars": "database)\n    data = {\n        'userid': id\n    }\n    "}, {"char_start": 131, "char_end": 134, "chars": " = "}, {"char_start": 166, "char_end": 216, "chars": "%(userid)s;\"\n    user = mysql.query_db(query, data"}]}, "commit_link": "github.com/apseftis86/python_schoolwork/commit/de375b933a798f7c66b8bbc0a89d24c5aa867a75", "file_name": "flask/flask_mysql/users/server.py", "vul_type": "cwe-089"}
{"func_name": "add_user", "func_src_before": "@app.route('/users/new', methods=['GET', 'POST'])\ndef add_user():\n    if request.method == 'POST':\n        mysql = connectToMySQL(\"users_db\")\n        query = \"INSERT INTO users (first_name, last_name, email, description, created_at) VALUES (%(fn)s, %(ln)s, %(e)s, %(d)s, now());\"\n        data = {\n            \"fn\": request.form['first_name'],\n            \"ln\": request.form['last_name'],\n            \"e\": request.form['email'],\n            \"d\": request.form['description'],\n        }\n        new_user = mysql.query_db(query, data)\n        return redirect(f'/users/{new_user}')\n    else:\n        return render_template('edit.html', user=None)", "func_src_after": "@app.route('/users/new', methods=['GET', 'POST'])\ndef add_user():\n    if request.method == 'POST':\n        mysql = connectToMySQL(database)\n        query = \"INSERT INTO users (first_name, last_name, email, description, created_at)\" \\\n                \"  VALUES (%(fn)s, %(ln)s, %(e)s, %(d)s, now());\"\n        data = {\n            \"fn\": request.form['first_name'],\n            \"ln\": request.form['last_name'],\n            \"e\": request.form['email'],\n            \"d\": request.form['description'],\n        }\n        new_user = mysql.query_db(query, data)\n        return redirect('/users/{}'.format(new_user))\n    else:\n        return render_template('edit.html', user=None)", "line_changes": {"deleted": [{"line_no": 4, "char_start": 99, "char_end": 142, "line": "        mysql = connectToMySQL(\"users_db\")\n"}, {"line_no": 5, "char_start": 142, "char_end": 280, "line": "        query = \"INSERT INTO users (first_name, last_name, email, description, created_at) VALUES (%(fn)s, %(ln)s, %(e)s, %(d)s, now());\"\n"}, {"line_no": 13, "char_start": 531, "char_end": 577, "line": "        return redirect(f'/users/{new_user}')\n"}], "added": [{"line_no": 4, "char_start": 99, "char_end": 140, "line": "        mysql = connectToMySQL(database)\n"}, {"line_no": 5, "char_start": 140, "char_end": 234, "line": "        query = \"INSERT INTO users (first_name, last_name, email, description, created_at)\" \\\n"}, {"line_no": 6, "char_start": 234, "char_end": 300, "line": "                \"  VALUES (%(fn)s, %(ln)s, %(e)s, %(d)s, now());\"\n"}, {"line_no": 14, "char_start": 551, "char_end": 605, "line": "        return redirect('/users/{}'.format(new_user))\n"}]}, "char_changes": {"deleted": [{"char_start": 130, "char_end": 140, "chars": "\"users_db\""}, {"char_start": 555, "char_end": 556, "chars": "f"}, {"char_start": 573, "char_end": 575, "chars": "}'"}], "added": [{"char_start": 130, "char_end": 138, "chars": "database"}, {"char_start": 230, "char_end": 252, "chars": "\" \\\n                \" "}, {"char_start": 584, "char_end": 594, "chars": "}'.format("}, {"char_start": 602, "char_end": 603, "chars": ")"}]}, "commit_link": "github.com/apseftis86/python_schoolwork/commit/de375b933a798f7c66b8bbc0a89d24c5aa867a75", "file_name": "flask/flask_mysql/users/server.py", "vul_type": "cwe-089"}
{"func_name": "edit_user", "func_src_before": "@app.route('/users/<id>/edit', methods=['GET', 'POST'])\ndef edit_user(id):\n   user_id = id\n   mysql = connectToMySQL(\"users_db\")\n   if request.method == 'POST':\n       query = \"UPDATE users SET first_name = %(fn)s, last_name = %(ln)s, email= %(e)s, description = %(d)s, updated_at = now() WHERE id = \" + user_id + \";\"\n       data = {\n           \"fn\" : request.form['first_name'],\n           \"ln\" : request.form['last_name'],\n           \"e\" : request.form['email'],\n           \"d\" : request.form['description'],\n       }\n       mysql.query_db(query, data)\n       return redirect('/users/{}'.format(user_id))\n   else:\n       user = mysql.query_db(\"SELECT * FROM users WHERE id = \" + user_id + \";\")\n       return render_template('edit.html', user=user[0])", "func_src_after": "@app.route('/users/<id>/edit', methods=['GET', 'POST'])\ndef edit_user(id):\n    mysql = connectToMySQL(database)\n    if request.method == 'POST':\n        data = {\n            \"user_id\": id,\n            \"fn\": request.form['first_name'],\n            \"ln\": request.form['last_name'],\n            \"e\": request.form['email'],\n            \"d\": request.form['description'],\n        }\n        query = \"UPDATE users SET first_name = %(fn)s, last_name = %(ln)s, email= %(e)s,\" \\\n                \" description = %(d)s, updated_at = now() WHERE id = %(user_id)s;\"\n        mysql.query_db(query, data)\n        return redirect('/users/{}'.format(id))\n    else:\n        data = {\n            \"user_id\": id,\n        }\n        query = \"SELECT * FROM users WHERE id =  %(user_id)s;\"\n        user = mysql.query_db(query, data)\n        return render_template('edit.html', user=user[0])", "line_changes": {"deleted": [{"line_no": 3, "char_start": 75, "char_end": 91, "line": "   user_id = id\n"}, {"line_no": 4, "char_start": 91, "char_end": 129, "line": "   mysql = connectToMySQL(\"users_db\")\n"}, {"line_no": 5, "char_start": 129, "char_end": 161, "line": "   if request.method == 'POST':\n"}, {"line_no": 6, "char_start": 161, "char_end": 318, "line": "       query = \"UPDATE users SET first_name = %(fn)s, last_name = %(ln)s, email= %(e)s, description = %(d)s, updated_at = now() WHERE id = \" + user_id + \";\"\n"}, {"line_no": 7, "char_start": 318, "char_end": 334, "line": "       data = {\n"}, {"line_no": 8, "char_start": 334, "char_end": 380, "line": "           \"fn\" : request.form['first_name'],\n"}, {"line_no": 9, "char_start": 380, "char_end": 425, "line": "           \"ln\" : request.form['last_name'],\n"}, {"line_no": 10, "char_start": 425, "char_end": 465, "line": "           \"e\" : request.form['email'],\n"}, {"line_no": 11, "char_start": 465, "char_end": 511, "line": "           \"d\" : request.form['description'],\n"}, {"line_no": 12, "char_start": 511, "char_end": 520, "line": "       }\n"}, {"line_no": 13, "char_start": 520, "char_end": 555, "line": "       mysql.query_db(query, data)\n"}, {"line_no": 14, "char_start": 555, "char_end": 607, "line": "       return redirect('/users/{}'.format(user_id))\n"}, {"line_no": 15, "char_start": 607, "char_end": 616, "line": "   else:\n"}, {"line_no": 16, "char_start": 616, "char_end": 696, "line": "       user = mysql.query_db(\"SELECT * FROM users WHERE id = \" + user_id + \";\")\n"}, {"line_no": 17, "char_start": 696, "char_end": 752, "line": "       return render_template('edit.html', user=user[0])\n"}], "added": [{"line_no": 3, "char_start": 75, "char_end": 112, "line": "    mysql = connectToMySQL(database)\n"}, {"line_no": 4, "char_start": 112, "char_end": 145, "line": "    if request.method == 'POST':\n"}, {"line_no": 5, "char_start": 145, "char_end": 162, "line": "        data = {\n"}, {"line_no": 6, "char_start": 162, "char_end": 189, "line": "            \"user_id\": id,\n"}, {"line_no": 7, "char_start": 189, "char_end": 235, "line": "            \"fn\": request.form['first_name'],\n"}, {"line_no": 8, "char_start": 235, "char_end": 280, "line": "            \"ln\": request.form['last_name'],\n"}, {"line_no": 9, "char_start": 280, "char_end": 320, "line": "            \"e\": request.form['email'],\n"}, {"line_no": 10, "char_start": 320, "char_end": 366, "line": "            \"d\": request.form['description'],\n"}, {"line_no": 11, "char_start": 366, "char_end": 376, "line": "        }\n"}, {"line_no": 12, "char_start": 376, "char_end": 468, "line": "        query = \"UPDATE users SET first_name = %(fn)s, last_name = %(ln)s, email= %(e)s,\" \\\n"}, {"line_no": 13, "char_start": 468, "char_end": 551, "line": "                \" description = %(d)s, updated_at = now() WHERE id = %(user_id)s;\"\n"}, {"line_no": 14, "char_start": 551, "char_end": 587, "line": "        mysql.query_db(query, data)\n"}, {"line_no": 15, "char_start": 587, "char_end": 635, "line": "        return redirect('/users/{}'.format(id))\n"}, {"line_no": 16, "char_start": 635, "char_end": 645, "line": "    else:\n"}, {"line_no": 17, "char_start": 645, "char_end": 662, "line": "        data = {\n"}, {"line_no": 18, "char_start": 662, "char_end": 689, "line": "            \"user_id\": id,\n"}, {"line_no": 19, "char_start": 689, "char_end": 699, "line": "        }\n"}, {"line_no": 20, "char_start": 699, "char_end": 762, "line": "        query = \"SELECT * FROM users WHERE id =  %(user_id)s;\"\n"}, {"line_no": 21, "char_start": 762, "char_end": 805, "line": "        user = mysql.query_db(query, data)\n"}, {"line_no": 22, "char_start": 805, "char_end": 862, "line": "        return render_template('edit.html', user=user[0])\n"}]}, "char_changes": {"deleted": [{"char_start": 76, "char_end": 91, "chars": "  user_id = id\n"}, {"char_start": 117, "char_end": 127, "chars": "\"users_db\""}, {"char_start": 168, "char_end": 334, "chars": "query = \"UPDATE users SET first_name = %(fn)s, last_name = %(ln)s, email= %(e)s, description = %(d)s, updated_at = now() WHERE id = \" + user_id + \";\"\n       data = {\n"}, {"char_start": 349, "char_end": 350, "chars": " "}, {"char_start": 395, "char_end": 396, "chars": " "}, {"char_start": 439, "char_end": 440, "chars": " "}, {"char_start": 479, "char_end": 480, "chars": " "}, {"char_start": 597, "char_end": 602, "chars": "user_"}, {"char_start": 623, "char_end": 636, "chars": "user = mysql."}, {"char_start": 641, "char_end": 645, "chars": "_db("}, {"char_start": 677, "char_end": 681, "chars": "\" + "}, {"char_start": 688, "char_end": 694, "chars": " + \";\""}], "added": [{"char_start": 102, "char_end": 110, "chars": "database"}, {"char_start": 112, "char_end": 113, "chars": " "}, {"char_start": 152, "char_end": 190, "chars": " data = {\n            \"user_id\": id,\n "}, {"char_start": 246, "char_end": 247, "chars": " "}, {"char_start": 291, "char_end": 292, "chars": " "}, {"char_start": 331, "char_end": 332, "chars": " "}, {"char_start": 366, "char_end": 367, "chars": " "}, {"char_start": 376, "char_end": 552, "chars": "        query = \"UPDATE users SET first_name = %(fn)s, last_name = %(ln)s, email= %(e)s,\" \\\n                \" description = %(d)s, updated_at = now() WHERE id = %(user_id)s;\"\n "}, {"char_start": 587, "char_end": 588, "chars": " "}, {"char_start": 635, "char_end": 636, "chars": " "}, {"char_start": 652, "char_end": 707, "chars": " data = {\n            \"user_id\": id,\n        }\n        "}, {"char_start": 712, "char_end": 715, "chars": " = "}, {"char_start": 747, "char_end": 803, "chars": " %(user_id)s;\"\n        user = mysql.query_db(query, data"}, {"char_start": 805, "char_end": 806, "chars": " "}]}, "commit_link": "github.com/apseftis86/python_schoolwork/commit/de375b933a798f7c66b8bbc0a89d24c5aa867a75", "file_name": "flask/flask_mysql/users/server.py", "vul_type": "cwe-089"}
{"func_name": "delete_user", "func_src_before": "@app.route('/users/<id>/destroy')\ndef delete_user(id):\n   user_id = id\n   mysql = connectToMySQL(\"users_db\")\n   query = \"DELETE from users WHERE id = \" + user_id + \";\"\n   deleted_user = mysql.query_db(query)\n   return redirect('/users')", "func_src_after": "@app.route('/users/<id>/destroy')\ndef delete_user(id):\n    data = {\n        'userid': id\n    }\n    mysql = connectToMySQL(database)\n    query = \"DELETE from users WHERE id =  =  %(user_id)s;\"\n    mysql.query_db(query, data)\n    return redirect('/users')", "line_changes": {"deleted": [{"line_no": 3, "char_start": 55, "char_end": 71, "line": "   user_id = id\n"}, {"line_no": 4, "char_start": 71, "char_end": 109, "line": "   mysql = connectToMySQL(\"users_db\")\n"}, {"line_no": 5, "char_start": 109, "char_end": 168, "line": "   query = \"DELETE from users WHERE id = \" + user_id + \";\"\n"}, {"line_no": 6, "char_start": 168, "char_end": 208, "line": "   deleted_user = mysql.query_db(query)\n"}, {"line_no": 7, "char_start": 208, "char_end": 236, "line": "   return redirect('/users')\n"}], "added": [{"line_no": 3, "char_start": 55, "char_end": 68, "line": "    data = {\n"}, {"line_no": 4, "char_start": 68, "char_end": 89, "line": "        'userid': id\n"}, {"line_no": 5, "char_start": 89, "char_end": 95, "line": "    }\n"}, {"line_no": 6, "char_start": 95, "char_end": 132, "line": "    mysql = connectToMySQL(database)\n"}, {"line_no": 7, "char_start": 132, "char_end": 192, "line": "    query = \"DELETE from users WHERE id =  =  %(user_id)s;\"\n"}, {"line_no": 8, "char_start": 192, "char_end": 224, "line": "    mysql.query_db(query, data)\n"}, {"line_no": 9, "char_start": 224, "char_end": 253, "line": "    return redirect('/users')\n"}]}, "char_changes": {"deleted": [{"char_start": 62, "char_end": 63, "chars": "_"}, {"char_start": 65, "char_end": 67, "chars": " ="}, {"char_start": 97, "char_end": 107, "chars": "\"users_db\""}, {"char_start": 150, "char_end": 154, "chars": "\" + "}, {"char_start": 161, "char_end": 165, "chars": " + \""}, {"char_start": 171, "char_end": 185, "chars": "deleted_user ="}], "added": [{"char_start": 58, "char_end": 77, "chars": " data = {\n        '"}, {"char_start": 83, "char_end": 85, "chars": "':"}, {"char_start": 89, "char_end": 96, "chars": "    }\n "}, {"char_start": 122, "char_end": 130, "chars": "database"}, {"char_start": 132, "char_end": 133, "chars": " "}, {"char_start": 174, "char_end": 180, "chars": " =  %("}, {"char_start": 187, "char_end": 189, "chars": ")s"}, {"char_start": 216, "char_end": 222, "chars": ", data"}, {"char_start": 224, "char_end": 225, "chars": " "}]}, "commit_link": "github.com/apseftis86/python_schoolwork/commit/de375b933a798f7c66b8bbc0a89d24c5aa867a75", "file_name": "flask/flask_mysql/users/server.py", "vul_type": "cwe-089"}
{"func_name": "sql_execute", "func_src_before": "    def sql_execute(self, sentence):\n        self.cursor.execute(sentence)\n        return self.cursor.fetchall()", "func_src_after": "    def sql_execute(self, sentence):\n    \tif type(sentence) is str:\n        \tself.cursor.execute(sentence)\n    \telse:\n        \tself.cursor.execute(sentence[0], sentence[1])", "line_changes": {"deleted": [{"line_no": 2, "char_start": 37, "char_end": 75, "line": "        self.cursor.execute(sentence)\n"}], "added": [{"line_no": 2, "char_start": 37, "char_end": 68, "line": "    \tif type(sentence) is str:\n"}, {"line_no": 3, "char_start": 68, "char_end": 107, "line": "        \tself.cursor.execute(sentence)\n"}, {"line_no": 4, "char_start": 107, "char_end": 118, "line": "    \telse:\n"}, {"line_no": 5, "char_start": 118, "char_end": 172, "line": "        \tself.cursor.execute(sentence[0], sentence[1])\n"}]}, "char_changes": {"deleted": [{"char_start": 41, "char_end": 111, "chars": "    self.cursor.execute(sentence)\n        return self.cursor.fetchall("}], "added": [{"char_start": 41, "char_end": 171, "chars": "\tif type(sentence) is str:\n        \tself.cursor.execute(sentence)\n    \telse:\n        \tself.cursor.execute(sentence[0], sentence[1]"}]}, "commit_link": "github.com/boxug/trape/commit/628149159ba25adbfc29a3ae1d4b10c7eb936dd3", "file_name": "core/db.py", "vul_type": "cwe-089"}
{"func_name": "sql_one_row", "func_src_before": "    def sql_one_row(self, sentence, column):\n        self.cursor.execute(sentence)\n        return self.cursor.fetchone()[column]", "func_src_after": "    def sql_one_row(self, sentence, column):\n        if type(sentence) is str:\n        \tself.cursor.execute(sentence)\n    \telse:\n        \tself.cursor.execute(sentence[0], sentence[1])\t\n        return self.cursor.fetchone()[column]", "line_changes": {"deleted": [{"line_no": 2, "char_start": 45, "char_end": 83, "line": "        self.cursor.execute(sentence)\n"}], "added": [{"line_no": 2, "char_start": 45, "char_end": 79, "line": "        if type(sentence) is str:\n"}, {"line_no": 3, "char_start": 79, "char_end": 118, "line": "        \tself.cursor.execute(sentence)\n"}, {"line_no": 4, "char_start": 118, "char_end": 129, "line": "    \telse:\n"}, {"line_no": 5, "char_start": 129, "char_end": 185, "line": "        \tself.cursor.execute(sentence[0], sentence[1])\t\n"}]}, "char_changes": {"deleted": [{"char_start": 53, "char_end": 82, "chars": "self.cursor.execute(sentence)"}], "added": [{"char_start": 53, "char_end": 184, "chars": "if type(sentence) is str:\n        \tself.cursor.execute(sentence)\n    \telse:\n        \tself.cursor.execute(sentence[0], sentence[1])\t"}]}, "commit_link": "github.com/boxug/trape/commit/628149159ba25adbfc29a3ae1d4b10c7eb936dd3", "file_name": "core/db.py", "vul_type": "cwe-089"}
{"func_name": "sql_insert", "func_src_before": "    def sql_insert(self, sentence):\n        self.cursor.execute(sentence)\n        self.conn.commit()\n        return True", "func_src_after": "    def sql_insert(self, sentence):\n        if type(sentence) is str:\n        \tself.cursor.execute(sentence)\n    \telse:\n        \tself.cursor.execute(sentence[0], sentence[1])\n        self.conn.commit()\n        return True", "line_changes": {"deleted": [{"line_no": 2, "char_start": 36, "char_end": 74, "line": "        self.cursor.execute(sentence)\n"}], "added": [{"line_no": 2, "char_start": 36, "char_end": 70, "line": "        if type(sentence) is str:\n"}, {"line_no": 3, "char_start": 70, "char_end": 109, "line": "        \tself.cursor.execute(sentence)\n"}, {"line_no": 4, "char_start": 109, "char_end": 120, "line": "    \telse:\n"}, {"line_no": 5, "char_start": 120, "char_end": 175, "line": "        \tself.cursor.execute(sentence[0], sentence[1])\n"}]}, "char_changes": {"deleted": [{"char_start": 44, "char_end": 72, "chars": "self.cursor.execute(sentence"}], "added": [{"char_start": 44, "char_end": 173, "chars": "if type(sentence) is str:\n        \tself.cursor.execute(sentence)\n    \telse:\n        \tself.cursor.execute(sentence[0], sentence[1]"}]}, "commit_link": "github.com/boxug/trape/commit/628149159ba25adbfc29a3ae1d4b10c7eb936dd3", "file_name": "core/db.py", "vul_type": "cwe-089"}
{"func_name": "prop_sentences_stats", "func_src_before": "    def prop_sentences_stats(self, type, vId = None):\n        return {\n            'get_data' : \"SELECT victims.*, geo.*, victims.ip AS ip_local, COUNT(clicks.id) FROM victims INNER JOIN geo ON victims.id = geo.id LEFT JOIN clicks ON clicks.id = victims.id GROUP BY victims.id ORDER BY victims.time DESC\",\n            'all_networks' : \"SELECT networks.* FROM networks ORDER BY id\",\n            'get_preview' : \"SELECT victims.*, geo.*, victims.ip AS ip_local FROM victims INNER JOIN geo ON victims.id = geo.id WHERE victims.id = '%s'\" % (vId),\n            'id_networks' : \"SELECT networks.* FROM networks WHERE id = '%s'\" % (vId),\n            'get_requests' : \"SELECT requests.*, geo.ip FROM requests INNER JOIN geo on geo.id = requests.user_id ORDER BY requests.date DESC, requests.id \",\n            'get_sessions' : \"SELECT COUNT(*) AS Total FROM networks\",\n            'get_clicks' : \"SELECT COUNT(*) AS Total FROM clicks\",\n            'get_online' : \"SELECT COUNT(*) AS Total FROM victims WHERE status = '%s'\" % ('online')\n        }.get(type, False)", "func_src_after": "    def prop_sentences_stats(self, type, vId = None):\n        return {\n        \t'get_data' : \"SELECT victims.*, geo.*, victims.ip AS ip_local, COUNT(clicks.id) FROM victims INNER JOIN geo ON victims.id = geo.id LEFT JOIN clicks ON clicks.id = victims.id GROUP BY victims.id ORDER BY victims.time DESC\",\n        \t'all_networks' : \"SELECT networks.* FROM networks ORDER BY id\",\n        \t'get_preview' : (\"SELECT victims.*, geo.*, victims.ip AS ip_local FROM victims INNER JOIN geo ON victims.id = geo.id WHERE victims.id = ?\" , vId),\n        \t'id_networks' : (\"SELECT networks.* FROM networks WHERE id = ?\", vId),\n        \t'get_requests' : \"SELECT requests.*, geo.ip FROM requests INNER JOIN geo on geo.id = requests.user_id ORDER BY requests.date DESC, requests.id \",\n        \t'get_sessions' : \"SELECT COUNT(*) AS Total FROM networks\",\n        \t'get_clicks' : \"SELECT COUNT(*) AS Total FROM clicks\",\n        \t'get_online' : (\"SELECT COUNT(*) AS Total FROM victims WHERE status = ?\", vId)\n        }.get(type, False)", "line_changes": {"deleted": [{"line_no": 3, "char_start": 71, "char_end": 306, "line": "            'get_data' : \"SELECT victims.*, geo.*, victims.ip AS ip_local, COUNT(clicks.id) FROM victims INNER JOIN geo ON victims.id = geo.id LEFT JOIN clicks ON clicks.id = victims.id GROUP BY victims.id ORDER BY victims.time DESC\",\n"}, {"line_no": 4, "char_start": 306, "char_end": 382, "line": "            'all_networks' : \"SELECT networks.* FROM networks ORDER BY id\",\n"}, {"line_no": 5, "char_start": 382, "char_end": 544, "line": "            'get_preview' : \"SELECT victims.*, geo.*, victims.ip AS ip_local FROM victims INNER JOIN geo ON victims.id = geo.id WHERE victims.id = '%s'\" % (vId),\n"}, {"line_no": 6, "char_start": 544, "char_end": 631, "line": "            'id_networks' : \"SELECT networks.* FROM networks WHERE id = '%s'\" % (vId),\n"}, {"line_no": 7, "char_start": 631, "char_end": 789, "line": "            'get_requests' : \"SELECT requests.*, geo.ip FROM requests INNER JOIN geo on geo.id = requests.user_id ORDER BY requests.date DESC, requests.id \",\n"}, {"line_no": 8, "char_start": 789, "char_end": 860, "line": "            'get_sessions' : \"SELECT COUNT(*) AS Total FROM networks\",\n"}, {"line_no": 9, "char_start": 860, "char_end": 927, "line": "            'get_clicks' : \"SELECT COUNT(*) AS Total FROM clicks\",\n"}, {"line_no": 10, "char_start": 927, "char_end": 1027, "line": "            'get_online' : \"SELECT COUNT(*) AS Total FROM victims WHERE status = '%s'\" % ('online')\n"}], "added": [{"line_no": 3, "char_start": 71, "char_end": 303, "line": "        \t'get_data' : \"SELECT victims.*, geo.*, victims.ip AS ip_local, COUNT(clicks.id) FROM victims INNER JOIN geo ON victims.id = geo.id LEFT JOIN clicks ON clicks.id = victims.id GROUP BY victims.id ORDER BY victims.time DESC\",\n"}, {"line_no": 4, "char_start": 303, "char_end": 376, "line": "        \t'all_networks' : \"SELECT networks.* FROM networks ORDER BY id\",\n"}, {"line_no": 5, "char_start": 376, "char_end": 532, "line": "        \t'get_preview' : (\"SELECT victims.*, geo.*, victims.ip AS ip_local FROM victims INNER JOIN geo ON victims.id = geo.id WHERE victims.id = ?\" , vId),\n"}, {"line_no": 6, "char_start": 532, "char_end": 612, "line": "        \t'id_networks' : (\"SELECT networks.* FROM networks WHERE id = ?\", vId),\n"}, {"line_no": 7, "char_start": 612, "char_end": 767, "line": "        \t'get_requests' : \"SELECT requests.*, geo.ip FROM requests INNER JOIN geo on geo.id = requests.user_id ORDER BY requests.date DESC, requests.id \",\n"}, {"line_no": 8, "char_start": 767, "char_end": 835, "line": "        \t'get_sessions' : \"SELECT COUNT(*) AS Total FROM networks\",\n"}, {"line_no": 9, "char_start": 835, "char_end": 899, "line": "        \t'get_clicks' : \"SELECT COUNT(*) AS Total FROM clicks\",\n"}, {"line_no": 10, "char_start": 899, "char_end": 987, "line": "        \t'get_online' : (\"SELECT COUNT(*) AS Total FROM victims WHERE status = ?\", vId)\n"}]}, "char_changes": {"deleted": [{"char_start": 79, "char_end": 83, "chars": "    "}, {"char_start": 314, "char_end": 318, "chars": "    "}, {"char_start": 390, "char_end": 394, "chars": "    "}, {"char_start": 529, "char_end": 538, "chars": "'%s'\" % ("}, {"char_start": 552, "char_end": 553, "chars": " "}, {"char_start": 553, "char_end": 556, "chars": "   "}, {"char_start": 616, "char_end": 625, "chars": "'%s'\" % ("}, {"char_start": 639, "char_end": 640, "chars": " "}, {"char_start": 640, "char_end": 643, "chars": "   "}, {"char_start": 797, "char_end": 801, "chars": "    "}, {"char_start": 868, "char_end": 869, "chars": " "}, {"char_start": 869, "char_end": 872, "chars": "   "}, {"char_start": 935, "char_end": 939, "chars": "    "}, {"char_start": 1008, "char_end": 1025, "chars": "'%s'\" % ('online'"}], "added": [{"char_start": 79, "char_end": 80, "chars": "\t"}, {"char_start": 311, "char_end": 312, "chars": "\t"}, {"char_start": 384, "char_end": 385, "chars": "\t"}, {"char_start": 401, "char_end": 402, "chars": "("}, {"char_start": 521, "char_end": 526, "chars": "?\" , "}, {"char_start": 540, "char_end": 541, "chars": "\t"}, {"char_start": 557, "char_end": 558, "chars": "("}, {"char_start": 602, "char_end": 606, "chars": "?\", "}, {"char_start": 620, "char_end": 621, "chars": "\t"}, {"char_start": 775, "char_end": 776, "chars": "\t"}, {"char_start": 843, "char_end": 844, "chars": "\t"}, {"char_start": 907, "char_end": 908, "chars": "\t"}, {"char_start": 923, "char_end": 924, "chars": "("}, {"char_start": 978, "char_end": 985, "chars": "?\", vId"}]}, "commit_link": "github.com/boxug/trape/commit/628149159ba25adbfc29a3ae1d4b10c7eb936dd3", "file_name": "core/db.py", "vul_type": "cwe-089"}
{"func_name": "prop_sentences_victim", "func_src_before": "    def prop_sentences_victim(self, type, data = None):\n        if type == 'count_victim':\n            return \"SELECT COUNT(*) AS C FROM victims WHERE id = '%s'\" % (data)\n        elif type == 'count_times':\n            return \"SELECT COUNT(*) AS C FROM clicks WHERE id = '%s'\" % (data)\n        elif type == 'update_victim':\n            return \"UPDATE victims SET ip = '%s', date = '%s', bVersion = '%s', browser = '%s', device = '%s', ports = '%s', time = '%s', cpu = '%s', status = '%s' WHERE id = '%s'\" % (data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online', data[1])\n        elif type == 'update_victim_geo':\n            return \"UPDATE geo SET city = '%s', country_code = '%s', country_name = '%s', ip = '%s', latitude = '%s', longitude = '%s', metro_code = '%s', region_code = '%s', region_name = '%s', time_zone = '%s', zip_code = '%s', isp = '%s', ua='%s' WHERE id = '%s'\" % (data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua, data[1])\n        elif type == 'insert_victim':\n            return \"INSERT INTO victims(id, ip, date, bVersion, browser, device, ports, time, cpu, status) VALUES('%s','%s', '%s','%s', '%s','%s', '%s', '%s', '%s', '%s')\" % (data[1], data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online')\n        elif type == 'insert_victim_geo':\n            return \"INSERT INTO geo(id, city, country_code, country_name, ip, latitude, longitude, metro_code, region_code, region_name, time_zone, zip_code, isp, ua) VALUES('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')\"  % (data[1], data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua)\n        elif type == 'count_victim_network':\n            return \"SELECT COUNT(*) AS C FROM networks WHERE id = '%s' AND network = '%s'\" % (data[0], data[1])\n        elif type == 'delete_networks':\n            return \"DELETE FROM networks WHERE id = '%s'\" % (data[0])\n        elif type == 'update_network':\n            return \"UPDATE networks SET date = '%s' WHERE id = '%s' AND network = '%s'\" % (data[2], data[0], data[1])\n        elif type == 'insert_networks':\n            return \"INSERT INTO networks(id, public_ip, ip, network, date) VALUES('%s','%s', '%s', '%s','%s')\" % (data[0], data[1], data[2], data[3], data[4])\n        elif type == 'insert_requests':\n            return \"INSERT INTO requests(id, user_id, site, fid, name, value, date) VALUES('%s', '%s','%s', '%s', '%s','%s', '%s')\" % (data[0].sId, data[0].id, data[0].site, data[0].fid, data[0].name, data[0].value, data[1])\n        elif type == 'insert_click':\n            return \"INSERT INTO clicks(id, site, date) VALUES('%s', '%s','%s')\" % (data[0], data[1], data[2])\n        elif type == 'report_online':\n            return \"UPDATE victims SET status = '%s' WHERE id = '%s'\" % ('online', data[0])\n        elif type == 'clean_online':\n            return \"UPDATE victims SET status = '%s' \" % ('offline')\n        elif type == 'disconnect_victim':\n            return \"UPDATE victims SET status = '%s' WHERE id = '%s'\" % ('offline', data)\n        else:\n            return False", "func_src_after": "    def prop_sentences_victim(self, type, data = None):\n        if type == 'count_victim':\n        \tt = (data,)\n        \treturn (\"SELECT COUNT(*) AS C FROM victims WHERE id = ?\" , t)\n        elif type == 'count_times':\n        \tt = (data,)\n        \treturn (\"SELECT COUNT(*) AS C FROM clicks WHERE id = ?\" , t)\n        elif type == 'update_victim':\n        \tt = (data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online', data[1],)\n        \treturn (\"UPDATE victims SET ip = ?, date = ?, bVersion = ?, browser = ?, device = ?, ports = ?, time = ?, cpu = ?, status = ? WHERE id = ?\", t)\n        elif type == 'update_victim_geo':\n        \tt = (data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua, data[1],)\n        \treturn (\"UPDATE geo SET city = ?, country_code = ?, country_name = ?, ip = ?, latitude = ?, longitude = ?, metro_code = ?, region_code = ?, region_name = ?, time_zone = ?, zip_code = ?, isp = ?, ua=? WHERE id = ?\", t)\n        elif type == 'insert_victim':\n        \tt = (data[1], data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online',)\n        \treturn (\"INSERT INTO victims(id, ip, date, bVersion, browser, device, ports, time, cpu, status) VALUES(?,?, ?,?, ?,?, ?, ?, ?, ?)\", t)\n        elif type == 'insert_victim_geo':\n        \tt = (data[1], data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua,)\n        \treturn (\"INSERT INTO geo(id, city, country_code, country_name, ip, latitude, longitude, metro_code, region_code, region_name, time_zone, zip_code, isp, ua) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\" , t)\n        elif type == 'count_victim_network':\n        \treturn (\"SELECT COUNT(*) AS C FROM networks WHERE id = ? AND network = ?\", (data[0], data[1],))\n        elif type == 'delete_networks':\n        \treturn (\"DELETE FROM networks WHERE id = ?\", (data[0],))\n        elif type == 'update_network':\n        \treturn (\"UPDATE networks SET date = ? WHERE id = ? AND network = ?\" , (data[2], data[0], data[1],))\n        elif type == 'insert_networks':\n        \tt = (data[0], data[1], data[2], data[3], data[4],)\n        \treturn (\"INSERT INTO networks(id, public_ip, ip, network, date) VALUES(?,?, ?, ?,?)\" , t)\n        elif type == 'insert_requests':\n        \tt = (data[0].sId, data[0].id, data[0].site, data[0].fid, data[0].name, data[0].value, data[1],)\n        \treturn (\"INSERT INTO requests(id, user_id, site, fid, name, value, date) VALUES(?, ?,?, ?, ?,?, ?)\" , t)\n        elif type == 'insert_click':\n        \treturn (\"INSERT INTO clicks(id, site, date) VALUES(?, ?,?)\", (data[0], data[1], data[2],))\n        elif type == 'report_online':\n        \treturn (\"UPDATE victims SET status = ? WHERE id = ?\" , ('online', data[0],))\n        elif type == 'clean_online':\n        \treturn (\"UPDATE victims SET status = ? \", ('offline',))\n        elif type == 'disconnect_victim':\n        \treturn (\"UPDATE victims SET status = ? WHERE id = ?\" , ('offline', data,))\n        else:\n        \treturn False", "line_changes": {"deleted": [{"line_no": 3, "char_start": 91, "char_end": 171, "line": "            return \"SELECT COUNT(*) AS C FROM victims WHERE id = '%s'\" % (data)\n"}, {"line_no": 5, "char_start": 207, "char_end": 286, "line": "            return \"SELECT COUNT(*) AS C FROM clicks WHERE id = '%s'\" % (data)\n"}, {"line_no": 7, "char_start": 324, "char_end": 640, "line": "            return \"UPDATE victims SET ip = '%s', date = '%s', bVersion = '%s', browser = '%s', device = '%s', ports = '%s', time = '%s', cpu = '%s', status = '%s' WHERE id = '%s'\" % (data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online', data[1])\n"}, {"line_no": 9, "char_start": 682, "char_end": 1192, "line": "            return \"UPDATE geo SET city = '%s', country_code = '%s', country_name = '%s', ip = '%s', latitude = '%s', longitude = '%s', metro_code = '%s', region_code = '%s', region_name = '%s', time_zone = '%s', zip_code = '%s', isp = '%s', ua='%s' WHERE id = '%s'\" % (data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua, data[1])\n"}, {"line_no": 11, "char_start": 1230, "char_end": 1537, "line": "            return \"INSERT INTO victims(id, ip, date, bVersion, browser, device, ports, time, cpu, status) VALUES('%s','%s', '%s','%s', '%s','%s', '%s', '%s', '%s', '%s')\" % (data[1], data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online')\n"}, {"line_no": 13, "char_start": 1579, "char_end": 2082, "line": "            return \"INSERT INTO geo(id, city, country_code, country_name, ip, latitude, longitude, metro_code, region_code, region_name, time_zone, zip_code, isp, ua) VALUES('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')\"  % (data[1], data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua)\n"}, {"line_no": 15, "char_start": 2127, "char_end": 2239, "line": "            return \"SELECT COUNT(*) AS C FROM networks WHERE id = '%s' AND network = '%s'\" % (data[0], data[1])\n"}, {"line_no": 17, "char_start": 2279, "char_end": 2349, "line": "            return \"DELETE FROM networks WHERE id = '%s'\" % (data[0])\n"}, {"line_no": 19, "char_start": 2388, "char_end": 2506, "line": "            return \"UPDATE networks SET date = '%s' WHERE id = '%s' AND network = '%s'\" % (data[2], data[0], data[1])\n"}, {"line_no": 21, "char_start": 2546, "char_end": 2705, "line": "            return \"INSERT INTO networks(id, public_ip, ip, network, date) VALUES('%s','%s', '%s', '%s','%s')\" % (data[0], data[1], data[2], data[3], data[4])\n"}, {"line_no": 23, "char_start": 2745, "char_end": 2970, "line": "            return \"INSERT INTO requests(id, user_id, site, fid, name, value, date) VALUES('%s', '%s','%s', '%s', '%s','%s', '%s')\" % (data[0].sId, data[0].id, data[0].site, data[0].fid, data[0].name, data[0].value, data[1])\n"}, {"line_no": 25, "char_start": 3007, "char_end": 3117, "line": "            return \"INSERT INTO clicks(id, site, date) VALUES('%s', '%s','%s')\" % (data[0], data[1], data[2])\n"}, {"line_no": 27, "char_start": 3155, "char_end": 3247, "line": "            return \"UPDATE victims SET status = '%s' WHERE id = '%s'\" % ('online', data[0])\n"}, {"line_no": 29, "char_start": 3284, "char_end": 3353, "line": "            return \"UPDATE victims SET status = '%s' \" % ('offline')\n"}, {"line_no": 31, "char_start": 3395, "char_end": 3485, "line": "            return \"UPDATE victims SET status = '%s' WHERE id = '%s'\" % ('offline', data)\n"}, {"line_no": 33, "char_start": 3499, "char_end": 3523, "line": "            return False\n"}], "added": [{"line_no": 3, "char_start": 91, "char_end": 112, "line": "        \tt = (data,)\n"}, {"line_no": 4, "char_start": 112, "char_end": 183, "line": "        \treturn (\"SELECT COUNT(*) AS C FROM victims WHERE id = ?\" , t)\n"}, {"line_no": 6, "char_start": 219, "char_end": 240, "line": "        \tt = (data,)\n"}, {"line_no": 7, "char_start": 240, "char_end": 310, "line": "        \treturn (\"SELECT COUNT(*) AS C FROM clicks WHERE id = ?\" , t)\n"}, {"line_no": 9, "char_start": 348, "char_end": 495, "line": "        \tt = (data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online', data[1],)\n"}, {"line_no": 10, "char_start": 495, "char_end": 648, "line": "        \treturn (\"UPDATE victims SET ip = ?, date = ?, bVersion = ?, browser = ?, device = ?, ports = ?, time = ?, cpu = ?, status = ? WHERE id = ?\", t)\n"}, {"line_no": 12, "char_start": 690, "char_end": 945, "line": "        \tt = (data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua, data[1],)\n"}, {"line_no": 13, "char_start": 945, "char_end": 1172, "line": "        \treturn (\"UPDATE geo SET city = ?, country_code = ?, country_name = ?, ip = ?, latitude = ?, longitude = ?, metro_code = ?, region_code = ?, region_name = ?, time_zone = ?, zip_code = ?, isp = ?, ua=? WHERE id = ?\", t)\n"}, {"line_no": 15, "char_start": 1210, "char_end": 1357, "line": "        \tt = (data[1], data[0].ip, data[0].date, data[0].version, data[0].browser, data[0].device, data[0].ports, data[2], data[0].cpu, 'online',)\n"}, {"line_no": 16, "char_start": 1357, "char_end": 1501, "line": "        \treturn (\"INSERT INTO victims(id, ip, date, bVersion, browser, device, ports, time, cpu, status) VALUES(?,?, ?,?, ?,?, ?, ?, ?, ?)\", t)\n"}, {"line_no": 18, "char_start": 1543, "char_end": 1798, "line": "        \tt = (data[1], data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua,)\n"}, {"line_no": 19, "char_start": 1798, "char_end": 2018, "line": "        \treturn (\"INSERT INTO geo(id, city, country_code, country_name, ip, latitude, longitude, metro_code, region_code, region_name, time_zone, zip_code, isp, ua) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\" , t)\n"}, {"line_no": 21, "char_start": 2063, "char_end": 2168, "line": "        \treturn (\"SELECT COUNT(*) AS C FROM networks WHERE id = ? AND network = ?\", (data[0], data[1],))\n"}, {"line_no": 23, "char_start": 2208, "char_end": 2274, "line": "        \treturn (\"DELETE FROM networks WHERE id = ?\", (data[0],))\n"}, {"line_no": 25, "char_start": 2313, "char_end": 2422, "line": "        \treturn (\"UPDATE networks SET date = ? WHERE id = ? AND network = ?\" , (data[2], data[0], data[1],))\n"}, {"line_no": 27, "char_start": 2462, "char_end": 2522, "line": "        \tt = (data[0], data[1], data[2], data[3], data[4],)\n"}, {"line_no": 28, "char_start": 2522, "char_end": 2621, "line": "        \treturn (\"INSERT INTO networks(id, public_ip, ip, network, date) VALUES(?,?, ?, ?,?)\" , t)\n"}, {"line_no": 30, "char_start": 2661, "char_end": 2766, "line": "        \tt = (data[0].sId, data[0].id, data[0].site, data[0].fid, data[0].name, data[0].value, data[1],)\n"}, {"line_no": 31, "char_start": 2766, "char_end": 2880, "line": "        \treturn (\"INSERT INTO requests(id, user_id, site, fid, name, value, date) VALUES(?, ?,?, ?, ?,?, ?)\" , t)\n"}, {"line_no": 33, "char_start": 2917, "char_end": 3017, "line": "        \treturn (\"INSERT INTO clicks(id, site, date) VALUES(?, ?,?)\", (data[0], data[1], data[2],))\n"}, {"line_no": 35, "char_start": 3055, "char_end": 3141, "line": "        \treturn (\"UPDATE victims SET status = ? WHERE id = ?\" , ('online', data[0],))\n"}, {"line_no": 37, "char_start": 3178, "char_end": 3243, "line": "        \treturn (\"UPDATE victims SET status = ? \", ('offline',))\n"}, {"line_no": 39, "char_start": 3285, "char_end": 3369, "line": "        \treturn (\"UPDATE victims SET status = ? WHERE id = ?\" , ('offline', data,))\n"}, {"line_no": 41, "char_start": 3383, "char_end": 3404, "line": "        \treturn False\n"}]}, "char_changes": {"deleted": [{"char_start": 156, "char_end": 169, "chars": "'%s'\" % (data"}, {"char_start": 271, "char_end": 284, "chars": "'%s'\" % (data"}, {"char_start": 332, "char_end": 506, "chars": "    return \"UPDATE victims SET ip = '%s', date = '%s', bVersion = '%s', browser = '%s', device = '%s', ports = '%s', time = '%s', cpu = '%s', status = '%s' WHERE id = '%s'\" %"}, {"char_start": 648, "char_end": 694, "chars": "elif type == 'update_victim_geo':\n            "}, {"char_start": 709, "char_end": 950, "chars": "geo SET city = '%s', country_code = '%s', country_name = '%s', ip = '%s', latitude = '%s', longitude = '%s', metro_code = '%s', region_code = '%s', region_name = '%s', time_zone = '%s', zip_code = '%s', isp = '%s', ua='%s' WHERE id = '%s'\" %"}, {"char_start": 1200, "char_end": 1403, "chars": "elif type == 'insert_victim':\n            return \"INSERT INTO victims(id, ip, date, bVersion, browser, device, ports, time, cpu, status) VALUES('%s','%s', '%s','%s', '%s','%s', '%s', '%s', '%s', '%s')\" %"}, {"char_start": 1545, "char_end": 1591, "chars": "elif type == 'insert_victim_geo':\n            "}, {"char_start": 1611, "char_end": 3483, "chars": "geo(id, city, country_code, country_name, ip, latitude, longitude, metro_code, region_code, region_name, time_zone, zip_code, isp, ua) VALUES('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')\"  % (data[1], data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua)\n        elif type == 'count_victim_network':\n            return \"SELECT COUNT(*) AS C FROM networks WHERE id = '%s' AND network = '%s'\" % (data[0], data[1])\n        elif type == 'delete_networks':\n            return \"DELETE FROM networks WHERE id = '%s'\" % (data[0])\n        elif type == 'update_network':\n            return \"UPDATE networks SET date = '%s' WHERE id = '%s' AND network = '%s'\" % (data[2], data[0], data[1])\n        elif type == 'insert_networks':\n            return \"INSERT INTO networks(id, public_ip, ip, network, date) VALUES('%s','%s', '%s', '%s','%s')\" % (data[0], data[1], data[2], data[3], data[4])\n        elif type == 'insert_requests':\n            return \"INSERT INTO requests(id, user_id, site, fid, name, value, date) VALUES('%s', '%s','%s', '%s', '%s','%s', '%s')\" % (data[0].sId, data[0].id, data[0].site, data[0].fid, data[0].name, data[0].value, data[1])\n        elif type == 'insert_click':\n            return \"INSERT INTO clicks(id, site, date) VALUES('%s', '%s','%s')\" % (data[0], data[1], data[2])\n        elif type == 'report_online':\n            return \"UPDATE victims SET status = '%s' WHERE id = '%s'\" % ('online', data[0])\n        elif type == 'clean_online':\n            return \"UPDATE victims SET status = '%s' \" % ('offline')\n        elif type == 'disconnect_victim':\n            return \"UPDATE victims SET status = '%s' WHERE id = '%s'\" % ('offline', data"}, {"char_start": 3507, "char_end": 3511, "chars": "    "}], "added": [{"char_start": 97, "char_end": 112, "chars": "  \tt = (data,)\n"}, {"char_start": 118, "char_end": 121, "chars": "  \t"}, {"char_start": 128, "char_end": 129, "chars": "("}, {"char_start": 175, "char_end": 181, "chars": "?\" , t"}, {"char_start": 225, "char_end": 240, "chars": "  \tt = (data,)\n"}, {"char_start": 246, "char_end": 249, "chars": "  \t"}, {"char_start": 256, "char_end": 257, "chars": "("}, {"char_start": 302, "char_end": 308, "chars": "?\" , t"}, {"char_start": 356, "char_end": 360, "chars": "\tt ="}, {"char_start": 492, "char_end": 493, "chars": ","}, {"char_start": 503, "char_end": 504, "chars": "\t"}, {"char_start": 511, "char_end": 512, "chars": "("}, {"char_start": 520, "char_end": 664, "chars": "victims SET ip = ?, date = ?, bVersion = ?, browser = ?, device = ?, ports = ?, time = ?, cpu = ?, status = ? WHERE id = ?\", t)\n        elif typ"}, {"char_start": 667, "char_end": 668, "chars": "="}, {"char_start": 670, "char_end": 702, "chars": "update_victim_geo':\n        \tt ="}, {"char_start": 942, "char_end": 943, "chars": ","}, {"char_start": 953, "char_end": 1222, "chars": "\treturn (\"UPDATE geo SET city = ?, country_code = ?, country_name = ?, ip = ?, latitude = ?, longitude = ?, metro_code = ?, region_code = ?, region_name = ?, time_zone = ?, zip_code = ?, isp = ?, ua=? WHERE id = ?\", t)\n        elif type == 'insert_victim':\n        \tt ="}, {"char_start": 1354, "char_end": 1355, "chars": ","}, {"char_start": 1365, "char_end": 1366, "chars": "\t"}, {"char_start": 1373, "char_end": 1374, "chars": "("}, {"char_start": 1387, "char_end": 3367, "chars": "victims(id, ip, date, bVersion, browser, device, ports, time, cpu, status) VALUES(?,?, ?,?, ?,?, ?, ?, ?, ?)\", t)\n        elif type == 'insert_victim_geo':\n        \tt = (data[1], data[0].city, data[0].country_code, data[0].country_name, data[0].ip, data[0].latitude, data[0].longitude, data[0].metro_code, data[0].region_code, data[0].region_name, data[0].time_zone, data[0].zip_code, data[0].isp, data[0].ua,)\n        \treturn (\"INSERT INTO geo(id, city, country_code, country_name, ip, latitude, longitude, metro_code, region_code, region_name, time_zone, zip_code, isp, ua) VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\" , t)\n        elif type == 'count_victim_network':\n        \treturn (\"SELECT COUNT(*) AS C FROM networks WHERE id = ? AND network = ?\", (data[0], data[1],))\n        elif type == 'delete_networks':\n        \treturn (\"DELETE FROM networks WHERE id = ?\", (data[0],))\n        elif type == 'update_network':\n        \treturn (\"UPDATE networks SET date = ? WHERE id = ? AND network = ?\" , (data[2], data[0], data[1],))\n        elif type == 'insert_networks':\n        \tt = (data[0], data[1], data[2], data[3], data[4],)\n        \treturn (\"INSERT INTO networks(id, public_ip, ip, network, date) VALUES(?,?, ?, ?,?)\" , t)\n        elif type == 'insert_requests':\n        \tt = (data[0].sId, data[0].id, data[0].site, data[0].fid, data[0].name, data[0].value, data[1],)\n        \treturn (\"INSERT INTO requests(id, user_id, site, fid, name, value, date) VALUES(?, ?,?, ?, ?,?, ?)\" , t)\n        elif type == 'insert_click':\n        \treturn (\"INSERT INTO clicks(id, site, date) VALUES(?, ?,?)\", (data[0], data[1], data[2],))\n        elif type == 'report_online':\n        \treturn (\"UPDATE victims SET status = ? WHERE id = ?\" , ('online', data[0],))\n        elif type == 'clean_online':\n        \treturn (\"UPDATE victims SET status = ? \", ('offline',))\n        elif type == 'disconnect_victim':\n        \treturn (\"UPDATE victims SET status = ? WHERE id = ?\" , ('offline', data,)"}, {"char_start": 3391, "char_end": 3392, "chars": "\t"}]}, "commit_link": "github.com/boxug/trape/commit/628149159ba25adbfc29a3ae1d4b10c7eb936dd3", "file_name": "core/db.py", "vul_type": "cwe-089"}
{"func_name": "sentences_victim", "func_src_before": "    def sentences_victim(self, type, data = None, sRun = 1, column = 0):\n        if sRun == 2:\n            return self.sql_insert(self.prop_sentences_victim(type, data))\n        elif sRun == 3:\n            return self.sql_one_row(self.prop_sentences_victim(type, data), column)\n        else:\n            return self.sql_execute(self.prop_sentences_victim(type, data))", "func_src_after": "    def sentences_victim(self, type, data = None, sRun = 1, column = 0):\n        if sRun == 2:\n        \treturn self.sql_insert(self.prop_sentences_victim(type, data))\n        elif sRun == 3:\n        \treturn self.sql_one_row(self.prop_sentences_victim(type, data), column)\n        else:\n        \treturn self.sql_execute(self.prop_sentences_victim(type, data))", "line_changes": {"deleted": [{"line_no": 3, "char_start": 95, "char_end": 170, "line": "            return self.sql_insert(self.prop_sentences_victim(type, data))\n"}, {"line_no": 5, "char_start": 194, "char_end": 278, "line": "            return self.sql_one_row(self.prop_sentences_victim(type, data), column)\n"}, {"line_no": 7, "char_start": 292, "char_end": 367, "line": "            return self.sql_execute(self.prop_sentences_victim(type, data))\n"}], "added": [{"line_no": 3, "char_start": 95, "char_end": 167, "line": "        \treturn self.sql_insert(self.prop_sentences_victim(type, data))\n"}, {"line_no": 5, "char_start": 191, "char_end": 272, "line": "        \treturn self.sql_one_row(self.prop_sentences_victim(type, data), column)\n"}, {"line_no": 7, "char_start": 286, "char_end": 358, "line": "        \treturn self.sql_execute(self.prop_sentences_victim(type, data))\n"}]}, "char_changes": {"deleted": [{"char_start": 103, "char_end": 107, "chars": "    "}, {"char_start": 202, "char_end": 206, "chars": "    "}, {"char_start": 300, "char_end": 304, "chars": "    "}], "added": [{"char_start": 103, "char_end": 104, "chars": "\t"}, {"char_start": 199, "char_end": 200, "chars": "\t"}, {"char_start": 294, "char_end": 295, "chars": "\t"}]}, "commit_link": "github.com/boxug/trape/commit/628149159ba25adbfc29a3ae1d4b10c7eb936dd3", "file_name": "core/db.py", "vul_type": "cwe-089"}
{"func_name": "msPostGISLayerSetTimeFilter", "func_src_before": "int msPostGISLayerSetTimeFilter(layerObj *lp, const char *timestring, const char *timefield)\n{\n  char **atimes, **aranges = NULL;\n  int numtimes=0,i=0,numranges=0;\n  size_t buffer_size = 512;\n  char buffer[512], bufferTmp[512];\n\n  buffer[0] = '\\0';\n  bufferTmp[0] = '\\0';\n\n  if (!lp || !timestring || !timefield)\n    return MS_FALSE;\n\n  /* discrete time */\n  if (strstr(timestring, \",\") == NULL &&\n      strstr(timestring, \"/\") == NULL) { /* discrete time */\n    createPostgresTimeCompareSimple(timefield, timestring, buffer, buffer_size);\n  } else {\n\n    /* multiple times, or ranges */\n    atimes = msStringSplit (timestring, ',', &numtimes);\n    if (atimes == NULL || numtimes < 1)\n      return MS_FALSE;\n\n    strlcat(buffer, \"(\", buffer_size);\n    for(i=0; i<numtimes; i++) {\n      if(i!=0) {\n        strlcat(buffer, \" OR \", buffer_size);\n      }\n      strlcat(buffer, \"(\", buffer_size);\n      aranges = msStringSplit(atimes[i],  '/', &numranges);\n      if(!aranges) return MS_FALSE;\n      if(numranges == 1) {\n        /* we don't have range, just a simple time */\n        createPostgresTimeCompareSimple(timefield, atimes[i], bufferTmp, buffer_size);\n        strlcat(buffer, bufferTmp, buffer_size);\n      } else if(numranges == 2) {\n        /* we have a range */\n        createPostgresTimeCompareRange(timefield, aranges[0], aranges[1], bufferTmp, buffer_size);\n        strlcat(buffer, bufferTmp, buffer_size);\n      } else {\n        return MS_FALSE;\n      }\n      msFreeCharArray(aranges, numranges);\n      strlcat(buffer, \")\", buffer_size);\n    }\n    strlcat(buffer, \")\", buffer_size);\n    msFreeCharArray(atimes, numtimes);\n  }\n  if(!*buffer) {\n    return MS_FALSE;\n  }\n  if(lp->filteritem) free(lp->filteritem);\n  lp->filteritem = msStrdup(timefield);\n  if (&lp->filter) {\n    /* if the filter is set and it's a string type, concatenate it with\n       the time. If not just free it */\n    if (lp->filter.type == MS_EXPRESSION) {\n      snprintf(bufferTmp, buffer_size, \"(%s) and %s\", lp->filter.string, buffer);\n      loadExpressionString(&lp->filter, bufferTmp);\n    } else {\n      freeExpression(&lp->filter);\n      loadExpressionString(&lp->filter, buffer);\n    }\n  }\n\n\n  return MS_TRUE;\n}", "func_src_after": "int msPostGISLayerSetTimeFilter(layerObj *lp, const char *timestring, const char *timefield)\n{\n  char **atimes, **aranges = NULL;\n  int numtimes=0,i=0,numranges=0;\n  size_t buffer_size = 512;\n  char buffer[512], bufferTmp[512];\n\n  buffer[0] = '\\0';\n  bufferTmp[0] = '\\0';\n\n  if (!lp || !timestring || !timefield)\n    return MS_FALSE;\n\n  if( strchr(timestring,'\\'') || strchr(timestring, '\\\\') ) {\n     msSetError(MS_MISCERR, \"Invalid time filter.\", \"msPostGISLayerSetTimeFilter()\");\n     return MS_FALSE;\n  }\n\n  /* discrete time */\n  if (strstr(timestring, \",\") == NULL &&\n      strstr(timestring, \"/\") == NULL) { /* discrete time */\n    createPostgresTimeCompareSimple(timefield, timestring, buffer, buffer_size);\n  } else {\n\n    /* multiple times, or ranges */\n    atimes = msStringSplit (timestring, ',', &numtimes);\n    if (atimes == NULL || numtimes < 1)\n      return MS_FALSE;\n\n    strlcat(buffer, \"(\", buffer_size);\n    for(i=0; i<numtimes; i++) {\n      if(i!=0) {\n        strlcat(buffer, \" OR \", buffer_size);\n      }\n      strlcat(buffer, \"(\", buffer_size);\n      aranges = msStringSplit(atimes[i],  '/', &numranges);\n      if(!aranges) return MS_FALSE;\n      if(numranges == 1) {\n        /* we don't have range, just a simple time */\n        createPostgresTimeCompareSimple(timefield, atimes[i], bufferTmp, buffer_size);\n        strlcat(buffer, bufferTmp, buffer_size);\n      } else if(numranges == 2) {\n        /* we have a range */\n        createPostgresTimeCompareRange(timefield, aranges[0], aranges[1], bufferTmp, buffer_size);\n        strlcat(buffer, bufferTmp, buffer_size);\n      } else {\n        return MS_FALSE;\n      }\n      msFreeCharArray(aranges, numranges);\n      strlcat(buffer, \")\", buffer_size);\n    }\n    strlcat(buffer, \")\", buffer_size);\n    msFreeCharArray(atimes, numtimes);\n  }\n  if(!*buffer) {\n    return MS_FALSE;\n  }\n  if(lp->filteritem) free(lp->filteritem);\n  lp->filteritem = msStrdup(timefield);\n  if (&lp->filter) {\n    /* if the filter is set and it's a string type, concatenate it with\n       the time. If not just free it */\n    if (lp->filter.type == MS_EXPRESSION) {\n      snprintf(bufferTmp, buffer_size, \"(%s) and %s\", lp->filter.string, buffer);\n      loadExpressionString(&lp->filter, bufferTmp);\n    } else {\n      freeExpression(&lp->filter);\n      loadExpressionString(&lp->filter, buffer);\n    }\n  }\n\n\n  return MS_TRUE;\n}", "line_changes": {"deleted": [], "added": [{"line_no": 14, "char_start": 335, "char_end": 397, "line": "  if( strchr(timestring,'\\'') || strchr(timestring, '\\\\') ) {\n"}, {"line_no": 15, "char_start": 397, "char_end": 483, "line": "     msSetError(MS_MISCERR, \"Invalid time filter.\", \"msPostGISLayerSetTimeFilter()\");\n"}, {"line_no": 16, "char_start": 483, "char_end": 505, "line": "     return MS_FALSE;\n"}, {"line_no": 17, "char_start": 505, "char_end": 509, "line": "  }\n"}, {"line_no": 18, "char_start": 509, "char_end": 510, "line": "\n"}]}, "char_changes": {"deleted": [], "added": [{"char_start": 335, "char_end": 510, "chars": "  if( strchr(timestring,'\\'') || strchr(timestring, '\\\\') ) {\n     msSetError(MS_MISCERR, \"Invalid time filter.\", \"msPostGISLayerSetTimeFilter()\");\n     return MS_FALSE;\n  }\n\n"}]}, "commit_link": "github.com/mapserver/mapserver/commit/3a10f6b829297dae63492a8c63385044bc6953ed", "file_name": "mappostgis.c", "vul_type": "cwe-089"}
{"func_name": "http::server::CWebServer::GetFloorplanImage", "func_src_before": "\t\tvoid CWebServer::GetFloorplanImage(WebEmSession & session, const request& req, reply & rep)\n\t\t{\n\t\t\tstd::string idx = request::findValue(&req, \"idx\");\n\t\t\tif (idx == \"\") {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tstd::vector<std::vector<std::string> > result;\n\t\t\tresult = m_sql.safe_queryBlob(\"SELECT Image FROM Floorplans WHERE ID=%s\", idx.c_str());\n\t\t\tif (result.empty())\n\t\t\t\treturn;\n\t\t\treply::set_content(&rep, result[0][0].begin(), result[0][0].end());\n\t\t\tstd::string oname = \"floorplan\";\n\t\t\tif (result[0][0].size() > 10)\n\t\t\t{\n\t\t\t\tif (result[0][0][0] == 'P')\n\t\t\t\t\toname += \".png\";\n\t\t\t\telse if (result[0][0][0] == -1)\n\t\t\t\t\toname += \".jpg\";\n\t\t\t\telse if (result[0][0][0] == 'B')\n\t\t\t\t\toname += \".bmp\";\n\t\t\t\telse if (result[0][0][0] == 'G')\n\t\t\t\t\toname += \".gif\";\n\t\t\t}\n\t\t\treply::add_header_attachment(&rep, oname);\n\t\t}", "func_src_after": "\t\tvoid CWebServer::GetFloorplanImage(WebEmSession & session, const request& req, reply & rep)\n\t\t{\n\t\t\tstd::string idx = request::findValue(&req, \"idx\");\n\t\t\tif (idx == \"\") {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tstd::vector<std::vector<std::string> > result;\n\t\t\tresult = m_sql.safe_queryBlob(\"SELECT Image FROM Floorplans WHERE ID=%d\", atol(idx.c_str()));\n\t\t\tif (result.empty())\n\t\t\t\treturn;\n\t\t\treply::set_content(&rep, result[0][0].begin(), result[0][0].end());\n\t\t\tstd::string oname = \"floorplan\";\n\t\t\tif (result[0][0].size() > 10)\n\t\t\t{\n\t\t\t\tif (result[0][0][0] == 'P')\n\t\t\t\t\toname += \".png\";\n\t\t\t\telse if (result[0][0][0] == -1)\n\t\t\t\t\toname += \".jpg\";\n\t\t\t\telse if (result[0][0][0] == 'B')\n\t\t\t\t\toname += \".bmp\";\n\t\t\t\telse if (result[0][0][0] == 'G')\n\t\t\t\t\toname += \".gif\";\n\t\t\t}\n\t\t\treply::add_header_attachment(&rep, oname);\n\t\t}", "line_changes": {"deleted": [{"line_no": 8, "char_start": 239, "char_end": 330, "line": "\t\t\tresult = m_sql.safe_queryBlob(\"SELECT Image FROM Floorplans WHERE ID=%s\", idx.c_str());\n"}], "added": [{"line_no": 8, "char_start": 239, "char_end": 336, "line": "\t\t\tresult = m_sql.safe_queryBlob(\"SELECT Image FROM Floorplans WHERE ID=%d\", atol(idx.c_str()));\n"}]}, "char_changes": {"deleted": [{"char_start": 312, "char_end": 313, "chars": "s"}], "added": [{"char_start": 312, "char_end": 313, "chars": "d"}, {"char_start": 316, "char_end": 321, "chars": "atol("}, {"char_start": 333, "char_end": 334, "chars": ")"}]}, "commit_link": "github.com/domoticz/domoticz/commit/ee70db46f81afa582c96b887b73bcd2a86feda00", "file_name": "main/WebServer.cpp", "vul_type": "cwe-089"}
